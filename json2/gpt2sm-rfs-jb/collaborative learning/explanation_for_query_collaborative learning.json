{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "collaborative learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6426410462046305,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5788616883076254,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "8385",
            "description": "phrases that depict learning from others and building upon shared knowledge",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5497951835271835,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "8385",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:55:28.122Z",
                "maxActApprox": 14.867,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8385,
                    3301,
                    16642,
                    11621,
                    4513,
                    17830,
                    12237,
                    9003,
                    9986,
                    18039,
                    3143,
                    21375,
                    1196,
                    8374,
                    21762,
                    9203,
                    1886,
                    13617,
                    15074,
                    14505,
                    12556,
                    17036,
                    21530,
                    18191,
                    16918
                ],
                "topkCosSimValues": [
                    1,
                    0.3621,
                    0.3287,
                    0.3267,
                    0.3252,
                    0.3199,
                    0.3045,
                    0.2834,
                    0.2798,
                    0.2784,
                    0.2778,
                    0.2777,
                    0.2705,
                    0.2614,
                    0.2599,
                    0.2493,
                    0.2471,
                    0.2436,
                    0.2423,
                    0.2393,
                    0.2384,
                    0.238,
                    0.2356,
                    0.2335,
                    0.2322
                ],
                "neuron_alignment_indices": [
                    760,
                    283,
                    382
                ],
                "neuron_alignment_values": [
                    0.102,
                    0.101,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    283,
                    382,
                    703
                ],
                "correlated_neurons_pearson": [
                    0.042,
                    0.035,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.032,
                    0.029
                ],
                "correlated_features_indices": [
                    8374,
                    8328,
                    8393
                ],
                "correlated_features_pearson": [
                    0.045,
                    0.018,
                    0.008
                ],
                "correlated_features_l1": [
                    0.047,
                    0.02,
                    0.015
                ],
                "neg_str": [
                    "BuyableInstoreAndOnline",
                    "portation",
                    "stead",
                    "pool",
                    "requ",
                    "................................",
                    " subsidy",
                    " redemption",
                    " cancell",
                    "................................................................"
                ],
                "neg_values": [
                    -0.749,
                    -0.679,
                    -0.667,
                    -0.643,
                    -0.611,
                    -0.608,
                    -0.607,
                    -0.603,
                    -0.6,
                    -0.598
                ],
                "pos_str": [
                    "\u00bb\u0134",
                    " glance",
                    " analys",
                    " analyzing",
                    " hindsight",
                    " studying",
                    " FAC",
                    " hier",
                    " subconscious",
                    " decipher"
                ],
                "pos_values": [
                    0.959,
                    0.916,
                    0.873,
                    0.852,
                    0.842,
                    0.809,
                    0.788,
                    0.781,
                    0.78,
                    0.765
                ],
                "frac_nonzero": 0.00485,
                "freq_hist_data_bar_heights": [
                    2952,
                    2361,
                    1854,
                    1507,
                    1241,
                    923,
                    772,
                    626,
                    512,
                    432,
                    368,
                    300,
                    211,
                    183,
                    150,
                    141,
                    127,
                    89,
                    96,
                    58,
                    50,
                    48,
                    36,
                    34,
                    27,
                    21,
                    21,
                    19,
                    13,
                    12,
                    8,
                    9,
                    9,
                    9,
                    4,
                    5,
                    2,
                    4,
                    5,
                    1,
                    1,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.149,
                    0.446,
                    0.743,
                    1.041,
                    1.338,
                    1.635,
                    1.933,
                    2.23,
                    2.527,
                    2.825,
                    3.122,
                    3.419,
                    3.717,
                    4.014,
                    4.312,
                    4.609,
                    4.906,
                    5.204,
                    5.501,
                    5.798,
                    6.096,
                    6.393,
                    6.69,
                    6.988,
                    7.285,
                    7.582,
                    7.88,
                    8.177,
                    8.474,
                    8.772,
                    9.069,
                    9.366,
                    9.664,
                    9.961,
                    10.258,
                    10.556,
                    10.853,
                    11.15,
                    11.448,
                    11.745,
                    12.042,
                    12.34,
                    12.637,
                    12.934,
                    13.232,
                    13.529,
                    13.826,
                    14.124,
                    14.421,
                    14.719
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    1,
                    13,
                    18,
                    33,
                    61,
                    83,
                    160,
                    261,
                    390,
                    638,
                    925,
                    1300,
                    1804,
                    2351,
                    2876,
                    3399,
                    3835,
                    4018,
                    4157,
                    4047,
                    3734,
                    3304,
                    2741,
                    2363,
                    1871,
                    1545,
                    1086,
                    935,
                    650,
                    475,
                    337,
                    252,
                    195,
                    125,
                    96,
                    55,
                    39,
                    31,
                    16,
                    13,
                    6,
                    8,
                    2,
                    2,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.732,
                    -0.698,
                    -0.664,
                    -0.63,
                    -0.596,
                    -0.562,
                    -0.527,
                    -0.493,
                    -0.459,
                    -0.425,
                    -0.391,
                    -0.357,
                    -0.322,
                    -0.288,
                    -0.254,
                    -0.22,
                    -0.186,
                    -0.152,
                    -0.117,
                    -0.083,
                    -0.049,
                    -0.015,
                    0.019,
                    0.054,
                    0.088,
                    0.122,
                    0.156,
                    0.19,
                    0.224,
                    0.259,
                    0.293,
                    0.327,
                    0.361,
                    0.395,
                    0.429,
                    0.464,
                    0.498,
                    0.532,
                    0.566,
                    0.6,
                    0.634,
                    0.669,
                    0.703,
                    0.737,
                    0.771,
                    0.805,
                    0.839,
                    0.874,
                    0.908,
                    0.942
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases that depict learning from others and building upon shared knowledge",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdme3px7ys5i6667niic835",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3pz7ysri666uzzv756q",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 11.894,
                        "binMax": 14.867,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3px7ys6i666o2p6pnx3",
                        "tokens": [
                            " before",
                            " coming",
                            " to",
                            " understand",
                            " its",
                            " limitations",
                            ".",
                            "\n",
                            "\n",
                            "Dec",
                            "on",
                            "struct",
                            "ive",
                            " post",
                            "modern",
                            "ism",
                            ",",
                            " their",
                            " critique",
                            " of",
                            " stage",
                            " 4",
                            " modern",
                            "ism",
                            "/",
                            "system",
                            "atic",
                            "ity",
                            "/",
                            "rational",
                            "ity",
                            ",",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " the",
                            " contemporary",
                            " university",
                            " humanities",
                            " curriculum",
                            ".",
                            " This",
                            " is",
                            " a",
                            " disaster",
                            ".",
                            " The",
                            " critique",
                            " is",
                            " largely",
                            " correct",
                            ";",
                            " but",
                            ",",
                            " as",
                            " Ke",
                            "gan",
                            " observed",
                            ",",
                            " to",
                            " teach",
                            " it",
                            " to",
                            " young",
                            " adults",
                            " is",
                            " harmful",
                            ".",
                            " Few",
                            " university",
                            " students",
                            " have",
                            " consolidated",
                            " rationality",
                            ".",
                            " Essentially",
                            " none",
                            " are",
                            " ready",
                            " to",
                            " move",
                            " beyond",
                            " it",
                            ".",
                            " Point",
                            "ing",
                            " out",
                            " its",
                            " defects",
                            " makes",
                            " their",
                            " developmental",
                            " task",
                            " more",
                            " difficult",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " cannot",
                            " understand",
                            " what",
                            " is",
                            " wrong",
                            " with",
                            " rational",
                            "ism",
                            " until",
                            " you",
                            " are",
                            " capable",
                            " of",
                            " being",
                            " rational",
                            ".",
                            " You",
                            " cannot",
                            " go",
                            " beyond",
                            " rationality",
                            " until",
                            " after",
                            " you",
                            " can",
                            " use",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.32,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.32,
                            10.238,
                            6.529,
                            3.316,
                            2.932,
                            1.183,
                            0,
                            0,
                            1.373,
                            0,
                            0,
                            0,
                            0,
                            1.877,
                            1.947,
                            0.137,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "3461",
            "description": "discussions about teamwork and collaboration",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.529607204818297,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "3461",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:04:10.185Z",
                "maxActApprox": 39.041,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3461,
                    47086,
                    17628,
                    13294,
                    33642,
                    1517,
                    5536,
                    38582,
                    1373,
                    14042,
                    12967,
                    15231,
                    29129,
                    15469,
                    31602,
                    44109,
                    29873,
                    43779,
                    35965,
                    16315,
                    15667,
                    35370,
                    4114,
                    38066,
                    46663
                ],
                "topkCosSimValues": [
                    1,
                    0.6695,
                    0.6662,
                    0.6313,
                    0.6286,
                    0.6238,
                    0.6173,
                    0.6142,
                    0.6096,
                    0.6005,
                    0.5973,
                    0.5948,
                    0.5942,
                    0.5934,
                    0.5836,
                    0.5801,
                    0.5799,
                    0.5775,
                    0.5756,
                    0.5728,
                    0.5643,
                    0.5595,
                    0.5527,
                    0.5514,
                    0.5442
                ],
                "neuron_alignment_indices": [
                    640,
                    618,
                    372
                ],
                "neuron_alignment_values": [
                    0.245,
                    0.102,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.011,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    640,
                    64,
                    143
                ],
                "correlated_neurons_pearson": [
                    0.083,
                    0.051,
                    0.047
                ],
                "correlated_neurons_l1": [
                    0.077,
                    -0.017,
                    0.045
                ],
                "correlated_features_indices": [
                    3374,
                    3451,
                    3461
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "ibrary",
                    "wart",
                    " estranged",
                    "warts",
                    " unin",
                    " extrad",
                    "antine",
                    " Reincarnated",
                    " centrally",
                    " inconvenient"
                ],
                "neg_values": [
                    -0.766,
                    -0.715,
                    -0.713,
                    -0.704,
                    -0.672,
                    -0.672,
                    -0.67,
                    -0.667,
                    -0.632,
                    -0.629
                ],
                "pos_str": [
                    "Interview",
                    "Narr",
                    "Posted",
                    "Anyway",
                    "Yeah",
                    "Were",
                    "MJ",
                    "Jones",
                    "Talking",
                    "JC"
                ],
                "pos_values": [
                    1.035,
                    0.948,
                    0.895,
                    0.89,
                    0.887,
                    0.863,
                    0.845,
                    0.844,
                    0.84,
                    0.833
                ],
                "frac_nonzero": 0.00148,
                "freq_hist_data_bar_heights": [
                    1071,
                    727,
                    518,
                    418,
                    308,
                    246,
                    220,
                    164,
                    145,
                    114,
                    73,
                    62,
                    71,
                    46,
                    47,
                    44,
                    35,
                    39,
                    25,
                    25,
                    19,
                    25,
                    20,
                    13,
                    18,
                    15,
                    16,
                    17,
                    15,
                    8,
                    12,
                    17,
                    9,
                    5,
                    6,
                    6,
                    5,
                    4,
                    5,
                    7,
                    5,
                    2,
                    8,
                    2,
                    4,
                    1,
                    1,
                    2,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.391,
                    1.171,
                    1.952,
                    2.733,
                    3.514,
                    4.295,
                    5.076,
                    5.856,
                    6.637,
                    7.418,
                    8.199,
                    8.98,
                    9.76,
                    10.541,
                    11.322,
                    12.103,
                    12.884,
                    13.664,
                    14.445,
                    15.226,
                    16.007,
                    16.788,
                    17.568,
                    18.349,
                    19.13,
                    19.911,
                    20.692,
                    21.472,
                    22.253,
                    23.034,
                    23.815,
                    24.596,
                    25.377,
                    26.157,
                    26.938,
                    27.719,
                    28.5,
                    29.281,
                    30.061,
                    30.842,
                    31.623,
                    32.404,
                    33.185,
                    33.965,
                    34.746,
                    35.527,
                    36.308,
                    37.089,
                    37.869,
                    38.65
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    4,
                    6,
                    18,
                    20,
                    46,
                    92,
                    173,
                    283,
                    435,
                    777,
                    1078,
                    1367,
                    1918,
                    2396,
                    2957,
                    3203,
                    3537,
                    3699,
                    3694,
                    3624,
                    3290,
                    3008,
                    2604,
                    2279,
                    1973,
                    1620,
                    1401,
                    1072,
                    900,
                    700,
                    550,
                    463,
                    312,
                    240,
                    169,
                    105,
                    84,
                    52,
                    35,
                    34,
                    15,
                    6,
                    8,
                    3,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.748,
                    -0.712,
                    -0.676,
                    -0.64,
                    -0.604,
                    -0.568,
                    -0.532,
                    -0.496,
                    -0.46,
                    -0.424,
                    -0.388,
                    -0.352,
                    -0.316,
                    -0.28,
                    -0.244,
                    -0.208,
                    -0.172,
                    -0.136,
                    -0.1,
                    -0.064,
                    -0.028,
                    0.008,
                    0.045,
                    0.081,
                    0.117,
                    0.153,
                    0.189,
                    0.225,
                    0.261,
                    0.297,
                    0.333,
                    0.369,
                    0.405,
                    0.441,
                    0.477,
                    0.513,
                    0.549,
                    0.585,
                    0.621,
                    0.657,
                    0.693,
                    0.729,
                    0.765,
                    0.801,
                    0.837,
                    0.873,
                    0.909,
                    0.945,
                    0.981,
                    1.017
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions about teamwork and collaboration",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4bxeqetwmi666dqpi3rmk",
                        "tokens": [
                            "re",
                            " doing",
                            " a",
                            " basic",
                            " cable",
                            " show",
                            " in",
                            " seven",
                            " days",
                            ",",
                            " and",
                            " I",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Tim",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " probably",
                            " gonna",
                            " be",
                            " able",
                            " to",
                            " just",
                            " shoot",
                            " one",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "Laughs",
                            ")",
                            " We",
                            " heard",
                            " about",
                            " all",
                            " these",
                            " other",
                            " things",
                            " that",
                            " Marsh",
                            "als",
                            " will",
                            " do",
                            ".",
                            " If",
                            " they",
                            " know",
                            " that",
                            " a",
                            " restaurant",
                            " is",
                            " owned",
                            " by",
                            " bad",
                            " guys",
                            ",",
                            " well",
                            ",",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " just",
                            " start",
                            " eating",
                            " there",
                            " and",
                            " have",
                            " cops",
                            " eating",
                            " there",
                            " all",
                            " the",
                            " time",
                            " to",
                            " dry",
                            " up",
                            " the",
                            " bad",
                            "-",
                            "guy",
                            " business",
                            ".",
                            " Obviously",
                            " pulling",
                            " licenses",
                            " and",
                            " doing",
                            " anything",
                            " that",
                            " they",
                            " can",
                            " in",
                            " terms",
                            " of",
                            " the",
                            " legal",
                            " status",
                            " of",
                            " an",
                            " operation",
                            " and",
                            " taking",
                            " it",
                            " down",
                            ".",
                            " We",
                            " thought",
                            ",",
                            " let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " just",
                            " tow",
                            " the",
                            " RV",
                            ".",
                            "\n",
                            "\n",
                            "Are",
                            " we"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.041,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.769,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.041,
                            8.616,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4bxeqetwni666uidowndc",
                        "tokens": [
                            " of",
                            " mis",
                            "fit",
                            " toys",
                            ".",
                            " And",
                            " I",
                            " think",
                            " the",
                            " world",
                            " is",
                            " full",
                            " of",
                            " more",
                            " mis",
                            "fits",
                            " than",
                            " the",
                            " people",
                            " that",
                            " have",
                            " it",
                            " together",
                            ".",
                            " I",
                            " was",
                            " a",
                            " mis",
                            "fit",
                            ".",
                            " You",
                            " know",
                            " I",
                            " was",
                            " an",
                            " underdog",
                            " in",
                            " life",
                            ".",
                            " And",
                            " I",
                            " feel",
                            " like",
                            " when",
                            " you",
                            " find",
                            " your",
                            " tribe",
                            " you",
                            " hold",
                            " on",
                            " to",
                            " them",
                            ",",
                            " and",
                            " so",
                            " I",
                            " think",
                            " the",
                            " mis",
                            "fits",
                            " of",
                            " the",
                            " world",
                            " really",
                            " found",
                            " someone",
                            " in",
                            " that",
                            " study",
                            " group",
                            " that",
                            " reminded",
                            " them",
                            " of",
                            " themselves",
                            ",",
                            " and",
                            " they",
                            " held",
                            " on",
                            ".",
                            "\n",
                            "\n",
                            "Larry",
                            " King",
                            ":",
                            " Do",
                            " you",
                            " miss",
                            " the",
                            " show",
                            "?",
                            "\n",
                            "\n",
                            "Y",
                            "vette",
                            " Nicole",
                            " Brown",
                            ":",
                            " I",
                            " do",
                            ".",
                            " I",
                            " was",
                            " going",
                            " to",
                            " say",
                            " I",
                            " miss",
                            " my",
                            " friends",
                            " in",
                            " the",
                            " cast",
                            " and",
                            " crew",
                            " but",
                            " I",
                            " actually",
                            " see",
                            " a",
                            " lot",
                            " of",
                            " them",
                            " so",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.974,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.974,
                            12.063,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.333,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4bxeretwoi666xgnpceo5",
                        "tokens": [
                            " element",
                            ".",
                            " I",
                            " was",
                            " playing",
                            " the",
                            " four",
                            " and",
                            " the",
                            " five",
                            " because",
                            " I",
                            " was",
                            " the",
                            " tallest",
                            " guy",
                            " on",
                            " my",
                            " team",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " somewhere",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " used",
                            " to",
                            " playing",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " used",
                            " to",
                            " playing",
                            " on",
                            " the",
                            " wing",
                            " or",
                            " the",
                            " one",
                            ",",
                            " two",
                            " or",
                            " three",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " learning",
                            " the",
                            " game",
                            " from",
                            " a",
                            " different",
                            " aspect",
                            " and",
                            " it",
                            " was",
                            " a",
                            " learning",
                            " process",
                            ".",
                            " So",
                            " I",
                            " had",
                            " to",
                            " deal",
                            " with",
                            " that",
                            ".",
                            " I",
                            " caught",
                            " a",
                            " rhythm",
                            " towards",
                            " the",
                            " middle",
                            " of",
                            " the",
                            " season",
                            " and",
                            " I",
                            " thought",
                            " I",
                            " played",
                            " pretty",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Develop",
                            "mental",
                            " wise",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " long",
                            " list",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " long",
                            " list",
                            " of",
                            " things",
                            " from",
                            " top",
                            " to",
                            " bottom",
                            ".",
                            " I",
                            " could",
                            " start"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.537,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.537,
                            10.203,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "1881",
            "description": "collaborative efforts and teamwork",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5108091831207275,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "1881",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:30:45.907Z",
                "maxActApprox": 23.408,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1881,
                    6549,
                    26699,
                    46943,
                    97502,
                    27187,
                    59586,
                    34786,
                    51949,
                    37238,
                    86175,
                    79432,
                    29464,
                    79049,
                    15976,
                    59732,
                    77394,
                    72454,
                    29878,
                    52518,
                    16594,
                    42297,
                    51037,
                    20674,
                    27567
                ],
                "topkCosSimValues": [
                    1,
                    0.5331,
                    0.5065,
                    0.4959,
                    0.4838,
                    0.4802,
                    0.4543,
                    0.4208,
                    0.409,
                    0.4063,
                    0.4057,
                    0.4023,
                    0.393,
                    0.3885,
                    0.3827,
                    0.3778,
                    0.3759,
                    0.3739,
                    0.3725,
                    0.3707,
                    0.3625,
                    0.3602,
                    0.3545,
                    0.3538,
                    0.3506
                ],
                "neuron_alignment_indices": [
                    295,
                    656,
                    317
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.106,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    391,
                    295,
                    765
                ],
                "correlated_neurons_pearson": [
                    0.016,
                    0.015,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.014,
                    0.014
                ],
                "correlated_features_indices": [
                    1857,
                    1915,
                    1938
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    " purity",
                    "dos",
                    " unanswered",
                    "void",
                    "going",
                    " equival",
                    "arer",
                    " consequence",
                    " Errors",
                    " consequences"
                ],
                "neg_values": [
                    -0.7,
                    -0.695,
                    -0.683,
                    -0.648,
                    -0.626,
                    -0.611,
                    -0.609,
                    -0.607,
                    -0.605,
                    -0.604
                ],
                "pos_str": [
                    " teamed",
                    " together",
                    " jointly",
                    "ortium",
                    " hatched",
                    " forces",
                    "raft",
                    " collabor",
                    " collaborated",
                    " brainstorm"
                ],
                "pos_values": [
                    0.847,
                    0.803,
                    0.759,
                    0.726,
                    0.702,
                    0.698,
                    0.697,
                    0.677,
                    0.674,
                    0.667
                ],
                "frac_nonzero": 0.00022,
                "freq_hist_data_bar_heights": [
                    147,
                    123,
                    86,
                    49,
                    45,
                    47,
                    25,
                    24,
                    26,
                    17,
                    11,
                    11,
                    3,
                    7,
                    6,
                    3,
                    8,
                    4,
                    2,
                    1,
                    1,
                    1,
                    3,
                    2,
                    2,
                    2,
                    3,
                    1,
                    5,
                    3,
                    1,
                    2,
                    2,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.239,
                    0.707,
                    1.175,
                    1.643,
                    2.111,
                    2.579,
                    3.047,
                    3.515,
                    3.983,
                    4.452,
                    4.92,
                    5.388,
                    5.856,
                    6.324,
                    6.792,
                    7.26,
                    7.728,
                    8.196,
                    8.664,
                    9.132,
                    9.6,
                    10.068,
                    10.536,
                    11.004,
                    11.472,
                    11.94,
                    12.409,
                    12.877,
                    13.345,
                    13.813,
                    14.281,
                    14.749,
                    15.217,
                    15.685,
                    16.153,
                    16.621,
                    17.089,
                    17.557,
                    18.025,
                    18.493,
                    18.961,
                    19.429,
                    19.897,
                    20.366,
                    20.834,
                    21.302,
                    21.77,
                    22.238,
                    22.706,
                    23.174
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    3,
                    10,
                    18,
                    28,
                    59,
                    65,
                    123,
                    196,
                    339,
                    443,
                    612,
                    822,
                    1120,
                    1486,
                    1801,
                    2302,
                    2752,
                    3122,
                    3475,
                    3752,
                    3898,
                    3915,
                    3622,
                    3347,
                    2943,
                    2522,
                    1909,
                    1580,
                    1249,
                    796,
                    619,
                    463,
                    302,
                    198,
                    139,
                    71,
                    44,
                    38,
                    29,
                    17,
                    8,
                    5,
                    4,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.654,
                    -0.623,
                    -0.592,
                    -0.561,
                    -0.53,
                    -0.499,
                    -0.468,
                    -0.437,
                    -0.406,
                    -0.375,
                    -0.344,
                    -0.313,
                    -0.282,
                    -0.251,
                    -0.22,
                    -0.189,
                    -0.158,
                    -0.127,
                    -0.096,
                    -0.066,
                    -0.035,
                    -0.004,
                    0.027,
                    0.058,
                    0.089,
                    0.12,
                    0.151,
                    0.182,
                    0.213,
                    0.244,
                    0.275,
                    0.306,
                    0.337,
                    0.368,
                    0.399,
                    0.43,
                    0.461,
                    0.492,
                    0.522,
                    0.553,
                    0.584,
                    0.615,
                    0.646,
                    0.677,
                    0.708,
                    0.739,
                    0.77,
                    0.801,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " cooperative actions and collaborations between different groups or individuals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "collaborative efforts and teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygeyxy4cr5n10exmuupvcyd",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 18.726,
                        "binMax": 23.408,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygeyxy2cr5210exp5m80lzm",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 23.408,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygeyxy5cr5w10ex5al8jxsf",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 9.363,
                        "binMax": 14.045,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "38931",
            "description": " references to collaborative methods and approaches",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5054610967636108,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "38931",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:20:13.841Z",
                "maxActApprox": 12.776,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    38931,
                    82176,
                    81434,
                    5878,
                    66835,
                    54473,
                    24201,
                    26110,
                    21676,
                    44328,
                    36723,
                    54107,
                    86339,
                    61109,
                    67613,
                    53982,
                    45941,
                    81386,
                    64990,
                    21393,
                    51517,
                    51083,
                    94753,
                    62986,
                    94980
                ],
                "topkCosSimValues": [
                    1,
                    0.5697,
                    0.5071,
                    0.4743,
                    0.4564,
                    0.4543,
                    0.4111,
                    0.4058,
                    0.3861,
                    0.3776,
                    0.3733,
                    0.3606,
                    0.36,
                    0.3552,
                    0.3544,
                    0.3448,
                    0.3392,
                    0.3381,
                    0.3379,
                    0.336,
                    0.3339,
                    0.3338,
                    0.3282,
                    0.3281,
                    0.3246
                ],
                "neuron_alignment_indices": [
                    732,
                    408,
                    106
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    732,
                    393,
                    73
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.038,
                    0.028
                ],
                "correlated_features_indices": [
                    38942,
                    38927,
                    38888
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.004,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "bernatorial",
                    "ital",
                    "ipient",
                    "\"]=>",
                    "ropolis",
                    "lees",
                    "minent",
                    "ilyn",
                    "iors",
                    "livion"
                ],
                "neg_values": [
                    -0.825,
                    -0.791,
                    -0.773,
                    -0.766,
                    -0.759,
                    -0.737,
                    -0.737,
                    -0.728,
                    -0.724,
                    -0.722
                ],
                "pos_str": [
                    " techniques",
                    " incorporates",
                    " borrowed",
                    " avoids",
                    " pioneered",
                    " levers",
                    " implements",
                    " specially",
                    " patented",
                    " ingenuity"
                ],
                "pos_values": [
                    1.078,
                    0.849,
                    0.848,
                    0.839,
                    0.825,
                    0.81,
                    0.793,
                    0.791,
                    0.775,
                    0.77
                ],
                "frac_nonzero": 0.00154,
                "freq_hist_data_bar_heights": [
                    887,
                    728,
                    571,
                    466,
                    355,
                    287,
                    235,
                    221,
                    140,
                    134,
                    116,
                    103,
                    88,
                    67,
                    42,
                    47,
                    40,
                    35,
                    39,
                    30,
                    26,
                    17,
                    20,
                    19,
                    15,
                    6,
                    14,
                    15,
                    16,
                    10,
                    10,
                    4,
                    7,
                    1,
                    3,
                    4,
                    3,
                    5,
                    5,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.128,
                    0.383,
                    0.639,
                    0.894,
                    1.15,
                    1.405,
                    1.661,
                    1.916,
                    2.172,
                    2.428,
                    2.683,
                    2.939,
                    3.194,
                    3.45,
                    3.705,
                    3.961,
                    4.216,
                    4.472,
                    4.727,
                    4.983,
                    5.238,
                    5.494,
                    5.749,
                    6.005,
                    6.26,
                    6.516,
                    6.771,
                    7.027,
                    7.282,
                    7.538,
                    7.793,
                    8.049,
                    8.304,
                    8.56,
                    8.815,
                    9.071,
                    9.326,
                    9.582,
                    9.837,
                    10.093,
                    10.348,
                    10.604,
                    10.86,
                    11.115,
                    11.371,
                    11.626,
                    11.882,
                    12.137,
                    12.393,
                    12.648
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    5,
                    5,
                    10,
                    28,
                    34,
                    60,
                    87,
                    187,
                    282,
                    427,
                    667,
                    923,
                    1432,
                    1837,
                    2453,
                    3026,
                    3519,
                    3950,
                    4116,
                    4078,
                    3913,
                    3733,
                    3307,
                    2818,
                    2405,
                    1792,
                    1444,
                    1052,
                    821,
                    577,
                    429,
                    295,
                    204,
                    148,
                    66,
                    39,
                    28,
                    21,
                    18,
                    7,
                    4,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.806,
                    -0.767,
                    -0.729,
                    -0.691,
                    -0.653,
                    -0.615,
                    -0.577,
                    -0.539,
                    -0.501,
                    -0.463,
                    -0.425,
                    -0.387,
                    -0.349,
                    -0.311,
                    -0.273,
                    -0.235,
                    -0.197,
                    -0.159,
                    -0.121,
                    -0.083,
                    -0.045,
                    -0.007,
                    0.031,
                    0.069,
                    0.108,
                    0.146,
                    0.184,
                    0.222,
                    0.26,
                    0.298,
                    0.336,
                    0.374,
                    0.412,
                    0.45,
                    0.488,
                    0.526,
                    0.564,
                    0.602,
                    0.64,
                    0.678,
                    0.716,
                    0.754,
                    0.792,
                    0.83,
                    0.868,
                    0.906,
                    0.944,
                    0.982,
                    1.021,
                    1.059
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to collaborative methods and approaches",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of pairs and relationships between elements in a text",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggqofe4so710exosu2lvdf",
                        "tokens": [
                            ".",
                            " Instead",
                            ",",
                            " the",
                            " study",
                            " uses",
                            " the",
                            " methods",
                            " that",
                            " are",
                            " usually",
                            " employed",
                            " by",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " method",
                            " has",
                            " also",
                            " been",
                            " extended",
                            " beyond",
                            " standard",
                            " employment",
                            " outcomes",
                            " for",
                            " the",
                            " United",
                            " States",
                            ".",
                            " Couch",
                            " and",
                            " W",
                            "itten",
                            "burg",
                            " (",
                            "2001",
                            ")",
                            " use",
                            " a",
                            " fixed",
                            "-",
                            "effects",
                            " model",
                            " to",
                            " assess",
                            " the",
                            " impact",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            " on",
                            " hours",
                            " worked",
                            ",",
                            " while",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            " (",
                            "2004",
                            ")",
                            " use",
                            " these",
                            " techniques",
                            " to",
                            " understand",
                            " how",
                            " labor",
                            " market",
                            " institutions",
                            " are",
                            " relevant",
                            " for",
                            " international",
                            " differences",
                            " in",
                            " the",
                            " effect",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            ".",
                            " Both",
                            " studies",
                            " find",
                            " the",
                            " traditional",
                            " negative",
                            " impact",
                            ".",
                            " Me",
                            "er",
                            " and",
                            " West",
                            " (",
                            "2013",
                            ")",
                            " use",
                            " state",
                            " fixed",
                            "-",
                            "effects",
                            " models",
                            " and",
                            " numerical",
                            " examples",
                            " to",
                            " argue",
                            " that",
                            " matching",
                            " studies",
                            " that",
                            " include",
                            " location"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.776,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.747,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.084,
                            0,
                            0,
                            0.92,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.776,
                            0,
                            3.206,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.221,
                        "binMax": 12.776,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggqofc4snn10exl66y8r9h",
                        "tokens": [
                            ".",
                            " Instead",
                            ",",
                            " the",
                            " study",
                            " uses",
                            " the",
                            " methods",
                            " that",
                            " are",
                            " usually",
                            " employed",
                            " by",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " method",
                            " has",
                            " also",
                            " been",
                            " extended",
                            " beyond",
                            " standard",
                            " employment",
                            " outcomes",
                            " for",
                            " the",
                            " United",
                            " States",
                            ".",
                            " Couch",
                            " and",
                            " W",
                            "itten",
                            "burg",
                            " (",
                            "2001",
                            ")",
                            " use",
                            " a",
                            " fixed",
                            "-",
                            "effects",
                            " model",
                            " to",
                            " assess",
                            " the",
                            " impact",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            " on",
                            " hours",
                            " worked",
                            ",",
                            " while",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            " (",
                            "2004",
                            ")",
                            " use",
                            " these",
                            " techniques",
                            " to",
                            " understand",
                            " how",
                            " labor",
                            " market",
                            " institutions",
                            " are",
                            " relevant",
                            " for",
                            " international",
                            " differences",
                            " in",
                            " the",
                            " effect",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            ".",
                            " Both",
                            " studies",
                            " find",
                            " the",
                            " traditional",
                            " negative",
                            " impact",
                            ".",
                            " Me",
                            "er",
                            " and",
                            " West",
                            " (",
                            "2013",
                            ")",
                            " use",
                            " state",
                            " fixed",
                            "-",
                            "effects",
                            " models",
                            " and",
                            " numerical",
                            " examples",
                            " to",
                            " argue",
                            " that",
                            " matching",
                            " studies",
                            " that",
                            " include",
                            " location"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.776,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.747,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.084,
                            0,
                            0,
                            0.92,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.776,
                            0,
                            3.206,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.776,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggqofc4sno10exkjnk56rx",
                        "tokens": [
                            " by",
                            " donating",
                            " his",
                            " time",
                            " and",
                            " holiday",
                            " gifts",
                            " for",
                            " youth",
                            " in",
                            " need",
                            ".",
                            " For",
                            " more",
                            " information",
                            " on",
                            " the",
                            " LA",
                            " Galaxy",
                            " Toy",
                            " Drive",
                            ",",
                            " please",
                            " visit",
                            " www",
                            ".",
                            "lag",
                            "al",
                            "axy",
                            ".",
                            "com",
                            "/",
                            "community",
                            ".",
                            "<|endoftext|>",
                            "Press",
                            " Release",
                            "\n",
                            "\n",
                            "Blue",
                            " Light",
                            " Observ",
                            "ations",
                            " Ind",
                            "icate",
                            " Water",
                            "-",
                            "Rich",
                            " Atmosp",
                            "here",
                            " of",
                            " a",
                            " Super",
                            "-",
                            "Earth",
                            "\n",
                            "\n",
                            "September",
                            " 3",
                            ",",
                            " 2013",
                            "\n",
                            "\n",
                            "A",
                            " Japanese",
                            " research",
                            " team",
                            " of",
                            " astronomers",
                            " and",
                            " planetary",
                            " scientists",
                            " has",
                            " used",
                            " Subaru",
                            " Telescope",
                            "'s",
                            " two",
                            " optical",
                            " cameras",
                            ",",
                            " Sup",
                            "r",
                            "ime",
                            "-",
                            "Cam",
                            " and",
                            " the",
                            " F",
                            "aint",
                            " Object",
                            " Camera",
                            " and",
                            " Spect",
                            "rog",
                            "raph",
                            " (",
                            "F",
                            "OC",
                            "AS",
                            "),",
                            " with",
                            " a",
                            " blue",
                            " transmission",
                            " filter",
                            " to",
                            " observe",
                            " planetary",
                            " trans",
                            "its",
                            " of",
                            " super",
                            "-",
                            "Earth",
                            " G",
                            "J",
                            " 12",
                            "14",
                            " b",
                            " (",
                            "Gil",
                            "ese",
                            " 12",
                            "14",
                            " b",
                            ")"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.978,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.542,
                            2.867,
                            0,
                            0,
                            0,
                            0,
                            8.308,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.359,
                            7.766,
                            0.628,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.776,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "5902",
            "description": "references to collaborative projects and educational initiatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49537421749157384,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "5902",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:08:27.998Z",
                "maxActApprox": 10.83,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5902,
                    14080,
                    34669,
                    17734,
                    6915,
                    22948,
                    4605,
                    48747,
                    17249,
                    17660,
                    42876,
                    1682,
                    20454,
                    11952,
                    16080,
                    44792,
                    23791,
                    42073,
                    37253,
                    18052,
                    21215,
                    14605,
                    44365,
                    12560,
                    19672
                ],
                "topkCosSimValues": [
                    1,
                    0.524,
                    0.4349,
                    0.4323,
                    0.4295,
                    0.4262,
                    0.4206,
                    0.4151,
                    0.4143,
                    0.3911,
                    0.3876,
                    0.3861,
                    0.3834,
                    0.3829,
                    0.3811,
                    0.3773,
                    0.373,
                    0.3679,
                    0.3651,
                    0.3634,
                    0.3619,
                    0.3608,
                    0.3575,
                    0.3571,
                    0.3563
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    626
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.149,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    558,
                    498,
                    220
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.034,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.037,
                    0.03
                ],
                "correlated_features_indices": [
                    5779,
                    5792,
                    5782
                ],
                "correlated_features_pearson": [
                    0.032,
                    0.025,
                    0.022
                ],
                "correlated_features_l1": [
                    0.033,
                    0.026,
                    0.024
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "fax",
                    "soType",
                    "enough",
                    "needs",
                    " Salary",
                    "mother",
                    "66666666",
                    "Smith",
                    "errors"
                ],
                "neg_values": [
                    -0.877,
                    -0.68,
                    -0.631,
                    -0.608,
                    -0.603,
                    -0.602,
                    -0.581,
                    -0.579,
                    -0.578,
                    -0.572
                ],
                "pos_str": [
                    " acronym",
                    " themed",
                    " combining",
                    " loosely",
                    " curated",
                    " reim",
                    " revamped",
                    " pioneering",
                    " collaborative",
                    " innovative"
                ],
                "pos_values": [
                    0.853,
                    0.839,
                    0.831,
                    0.83,
                    0.805,
                    0.796,
                    0.789,
                    0.749,
                    0.745,
                    0.744
                ],
                "frac_nonzero": 0.00293,
                "freq_hist_data_bar_heights": [
                    1226,
                    1100,
                    934,
                    764,
                    623,
                    592,
                    487,
                    500,
                    411,
                    356,
                    263,
                    287,
                    200,
                    192,
                    181,
                    147,
                    117,
                    111,
                    101,
                    91,
                    85,
                    58,
                    52,
                    49,
                    51,
                    40,
                    36,
                    26,
                    24,
                    18,
                    15,
                    14,
                    17,
                    8,
                    8,
                    6,
                    5,
                    5,
                    4,
                    5,
                    3,
                    3,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.108,
                    0.325,
                    0.542,
                    0.758,
                    0.975,
                    1.191,
                    1.408,
                    1.624,
                    1.841,
                    2.058,
                    2.274,
                    2.491,
                    2.707,
                    2.924,
                    3.141,
                    3.357,
                    3.574,
                    3.79,
                    4.007,
                    4.224,
                    4.44,
                    4.657,
                    4.873,
                    5.09,
                    5.307,
                    5.523,
                    5.74,
                    5.956,
                    6.173,
                    6.39,
                    6.606,
                    6.823,
                    7.039,
                    7.256,
                    7.473,
                    7.689,
                    7.906,
                    8.122,
                    8.339,
                    8.556,
                    8.772,
                    8.989,
                    9.205,
                    9.422,
                    9.639,
                    9.855,
                    10.072,
                    10.288,
                    10.505,
                    10.722
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    6,
                    11,
                    32,
                    42,
                    93,
                    133,
                    264,
                    437,
                    682,
                    1088,
                    1486,
                    2036,
                    2647,
                    3354,
                    3836,
                    4158,
                    4307,
                    4236,
                    3995,
                    3565,
                    3145,
                    2646,
                    2066,
                    1515,
                    1270,
                    953,
                    657,
                    465,
                    363,
                    250,
                    182,
                    119,
                    72,
                    60,
                    32,
                    15,
                    14,
                    5,
                    7,
                    0,
                    3,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.86,
                    -0.825,
                    -0.791,
                    -0.756,
                    -0.722,
                    -0.687,
                    -0.652,
                    -0.618,
                    -0.583,
                    -0.549,
                    -0.514,
                    -0.479,
                    -0.445,
                    -0.41,
                    -0.375,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.064,
                    -0.029,
                    0.005,
                    0.04,
                    0.074,
                    0.109,
                    0.144,
                    0.178,
                    0.213,
                    0.248,
                    0.282,
                    0.317,
                    0.351,
                    0.386,
                    0.421,
                    0.455,
                    0.49,
                    0.524,
                    0.559,
                    0.594,
                    0.628,
                    0.663,
                    0.698,
                    0.732,
                    0.767,
                    0.801,
                    0.836
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to collaborative projects and educational initiatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4heuqh37bi666m6l6lyza",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuuh388i666aew2pu4t",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 4.332,
                        "binMax": 6.498,
                        "binContains": 0.00014,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuqh37ci666gdc1fdp1",
                        "tokens": [
                            " space",
                            " and",
                            " a",
                            " three",
                            "-",
                            "day",
                            " sym",
                            "posium",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013a",
                            "I",
                            " have",
                            " written",
                            " a",
                            " wicked",
                            " book",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " said",
                            " Mel",
                            "ville",
                            " when",
                            " his",
                            " novel",
                            " was",
                            " first",
                            " published",
                            " in",
                            " 18",
                            "51",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "and",
                            " I",
                            " feel",
                            " as",
                            " spot",
                            "less",
                            " as",
                            " the",
                            " lamb",
                            "\u00e2\u0122",
                            "\u013b",
                            ".",
                            " Deep",
                            "ly",
                            " subversive",
                            ",",
                            " in",
                            " almost",
                            " every",
                            " way",
                            " imaginable",
                            ",",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " is",
                            " a",
                            " virtual",
                            ",",
                            " alternative",
                            " bible",
                            " \u2013",
                            " and",
                            " as",
                            " such",
                            ",",
                            " ripe",
                            " for",
                            " re",
                            "interpret",
                            "ation",
                            " in",
                            " this",
                            " new",
                            " world",
                            " of",
                            " new",
                            " media",
                            ".",
                            " Out",
                            " of",
                            " Dominion",
                            " was",
                            " born",
                            " its",
                            " bastard",
                            " child",
                            " \u2013",
                            " or",
                            " perhaps",
                            " its",
                            " imm",
                            "ac",
                            "ulate",
                            " conception",
                            " \u2013",
                            " the",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " Big",
                            " Read",
                            ":",
                            " an",
                            " online",
                            " version",
                            " of",
                            " Mel",
                            "ville",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mag",
                            "ister",
                            "ial",
                            " to",
                            "me",
                            ":"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.607,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.969,
                            10.607,
                            8.971,
                            3.062,
                            2.038,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            1.269,
                            0,
                            0,
                            2.09
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44116",
            "description": " patterns related to collaboration and association among subjects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4918786883354187,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44116",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:29:10.363Z",
                "maxActApprox": 8.276,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44116,
                    34307,
                    70229,
                    24639,
                    89542,
                    80919,
                    80132,
                    7690,
                    58210,
                    17520,
                    82997,
                    70075,
                    9052,
                    44976,
                    6049,
                    39579,
                    82740,
                    44715,
                    35764,
                    65953,
                    7375,
                    26342,
                    46719,
                    29930,
                    75388
                ],
                "topkCosSimValues": [
                    1,
                    0.4373,
                    0.4322,
                    0.4268,
                    0.423,
                    0.4144,
                    0.4139,
                    0.4119,
                    0.4083,
                    0.3953,
                    0.3926,
                    0.3898,
                    0.3852,
                    0.383,
                    0.3811,
                    0.3804,
                    0.3727,
                    0.3717,
                    0.3713,
                    0.3681,
                    0.3649,
                    0.364,
                    0.3625,
                    0.3609,
                    0.3604
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    552
                ],
                "neuron_alignment_values": [
                    0.244,
                    0.138,
                    0.087
                ],
                "neuron_alignment_l1": [
                    0.012,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    756,
                    87,
                    437
                ],
                "correlated_neurons_pearson": [
                    0.036,
                    0.032,
                    0.03
                ],
                "correlated_neurons_l1": [
                    -0.004,
                    -0.013,
                    0.025
                ],
                "correlated_features_indices": [
                    44190,
                    44198,
                    44095
                ],
                "correlated_features_pearson": [
                    0.048,
                    0.011,
                    0.009
                ],
                "correlated_features_l1": [
                    0.05,
                    0.011,
                    0.01
                ],
                "neg_str": [
                    " extremes",
                    "icult",
                    "nosis",
                    "natureconservancy",
                    "pu",
                    "die",
                    " glare",
                    "nces",
                    " surfaces",
                    " disabilities"
                ],
                "neg_values": [
                    -0.661,
                    -0.659,
                    -0.635,
                    -0.594,
                    -0.593,
                    -0.587,
                    -0.577,
                    -0.568,
                    -0.564,
                    -0.555
                ],
                "pos_str": [
                    " intending",
                    " promptly",
                    "then",
                    " expecting",
                    " guaranteeing",
                    "didn",
                    "announced",
                    " followed",
                    " congratulations",
                    " proceeded"
                ],
                "pos_values": [
                    0.773,
                    0.771,
                    0.769,
                    0.744,
                    0.742,
                    0.736,
                    0.725,
                    0.696,
                    0.686,
                    0.678
                ],
                "frac_nonzero": 0.0025,
                "freq_hist_data_bar_heights": [
                    1115,
                    913,
                    841,
                    740,
                    630,
                    546,
                    447,
                    381,
                    306,
                    311,
                    242,
                    207,
                    171,
                    150,
                    141,
                    109,
                    96,
                    88,
                    62,
                    54,
                    42,
                    53,
                    32,
                    24,
                    24,
                    19,
                    17,
                    13,
                    17,
                    9,
                    6,
                    11,
                    9,
                    8,
                    2,
                    4,
                    3,
                    2,
                    5,
                    3,
                    0,
                    1,
                    2,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.083,
                    0.248,
                    0.414,
                    0.579,
                    0.745,
                    0.91,
                    1.076,
                    1.241,
                    1.407,
                    1.572,
                    1.738,
                    1.903,
                    2.069,
                    2.234,
                    2.4,
                    2.565,
                    2.731,
                    2.896,
                    3.062,
                    3.227,
                    3.393,
                    3.558,
                    3.724,
                    3.889,
                    4.055,
                    4.221,
                    4.386,
                    4.552,
                    4.717,
                    4.883,
                    5.048,
                    5.214,
                    5.379,
                    5.545,
                    5.71,
                    5.876,
                    6.041,
                    6.207,
                    6.372,
                    6.538,
                    6.703,
                    6.869,
                    7.034,
                    7.2,
                    7.365,
                    7.531,
                    7.696,
                    7.862,
                    8.027,
                    8.193
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    4,
                    8,
                    15,
                    15,
                    38,
                    75,
                    122,
                    188,
                    285,
                    431,
                    632,
                    822,
                    1081,
                    1394,
                    1784,
                    2163,
                    2599,
                    2917,
                    3258,
                    3528,
                    3777,
                    3684,
                    3606,
                    3340,
                    2886,
                    2636,
                    2157,
                    1685,
                    1384,
                    988,
                    763,
                    562,
                    384,
                    326,
                    223,
                    154,
                    93,
                    83,
                    42,
                    48,
                    23,
                    11,
                    13,
                    12,
                    7,
                    1,
                    4,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.646,
                    -0.618,
                    -0.589,
                    -0.56,
                    -0.532,
                    -0.503,
                    -0.474,
                    -0.446,
                    -0.417,
                    -0.388,
                    -0.359,
                    -0.331,
                    -0.302,
                    -0.273,
                    -0.245,
                    -0.216,
                    -0.187,
                    -0.159,
                    -0.13,
                    -0.101,
                    -0.073,
                    -0.044,
                    -0.015,
                    0.013,
                    0.042,
                    0.071,
                    0.099,
                    0.128,
                    0.157,
                    0.185,
                    0.214,
                    0.243,
                    0.271,
                    0.3,
                    0.329,
                    0.358,
                    0.386,
                    0.415,
                    0.444,
                    0.472,
                    0.501,
                    0.53,
                    0.558,
                    0.587,
                    0.616,
                    0.644,
                    0.673,
                    0.702,
                    0.73,
                    0.759
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " instances of conjunctions and phrases that indicate connectivity or comparisons between ideas",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " patterns related to collaboration and association among subjects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh25958prd10exf0tltws2",
                        "tokens": [
                            " benefits",
                            " from",
                            " this",
                            " from",
                            " time",
                            " to",
                            " time",
                            ".",
                            " For",
                            " example",
                            ":",
                            " Cool",
                            "io",
                            "'s",
                            " anger",
                            " over",
                            " \"",
                            "Am",
                            "ish",
                            " Paradise",
                            "\"",
                            " helped",
                            " make",
                            " the",
                            " song",
                            " a",
                            " bigger",
                            " hit",
                            ".",
                            " Before",
                            " Straight",
                            " Out",
                            "ta",
                            " Lyn",
                            "wood",
                            " was",
                            " released",
                            ",",
                            " \"",
                            "You",
                            "'re",
                            " Pit",
                            "iful",
                            "\",",
                            " a",
                            " parody",
                            " of",
                            " James",
                            " Bl",
                            "unt",
                            "'s",
                            " \"",
                            "You",
                            "'re",
                            " Beautiful",
                            "\",",
                            " was",
                            " set",
                            " to",
                            " be",
                            " the",
                            " lead",
                            " single",
                            ".",
                            " James",
                            " Bl",
                            "unt",
                            " approved",
                            " of",
                            " it",
                            ",",
                            " but",
                            " at",
                            " the",
                            " last",
                            " minute",
                            ",",
                            " his",
                            " record",
                            " label",
                            ",",
                            " Atlantic",
                            ",",
                            " changed",
                            " their",
                            " mind",
                            ",",
                            " and",
                            " \"",
                            "White",
                            " and",
                            " Ner",
                            "dy",
                            "\"",
                            " became",
                            " the",
                            " lead",
                            " instead",
                            ".",
                            " As",
                            " a",
                            " result",
                            ",",
                            " Al",
                            " released",
                            " the",
                            " song",
                            " for",
                            " free",
                            " and",
                            " performs",
                            " it",
                            " on",
                            " tour",
                            ",",
                            " mocking",
                            " Atlantic",
                            " in",
                            " the",
                            " process",
                            ".",
                            " Due",
                            " to",
                            " the",
                            " backlash",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44116",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.276,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.381,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.276,
                            0.28,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:29:17.824Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.275,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh25978pry10exia0ukxbr",
                        "tokens": [
                            " benefits",
                            " from",
                            " this",
                            " from",
                            " time",
                            " to",
                            " time",
                            ".",
                            " For",
                            " example",
                            ":",
                            " Cool",
                            "io",
                            "'s",
                            " anger",
                            " over",
                            " \"",
                            "Am",
                            "ish",
                            " Paradise",
                            "\"",
                            " helped",
                            " make",
                            " the",
                            " song",
                            " a",
                            " bigger",
                            " hit",
                            ".",
                            " Before",
                            " Straight",
                            " Out",
                            "ta",
                            " Lyn",
                            "wood",
                            " was",
                            " released",
                            ",",
                            " \"",
                            "You",
                            "'re",
                            " Pit",
                            "iful",
                            "\",",
                            " a",
                            " parody",
                            " of",
                            " James",
                            " Bl",
                            "unt",
                            "'s",
                            " \"",
                            "You",
                            "'re",
                            " Beautiful",
                            "\",",
                            " was",
                            " set",
                            " to",
                            " be",
                            " the",
                            " lead",
                            " single",
                            ".",
                            " James",
                            " Bl",
                            "unt",
                            " approved",
                            " of",
                            " it",
                            ",",
                            " but",
                            " at",
                            " the",
                            " last",
                            " minute",
                            ",",
                            " his",
                            " record",
                            " label",
                            ",",
                            " Atlantic",
                            ",",
                            " changed",
                            " their",
                            " mind",
                            ",",
                            " and",
                            " \"",
                            "White",
                            " and",
                            " Ner",
                            "dy",
                            "\"",
                            " became",
                            " the",
                            " lead",
                            " instead",
                            ".",
                            " As",
                            " a",
                            " result",
                            ",",
                            " Al",
                            " released",
                            " the",
                            " song",
                            " for",
                            " free",
                            " and",
                            " performs",
                            " it",
                            " on",
                            " tour",
                            ",",
                            " mocking",
                            " Atlantic",
                            " in",
                            " the",
                            " process",
                            ".",
                            " Due",
                            " to",
                            " the",
                            " backlash",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44116",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.276,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.381,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.276,
                            0.28,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:29:17.824Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.62,
                        "binMax": 8.275,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh25958pre10exc7v40qil",
                        "tokens": [
                            "How",
                            " I",
                            " did",
                            ":",
                            " I",
                            " loved",
                            " the",
                            " B",
                            "ort",
                            "les",
                            " pick",
                            ",",
                            " and",
                            " right",
                            " now",
                            " that",
                            " doesn",
                            "'t",
                            " look",
                            " good",
                            ".",
                            " Smith",
                            " was",
                            " my",
                            " third",
                            "-",
                            "day",
                            " gem",
                            ",",
                            " and",
                            " that",
                            " has",
                            " been",
                            " a",
                            " big",
                            "-",
                            "time",
                            " hit",
                            ".",
                            " I",
                            " liked",
                            " what",
                            " they",
                            " did",
                            " the",
                            " rest",
                            " of",
                            " the",
                            " way",
                            ",",
                            " and",
                            " especially",
                            " liked",
                            " the",
                            " pick",
                            " of",
                            " L",
                            "inder",
                            ".",
                            " If",
                            " B",
                            "ort",
                            "les",
                            " were",
                            " a",
                            " hit",
                            ",",
                            " this",
                            " would",
                            " be",
                            " an",
                            " unreal",
                            " draft",
                            ".",
                            " Since",
                            " he",
                            " isn",
                            "'t",
                            ",",
                            " the",
                            " grade",
                            " drops",
                            " down",
                            ".",
                            "\n",
                            "\n",
                            "New",
                            " grade",
                            ":",
                            " B",
                            "\n",
                            "\n",
                            "Kansas",
                            " City",
                            " Chiefs",
                            "\n",
                            "\n",
                            "2014",
                            " grade",
                            ":",
                            " C",
                            "+",
                            "\n",
                            "\n",
                            "The",
                            " skinny",
                            ":",
                            " They",
                            " took",
                            " edge",
                            " rusher",
                            " Dee",
                            " Ford",
                            " in",
                            " the",
                            " first",
                            " round",
                            ",",
                            " and",
                            " after",
                            " a",
                            " slow",
                            " start",
                            " he",
                            " has",
                            " developed",
                            " into"
                        ],
                        "dataIndex": null,
                        "index": "44116",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.821,
                        "maxValueTokenIndex": 117,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.456,
                            7.821,
                            7.308,
                            0.836,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:29:17.824Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.275,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "60260",
            "description": " instances of collaboration and teamwork",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49143165349960327,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "60260",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:48:06.397Z",
                "maxActApprox": 44.354,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    60260,
                    61354,
                    52147,
                    84813,
                    57080,
                    18019,
                    57561,
                    97502,
                    15621,
                    88863,
                    3489,
                    25397,
                    42339,
                    2501,
                    80658,
                    27599,
                    5082,
                    37304,
                    64581,
                    69444,
                    89129,
                    17372,
                    23834,
                    9587,
                    42948
                ],
                "topkCosSimValues": [
                    1,
                    0.5417,
                    0.5243,
                    0.5195,
                    0.4837,
                    0.4813,
                    0.4716,
                    0.4574,
                    0.4571,
                    0.4504,
                    0.4342,
                    0.4224,
                    0.4216,
                    0.4182,
                    0.4171,
                    0.4091,
                    0.4,
                    0.3984,
                    0.3972,
                    0.3898,
                    0.3864,
                    0.3805,
                    0.3786,
                    0.3766,
                    0.3715
                ],
                "neuron_alignment_indices": [
                    157,
                    247,
                    111
                ],
                "neuron_alignment_values": [
                    0.103,
                    0.102,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    262,
                    251,
                    318
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.011,
                    0.012
                ],
                "correlated_features_indices": [
                    60199,
                    60174,
                    60205
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " Falling",
                    " toppled",
                    " downed",
                    " Corpor",
                    " tumble",
                    " litter",
                    " Personality",
                    " Citation",
                    " Cyp",
                    "byter"
                ],
                "neg_values": [
                    -0.739,
                    -0.678,
                    -0.635,
                    -0.608,
                    -0.584,
                    -0.576,
                    -0.576,
                    -0.57,
                    -0.563,
                    -0.554
                ],
                "pos_str": [
                    " collabor",
                    " diligently",
                    " tirelessly",
                    "nergy",
                    " toward",
                    " together",
                    " alongside",
                    " internally",
                    " towards",
                    " overtime"
                ],
                "pos_values": [
                    0.92,
                    0.868,
                    0.816,
                    0.781,
                    0.772,
                    0.765,
                    0.749,
                    0.744,
                    0.742,
                    0.741
                ],
                "frac_nonzero": 0.00014,
                "freq_hist_data_bar_heights": [
                    128,
                    75,
                    65,
                    33,
                    22,
                    26,
                    12,
                    8,
                    9,
                    8,
                    7,
                    4,
                    5,
                    4,
                    4,
                    3,
                    1,
                    8,
                    2,
                    0,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.453,
                    1.34,
                    2.227,
                    3.113,
                    4,
                    4.887,
                    5.774,
                    6.661,
                    7.548,
                    8.435,
                    9.322,
                    10.208,
                    11.095,
                    11.982,
                    12.869,
                    13.756,
                    14.643,
                    15.53,
                    16.417,
                    17.304,
                    18.19,
                    19.077,
                    19.964,
                    20.851,
                    21.738,
                    22.625,
                    23.512,
                    24.399,
                    25.285,
                    26.172,
                    27.059,
                    27.946,
                    28.833,
                    29.72,
                    30.607,
                    31.494,
                    32.381,
                    33.267,
                    34.154,
                    35.041,
                    35.928,
                    36.815,
                    37.702,
                    38.589,
                    39.476,
                    40.362,
                    41.249,
                    42.136,
                    43.023,
                    43.91
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    2,
                    3,
                    6,
                    16,
                    41,
                    54,
                    103,
                    172,
                    302,
                    491,
                    694,
                    1042,
                    1464,
                    1969,
                    2699,
                    3240,
                    3780,
                    4253,
                    4255,
                    4297,
                    4088,
                    3695,
                    3106,
                    2690,
                    2107,
                    1599,
                    1223,
                    907,
                    632,
                    442,
                    328,
                    192,
                    137,
                    69,
                    43,
                    41,
                    22,
                    16,
                    12,
                    5,
                    7,
                    5,
                    3,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.722,
                    -0.689,
                    -0.656,
                    -0.622,
                    -0.589,
                    -0.556,
                    -0.523,
                    -0.49,
                    -0.457,
                    -0.423,
                    -0.39,
                    -0.357,
                    -0.324,
                    -0.291,
                    -0.258,
                    -0.224,
                    -0.191,
                    -0.158,
                    -0.125,
                    -0.092,
                    -0.059,
                    -0.025,
                    0.008,
                    0.041,
                    0.074,
                    0.107,
                    0.14,
                    0.174,
                    0.207,
                    0.24,
                    0.273,
                    0.306,
                    0.339,
                    0.373,
                    0.406,
                    0.439,
                    0.472,
                    0.505,
                    0.538,
                    0.572,
                    0.605,
                    0.638,
                    0.671,
                    0.704,
                    0.737,
                    0.771,
                    0.804,
                    0.837,
                    0.87,
                    0.903
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases regarding collaboration and teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of collaboration and teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghqh7ykypm10ex8lv88oxq",
                        "tokens": [
                            " Hear",
                            "st",
                            ",",
                            " and",
                            " Goldman",
                            " Sachs",
                            " invested",
                            " $",
                            "100",
                            " million",
                            " into",
                            " Current",
                            " Comm",
                            " Group",
                            " in",
                            " July",
                            " 2005",
                            ".",
                            " C",
                            "URRENT",
                            " has",
                            " been",
                            " alive",
                            " and",
                            " kicking",
                            " since",
                            " 2004",
                            ".",
                            " Current",
                            " uses",
                            " a",
                            " Smart",
                            " Grid",
                            " solution",
                            " to",
                            " increase",
                            " efficiency",
                            " for",
                            " high",
                            "-",
                            "speed",
                            " Internet",
                            " while",
                            " reducing",
                            " environmental",
                            " impacts",
                            " and",
                            " electric",
                            " usage",
                            ".",
                            "\n",
                            "\n",
                            "Current",
                            " has",
                            " worked",
                            " on",
                            " building",
                            " Smart",
                            " Gr",
                            "ids",
                            " in",
                            " Dallas",
                            ",",
                            " Boulder",
                            ",",
                            " and",
                            " certain",
                            " areas",
                            " in",
                            " Europe",
                            ".",
                            " Current",
                            " Communications",
                            " is",
                            " working",
                            " closely",
                            " with",
                            " X",
                            "cel",
                            " Energy",
                            " on",
                            " this",
                            " project",
                            ".",
                            "\n",
                            "\n",
                            "19",
                            ".",
                            " Android",
                            " (",
                            "Price",
                            ":",
                            " unknown",
                            ",",
                            " Date",
                            ":",
                            " August",
                            " 17",
                            ",",
                            " 2005",
                            ")",
                            "\n",
                            "\n",
                            "Google",
                            " quietly",
                            " acquired",
                            " Android",
                            " Inc",
                            ".",
                            " in",
                            " August",
                            " 2005",
                            " for",
                            " an",
                            " unknown",
                            " price",
                            ".",
                            " Android",
                            " was",
                            " 22",
                            " months",
                            " old",
                            " when",
                            " Google",
                            " bought",
                            " them",
                            " out"
                        ],
                        "dataIndex": null,
                        "index": "60260",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.354,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:48:13.088Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.353,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghqh80kyq910ex7l9js41r",
                        "tokens": [
                            " Hear",
                            "st",
                            ",",
                            " and",
                            " Goldman",
                            " Sachs",
                            " invested",
                            " $",
                            "100",
                            " million",
                            " into",
                            " Current",
                            " Comm",
                            " Group",
                            " in",
                            " July",
                            " 2005",
                            ".",
                            " C",
                            "URRENT",
                            " has",
                            " been",
                            " alive",
                            " and",
                            " kicking",
                            " since",
                            " 2004",
                            ".",
                            " Current",
                            " uses",
                            " a",
                            " Smart",
                            " Grid",
                            " solution",
                            " to",
                            " increase",
                            " efficiency",
                            " for",
                            " high",
                            "-",
                            "speed",
                            " Internet",
                            " while",
                            " reducing",
                            " environmental",
                            " impacts",
                            " and",
                            " electric",
                            " usage",
                            ".",
                            "\n",
                            "\n",
                            "Current",
                            " has",
                            " worked",
                            " on",
                            " building",
                            " Smart",
                            " Gr",
                            "ids",
                            " in",
                            " Dallas",
                            ",",
                            " Boulder",
                            ",",
                            " and",
                            " certain",
                            " areas",
                            " in",
                            " Europe",
                            ".",
                            " Current",
                            " Communications",
                            " is",
                            " working",
                            " closely",
                            " with",
                            " X",
                            "cel",
                            " Energy",
                            " on",
                            " this",
                            " project",
                            ".",
                            "\n",
                            "\n",
                            "19",
                            ".",
                            " Android",
                            " (",
                            "Price",
                            ":",
                            " unknown",
                            ",",
                            " Date",
                            ":",
                            " August",
                            " 17",
                            ",",
                            " 2005",
                            ")",
                            "\n",
                            "\n",
                            "Google",
                            " quietly",
                            " acquired",
                            " Android",
                            " Inc",
                            ".",
                            " in",
                            " August",
                            " 2005",
                            " for",
                            " an",
                            " unknown",
                            " price",
                            ".",
                            " Android",
                            " was",
                            " 22",
                            " months",
                            " old",
                            " when",
                            " Google",
                            " bought",
                            " them",
                            " out"
                        ],
                        "dataIndex": null,
                        "index": "60260",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.354,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:48:13.088Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 35.483,
                        "binMax": 44.353,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghqh7ykypn10ex89s02d80",
                        "tokens": [
                            "aul",
                            " said",
                            ".",
                            " \"",
                            "We",
                            "'ve",
                            " been",
                            " working",
                            " very",
                            " closely",
                            " with",
                            " the",
                            " Homeland",
                            " Security",
                            " secretary",
                            " on",
                            " this",
                            " and",
                            " we",
                            " are",
                            " final",
                            "izing",
                            " language",
                            " on",
                            " the",
                            " bill",
                            ".\"",
                            "\n",
                            "\n",
                            "Trump",
                            " looms",
                            " over",
                            " the",
                            " process",
                            ".",
                            " He",
                            " was",
                            " angry",
                            " when",
                            " Republicans",
                            " excluded",
                            " border",
                            " wall",
                            " funding",
                            " at",
                            " the",
                            " behest",
                            " of",
                            " Democrats",
                            " in",
                            " the",
                            " fiscal",
                            " 2017",
                            " bill",
                            ",",
                            " suggesting",
                            " in",
                            " a",
                            " May",
                            " 2",
                            " tweet",
                            " that",
                            " \"",
                            "Our",
                            " country",
                            " needs",
                            " a",
                            " good",
                            " '",
                            "shut",
                            "down",
                            "'",
                            " in",
                            " September",
                            " to",
                            " fix",
                            " mess",
                            "!\"",
                            "\n",
                            "\n",
                            "Republicans",
                            " are",
                            " now",
                            " trying",
                            " to",
                            " plac",
                            "ate",
                            " Trump",
                            ",",
                            " but",
                            " avoid",
                            " a",
                            " government",
                            " shutdown",
                            " by",
                            " anger",
                            "ing",
                            " either",
                            " Democrats",
                            " or",
                            " the",
                            " president",
                            ",",
                            " who",
                            " also",
                            " wield",
                            "s",
                            " a",
                            " veto",
                            " pen",
                            " and",
                            " could",
                            " threaten",
                            " not",
                            " to",
                            " sign",
                            " a",
                            " spending",
                            " bill",
                            " without",
                            " border",
                            " wall",
                            " funds",
                            ".",
                            "\n",
                            "\n",
                            "\""
                        ],
                        "dataIndex": null,
                        "index": "60260",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.837,
                        "maxValueTokenIndex": 9,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.851,
                            42.837,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:48:13.088Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.353,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "37298",
            "description": " statements related to teaching and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47814986239970636,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "37298",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:18:08.931Z",
                "maxActApprox": 9.544,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37298,
                    90447,
                    44148,
                    93599,
                    2714,
                    82087,
                    36307,
                    18136,
                    17278,
                    70016,
                    71300,
                    59012,
                    23643,
                    97518,
                    40768,
                    70808,
                    98181,
                    78615,
                    85101,
                    21925,
                    40309,
                    53445,
                    26319,
                    42245,
                    49591
                ],
                "topkCosSimValues": [
                    1,
                    0.5543,
                    0.5408,
                    0.5356,
                    0.517,
                    0.516,
                    0.5119,
                    0.5118,
                    0.4883,
                    0.4736,
                    0.4733,
                    0.4704,
                    0.4662,
                    0.4625,
                    0.4608,
                    0.4595,
                    0.4592,
                    0.4577,
                    0.4546,
                    0.4544,
                    0.4533,
                    0.4516,
                    0.4492,
                    0.448,
                    0.4464
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    218
                ],
                "neuron_alignment_values": [
                    0.264,
                    0.118,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    8,
                    566,
                    87
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.037,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.056,
                    0.039,
                    -0.014
                ],
                "correlated_features_indices": [
                    37301,
                    37309,
                    37397
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "rete",
                    "aucas",
                    "atile",
                    " Unique",
                    "ciating",
                    " oval",
                    " exceeds",
                    " ambul",
                    "nexus",
                    "yth"
                ],
                "neg_values": [
                    -0.555,
                    -0.545,
                    -0.534,
                    -0.529,
                    -0.502,
                    -0.495,
                    -0.492,
                    -0.474,
                    -0.474,
                    -0.474
                ],
                "pos_str": [
                    " nonetheless",
                    " nevertheless",
                    " apologies",
                    " caveats",
                    " caution",
                    "endix",
                    " doubtless",
                    " gladly",
                    "warning",
                    " caveat"
                ],
                "pos_values": [
                    0.872,
                    0.768,
                    0.758,
                    0.707,
                    0.683,
                    0.641,
                    0.638,
                    0.63,
                    0.624,
                    0.624
                ],
                "frac_nonzero": 0.00287,
                "freq_hist_data_bar_heights": [
                    1368,
                    1126,
                    971,
                    817,
                    720,
                    624,
                    563,
                    441,
                    389,
                    346,
                    262,
                    219,
                    176,
                    182,
                    137,
                    119,
                    96,
                    87,
                    54,
                    60,
                    58,
                    36,
                    34,
                    32,
                    21,
                    19,
                    13,
                    11,
                    12,
                    9,
                    6,
                    3,
                    7,
                    2,
                    6,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.286,
                    0.477,
                    0.668,
                    0.859,
                    1.05,
                    1.241,
                    1.432,
                    1.623,
                    1.813,
                    2.004,
                    2.195,
                    2.386,
                    2.577,
                    2.768,
                    2.959,
                    3.149,
                    3.34,
                    3.531,
                    3.722,
                    3.913,
                    4.104,
                    4.295,
                    4.486,
                    4.676,
                    4.867,
                    5.058,
                    5.249,
                    5.44,
                    5.631,
                    5.822,
                    6.012,
                    6.203,
                    6.394,
                    6.585,
                    6.776,
                    6.967,
                    7.158,
                    7.349,
                    7.539,
                    7.73,
                    7.921,
                    8.112,
                    8.303,
                    8.494,
                    8.685,
                    8.875,
                    9.066,
                    9.257,
                    9.448
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    7,
                    14,
                    28,
                    58,
                    117,
                    184,
                    319,
                    492,
                    788,
                    1177,
                    1627,
                    2113,
                    2641,
                    3121,
                    3628,
                    3919,
                    3956,
                    3942,
                    3876,
                    3556,
                    3014,
                    2683,
                    2153,
                    1739,
                    1406,
                    1057,
                    774,
                    568,
                    356,
                    295,
                    209,
                    159,
                    95,
                    63,
                    47,
                    20,
                    20,
                    13,
                    5,
                    8,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.541,
                    -0.512,
                    -0.484,
                    -0.455,
                    -0.426,
                    -0.398,
                    -0.369,
                    -0.341,
                    -0.312,
                    -0.284,
                    -0.255,
                    -0.227,
                    -0.198,
                    -0.17,
                    -0.141,
                    -0.113,
                    -0.084,
                    -0.055,
                    -0.027,
                    0.002,
                    0.03,
                    0.059,
                    0.087,
                    0.116,
                    0.144,
                    0.173,
                    0.201,
                    0.23,
                    0.259,
                    0.287,
                    0.316,
                    0.344,
                    0.373,
                    0.401,
                    0.43,
                    0.458,
                    0.487,
                    0.515,
                    0.544,
                    0.573,
                    0.601,
                    0.63,
                    0.658,
                    0.687,
                    0.715,
                    0.744,
                    0.772,
                    0.801,
                    0.829,
                    0.858
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements related to teaching and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases expressing advice or suggestions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggntmh3k9e10ex8zq32xmy",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmj3k9y10exc6tmgsm1",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.635,
                        "binMax": 9.543,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmh3k9f10exukem1fpm",
                        "tokens": [
                            " this",
                            " console",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "Now",
                            " N",
                            "aughty",
                            " Dog",
                            " returns",
                            " to",
                            " the",
                            " spotlight",
                            " with",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            ".",
                            " Both",
                            " expected",
                            "ly",
                            " and",
                            " amazingly",
                            ",",
                            " N",
                            "aughty",
                            " Dog",
                            " has",
                            " indeed",
                            " best",
                            "ed",
                            " Nate",
                            "'s",
                            " first",
                            " adventure",
                            " and",
                            " has",
                            " created",
                            " a",
                            " sequel",
                            " that",
                            " is",
                            " not",
                            " only",
                            " bigger",
                            " and",
                            " better",
                            " in",
                            " practically",
                            " every",
                            " way",
                            ",",
                            " but",
                            " also",
                            " packs",
                            " a",
                            " multiplayer",
                            " component",
                            " that",
                            " could",
                            " be",
                            " released",
                            " as",
                            " its",
                            " own",
                            " separate",
                            ",",
                            " full",
                            "-",
                            "priced",
                            " game",
                            " and",
                            " people",
                            " would",
                            " stand",
                            " in",
                            " line",
                            " to",
                            " hand",
                            " over",
                            " their",
                            " cash",
                            ".",
                            "\n",
                            "\n",
                            "Yes",
                            ",",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            " is",
                            " fantastic",
                            ".",
                            "\n",
                            "\n",
                            "Click",
                            " the",
                            " image",
                            " to",
                            " watch",
                            " our",
                            " in",
                            "-",
                            "depth",
                            " video",
                            " review",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "rying",
                            " to",
                            " remain",
                            " as",
                            " spoiler",
                            "-",
                            "free",
                            " as",
                            " possible",
                            ",",
                            " I",
                            "'ll"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.545,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.14,
                            7.545
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3427",
            "description": "concepts related to teaching and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47481024265289307,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3427",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:27.928Z",
                "maxActApprox": 15.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3427,
                    77561,
                    60325,
                    73728,
                    50077,
                    33640,
                    55572,
                    46187,
                    52346,
                    44237,
                    71908,
                    41600,
                    11,
                    70412,
                    53181,
                    83314,
                    42965,
                    79098,
                    21161,
                    23492,
                    28490,
                    42202,
                    93440,
                    42300,
                    59028
                ],
                "topkCosSimValues": [
                    1,
                    0.5752,
                    0.5313,
                    0.518,
                    0.4759,
                    0.4686,
                    0.4422,
                    0.3923,
                    0.391,
                    0.3864,
                    0.3785,
                    0.3768,
                    0.3757,
                    0.3679,
                    0.367,
                    0.367,
                    0.3629,
                    0.3589,
                    0.3481,
                    0.3475,
                    0.3419,
                    0.3416,
                    0.3379,
                    0.3346,
                    0.3338
                ],
                "neuron_alignment_indices": [
                    635,
                    603,
                    263
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.094,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    263,
                    236,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    3457,
                    3415,
                    3391
                ],
                "correlated_features_pearson": [
                    0.054,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.054,
                    0.009,
                    0.001
                ],
                "neg_str": [
                    "Rum",
                    "storm",
                    "inqu",
                    " Inqu",
                    "estate",
                    "luster",
                    " inquiries",
                    " Noel",
                    " Bellev",
                    " Graves"
                ],
                "neg_values": [
                    -0.653,
                    -0.639,
                    -0.636,
                    -0.612,
                    -0.604,
                    -0.598,
                    -0.595,
                    -0.589,
                    -0.588,
                    -0.586
                ],
                "pos_str": [
                    " versatility",
                    " ropes",
                    " prowess",
                    "agy",
                    " horizont",
                    " ingenuity",
                    "alore",
                    "emade",
                    " vectors",
                    " flexibility"
                ],
                "pos_values": [
                    0.9,
                    0.817,
                    0.79,
                    0.753,
                    0.746,
                    0.734,
                    0.699,
                    0.698,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00055,
                "freq_hist_data_bar_heights": [
                    266,
                    194,
                    153,
                    123,
                    145,
                    105,
                    91,
                    85,
                    57,
                    50,
                    46,
                    43,
                    51,
                    29,
                    23,
                    30,
                    31,
                    15,
                    26,
                    22,
                    20,
                    8,
                    9,
                    10,
                    12,
                    7,
                    6,
                    6,
                    6,
                    6,
                    7,
                    8,
                    4,
                    6,
                    0,
                    3,
                    2,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.164,
                    0.483,
                    0.802,
                    1.121,
                    1.439,
                    1.758,
                    2.077,
                    2.396,
                    2.715,
                    3.033,
                    3.352,
                    3.671,
                    3.99,
                    4.308,
                    4.627,
                    4.946,
                    5.265,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.858,
                    7.177,
                    7.496,
                    7.815,
                    8.133,
                    8.452,
                    8.771,
                    9.09,
                    9.408,
                    9.727,
                    10.046,
                    10.365,
                    10.683,
                    11.002,
                    11.321,
                    11.64,
                    11.958,
                    12.277,
                    12.596,
                    12.915,
                    13.233,
                    13.552,
                    13.871,
                    14.19,
                    14.508,
                    14.827,
                    15.146,
                    15.465,
                    15.784
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    6,
                    21,
                    29,
                    57,
                    67,
                    144,
                    219,
                    332,
                    505,
                    720,
                    983,
                    1366,
                    1739,
                    2245,
                    2684,
                    3097,
                    3501,
                    3914,
                    3820,
                    3809,
                    3646,
                    3331,
                    2951,
                    2520,
                    2074,
                    1696,
                    1302,
                    1023,
                    739,
                    528,
                    402,
                    246,
                    194,
                    117,
                    80,
                    50,
                    29,
                    18,
                    14,
                    10,
                    10,
                    6,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.638,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.203,
                    -0.172,
                    -0.141,
                    -0.11,
                    -0.079,
                    -0.048,
                    -0.016,
                    0.015,
                    0.046,
                    0.077,
                    0.108,
                    0.139,
                    0.17,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.418,
                    0.449,
                    0.48,
                    0.511,
                    0.542,
                    0.574,
                    0.605,
                    0.636,
                    0.667,
                    0.698,
                    0.729,
                    0.76,
                    0.791,
                    0.822,
                    0.853,
                    0.884
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and instructions related to methods and processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to teaching and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf154kdwgm10ex7gzz8956",
                        "tokens": [
                            " Al",
                            "inea",
                            " outside",
                            " Chicago",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " chance",
                            " to",
                            " present",
                            " their",
                            " cooking",
                            " in",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " disc",
                            "erning",
                            " food",
                            " city",
                            " without",
                            " the",
                            " full",
                            "-",
                            "time",
                            " commitment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " can",
                            "'t",
                            " tell",
                            " you",
                            " how",
                            " many",
                            " chefs",
                            " have",
                            " said",
                            " to",
                            " me",
                            ",",
                            " '",
                            "Yeah",
                            ",",
                            " you",
                            "'re",
                            " a",
                            " big",
                            " fish",
                            " in",
                            " a",
                            " small",
                            " pond",
                            ".",
                            " The",
                            " only",
                            " reason",
                            " you",
                            "'re",
                            " so",
                            " popular",
                            " is",
                            " because",
                            " you",
                            "'re",
                            " in",
                            " the",
                            " Midwest",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " In",
                            " a",
                            " way",
                            ",",
                            " we",
                            "'re",
                            " am",
                            "ped",
                            " up",
                            ",\"",
                            " A",
                            "chat",
                            "z",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " want",
                            " to",
                            " introduce",
                            " Al",
                            "inea",
                            " food",
                            " to",
                            " the",
                            " j",
                            "aded",
                            " New",
                            " Yorker",
                            ".",
                            " We",
                            "'re",
                            " going",
                            " to",
                            " show",
                            " New",
                            " Yorkers",
                            " what",
                            " Chicago",
                            " food",
                            " is",
                            " all",
                            " about",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " collaboration"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.943,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            1.683,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.943,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgn10exy3t5v2tt",
                        "tokens": [
                            " has",
                            " come",
                            " to",
                            " this",
                            " particular",
                            " point",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Load",
                            " third",
                            " party",
                            " embed",
                            "\n",
                            "\n",
                            "As",
                            " an",
                            " avid",
                            " bike",
                            ",",
                            " parks",
                            " and",
                            " neighborhood",
                            " advocate",
                            ",",
                            " Ford",
                            " has",
                            " been",
                            " fighting",
                            " the",
                            " decline",
                            " of",
                            " Detroit",
                            " for",
                            " years",
                            ".",
                            " To",
                            " see",
                            " his",
                            " hometown",
                            " become",
                            " trendy",
                            " with",
                            " everyone",
                            " from",
                            " tech",
                            " developers",
                            " to",
                            " hip",
                            "ster",
                            " craft",
                            "-",
                            "l",
                            "iqu",
                            "or",
                            " dist",
                            "ill",
                            "ers",
                            " makes",
                            " him",
                            " laugh",
                            " with",
                            " joy",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Being",
                            " a",
                            " unique",
                            " individual",
                            " showcasing",
                            " your",
                            " talent",
                            " is",
                            " like",
                            " the",
                            " new",
                            " hot",
                            " thing",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Everybody",
                            " wants",
                            " to",
                            " show",
                            " us",
                            " what",
                            " they",
                            " can",
                            " do",
                            ".",
                            " People",
                            " are",
                            " coming",
                            " here",
                            " from",
                            " all",
                            " over",
                            " the",
                            " country",
                            ",",
                            " because",
                            " of",
                            " the",
                            " access",
                            " to",
                            " material",
                            ",",
                            " talent",
                            " and",
                            " overall",
                            " attitude",
                            " to",
                            " get"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.881,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.746,
                            1.82,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.881,
                            4.034,
                            4.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgo10exkj0oeyt1",
                        "tokens": [
                            " I",
                            " would",
                            " love",
                            " to",
                            " show",
                            " how",
                            " the",
                            " card",
                            " handle",
                            " but",
                            " I",
                            "'m",
                            " not",
                            " really",
                            " good",
                            " a",
                            " that",
                            ",",
                            " this",
                            " video",
                            " is",
                            " the",
                            " best",
                            " i",
                            " could",
                            " do",
                            "...",
                            " Sorry",
                            " :(",
                            " https",
                            "://",
                            "www",
                            ".",
                            "youtube",
                            ".",
                            "com",
                            "/",
                            "watch",
                            "?",
                            "v",
                            "=",
                            "U",
                            "An",
                            "8",
                            "g",
                            "U",
                            "5",
                            "r",
                            "61",
                            "s",
                            " ***",
                            " #",
                            "Le",
                            " Website",
                            " To",
                            " make",
                            " all",
                            " this",
                            " a",
                            " little",
                            " less",
                            " complicated",
                            " i",
                            " set",
                            " up",
                            " a",
                            " website",
                            " with",
                            " the",
                            " very",
                            " original",
                            " and",
                            " thought",
                            "-",
                            "through",
                            " name",
                            " [",
                            "L",
                            "OL",
                            "Playing",
                            "C",
                            "ards",
                            ".",
                            "com",
                            "](",
                            "http",
                            "://",
                            "www",
                            ".",
                            "lol",
                            "playing",
                            "cards",
                            ".",
                            "com",
                            "/",
                            ").",
                            " here",
                            " are",
                            " some",
                            " screenshots",
                            ":",
                            " Front",
                            " page",
                            " with",
                            " the",
                            " story",
                            " and",
                            " stuff",
                            "s",
                            ":",
                            " http",
                            "://",
                            "i",
                            ".",
                            "imgur",
                            ".",
                            "com",
                            "/",
                            "q",
                            "fy",
                            "B",
                            "10",
                            "Z",
                            ".",
                            "png",
                            " A",
                            " page"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.408,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.408,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44646",
            "description": " interactions and discussions involving strategies, teamwork, and collaboration",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46854543685913086,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44646",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:30:01.882Z",
                "maxActApprox": 8.516,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44646,
                    36174,
                    69792,
                    92979,
                    22925,
                    92060,
                    71998,
                    40471,
                    98181,
                    10114,
                    46141,
                    51050,
                    92042,
                    57715,
                    33659,
                    36945,
                    23852,
                    67844,
                    60889,
                    1413,
                    16100,
                    15821,
                    7203,
                    53029,
                    50258
                ],
                "topkCosSimValues": [
                    1,
                    0.4834,
                    0.4348,
                    0.4205,
                    0.3961,
                    0.3901,
                    0.3836,
                    0.376,
                    0.3755,
                    0.3729,
                    0.3674,
                    0.3669,
                    0.365,
                    0.3643,
                    0.3574,
                    0.3511,
                    0.344,
                    0.3417,
                    0.3415,
                    0.3407,
                    0.3388,
                    0.3374,
                    0.3367,
                    0.3356,
                    0.3327
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    373
                ],
                "neuron_alignment_values": [
                    0.202,
                    0.143,
                    0.134
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    665,
                    567,
                    435
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.032,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.041,
                    0.025,
                    0.021
                ],
                "correlated_features_indices": [
                    44599,
                    44588,
                    44617
                ],
                "correlated_features_pearson": [
                    0.02,
                    0.006,
                    0.006
                ],
                "correlated_features_l1": [
                    0.022,
                    0.007,
                    0.006
                ],
                "neg_str": [
                    "amon",
                    "umn",
                    " joked",
                    "\"],\"",
                    " sadly",
                    "yrs",
                    "enko",
                    " confir",
                    "zed",
                    "ighed"
                ],
                "neg_values": [
                    -0.646,
                    -0.606,
                    -0.603,
                    -0.581,
                    -0.568,
                    -0.566,
                    -0.555,
                    -0.549,
                    -0.548,
                    -0.547
                ],
                "pos_str": [
                    " oneself",
                    " yourself",
                    " Yourself",
                    " yourselves",
                    " ourselves",
                    " existing",
                    " manually",
                    " uncond",
                    " upstream",
                    "ezvous"
                ],
                "pos_values": [
                    1.307,
                    1.187,
                    1.04,
                    0.882,
                    0.852,
                    0.851,
                    0.676,
                    0.653,
                    0.647,
                    0.638
                ],
                "frac_nonzero": 0.00335,
                "freq_hist_data_bar_heights": [
                    1463,
                    1256,
                    1036,
                    972,
                    817,
                    691,
                    586,
                    536,
                    438,
                    399,
                    281,
                    285,
                    263,
                    206,
                    183,
                    149,
                    129,
                    115,
                    96,
                    94,
                    80,
                    63,
                    52,
                    40,
                    52,
                    32,
                    32,
                    30,
                    23,
                    18,
                    11,
                    17,
                    15,
                    15,
                    12,
                    7,
                    7,
                    5,
                    5,
                    1,
                    1,
                    3,
                    1,
                    1,
                    1,
                    4,
                    2,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.085,
                    0.256,
                    0.426,
                    0.596,
                    0.766,
                    0.937,
                    1.107,
                    1.277,
                    1.448,
                    1.618,
                    1.788,
                    1.959,
                    2.129,
                    2.299,
                    2.47,
                    2.64,
                    2.81,
                    2.981,
                    3.151,
                    3.321,
                    3.492,
                    3.662,
                    3.832,
                    4.003,
                    4.173,
                    4.343,
                    4.513,
                    4.684,
                    4.854,
                    5.024,
                    5.195,
                    5.365,
                    5.535,
                    5.706,
                    5.876,
                    6.046,
                    6.217,
                    6.387,
                    6.557,
                    6.728,
                    6.898,
                    7.068,
                    7.239,
                    7.409,
                    7.579,
                    7.749,
                    7.92,
                    8.09,
                    8.26,
                    8.431
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    9,
                    23,
                    32,
                    70,
                    146,
                    264,
                    479,
                    882,
                    1406,
                    2188,
                    3047,
                    4041,
                    4760,
                    5288,
                    5439,
                    5231,
                    4510,
                    3745,
                    2757,
                    2065,
                    1425,
                    946,
                    639,
                    379,
                    207,
                    122,
                    69,
                    38,
                    19,
                    12,
                    5,
                    3,
                    0,
                    0,
                    0,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.626,
                    -0.587,
                    -0.548,
                    -0.509,
                    -0.47,
                    -0.431,
                    -0.392,
                    -0.353,
                    -0.314,
                    -0.275,
                    -0.236,
                    -0.197,
                    -0.158,
                    -0.119,
                    -0.08,
                    -0.041,
                    -0.001,
                    0.038,
                    0.077,
                    0.116,
                    0.155,
                    0.194,
                    0.233,
                    0.272,
                    0.311,
                    0.35,
                    0.389,
                    0.428,
                    0.467,
                    0.506,
                    0.545,
                    0.584,
                    0.623,
                    0.662,
                    0.701,
                    0.741,
                    0.78,
                    0.819,
                    0.858,
                    0.897,
                    0.936,
                    0.975,
                    1.014,
                    1.053,
                    1.092,
                    1.131,
                    1.17,
                    1.209,
                    1.248,
                    1.287
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " interactions and discussions involving strategies, teamwork, and collaboration",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh38d9946s10exjoxx04bj",
                        "tokens": [
                            ",",
                            " scientists",
                            ",",
                            " high",
                            "-",
                            "ranking",
                            " military",
                            " officials",
                            ",",
                            " the",
                            " works",
                            ".",
                            " I",
                            " mean",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " really",
                            " credible",
                            " people",
                            " covering",
                            " this",
                            " subject",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " UFO",
                            " Congress",
                            " co",
                            "-",
                            "organ",
                            "izer",
                            " and",
                            " paranormal",
                            " journalist",
                            " Ma",
                            "ureen",
                            " El",
                            "s",
                            "berry",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " attending",
                            " a",
                            " UFO",
                            " conference",
                            ",",
                            " the",
                            " best",
                            " approach",
                            " is",
                            " to",
                            " come",
                            " in",
                            " with",
                            " an",
                            " open",
                            " mind",
                            ",",
                            " ask",
                            " lots",
                            " of",
                            " questions",
                            " and",
                            " talk",
                            " with",
                            " people",
                            " about",
                            " why",
                            " they",
                            " are",
                            " there",
                            ".",
                            " Everyone",
                            " has",
                            " a",
                            " story",
                            ",",
                            " from",
                            " the",
                            " speakers",
                            " to",
                            " the",
                            " attendees",
                            ",",
                            " and",
                            " even",
                            " the",
                            " vendors",
                            " (",
                            "some",
                            " of",
                            " whom",
                            " double",
                            " as",
                            " u",
                            "f",
                            "ologists",
                            ").",
                            "\n",
                            "\n",
                            "The",
                            " highlight",
                            " of",
                            " this",
                            " year",
                            "'s",
                            " conference",
                            " was",
                            " undeniably",
                            " the",
                            " speaker",
                            " series",
                            ",",
                            " and",
                            " it",
                            " was",
                            " standing",
                            " room"
                        ],
                        "dataIndex": null,
                        "index": "44646",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.516,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.074,
                            4.284,
                            8.516,
                            4.669,
                            3.933,
                            0.836,
                            3.375,
                            1.205,
                            3.261,
                            0.535,
                            3.126,
                            4.742,
                            1.055,
                            1.476,
                            2.922,
                            1.852,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:08.492Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.516,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh38d9946t10exf28t5jbh",
                        "tokens": [
                            " a",
                            " cheat",
                            ".",
                            " I",
                            " spent",
                            " half",
                            " an",
                            " hour",
                            " t",
                            "rom",
                            "ping",
                            " around",
                            " the",
                            " se",
                            "ab",
                            "ed",
                            " looking",
                            " for",
                            " a",
                            " particular",
                            " item",
                            " among",
                            " the",
                            " wreckage",
                            "\u2014",
                            " a",
                            " computer",
                            " chip",
                            "\u2014",
                            " that",
                            " would",
                            " spare",
                            " me",
                            " the",
                            " need",
                            " to",
                            " kill",
                            " a",
                            " sap",
                            "ient",
                            " drone",
                            " for",
                            " the",
                            " same",
                            " vital",
                            " part",
                            ".",
                            " It",
                            " would",
                            " have",
                            " been",
                            " easy",
                            " enough",
                            " for",
                            " Fr",
                            "ictional",
                            " to",
                            " give",
                            " me",
                            " that",
                            " option",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " already",
                            " littered",
                            " the",
                            " se",
                            "ab",
                            "ed",
                            " with",
                            " wrecked",
                            " drones",
                            ",",
                            " it",
                            " wouldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " killed",
                            " them",
                            " to",
                            " leave",
                            " me",
                            " some",
                            " usable",
                            " salvage",
                            ".",
                            " But",
                            " no",
                            ".",
                            " The",
                            " the",
                            " only",
                            " way",
                            " forward",
                            " was",
                            " to",
                            " slaughter",
                            " an",
                            " innocent",
                            " being",
                            ".",
                            " It",
                            " made",
                            " the",
                            " point",
                            ",",
                            " philosoph",
                            "ically",
                            ",",
                            " but",
                            " it",
                            " felt",
                            " wrong",
                            " somehow",
                            ".",
                            " Forced",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " would",
                            " normally"
                        ],
                        "dataIndex": null,
                        "index": "44646",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.471,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.334,
                            8.471,
                            7.775,
                            3.221,
                            1.864,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:08.492Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.516,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh38da947010exj3ne6j8q",
                        "tokens": [
                            " a",
                            " cheat",
                            ".",
                            " I",
                            " spent",
                            " half",
                            " an",
                            " hour",
                            " t",
                            "rom",
                            "ping",
                            " around",
                            " the",
                            " se",
                            "ab",
                            "ed",
                            " looking",
                            " for",
                            " a",
                            " particular",
                            " item",
                            " among",
                            " the",
                            " wreckage",
                            "\u2014",
                            " a",
                            " computer",
                            " chip",
                            "\u2014",
                            " that",
                            " would",
                            " spare",
                            " me",
                            " the",
                            " need",
                            " to",
                            " kill",
                            " a",
                            " sap",
                            "ient",
                            " drone",
                            " for",
                            " the",
                            " same",
                            " vital",
                            " part",
                            ".",
                            " It",
                            " would",
                            " have",
                            " been",
                            " easy",
                            " enough",
                            " for",
                            " Fr",
                            "ictional",
                            " to",
                            " give",
                            " me",
                            " that",
                            " option",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " already",
                            " littered",
                            " the",
                            " se",
                            "ab",
                            "ed",
                            " with",
                            " wrecked",
                            " drones",
                            ",",
                            " it",
                            " wouldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " killed",
                            " them",
                            " to",
                            " leave",
                            " me",
                            " some",
                            " usable",
                            " salvage",
                            ".",
                            " But",
                            " no",
                            ".",
                            " The",
                            " the",
                            " only",
                            " way",
                            " forward",
                            " was",
                            " to",
                            " slaughter",
                            " an",
                            " innocent",
                            " being",
                            ".",
                            " It",
                            " made",
                            " the",
                            " point",
                            ",",
                            " philosoph",
                            "ically",
                            ",",
                            " but",
                            " it",
                            " felt",
                            " wrong",
                            " somehow",
                            ".",
                            " Forced",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " would",
                            " normally"
                        ],
                        "dataIndex": null,
                        "index": "44646",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.471,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.334,
                            8.471,
                            7.775,
                            3.221,
                            1.864,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:08.492Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.516,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3758",
            "description": " discussions about benefits, mutual gains, and outcomes related to collaborative efforts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46732765436172485,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3758",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:49.318Z",
                "maxActApprox": 32.994,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3758,
                    75198,
                    36968,
                    24038,
                    94032,
                    51659,
                    67211,
                    45507,
                    47287,
                    85437,
                    12536,
                    83905,
                    17940,
                    26359,
                    2375,
                    70641,
                    65799,
                    25580,
                    81330,
                    50982,
                    66681,
                    59947,
                    25364,
                    27114,
                    5846
                ],
                "topkCosSimValues": [
                    1,
                    0.446,
                    0.4347,
                    0.4325,
                    0.4217,
                    0.4134,
                    0.407,
                    0.4037,
                    0.4024,
                    0.3743,
                    0.3722,
                    0.3589,
                    0.3534,
                    0.3491,
                    0.3414,
                    0.3402,
                    0.3363,
                    0.3356,
                    0.3351,
                    0.3348,
                    0.3289,
                    0.3271,
                    0.3244,
                    0.3225,
                    0.3212
                ],
                "neuron_alignment_indices": [
                    393,
                    697,
                    7
                ],
                "neuron_alignment_values": [
                    0.124,
                    0.123,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    636,
                    362,
                    379
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.01,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.012,
                    0.01
                ],
                "correlated_features_indices": [
                    3741,
                    3786,
                    3725
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    " Leilan",
                    "ocene",
                    "perature",
                    "cn",
                    "etsk",
                    "soDeliveryDate",
                    "chairs",
                    "ommel",
                    "entary",
                    " moderators"
                ],
                "neg_values": [
                    -0.701,
                    -0.7,
                    -0.679,
                    -0.675,
                    -0.664,
                    -0.643,
                    -0.641,
                    -0.63,
                    -0.622,
                    -0.617
                ],
                "pos_str": [
                    " brunt",
                    " rewards",
                    " whirlwind",
                    " benefits",
                    " glory",
                    " dividends",
                    " riches",
                    " benefit",
                    " spo",
                    " advantages"
                ],
                "pos_values": [
                    1.163,
                    1.16,
                    1.087,
                    1.076,
                    1.018,
                    0.978,
                    0.924,
                    0.895,
                    0.876,
                    0.869
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    175,
                    109,
                    66,
                    54,
                    33,
                    23,
                    17,
                    6,
                    1,
                    7,
                    2,
                    2,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.336,
                    0.996,
                    1.656,
                    2.315,
                    2.975,
                    3.635,
                    4.295,
                    4.954,
                    5.614,
                    6.274,
                    6.934,
                    7.593,
                    8.253,
                    8.913,
                    9.573,
                    10.232,
                    10.892,
                    11.552,
                    12.212,
                    12.871,
                    13.531,
                    14.191,
                    14.851,
                    15.51,
                    16.17,
                    16.83,
                    17.49,
                    18.149,
                    18.809,
                    19.469,
                    20.129,
                    20.788,
                    21.448,
                    22.108,
                    22.768,
                    23.427,
                    24.087,
                    24.747,
                    25.407,
                    26.066,
                    26.726,
                    27.386,
                    28.046,
                    28.705,
                    29.365,
                    30.025,
                    30.685,
                    31.344,
                    32.004,
                    32.664
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    3,
                    11,
                    23,
                    25,
                    49,
                    103,
                    167,
                    324,
                    496,
                    787,
                    1226,
                    1710,
                    2295,
                    2938,
                    3645,
                    4285,
                    4461,
                    4509,
                    4282,
                    3860,
                    3438,
                    2838,
                    2291,
                    1855,
                    1312,
                    958,
                    725,
                    492,
                    358,
                    244,
                    169,
                    116,
                    92,
                    54,
                    36,
                    26,
                    15,
                    8,
                    5,
                    4,
                    7,
                    3,
                    1,
                    0,
                    1,
                    1,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.682,
                    -0.645,
                    -0.608,
                    -0.57,
                    -0.533,
                    -0.496,
                    -0.458,
                    -0.421,
                    -0.384,
                    -0.347,
                    -0.309,
                    -0.272,
                    -0.235,
                    -0.197,
                    -0.16,
                    -0.123,
                    -0.086,
                    -0.048,
                    -0.011,
                    0.026,
                    0.063,
                    0.101,
                    0.138,
                    0.175,
                    0.213,
                    0.25,
                    0.287,
                    0.324,
                    0.362,
                    0.399,
                    0.436,
                    0.474,
                    0.511,
                    0.548,
                    0.585,
                    0.623,
                    0.66,
                    0.697,
                    0.735,
                    0.772,
                    0.809,
                    0.846,
                    0.884,
                    0.921,
                    0.958,
                    0.996,
                    1.033,
                    1.07,
                    1.107,
                    1.145
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " discussions about benefits, mutual gains, and outcomes related to collaborative efforts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf1nwye5im10exf63czssh",
                        "tokens": [
                            " 10",
                            " prints",
                            " and",
                            " five",
                            " t",
                            "-",
                            "shirts",
                            "\n",
                            "\n",
                            "For",
                            " 500",
                            " copies",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " hook",
                            " you",
                            " up",
                            " with",
                            " 25",
                            " prints",
                            ",",
                            " 15",
                            " t",
                            "-",
                            "shirts",
                            ",",
                            " and",
                            " your",
                            " own",
                            " variant",
                            " cover",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            " of",
                            " a",
                            " series",
                            " of",
                            " covers",
                            " inspired",
                            " by",
                            " serial",
                            " killer",
                            " movies",
                            "\n",
                            "\n",
                            "So",
                            ",",
                            " you",
                            " sold",
                            " yet",
                            "?",
                            " Are",
                            " you",
                            " Indo",
                            "ctr",
                            "inated",
                            "?",
                            "\n",
                            "\n",
                            "Good",
                            ".",
                            " Now",
                            " let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " work",
                            " together",
                            " to",
                            " sell",
                            " some",
                            " comics",
                            " and",
                            " reap",
                            " the",
                            " mutual",
                            " rewards",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " know",
                            " more",
                            " about",
                            " Indo",
                            "ctr",
                            "ination",
                            ",",
                            " contact",
                            " me",
                            " via",
                            " social",
                            " media",
                            " or",
                            " my",
                            " email",
                            " (",
                            "which",
                            " most",
                            " of",
                            " you",
                            " have",
                            "),",
                            " or",
                            " visit",
                            " indoctr",
                            "ination",
                            "com",
                            "ic",
                            ".",
                            "com",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " you",
                            ",",
                            " again"
                        ],
                        "dataIndex": null,
                        "index": "3758",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.994,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.018,
                            32.994,
                            7.075,
                            3.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:56.122Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 32.994,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf1nwze5iy10exhn36ei5m",
                        "tokens": [
                            " 10",
                            " prints",
                            " and",
                            " five",
                            " t",
                            "-",
                            "shirts",
                            "\n",
                            "\n",
                            "For",
                            " 500",
                            " copies",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " hook",
                            " you",
                            " up",
                            " with",
                            " 25",
                            " prints",
                            ",",
                            " 15",
                            " t",
                            "-",
                            "shirts",
                            ",",
                            " and",
                            " your",
                            " own",
                            " variant",
                            " cover",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            " of",
                            " a",
                            " series",
                            " of",
                            " covers",
                            " inspired",
                            " by",
                            " serial",
                            " killer",
                            " movies",
                            "\n",
                            "\n",
                            "So",
                            ",",
                            " you",
                            " sold",
                            " yet",
                            "?",
                            " Are",
                            " you",
                            " Indo",
                            "ctr",
                            "inated",
                            "?",
                            "\n",
                            "\n",
                            "Good",
                            ".",
                            " Now",
                            " let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " work",
                            " together",
                            " to",
                            " sell",
                            " some",
                            " comics",
                            " and",
                            " reap",
                            " the",
                            " mutual",
                            " rewards",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " know",
                            " more",
                            " about",
                            " Indo",
                            "ctr",
                            "ination",
                            ",",
                            " contact",
                            " me",
                            " via",
                            " social",
                            " media",
                            " or",
                            " my",
                            " email",
                            " (",
                            "which",
                            " most",
                            " of",
                            " you",
                            " have",
                            "),",
                            " or",
                            " visit",
                            " indoctr",
                            "ination",
                            "com",
                            "ic",
                            ".",
                            "com",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " you",
                            ",",
                            " again"
                        ],
                        "dataIndex": null,
                        "index": "3758",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.994,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.018,
                            32.994,
                            7.075,
                            3.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:56.122Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 32.994,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf1nx0e5j810exe9v2uacu",
                        "tokens": [
                            " 10",
                            " prints",
                            " and",
                            " five",
                            " t",
                            "-",
                            "shirts",
                            "\n",
                            "\n",
                            "For",
                            " 500",
                            " copies",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " hook",
                            " you",
                            " up",
                            " with",
                            " 25",
                            " prints",
                            ",",
                            " 15",
                            " t",
                            "-",
                            "shirts",
                            ",",
                            " and",
                            " your",
                            " own",
                            " variant",
                            " cover",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            " of",
                            " a",
                            " series",
                            " of",
                            " covers",
                            " inspired",
                            " by",
                            " serial",
                            " killer",
                            " movies",
                            "\n",
                            "\n",
                            "So",
                            ",",
                            " you",
                            " sold",
                            " yet",
                            "?",
                            " Are",
                            " you",
                            " Indo",
                            "ctr",
                            "inated",
                            "?",
                            "\n",
                            "\n",
                            "Good",
                            ".",
                            " Now",
                            " let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " work",
                            " together",
                            " to",
                            " sell",
                            " some",
                            " comics",
                            " and",
                            " reap",
                            " the",
                            " mutual",
                            " rewards",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " know",
                            " more",
                            " about",
                            " Indo",
                            "ctr",
                            "ination",
                            ",",
                            " contact",
                            " me",
                            " via",
                            " social",
                            " media",
                            " or",
                            " my",
                            " email",
                            " (",
                            "which",
                            " most",
                            " of",
                            " you",
                            " have",
                            "),",
                            " or",
                            " visit",
                            " indoctr",
                            "ination",
                            "com",
                            "ic",
                            ".",
                            "com",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " you",
                            ",",
                            " again"
                        ],
                        "dataIndex": null,
                        "index": "3758",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.994,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.018,
                            32.994,
                            7.075,
                            3.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:56.122Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 26.395,
                        "binMax": 32.994,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "46711",
            "description": "terminology and concepts related to collaboration and discussion facilitation",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46668306191664644,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "46711",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:22:12.197Z",
                "maxActApprox": 9.407,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    46711,
                    36064,
                    44343,
                    6220,
                    39133,
                    9729,
                    9487,
                    40123,
                    37255,
                    26164,
                    27193,
                    44279,
                    9560,
                    13632,
                    25048,
                    7970,
                    18880,
                    7331,
                    34472,
                    10326,
                    10469,
                    40651,
                    13455,
                    36663,
                    45658
                ],
                "topkCosSimValues": [
                    1,
                    0.3826,
                    0.3823,
                    0.3695,
                    0.3663,
                    0.3578,
                    0.341,
                    0.3375,
                    0.3342,
                    0.3324,
                    0.3201,
                    0.3161,
                    0.3144,
                    0.3115,
                    0.3101,
                    0.3092,
                    0.3086,
                    0.3078,
                    0.3071,
                    0.3068,
                    0.3045,
                    0.3038,
                    0.3027,
                    0.2969,
                    0.2959
                ],
                "neuron_alignment_indices": [
                    679,
                    76,
                    583
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.104,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    285,
                    679,
                    283
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.027,
                    0.027
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.045,
                    0.008
                ],
                "correlated_features_indices": [
                    46619,
                    46629,
                    46705
                ],
                "correlated_features_pearson": [
                    0.015,
                    0.01,
                    0.009
                ],
                "correlated_features_l1": [
                    0.016,
                    0.01,
                    0.011
                ],
                "neg_str": [
                    "addons",
                    " cursed",
                    "addafi",
                    " platinum",
                    "Legendary",
                    " shipped",
                    " Viper",
                    "itol",
                    " plantations",
                    " unlucky"
                ],
                "neg_values": [
                    -0.738,
                    -0.73,
                    -0.722,
                    -0.706,
                    -0.697,
                    -0.695,
                    -0.693,
                    -0.693,
                    -0.69,
                    -0.69
                ],
                "pos_str": [
                    " communication",
                    " communicating",
                    " dialogue",
                    " interacting",
                    " cues",
                    " orally",
                    " discourse",
                    " communicates",
                    " empathy",
                    " voice"
                ],
                "pos_values": [
                    1.01,
                    1.005,
                    0.956,
                    0.942,
                    0.936,
                    0.929,
                    0.921,
                    0.918,
                    0.917,
                    0.912
                ],
                "frac_nonzero": 0.00318,
                "freq_hist_data_bar_heights": [
                    1567,
                    1342,
                    1066,
                    951,
                    802,
                    717,
                    581,
                    461,
                    365,
                    342,
                    314,
                    241,
                    214,
                    188,
                    133,
                    119,
                    112,
                    94,
                    57,
                    68,
                    49,
                    41,
                    30,
                    28,
                    19,
                    20,
                    19,
                    11,
                    11,
                    7,
                    3,
                    9,
                    1,
                    8,
                    4,
                    3,
                    1,
                    2,
                    3,
                    3,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.094,
                    0.282,
                    0.471,
                    0.659,
                    0.847,
                    1.035,
                    1.223,
                    1.411,
                    1.599,
                    1.788,
                    1.976,
                    2.164,
                    2.352,
                    2.54,
                    2.728,
                    2.916,
                    3.104,
                    3.293,
                    3.481,
                    3.669,
                    3.857,
                    4.045,
                    4.233,
                    4.421,
                    4.609,
                    4.798,
                    4.986,
                    5.174,
                    5.362,
                    5.55,
                    5.738,
                    5.926,
                    6.115,
                    6.303,
                    6.491,
                    6.679,
                    6.867,
                    7.055,
                    7.243,
                    7.431,
                    7.62,
                    7.808,
                    7.996,
                    8.184,
                    8.372,
                    8.56,
                    8.748,
                    8.936,
                    9.125,
                    9.313
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    10,
                    10,
                    23,
                    36,
                    63,
                    108,
                    171,
                    271,
                    402,
                    609,
                    874,
                    1194,
                    1495,
                    2016,
                    2393,
                    2788,
                    3220,
                    3413,
                    3512,
                    3439,
                    3430,
                    3289,
                    2937,
                    2587,
                    2190,
                    1950,
                    1587,
                    1344,
                    1076,
                    860,
                    697,
                    534,
                    428,
                    336,
                    243,
                    186,
                    153,
                    96,
                    73,
                    54,
                    53,
                    30,
                    21,
                    19,
                    13,
                    9,
                    7,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.72,
                    -0.685,
                    -0.65,
                    -0.615,
                    -0.58,
                    -0.545,
                    -0.51,
                    -0.476,
                    -0.441,
                    -0.406,
                    -0.371,
                    -0.336,
                    -0.301,
                    -0.266,
                    -0.231,
                    -0.196,
                    -0.161,
                    -0.126,
                    -0.091,
                    -0.056,
                    -0.021,
                    0.014,
                    0.049,
                    0.084,
                    0.119,
                    0.154,
                    0.189,
                    0.224,
                    0.259,
                    0.294,
                    0.328,
                    0.363,
                    0.398,
                    0.433,
                    0.468,
                    0.503,
                    0.538,
                    0.573,
                    0.608,
                    0.643,
                    0.678,
                    0.713,
                    0.748,
                    0.783,
                    0.818,
                    0.853,
                    0.888,
                    0.923,
                    0.958,
                    0.993
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terminology and concepts related to collaboration and discussion facilitation",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk747qtip91i666ehni1sna",
                        "tokens": [
                            " Indiana",
                            " Jones",
                            ",",
                            " Professor",
                            " Plum",
                            " of",
                            " \"",
                            "Cl",
                            "ue",
                            " University",
                            ",\"",
                            " and",
                            " G",
                            "ild",
                            "er",
                            "oy",
                            " Lock",
                            "hart",
                            " from",
                            " Harry",
                            " Potter",
                            "'s",
                            " Hogwarts",
                            " School",
                            " of",
                            " Witch",
                            "craft",
                            " and",
                            " Wizard",
                            "ry",
                            ",",
                            " among",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Watch",
                            "list",
                            ",",
                            " launched",
                            " Monday",
                            ",",
                            " is",
                            " a",
                            " project",
                            " of",
                            " Turning",
                            " Point",
                            " USA",
                            ".",
                            " The",
                            " group",
                            "'s",
                            " mission",
                            " is",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            ",",
                            " educate",
                            ",",
                            " train",
                            " and",
                            " organize",
                            " students",
                            " to",
                            " promote",
                            " the",
                            " principles",
                            " of",
                            " fiscal",
                            " responsibility",
                            ",",
                            " free",
                            " markets",
                            " and",
                            " limited",
                            " government",
                            ".\"",
                            " Its",
                            " national",
                            " college",
                            " and",
                            " university",
                            " field",
                            " program",
                            " works",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            " young",
                            " conservative",
                            " activists",
                            ",",
                            " build",
                            " and",
                            " maintain",
                            " effective",
                            " student",
                            " groups",
                            ",",
                            " advertise",
                            " and",
                            " re",
                            "brand",
                            " conservative",
                            " values",
                            ",",
                            " engage",
                            " in",
                            " face",
                            "-",
                            "to",
                            "-",
                            "face",
                            " and",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " conversations",
                            " about",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46711",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.407,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.661,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            1.453,
                            3.108,
                            9.407,
                            2.634,
                            2.547,
                            0.814,
                            5.642,
                            3.39,
                            6.278,
                            0.904,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:20.521Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 9.407,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk747qwip9ni666sekrslsv",
                        "tokens": [
                            " Indiana",
                            " Jones",
                            ",",
                            " Professor",
                            " Plum",
                            " of",
                            " \"",
                            "Cl",
                            "ue",
                            " University",
                            ",\"",
                            " and",
                            " G",
                            "ild",
                            "er",
                            "oy",
                            " Lock",
                            "hart",
                            " from",
                            " Harry",
                            " Potter",
                            "'s",
                            " Hogwarts",
                            " School",
                            " of",
                            " Witch",
                            "craft",
                            " and",
                            " Wizard",
                            "ry",
                            ",",
                            " among",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Watch",
                            "list",
                            ",",
                            " launched",
                            " Monday",
                            ",",
                            " is",
                            " a",
                            " project",
                            " of",
                            " Turning",
                            " Point",
                            " USA",
                            ".",
                            " The",
                            " group",
                            "'s",
                            " mission",
                            " is",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            ",",
                            " educate",
                            ",",
                            " train",
                            " and",
                            " organize",
                            " students",
                            " to",
                            " promote",
                            " the",
                            " principles",
                            " of",
                            " fiscal",
                            " responsibility",
                            ",",
                            " free",
                            " markets",
                            " and",
                            " limited",
                            " government",
                            ".\"",
                            " Its",
                            " national",
                            " college",
                            " and",
                            " university",
                            " field",
                            " program",
                            " works",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            " young",
                            " conservative",
                            " activists",
                            ",",
                            " build",
                            " and",
                            " maintain",
                            " effective",
                            " student",
                            " groups",
                            ",",
                            " advertise",
                            " and",
                            " re",
                            "brand",
                            " conservative",
                            " values",
                            ",",
                            " engage",
                            " in",
                            " face",
                            "-",
                            "to",
                            "-",
                            "face",
                            " and",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " conversations",
                            " about",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46711",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.407,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.661,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            1.453,
                            3.108,
                            9.407,
                            2.634,
                            2.547,
                            0.814,
                            5.642,
                            3.39,
                            6.278,
                            0.904,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:20.521Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 7.525,
                        "binMax": 9.407,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk747qwip9si66630kw0e8g",
                        "tokens": [
                            " Indiana",
                            " Jones",
                            ",",
                            " Professor",
                            " Plum",
                            " of",
                            " \"",
                            "Cl",
                            "ue",
                            " University",
                            ",\"",
                            " and",
                            " G",
                            "ild",
                            "er",
                            "oy",
                            " Lock",
                            "hart",
                            " from",
                            " Harry",
                            " Potter",
                            "'s",
                            " Hogwarts",
                            " School",
                            " of",
                            " Witch",
                            "craft",
                            " and",
                            " Wizard",
                            "ry",
                            ",",
                            " among",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Watch",
                            "list",
                            ",",
                            " launched",
                            " Monday",
                            ",",
                            " is",
                            " a",
                            " project",
                            " of",
                            " Turning",
                            " Point",
                            " USA",
                            ".",
                            " The",
                            " group",
                            "'s",
                            " mission",
                            " is",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            ",",
                            " educate",
                            ",",
                            " train",
                            " and",
                            " organize",
                            " students",
                            " to",
                            " promote",
                            " the",
                            " principles",
                            " of",
                            " fiscal",
                            " responsibility",
                            ",",
                            " free",
                            " markets",
                            " and",
                            " limited",
                            " government",
                            ".\"",
                            " Its",
                            " national",
                            " college",
                            " and",
                            " university",
                            " field",
                            " program",
                            " works",
                            " to",
                            " \"",
                            "ident",
                            "ify",
                            " young",
                            " conservative",
                            " activists",
                            ",",
                            " build",
                            " and",
                            " maintain",
                            " effective",
                            " student",
                            " groups",
                            ",",
                            " advertise",
                            " and",
                            " re",
                            "brand",
                            " conservative",
                            " values",
                            ",",
                            " engage",
                            " in",
                            " face",
                            "-",
                            "to",
                            "-",
                            "face",
                            " and",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " conversations",
                            " about",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46711",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.407,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.661,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            1.453,
                            3.108,
                            9.407,
                            2.634,
                            2.547,
                            0.814,
                            5.642,
                            3.39,
                            6.278,
                            0.904,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:20.521Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 5.644,
                        "binMax": 7.525,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67437",
            "description": " actions associated with sharing, learning, and creating",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46547433733940125,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67437",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:55:57.104Z",
                "maxActApprox": 16.775,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67437,
                    20344,
                    82960,
                    51723,
                    201,
                    30390,
                    66426,
                    34190,
                    2922,
                    72289,
                    53029,
                    66794,
                    94072,
                    32648,
                    3113,
                    10428,
                    53797,
                    91010,
                    41901,
                    93241,
                    16621,
                    65571,
                    91347,
                    46610,
                    68613
                ],
                "topkCosSimValues": [
                    1,
                    0.4554,
                    0.4545,
                    0.4386,
                    0.4101,
                    0.3909,
                    0.3885,
                    0.3818,
                    0.378,
                    0.3769,
                    0.376,
                    0.3759,
                    0.3638,
                    0.3622,
                    0.347,
                    0.3453,
                    0.3425,
                    0.3371,
                    0.3369,
                    0.3363,
                    0.3321,
                    0.3317,
                    0.3299,
                    0.3297,
                    0.3282
                ],
                "neuron_alignment_indices": [
                    602,
                    500,
                    570
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.093,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    604,
                    738,
                    25
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.026,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.021
                ],
                "correlated_features_indices": [
                    67317,
                    67332,
                    67335
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    " mishand",
                    " Historically",
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "COMPLE",
                    "currently",
                    "urnal",
                    "abama",
                    "\u0123\u0138",
                    "Eastern",
                    "ablished"
                ],
                "neg_values": [
                    -0.623,
                    -0.622,
                    -0.592,
                    -0.588,
                    -0.582,
                    -0.579,
                    -0.576,
                    -0.575,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    " yourself",
                    " yourselves",
                    " yours",
                    "anooga",
                    " your",
                    " Yourself",
                    " ya",
                    "!'",
                    " whatever",
                    "oice"
                ],
                "pos_values": [
                    1.079,
                    0.921,
                    0.898,
                    0.798,
                    0.775,
                    0.752,
                    0.751,
                    0.742,
                    0.723,
                    0.721
                ],
                "frac_nonzero": 0.00094,
                "freq_hist_data_bar_heights": [
                    628,
                    432,
                    367,
                    300,
                    227,
                    182,
                    123,
                    110,
                    97,
                    78,
                    71,
                    50,
                    42,
                    39,
                    22,
                    29,
                    23,
                    19,
                    18,
                    13,
                    10,
                    10,
                    8,
                    7,
                    2,
                    7,
                    3,
                    4,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.168,
                    0.504,
                    0.839,
                    1.175,
                    1.51,
                    1.846,
                    2.181,
                    2.517,
                    2.852,
                    3.188,
                    3.523,
                    3.859,
                    4.194,
                    4.53,
                    4.865,
                    5.201,
                    5.536,
                    5.872,
                    6.207,
                    6.542,
                    6.878,
                    7.213,
                    7.549,
                    7.884,
                    8.22,
                    8.555,
                    8.891,
                    9.226,
                    9.562,
                    9.897,
                    10.233,
                    10.568,
                    10.904,
                    11.239,
                    11.575,
                    11.91,
                    12.246,
                    12.581,
                    12.917,
                    13.252,
                    13.588,
                    13.923,
                    14.259,
                    14.594,
                    14.93,
                    15.265,
                    15.6,
                    15.936,
                    16.271,
                    16.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    8,
                    19,
                    18,
                    41,
                    87,
                    156,
                    290,
                    426,
                    647,
                    1098,
                    1493,
                    2095,
                    2523,
                    3182,
                    3691,
                    4000,
                    4423,
                    4377,
                    4098,
                    3841,
                    3321,
                    2787,
                    2187,
                    1700,
                    1204,
                    826,
                    598,
                    374,
                    270,
                    165,
                    123,
                    66,
                    43,
                    23,
                    20,
                    10,
                    5,
                    6,
                    5,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.606,
                    -0.572,
                    -0.537,
                    -0.503,
                    -0.469,
                    -0.435,
                    -0.401,
                    -0.367,
                    -0.333,
                    -0.299,
                    -0.265,
                    -0.231,
                    -0.197,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.061,
                    -0.027,
                    0.007,
                    0.041,
                    0.075,
                    0.109,
                    0.143,
                    0.177,
                    0.211,
                    0.245,
                    0.28,
                    0.314,
                    0.348,
                    0.382,
                    0.416,
                    0.45,
                    0.484,
                    0.518,
                    0.552,
                    0.586,
                    0.62,
                    0.654,
                    0.688,
                    0.722,
                    0.756,
                    0.79,
                    0.824,
                    0.858,
                    0.892,
                    0.926,
                    0.96,
                    0.994,
                    1.028,
                    1.062
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions associated with sharing, learning, and creating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "actions related to sharing and engaging with content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi0kzjqfos10ex9oe2q0k7",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzjqfoy10exm0wixfaq",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzlqfpe10exe96je5qi",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 13.42,
                        "binMax": 16.775,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4638108887559713,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "8677",
            "description": "terms related to sharing and collaborative activities",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4605216383934021,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "8677",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:13:21.390Z",
                "maxActApprox": 45.817,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8677,
                    27175,
                    44113,
                    39463,
                    29579,
                    6190,
                    3957,
                    15498,
                    30253,
                    33392,
                    39358,
                    30601,
                    24556,
                    4519,
                    37112,
                    31480,
                    11541,
                    5850,
                    46775,
                    22512,
                    47819,
                    31740,
                    5397,
                    15722,
                    37824
                ],
                "topkCosSimValues": [
                    1,
                    0.742,
                    0.7047,
                    0.6834,
                    0.6775,
                    0.5734,
                    0.5704,
                    0.5187,
                    0.4402,
                    0.4133,
                    0.4087,
                    0.4072,
                    0.4054,
                    0.3988,
                    0.3981,
                    0.368,
                    0.3643,
                    0.3626,
                    0.3578,
                    0.356,
                    0.3471,
                    0.3458,
                    0.3445,
                    0.344,
                    0.3438
                ],
                "neuron_alignment_indices": [
                    578,
                    656,
                    1
                ],
                "neuron_alignment_values": [
                    0.109,
                    0.103,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    1,
                    578,
                    639
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.018,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.015,
                    0.017
                ],
                "correlated_features_indices": [
                    8722,
                    8646,
                    8616
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.003,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.004,
                    0
                ],
                "neg_str": [
                    "paio",
                    "ichick",
                    "stad",
                    "annis",
                    "veyard",
                    "inez",
                    "herty",
                    " hur",
                    "ogie",
                    "\u012b"
                ],
                "neg_values": [
                    -0.762,
                    -0.731,
                    -0.708,
                    -0.693,
                    -0.689,
                    -0.676,
                    -0.67,
                    -0.666,
                    -0.664,
                    -0.66
                ],
                "pos_str": [
                    "itarian",
                    "hare",
                    "cro",
                    "ware",
                    "sheets",
                    "holders",
                    " networks",
                    " platforms",
                    "mates",
                    " algorithms"
                ],
                "pos_values": [
                    0.865,
                    0.864,
                    0.847,
                    0.836,
                    0.824,
                    0.778,
                    0.777,
                    0.77,
                    0.756,
                    0.749
                ],
                "frac_nonzero": 0.00019,
                "freq_hist_data_bar_heights": [
                    81,
                    71,
                    38,
                    44,
                    38,
                    31,
                    30,
                    22,
                    13,
                    16,
                    15,
                    18,
                    8,
                    11,
                    12,
                    8,
                    11,
                    13,
                    8,
                    7,
                    7,
                    4,
                    7,
                    6,
                    7,
                    0,
                    2,
                    5,
                    5,
                    5,
                    1,
                    7,
                    3,
                    3,
                    4,
                    6,
                    9,
                    4,
                    5,
                    5,
                    2,
                    5,
                    1,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.469,
                    1.386,
                    2.302,
                    3.218,
                    4.134,
                    5.05,
                    5.966,
                    6.882,
                    7.798,
                    8.714,
                    9.631,
                    10.547,
                    11.463,
                    12.379,
                    13.295,
                    14.211,
                    15.127,
                    16.043,
                    16.959,
                    17.876,
                    18.792,
                    19.708,
                    20.624,
                    21.54,
                    22.456,
                    23.372,
                    24.288,
                    25.204,
                    26.121,
                    27.037,
                    27.953,
                    28.869,
                    29.785,
                    30.701,
                    31.617,
                    32.533,
                    33.449,
                    34.366,
                    35.282,
                    36.198,
                    37.114,
                    38.03,
                    38.946,
                    39.862,
                    40.778,
                    41.694,
                    42.611,
                    43.527,
                    44.443,
                    45.359
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    5,
                    11,
                    7,
                    9,
                    16,
                    40,
                    66,
                    98,
                    145,
                    257,
                    341,
                    536,
                    813,
                    1108,
                    1526,
                    1847,
                    2524,
                    2917,
                    3549,
                    3816,
                    4066,
                    4154,
                    3910,
                    3655,
                    3292,
                    2734,
                    2227,
                    1809,
                    1359,
                    1062,
                    719,
                    528,
                    353,
                    247,
                    162,
                    110,
                    73,
                    48,
                    40,
                    30,
                    14,
                    7,
                    4,
                    6,
                    6,
                    3,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.746,
                    -0.713,
                    -0.681,
                    -0.648,
                    -0.616,
                    -0.583,
                    -0.55,
                    -0.518,
                    -0.485,
                    -0.453,
                    -0.42,
                    -0.388,
                    -0.355,
                    -0.323,
                    -0.29,
                    -0.258,
                    -0.225,
                    -0.192,
                    -0.16,
                    -0.127,
                    -0.095,
                    -0.062,
                    -0.03,
                    0.003,
                    0.035,
                    0.068,
                    0.1,
                    0.133,
                    0.166,
                    0.198,
                    0.231,
                    0.263,
                    0.296,
                    0.328,
                    0.361,
                    0.393,
                    0.426,
                    0.458,
                    0.491,
                    0.524,
                    0.556,
                    0.589,
                    0.621,
                    0.654,
                    0.686,
                    0.719,
                    0.751,
                    0.784,
                    0.816,
                    0.849
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to sharing and collaborative activities",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4nmqmjnczi666pd976z50",
                        "tokens": [
                            ",",
                            " are",
                            " scheduled",
                            " to",
                            " arrive",
                            " in",
                            " the",
                            " early",
                            " afternoon",
                            " of",
                            " Aug",
                            ".",
                            " 15",
                            " \u2014",
                            " a",
                            " day",
                            " that",
                            " marks",
                            " the",
                            " 67",
                            "th",
                            " anniversary",
                            " of",
                            " South",
                            " Korea",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " independence",
                            " from",
                            " Japanese",
                            " colonial",
                            " rule",
                            ".",
                            " Their",
                            " swim",
                            " follows",
                            " a",
                            " visit",
                            " last",
                            " Friday",
                            " by",
                            " South",
                            " Korean",
                            " President",
                            " Lee",
                            " My",
                            "ung",
                            "-",
                            "b",
                            "ak",
                            " \u2014",
                            " the",
                            " first",
                            " ever",
                            " by",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " top",
                            " leader",
                            " \u2014",
                            " which",
                            " prompted",
                            " Japan",
                            " to",
                            " summon",
                            " the",
                            " South",
                            " Korean",
                            " ambassador",
                            " in",
                            " Tokyo",
                            " and",
                            " to",
                            " recall",
                            " its",
                            " top",
                            " diplomat",
                            " from",
                            " Seoul",
                            ".",
                            " Japan",
                            " also",
                            " suggested",
                            " that",
                            " it",
                            " might",
                            " take",
                            " the",
                            " territorial",
                            " dispute",
                            " to",
                            " the",
                            " International",
                            " Court",
                            " of",
                            " Justice",
                            ".",
                            "\n",
                            "\n",
                            "(",
                            "MORE",
                            ":",
                            " Why",
                            " South",
                            " Korea",
                            " Is",
                            " in",
                            " an",
                            " U",
                            "pro",
                            "ar",
                            " over",
                            " Intelligence",
                            " Sharing",
                            " with",
                            " Japan",
                            ")",
                            "\n",
                            "\n",
                            "The",
                            " islands",
                            " are",
                            " located"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.817,
                        "maxValueTokenIndex": 117,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.817,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 45.817,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4nmqmjnd0i666gfz7m736",
                        "tokens": [
                            "Update",
                            ":",
                            " Oct",
                            ".",
                            " 12",
                            ":",
                            " Python",
                            " script",
                            " to",
                            " query",
                            " the",
                            " API",
                            "\n",
                            "\n",
                            "We",
                            " are",
                            " very",
                            " excited",
                            " to",
                            " announce",
                            " that",
                            " J",
                            "EB",
                            " 2",
                            ".",
                            "3",
                            ".",
                            "6",
                            " integrates",
                            " with",
                            " a",
                            " new",
                            " project",
                            " we",
                            " called",
                            " the",
                            " Mal",
                            "ware",
                            " Sharing",
                            " Network",
                            ".",
                            " It",
                            " allows",
                            " reverse",
                            " engineers",
                            " to",
                            " share",
                            " samples",
                            " anonymously",
                            ",",
                            " in",
                            " a",
                            " give",
                            "-",
                            "and",
                            "-",
                            "take",
                            " fashion",
                            ".",
                            " The",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " give",
                            ",",
                            " the",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " will",
                            " receive",
                            ".",
                            "\n",
                            "\n",
                            "Files",
                            " are",
                            " shared",
                            " with",
                            " P",
                            "NF",
                            " Software",
                            " (",
                            "they",
                            " are",
                            " not",
                            " shared",
                            " directly",
                            " with",
                            " other",
                            " users",
                            ");",
                            "\n",
                            "\n",
                            "Contribut",
                            "ions",
                            " and",
                            " users",
                            " are",
                            " algorithm",
                            "ically",
                            " ranked",
                            " and",
                            " scored",
                            ";",
                            "\n",
                            "\n",
                            "In",
                            " exchange",
                            " for",
                            " their",
                            " contributions",
                            ",",
                            " users",
                            " receive",
                            " more",
                            " files",
                            ",",
                            " based",
                            " on",
                            " their",
                            " score",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.853,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.436,
                            0,
                            0.69,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.082,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.323,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 45.817,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4nmqojndki666zp25jkzc",
                        "tokens": [
                            "Update",
                            ":",
                            " Oct",
                            ".",
                            " 12",
                            ":",
                            " Python",
                            " script",
                            " to",
                            " query",
                            " the",
                            " API",
                            "\n",
                            "\n",
                            "We",
                            " are",
                            " very",
                            " excited",
                            " to",
                            " announce",
                            " that",
                            " J",
                            "EB",
                            " 2",
                            ".",
                            "3",
                            ".",
                            "6",
                            " integrates",
                            " with",
                            " a",
                            " new",
                            " project",
                            " we",
                            " called",
                            " the",
                            " Mal",
                            "ware",
                            " Sharing",
                            " Network",
                            ".",
                            " It",
                            " allows",
                            " reverse",
                            " engineers",
                            " to",
                            " share",
                            " samples",
                            " anonymously",
                            ",",
                            " in",
                            " a",
                            " give",
                            "-",
                            "and",
                            "-",
                            "take",
                            " fashion",
                            ".",
                            " The",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " give",
                            ",",
                            " the",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " will",
                            " receive",
                            ".",
                            "\n",
                            "\n",
                            "Files",
                            " are",
                            " shared",
                            " with",
                            " P",
                            "NF",
                            " Software",
                            " (",
                            "they",
                            " are",
                            " not",
                            " shared",
                            " directly",
                            " with",
                            " other",
                            " users",
                            ");",
                            "\n",
                            "\n",
                            "Contribut",
                            "ions",
                            " and",
                            " users",
                            " are",
                            " algorithm",
                            "ically",
                            " ranked",
                            " and",
                            " scored",
                            ";",
                            "\n",
                            "\n",
                            "In",
                            " exchange",
                            " for",
                            " their",
                            " contributions",
                            ",",
                            " users",
                            " receive",
                            " more",
                            " files",
                            ",",
                            " based",
                            " on",
                            " their",
                            " score",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.853,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.436,
                            0,
                            0.69,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.082,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.323,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 36.654,
                        "binMax": 45.817,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "76184",
            "description": "concepts related to collaboration or teamwork in creative processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4493904113769531,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "76184",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:05:29.914Z",
                "maxActApprox": 10.731,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    76184,
                    37271,
                    59348,
                    6188,
                    57874,
                    76946,
                    16275,
                    76764,
                    96849,
                    4005,
                    41140,
                    33207,
                    8293,
                    14350,
                    18389,
                    42519,
                    68084,
                    45663,
                    43711,
                    69179,
                    30763,
                    44527,
                    27807,
                    74945,
                    91067
                ],
                "topkCosSimValues": [
                    1,
                    0.5774,
                    0.5016,
                    0.5007,
                    0.4218,
                    0.4214,
                    0.4144,
                    0.4014,
                    0.399,
                    0.3883,
                    0.3878,
                    0.3839,
                    0.3837,
                    0.3819,
                    0.3686,
                    0.3667,
                    0.3593,
                    0.3559,
                    0.3413,
                    0.3377,
                    0.3323,
                    0.3322,
                    0.3277,
                    0.3219,
                    0.3214
                ],
                "neuron_alignment_indices": [
                    447,
                    624,
                    664
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.107,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    624,
                    105,
                    679
                ],
                "correlated_neurons_pearson": [
                    0.047,
                    0.04,
                    0.035
                ],
                "correlated_neurons_l1": [
                    0.039,
                    0.037,
                    0.061
                ],
                "correlated_features_indices": [
                    76164,
                    76145,
                    76152
                ],
                "correlated_features_pearson": [
                    0.012,
                    0.01,
                    0.009
                ],
                "correlated_features_l1": [
                    0.014,
                    0.01,
                    0.012
                ],
                "neg_str": [
                    "utterstock",
                    " pathetic",
                    " trillions",
                    "\u00e0",
                    "Liber",
                    " MSM",
                    " impunity",
                    " Citation",
                    " repe",
                    "carry"
                ],
                "neg_values": [
                    -0.78,
                    -0.709,
                    -0.707,
                    -0.705,
                    -0.703,
                    -0.699,
                    -0.695,
                    -0.674,
                    -0.669,
                    -0.662
                ],
                "pos_str": [
                    " brainstorm",
                    " designers",
                    " designing",
                    " inspir",
                    " reluct",
                    " creatively",
                    " composer",
                    " collaborating",
                    " sketches",
                    " conceived"
                ],
                "pos_values": [
                    1.165,
                    1.09,
                    1.011,
                    0.991,
                    0.966,
                    0.963,
                    0.949,
                    0.935,
                    0.933,
                    0.924
                ],
                "frac_nonzero": 0.007019999999999999,
                "freq_hist_data_bar_heights": [
                    3321,
                    2712,
                    2417,
                    2055,
                    1661,
                    1516,
                    1170,
                    1093,
                    847,
                    794,
                    638,
                    550,
                    441,
                    410,
                    328,
                    322,
                    275,
                    241,
                    201,
                    173,
                    130,
                    157,
                    101,
                    97,
                    73,
                    60,
                    56,
                    38,
                    33,
                    29,
                    23,
                    33,
                    18,
                    12,
                    15,
                    12,
                    15,
                    10,
                    3,
                    0,
                    4,
                    4,
                    3,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.107,
                    0.322,
                    0.537,
                    0.751,
                    0.966,
                    1.18,
                    1.395,
                    1.61,
                    1.824,
                    2.039,
                    2.254,
                    2.468,
                    2.683,
                    2.897,
                    3.112,
                    3.327,
                    3.541,
                    3.756,
                    3.97,
                    4.185,
                    4.4,
                    4.614,
                    4.829,
                    5.044,
                    5.258,
                    5.473,
                    5.687,
                    5.902,
                    6.117,
                    6.331,
                    6.546,
                    6.761,
                    6.975,
                    7.19,
                    7.404,
                    7.619,
                    7.834,
                    8.048,
                    8.263,
                    8.478,
                    8.692,
                    8.907,
                    9.121,
                    9.336,
                    9.551,
                    9.765,
                    9.98,
                    10.194,
                    10.409,
                    10.624
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    4,
                    7,
                    20,
                    25,
                    71,
                    113,
                    241,
                    383,
                    591,
                    862,
                    1233,
                    1673,
                    2165,
                    2757,
                    3286,
                    3799,
                    4048,
                    4222,
                    4194,
                    3902,
                    3475,
                    3040,
                    2519,
                    2068,
                    1522,
                    1136,
                    860,
                    617,
                    429,
                    296,
                    228,
                    139,
                    81,
                    60,
                    50,
                    36,
                    25,
                    26,
                    20,
                    11,
                    5,
                    4,
                    5,
                    1,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.761,
                    -0.722,
                    -0.683,
                    -0.644,
                    -0.605,
                    -0.567,
                    -0.528,
                    -0.489,
                    -0.45,
                    -0.411,
                    -0.372,
                    -0.333,
                    -0.294,
                    -0.255,
                    -0.216,
                    -0.177,
                    -0.139,
                    -0.1,
                    -0.061,
                    -0.022,
                    0.017,
                    0.056,
                    0.095,
                    0.134,
                    0.173,
                    0.212,
                    0.25,
                    0.289,
                    0.328,
                    0.367,
                    0.406,
                    0.445,
                    0.484,
                    0.523,
                    0.562,
                    0.601,
                    0.64,
                    0.678,
                    0.717,
                    0.756,
                    0.795,
                    0.834,
                    0.873,
                    0.912,
                    0.951,
                    0.99,
                    1.029,
                    1.067,
                    1.106,
                    1.145
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions of collaborative creative processes in media production",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to collaboration or teamwork in creative processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygics3lx3jd10exhngpnz23",
                        "tokens": [
                            " celebrate",
                            " the",
                            " 200",
                            "th",
                            " episode",
                            ",",
                            " Parker",
                            " and",
                            " Stone",
                            " started",
                            " reviewing",
                            " the",
                            " plots",
                            " and",
                            " controversies",
                            " of",
                            " previous",
                            " episodes",
                            ",",
                            " many",
                            " of",
                            " which",
                            " had",
                            " a",
                            " common",
                            " thread",
                            " of",
                            " mocking",
                            " a",
                            " particular",
                            " celebrity",
                            ".",
                            " This",
                            " led",
                            " to",
                            " the",
                            " idea",
                            " of",
                            " the",
                            " having",
                            " all",
                            " the",
                            " celebrities",
                            " band",
                            " together",
                            " in",
                            " a",
                            " class",
                            " action",
                            " lawsuit",
                            " against",
                            " the",
                            " town",
                            ".",
                            " Parker",
                            " said",
                            " their",
                            " reactions",
                            " mirrored",
                            " the",
                            " real",
                            "-",
                            "life",
                            " reactions",
                            " some",
                            " of",
                            " the",
                            " celebrities",
                            " had",
                            " to",
                            " their",
                            " portray",
                            "als",
                            ",",
                            " adding",
                            ",",
                            " \"",
                            "If",
                            " they",
                            " could",
                            " join",
                            " forces",
                            ",",
                            " they",
                            " probably",
                            " would",
                            ".\"[",
                            "2",
                            "]",
                            "\n",
                            "\n",
                            "Stone",
                            " said",
                            " in",
                            " writing",
                            " the",
                            " episode",
                            ",",
                            " they",
                            " were",
                            " determined",
                            " not",
                            " to",
                            " produce",
                            " a",
                            " clip",
                            " show",
                            ",",
                            " but",
                            " to",
                            " merge",
                            " all",
                            " of",
                            " the",
                            " old",
                            " ideas",
                            " into",
                            " a",
                            " new",
                            ",",
                            " original",
                            " script",
                            ".",
                            " The",
                            " process",
                            " proved",
                            " challenging"
                        ],
                        "dataIndex": null,
                        "index": "76184",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.731,
                        "maxValueTokenIndex": 122,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.452,
                            0,
                            1.307,
                            0.452,
                            0.999,
                            2.896,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.051,
                            0,
                            0,
                            0.409,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.126,
                            1.303,
                            0,
                            0.042,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.841,
                            0,
                            0.529,
                            0,
                            1.456,
                            1.596,
                            0,
                            2.694,
                            0.167,
                            4.162,
                            7.616,
                            6.092,
                            1.324,
                            0.344,
                            0.416,
                            0,
                            0,
                            0,
                            0,
                            3.508,
                            2.254,
                            3.878,
                            1.135,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.515,
                            0,
                            0,
                            0,
                            0,
                            10.731,
                            6.381,
                            5.395,
                            0.42,
                            3.799
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:05:33.590Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygics3ox3k310ex4v7t2vru",
                        "tokens": [
                            " celebrate",
                            " the",
                            " 200",
                            "th",
                            " episode",
                            ",",
                            " Parker",
                            " and",
                            " Stone",
                            " started",
                            " reviewing",
                            " the",
                            " plots",
                            " and",
                            " controversies",
                            " of",
                            " previous",
                            " episodes",
                            ",",
                            " many",
                            " of",
                            " which",
                            " had",
                            " a",
                            " common",
                            " thread",
                            " of",
                            " mocking",
                            " a",
                            " particular",
                            " celebrity",
                            ".",
                            " This",
                            " led",
                            " to",
                            " the",
                            " idea",
                            " of",
                            " the",
                            " having",
                            " all",
                            " the",
                            " celebrities",
                            " band",
                            " together",
                            " in",
                            " a",
                            " class",
                            " action",
                            " lawsuit",
                            " against",
                            " the",
                            " town",
                            ".",
                            " Parker",
                            " said",
                            " their",
                            " reactions",
                            " mirrored",
                            " the",
                            " real",
                            "-",
                            "life",
                            " reactions",
                            " some",
                            " of",
                            " the",
                            " celebrities",
                            " had",
                            " to",
                            " their",
                            " portray",
                            "als",
                            ",",
                            " adding",
                            ",",
                            " \"",
                            "If",
                            " they",
                            " could",
                            " join",
                            " forces",
                            ",",
                            " they",
                            " probably",
                            " would",
                            ".\"[",
                            "2",
                            "]",
                            "\n",
                            "\n",
                            "Stone",
                            " said",
                            " in",
                            " writing",
                            " the",
                            " episode",
                            ",",
                            " they",
                            " were",
                            " determined",
                            " not",
                            " to",
                            " produce",
                            " a",
                            " clip",
                            " show",
                            ",",
                            " but",
                            " to",
                            " merge",
                            " all",
                            " of",
                            " the",
                            " old",
                            " ideas",
                            " into",
                            " a",
                            " new",
                            ",",
                            " original",
                            " script",
                            ".",
                            " The",
                            " process",
                            " proved",
                            " challenging"
                        ],
                        "dataIndex": null,
                        "index": "76184",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.731,
                        "maxValueTokenIndex": 122,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.452,
                            0,
                            1.307,
                            0.452,
                            0.999,
                            2.896,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.051,
                            0,
                            0,
                            0.409,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.126,
                            1.303,
                            0,
                            0.042,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.841,
                            0,
                            0.529,
                            0,
                            1.456,
                            1.596,
                            0,
                            2.694,
                            0.167,
                            4.162,
                            7.616,
                            6.092,
                            1.324,
                            0.344,
                            0.416,
                            0,
                            0,
                            0,
                            0,
                            3.508,
                            2.254,
                            3.878,
                            1.135,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.515,
                            0,
                            0,
                            0,
                            0,
                            10.731,
                            6.381,
                            5.395,
                            0.42,
                            3.799
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:05:33.590Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.439,
                        "binMax": 8.585,
                        "binContains": 4e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygics3lx3je10exncju2d61",
                        "tokens": [
                            "-",
                            "hour",
                            " idea",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " makes",
                            " it",
                            " really",
                            " cool",
                            " to",
                            " me",
                            ",",
                            " that",
                            " we",
                            " can",
                            " really",
                            " fire",
                            " on",
                            " all",
                            " cylinders",
                            ",",
                            " and",
                            " be",
                            " outrageous",
                            " and",
                            " fast",
                            " paced",
                            " and",
                            " non",
                            "-",
                            "stop",
                            " without",
                            " a",
                            " lot",
                            " of",
                            " secondary",
                            " character",
                            " exposition",
                            " that",
                            " sometimes",
                            " you",
                            " find",
                            " in",
                            " these",
                            " hour",
                            " shows",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Tap",
                            "ert",
                            " explained",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "One",
                            " of",
                            " the",
                            " reasons",
                            " we",
                            " decided",
                            " we",
                            " wanted",
                            " to",
                            " do",
                            " a",
                            " half",
                            " hour",
                            " was",
                            " that",
                            " we",
                            " thought",
                            " that",
                            " this",
                            " was",
                            " \u2013",
                            " the",
                            " break",
                            "neck",
                            " pace",
                            " that",
                            " the",
                            " movies",
                            " often",
                            " had",
                            ",",
                            " that",
                            " really",
                            " was",
                            " the",
                            " right",
                            " format",
                            " in",
                            " the",
                            " world",
                            " of",
                            " television",
                            " for",
                            " this",
                            " particular",
                            " project",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " R",
                            "aim",
                            "i",
                            " continued",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            " Ash",
                            " Vs",
                            ".",
                            " Evil",
                            " Dead",
                            " expands",
                            " the",
                            " Evil",
                            " Dead",
                            " universe"
                        ],
                        "dataIndex": null,
                        "index": "76184",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.226,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.059,
                            2.69,
                            0,
                            0,
                            2.434,
                            4.873,
                            5.071,
                            3.183,
                            5.352,
                            9.127,
                            4.098,
                            2.73,
                            3.305,
                            0.758,
                            1.542,
                            0,
                            0,
                            10.226,
                            9.208,
                            6.617,
                            2.266,
                            0.775,
                            0.991,
                            0.187,
                            0,
                            1.749,
                            0,
                            0,
                            0,
                            0,
                            0.127,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.206,
                            1.17,
                            0.823,
                            0,
                            1.424,
                            0.056,
                            0,
                            0,
                            0,
                            0,
                            0.561,
                            0,
                            2.942,
                            6.717,
                            0,
                            1.532,
                            1.496,
                            0,
                            2.103,
                            1.06,
                            0.16,
                            0,
                            5.845,
                            1.934,
                            0,
                            0,
                            0,
                            0,
                            0.429,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:05:33.590Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13842",
            "description": "references to collaborative discussions or shared decision-making processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4492588967526625,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13842",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:45:13.019Z",
                "maxActApprox": 10.6,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13842,
                    96787,
                    45991,
                    97875,
                    397,
                    77301,
                    69078,
                    21410,
                    2315,
                    63207,
                    44267,
                    70460,
                    61029,
                    72341,
                    46969,
                    89964,
                    50429,
                    15366,
                    4039,
                    72010,
                    53704,
                    30045,
                    32076,
                    81359,
                    91579
                ],
                "topkCosSimValues": [
                    1,
                    0.4039,
                    0.3949,
                    0.39,
                    0.3729,
                    0.3727,
                    0.3715,
                    0.3588,
                    0.3588,
                    0.3579,
                    0.3547,
                    0.3491,
                    0.3419,
                    0.3286,
                    0.3224,
                    0.319,
                    0.3095,
                    0.309,
                    0.3084,
                    0.306,
                    0.3026,
                    0.302,
                    0.3014,
                    0.2959,
                    0.2948
                ],
                "neuron_alignment_indices": [
                    373,
                    481,
                    732
                ],
                "neuron_alignment_values": [
                    0.199,
                    0.171,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.008,
                    0.005
                ],
                "correlated_neurons_indices": [
                    8,
                    267,
                    598
                ],
                "correlated_neurons_pearson": [
                    0.033,
                    0.031,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.036,
                    0.033,
                    0.021
                ],
                "correlated_features_indices": [
                    13806,
                    13807,
                    13823
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_features_l1": [
                    0.007,
                    0.008,
                    0.007
                ],
                "neg_str": [
                    "sic",
                    "educ",
                    "\"]",
                    ".\")",
                    ".\"[",
                    "WH",
                    ",...",
                    "!!\"",
                    ".</",
                    "\"],\""
                ],
                "neg_values": [
                    -0.748,
                    -0.717,
                    -0.673,
                    -0.671,
                    -0.646,
                    -0.637,
                    -0.626,
                    -0.62,
                    -0.614,
                    -0.611
                ],
                "pos_str": [
                    " unsurprisingly",
                    "arently",
                    " underrated",
                    " abound",
                    " notably",
                    " admittedly",
                    " traditionally",
                    " mostly",
                    " likewise",
                    " sorely"
                ],
                "pos_values": [
                    0.781,
                    0.728,
                    0.71,
                    0.706,
                    0.667,
                    0.654,
                    0.644,
                    0.637,
                    0.626,
                    0.626
                ],
                "frac_nonzero": 0.0031,
                "freq_hist_data_bar_heights": [
                    1830,
                    1517,
                    1174,
                    985,
                    744,
                    646,
                    516,
                    436,
                    375,
                    257,
                    223,
                    181,
                    155,
                    121,
                    99,
                    82,
                    66,
                    67,
                    34,
                    41,
                    42,
                    34,
                    20,
                    16,
                    10,
                    13,
                    10,
                    15,
                    6,
                    6,
                    5,
                    3,
                    6,
                    1,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    2,
                    6,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.106,
                    0.318,
                    0.53,
                    0.742,
                    0.954,
                    1.166,
                    1.378,
                    1.59,
                    1.802,
                    2.014,
                    2.226,
                    2.438,
                    2.65,
                    2.862,
                    3.074,
                    3.286,
                    3.498,
                    3.71,
                    3.922,
                    4.134,
                    4.346,
                    4.558,
                    4.77,
                    4.982,
                    5.194,
                    5.406,
                    5.618,
                    5.83,
                    6.042,
                    6.254,
                    6.466,
                    6.678,
                    6.89,
                    7.102,
                    7.314,
                    7.526,
                    7.738,
                    7.95,
                    8.162,
                    8.374,
                    8.586,
                    8.798,
                    9.01,
                    9.222,
                    9.434,
                    9.646,
                    9.858,
                    10.07,
                    10.282,
                    10.494
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    3,
                    7,
                    7,
                    13,
                    25,
                    45,
                    85,
                    131,
                    180,
                    265,
                    437,
                    592,
                    796,
                    1105,
                    1493,
                    1988,
                    2445,
                    2819,
                    3382,
                    3612,
                    3897,
                    3997,
                    3858,
                    3645,
                    3301,
                    2863,
                    2336,
                    1900,
                    1417,
                    1059,
                    809,
                    579,
                    425,
                    250,
                    163,
                    115,
                    70,
                    52,
                    26,
                    27,
                    15,
                    11,
                    3,
                    1,
                    2,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.732,
                    -0.702,
                    -0.671,
                    -0.641,
                    -0.61,
                    -0.579,
                    -0.549,
                    -0.518,
                    -0.488,
                    -0.457,
                    -0.427,
                    -0.396,
                    -0.365,
                    -0.335,
                    -0.304,
                    -0.274,
                    -0.243,
                    -0.213,
                    -0.182,
                    -0.151,
                    -0.121,
                    -0.09,
                    -0.06,
                    -0.029,
                    0.001,
                    0.032,
                    0.063,
                    0.093,
                    0.124,
                    0.154,
                    0.185,
                    0.215,
                    0.246,
                    0.277,
                    0.307,
                    0.338,
                    0.368,
                    0.399,
                    0.429,
                    0.46,
                    0.491,
                    0.521,
                    0.552,
                    0.582,
                    0.613,
                    0.644,
                    0.674,
                    0.705,
                    0.735,
                    0.766
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to collaborative discussions or shared decision-making processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "complex phrases and references to ongoing discussions or negotiations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfhn7qlsfl10exa6fjszan",
                        "tokens": [
                            ".",
                            " Thanks",
                            " for",
                            " submitting",
                            " this",
                            "!",
                            "\n",
                            "\n",
                            "Then",
                            ",",
                            " add",
                            " the",
                            " G",
                            "PG",
                            " key",
                            ".",
                            "\n",
                            "\n",
                            "sudo",
                            " apt",
                            "-",
                            "key",
                            " adv",
                            " --",
                            "keys",
                            "erver",
                            " keys",
                            "erver",
                            ".",
                            "ubuntu",
                            ".",
                            "com",
                            " --",
                            "rec",
                            "v",
                            " C",
                            "0",
                            "A",
                            "52",
                            "C",
                            "50",
                            "\n",
                            "\n",
                            "Next",
                            ",",
                            " update",
                            " your",
                            " repositories",
                            " and",
                            " install",
                            " Un",
                            "ifi",
                            ".",
                            "\n",
                            "\n",
                            "sudo",
                            " apt",
                            "-",
                            "get",
                            " update",
                            " &&",
                            " sudo",
                            " apt",
                            "-",
                            "get",
                            " install",
                            " un",
                            "ifi",
                            "\n",
                            "\n",
                            "Now",
                            ",",
                            " start",
                            " Un",
                            "ifi",
                            ".",
                            "\n",
                            "\n",
                            "sudo",
                            " system",
                            "ctl",
                            " enable",
                            " un",
                            "ifi",
                            " sudo",
                            " system",
                            "ctl",
                            " start",
                            " un",
                            "ifi",
                            "\n",
                            "\n",
                            "Finally",
                            ",",
                            " we",
                            " need",
                            " to",
                            " disable",
                            " Mongo",
                            "DB",
                            ",",
                            " since",
                            " Uni",
                            "Fi",
                            " will",
                            " run",
                            " its",
                            " own",
                            " instance",
                            ".",
                            "\n",
                            "\n",
                            "sudo",
                            " system",
                            "ctl",
                            " stop",
                            " m",
                            "ong",
                            "od",
                            "b",
                            " sudo",
                            " system",
                            "ctl",
                            " disable",
                            " m",
                            "ong",
                            "od"
                        ],
                        "dataIndex": null,
                        "index": "13842",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.6,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.678,
                            10.6,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:21.703Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.6,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhn7rlsfm10exwqrzkucs",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " started",
                            " to",
                            " promote",
                            " it",
                            " yet",
                            " as",
                            " we",
                            "'re",
                            " still",
                            " trying",
                            " figure",
                            " out",
                            " the",
                            " target",
                            " audience",
                            " to",
                            " get",
                            " the",
                            " ball",
                            " rolling",
                            ",",
                            " so",
                            " there",
                            "'s",
                            " nothing",
                            " much",
                            " to",
                            " see",
                            " there",
                            " at",
                            " this",
                            " moment",
                            ".",
                            " Once",
                            " we",
                            " get",
                            " the",
                            " ball",
                            " rolling",
                            " then",
                            " we",
                            " will",
                            " start",
                            " to",
                            " make",
                            " some",
                            " noise",
                            " about",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "As",
                            " for",
                            " the",
                            " Exchange",
                            " House",
                            ",",
                            " that",
                            " remains",
                            " to",
                            " be",
                            " discussed",
                            " once",
                            " all",
                            " the",
                            " pieces",
                            " fall",
                            " into",
                            " place",
                            ",",
                            " such",
                            " as",
                            " regulation",
                            " and",
                            " higher",
                            " adoption",
                            " as",
                            " a",
                            " payment",
                            " method",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " added",
                            ".",
                            "\n",
                            "\n",
                            "Related",
                            " Stories",
                            ":",
                            "\n",
                            "\n",
                            "K",
                            "ed",
                            ".",
                            "ai",
                            " offers",
                            " e",
                            "-",
                            "commerce",
                            " easy",
                            " enough",
                            " for",
                            " mom",
                            "\n",
                            "\n",
                            "Invest",
                            "ing",
                            " in",
                            " Bitcoin",
                            ":",
                            " What",
                            " does",
                            " it",
                            " take",
                            "?"
                        ],
                        "dataIndex": null,
                        "index": "13842",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.32,
                        "maxValueTokenIndex": 67,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.513,
                            10.32,
                            7.206,
                            0.407,
                            0,
                            5.509,
                            2.045,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.983,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.361,
                            1.382,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:21.703Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.6,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhn7rlsfn10ex14nwtw0n",
                        "tokens": [
                            " labor",
                            " is",
                            " becoming",
                            " like",
                            " every",
                            " other",
                            " part",
                            " of",
                            " the",
                            " American",
                            " workforce",
                            ":",
                            " c",
                            "owed",
                            ",",
                            " har",
                            "ried",
                            ",",
                            " doc",
                            "ile",
                            ",",
                            " dis",
                            "em",
                            "powered",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " mac",
                            "rop",
                            "olitical",
                            " terms",
                            ",",
                            " the",
                            " erosion",
                            " of",
                            " tenure",
                            " and",
                            " shared",
                            " governance",
                            " undermines",
                            " the",
                            " power",
                            " of",
                            " a",
                            " large",
                            " body",
                            " of",
                            " liberal",
                            " professionals",
                            ".",
                            " In",
                            " this",
                            " it",
                            " resembles",
                            " the",
                            " campaign",
                            " against",
                            " teachers",
                            " unions",
                            ".",
                            " Ten",
                            "ure",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " is",
                            " a",
                            " lot",
                            " like",
                            " union",
                            "ization",
                            ":",
                            " imperfect",
                            ",",
                            " open",
                            " to",
                            " corruption",
                            " and",
                            " abuse",
                            ",",
                            " but",
                            " incom",
                            "par",
                            "ably",
                            " better",
                            " than",
                            " the",
                            " alternative",
                            ".",
                            " Indeed",
                            ",",
                            " tenure",
                            " is",
                            " what",
                            " professors",
                            " have",
                            " instead",
                            " of",
                            " unions",
                            " (",
                            "at",
                            " least",
                            " at",
                            " private",
                            " universities",
                            ",",
                            " where",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " banned",
                            " by",
                            " law",
                            " from",
                            " organizing",
                            ").",
                            " As",
                            " for",
                            " shared",
                            " governance",
                            ",",
                            " it",
                            " is",
                            " nothing"
                        ],
                        "dataIndex": null,
                        "index": "13842",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.063,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.793,
                            10.063,
                            8.868,
                            3.509
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:21.703Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.6,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "conversations about collaboration and project planning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44814974069595337,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}