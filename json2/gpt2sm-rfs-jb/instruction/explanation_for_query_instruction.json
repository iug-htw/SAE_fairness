{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "instruction"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "1143",
            "description": "instructions or steps",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7368447937461869,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "1143",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:16:32.062Z",
                "maxActApprox": 31.594,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1143,
                    5943,
                    10505,
                    8961,
                    936,
                    1162,
                    3172,
                    4454,
                    1918,
                    8529,
                    3796,
                    8070,
                    4317,
                    10700,
                    9413,
                    1811,
                    448,
                    4114,
                    513,
                    6317,
                    5294,
                    8451,
                    2082,
                    7801,
                    9109
                ],
                "topkCosSimValues": [
                    1,
                    0.6725,
                    0.6535,
                    0.6329,
                    0.6001,
                    0.5975,
                    0.589,
                    0.5796,
                    0.5644,
                    0.5585,
                    0.5531,
                    0.5477,
                    0.5416,
                    0.5415,
                    0.5299,
                    0.523,
                    0.4983,
                    0.494,
                    0.4839,
                    0.4645,
                    0.463,
                    0.4495,
                    0.4485,
                    0.4481,
                    0.4333
                ],
                "neuron_alignment_indices": [
                    718,
                    104,
                    608
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.118,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    718,
                    608,
                    104
                ],
                "correlated_neurons_pearson": [
                    0.086,
                    0.084,
                    0.075
                ],
                "correlated_neurons_l1": [
                    0.093,
                    0.094,
                    0.072
                ],
                "correlated_features_indices": [
                    1136,
                    1101,
                    1038
                ],
                "correlated_features_pearson": [
                    0.018,
                    0.009,
                    0.001
                ],
                "correlated_features_l1": [
                    0.02,
                    0.011,
                    0.004
                ],
                "neg_str": [
                    " Contributions",
                    " endorsements",
                    "spection",
                    " Perspective",
                    " folded",
                    " Observer",
                    " tong",
                    " Prosecut",
                    " Typ",
                    " copied"
                ],
                "neg_values": [
                    -0.641,
                    -0.633,
                    -0.617,
                    -0.587,
                    -0.585,
                    -0.585,
                    -0.569,
                    -0.56,
                    -0.555,
                    -0.551
                ],
                "pos_str": [
                    " ensure",
                    " maximize",
                    " minimize",
                    " avoid",
                    " facilitate",
                    " alleviate",
                    " commemorate",
                    " lessen",
                    " satisfy",
                    " prevent"
                ],
                "pos_values": [
                    1.461,
                    1.33,
                    1.319,
                    1.3,
                    1.288,
                    1.283,
                    1.265,
                    1.264,
                    1.25,
                    1.243
                ],
                "frac_nonzero": 0.00348,
                "freq_hist_data_bar_heights": [
                    1448,
                    1250,
                    956,
                    766,
                    707,
                    607,
                    542,
                    473,
                    424,
                    378,
                    307,
                    323,
                    254,
                    275,
                    219,
                    198,
                    202,
                    178,
                    167,
                    136,
                    142,
                    118,
                    95,
                    90,
                    83,
                    69,
                    73,
                    63,
                    64,
                    47,
                    38,
                    50,
                    33,
                    34,
                    34,
                    27,
                    14,
                    12,
                    19,
                    9,
                    11,
                    7,
                    2,
                    5,
                    1,
                    4,
                    1,
                    1,
                    3,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.316,
                    0.948,
                    1.58,
                    2.212,
                    2.844,
                    3.476,
                    4.108,
                    4.74,
                    5.371,
                    6.003,
                    6.635,
                    7.267,
                    7.899,
                    8.531,
                    9.163,
                    9.794,
                    10.426,
                    11.058,
                    11.69,
                    12.322,
                    12.954,
                    13.586,
                    14.217,
                    14.849,
                    15.481,
                    16.113,
                    16.745,
                    17.377,
                    18.009,
                    18.64,
                    19.272,
                    19.904,
                    20.536,
                    21.168,
                    21.8,
                    22.432,
                    23.064,
                    23.695,
                    24.327,
                    24.959,
                    25.591,
                    26.223,
                    26.855,
                    27.487,
                    28.118,
                    28.75,
                    29.382,
                    30.014,
                    30.646,
                    31.278
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    12,
                    38,
                    80,
                    185,
                    413,
                    748,
                    1266,
                    2109,
                    3003,
                    3841,
                    4704,
                    5165,
                    5070,
                    4727,
                    3993,
                    3364,
                    2742,
                    2129,
                    1644,
                    1239,
                    914,
                    717,
                    525,
                    347,
                    256,
                    207,
                    170,
                    116,
                    110,
                    84,
                    56,
                    57,
                    42,
                    38,
                    34,
                    19,
                    19,
                    14,
                    12,
                    9,
                    12,
                    4,
                    7,
                    4,
                    3,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.62,
                    -0.578,
                    -0.536,
                    -0.494,
                    -0.452,
                    -0.41,
                    -0.368,
                    -0.326,
                    -0.284,
                    -0.242,
                    -0.2,
                    -0.158,
                    -0.116,
                    -0.074,
                    -0.032,
                    0.01,
                    0.052,
                    0.094,
                    0.136,
                    0.178,
                    0.22,
                    0.262,
                    0.305,
                    0.347,
                    0.389,
                    0.431,
                    0.473,
                    0.515,
                    0.557,
                    0.599,
                    0.641,
                    0.683,
                    0.725,
                    0.767,
                    0.809,
                    0.851,
                    0.893,
                    0.935,
                    0.977,
                    1.019,
                    1.061,
                    1.103,
                    1.145,
                    1.187,
                    1.229,
                    1.272,
                    1.314,
                    1.356,
                    1.398,
                    1.44
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or steps",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtkqmkzjyai666y6oqhqfi",
                        "tokens": [
                            " or",
                            " brunch",
                            ".",
                            "\n",
                            "\n",
                            "To",
                            " prepare",
                            " the",
                            " dish",
                            ",",
                            " simply",
                            " pre",
                            "heat",
                            " your",
                            " oven",
                            " to",
                            " 425",
                            " degrees",
                            " and",
                            " place",
                            " a",
                            " cast",
                            "-",
                            "iron",
                            " or",
                            " oven",
                            "-",
                            "safe",
                            " skillet",
                            " on",
                            " the",
                            " middle",
                            " rack",
                            ".",
                            " Then",
                            ",",
                            " cut",
                            " a",
                            " medium",
                            "-",
                            "to",
                            "-",
                            "large",
                            " ripe",
                            " avocado",
                            " in",
                            " half",
                            ",",
                            " remove",
                            " the",
                            " pit",
                            ",",
                            " and",
                            " using",
                            " a",
                            " spoon",
                            ",",
                            " scoop",
                            " out",
                            " a",
                            " little",
                            " bit",
                            " more",
                            " of",
                            " the",
                            " avocado",
                            " to",
                            " make",
                            " more",
                            " room",
                            " for",
                            " the",
                            " egg",
                            ".",
                            " If",
                            " your",
                            " base",
                            " is",
                            " w",
                            "obb",
                            "ly",
                            ",",
                            " you",
                            " may",
                            " want",
                            " to",
                            " slice",
                            " a",
                            " little",
                            " of",
                            " the",
                            " skin",
                            " off",
                            " to",
                            " stabilize",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "Next",
                            ",",
                            " carefully",
                            " remove",
                            " the",
                            " heated",
                            " pan",
                            " from",
                            " the",
                            " oven",
                            " and",
                            " crack",
                            " a",
                            " small",
                            " egg",
                            " into",
                            " the",
                            " hole",
                            " of",
                            " the",
                            " avocado",
                            ",",
                            " reserv",
                            "ing",
                            " a",
                            " small",
                            " amount",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "1143",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.594,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.042,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.594,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:39.816Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.594,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtkqmkzjybi666g61i1ygr",
                        "tokens": [
                            " ones",
                            " with",
                            " be",
                            "ards",
                            "\u00e2\u0122",
                            "\u013f",
                            ".",
                            " It",
                            " was",
                            " given",
                            " by",
                            " the",
                            " Portuguese",
                            " explorers",
                            " that",
                            " arrived",
                            " on",
                            " the",
                            " island",
                            " on",
                            " the",
                            " 16",
                            "th",
                            " century",
                            ",",
                            " because",
                            " of",
                            " the",
                            " big",
                            " bearded",
                            " fig",
                            " plants",
                            " that",
                            " covered",
                            " the",
                            " islands",
                            ".",
                            "\n",
                            "\n",
                            "Since",
                            " then",
                            ",",
                            " we",
                            " have",
                            " learned",
                            " how",
                            " to",
                            " smoke",
                            " just",
                            " about",
                            " everything",
                            " from",
                            " vegetables",
                            ",",
                            " and",
                            " chees",
                            "es",
                            ",",
                            " to",
                            " sa",
                            "us",
                            "ages",
                            ",",
                            " bacon",
                            ",",
                            " and",
                            " h",
                            "ams",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " widely",
                            " believed",
                            " the",
                            " West",
                            " Indies",
                            " native",
                            " T",
                            "ain",
                            "o",
                            " people",
                            ",",
                            " a",
                            " sub",
                            "group",
                            " of",
                            " the",
                            " South",
                            " American",
                            " A",
                            "raw",
                            "aks",
                            ",",
                            " first",
                            " used",
                            " green",
                            ",",
                            " fire",
                            "-",
                            "resistant",
                            " bearded",
                            " fig",
                            " branches",
                            " for",
                            " cooking",
                            ".",
                            " They",
                            " mar",
                            "inated",
                            " foods",
                            " in",
                            " tropical",
                            " herbs",
                            " and",
                            " spices",
                            " to",
                            " enhance",
                            " natural",
                            " flavors",
                            " and",
                            " preserve",
                            " them",
                            " after",
                            " cooking",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1143",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.071,
                        "maxValueTokenIndex": 117,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.846,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.071,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:39.816Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.594,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtkqmkzjyci666bh6e0ecq",
                        "tokens": [
                            " overnight",
                            " and",
                            " then",
                            " section",
                            "ed",
                            " at",
                            " 30",
                            " \u00c2\u00b5",
                            "m",
                            " on",
                            " a",
                            " freezing",
                            " micro",
                            "t",
                            "ome",
                            " in",
                            " four",
                            " series",
                            ".",
                            " One",
                            " series",
                            " of",
                            " sections",
                            " were",
                            " processed",
                            " for",
                            " N",
                            "iss",
                            "l",
                            " st",
                            "aining",
                            " as",
                            " described",
                            " previously",
                            " [",
                            "11",
                            "]",
                            " to",
                            " evaluate",
                            " the",
                            " extent",
                            " of",
                            " the",
                            " lesions",
                            ".",
                            "\n",
                            "\n",
                            "Mod",
                            "af",
                            "in",
                            "il",
                            " (",
                            "S",
                            "igma",
                            "-",
                            "A",
                            "ld",
                            "rich",
                            ")",
                            " was",
                            " dissolved",
                            " in",
                            " sterile",
                            " saline",
                            " containing",
                            " 10",
                            "%",
                            " D",
                            "MS",
                            "O",
                            " and",
                            " 2",
                            "%",
                            " (",
                            "w",
                            "/",
                            "v",
                            ")",
                            " crem",
                            "oph",
                            "or",
                            " immediately",
                            " before",
                            " use",
                            " and",
                            " administered",
                            " intra",
                            "per",
                            "itone",
                            "ally",
                            " (",
                            "i",
                            ".",
                            "p",
                            ".)",
                            " at",
                            " 9",
                            " A",
                            ".",
                            "M",
                            ".",
                            " on",
                            " the",
                            " experimental",
                            " day",
                            " at",
                            " a",
                            " dose",
                            " of",
                            " 90",
                            " mg",
                            "/",
                            "kg",
                            ".",
                            " For",
                            " baseline",
                            " date",
                            ",",
                            " rats",
                            " were",
                            " injected",
                            " i",
                            ".",
                            "p",
                            ".",
                            " with",
                            " vehicle"
                        ],
                        "dataIndex": null,
                        "index": "1143",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.896,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.896,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:39.816Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.594,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17912",
            "description": "instructions and guidelines",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.731266975402832,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17912",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:40.710Z",
                "maxActApprox": 42.225,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17912,
                    4816,
                    10990,
                    18268,
                    18493,
                    9365,
                    8581,
                    15464,
                    24042,
                    7804,
                    14474,
                    18784,
                    23777,
                    10584,
                    21367,
                    21326,
                    21038,
                    2537,
                    15452,
                    1353,
                    13224,
                    12295,
                    15085,
                    17758,
                    17853
                ],
                "topkCosSimValues": [
                    1,
                    0.5684,
                    0.4935,
                    0.4345,
                    0.4115,
                    0.3998,
                    0.3943,
                    0.3873,
                    0.3842,
                    0.3722,
                    0.3708,
                    0.3654,
                    0.3633,
                    0.3604,
                    0.3474,
                    0.3455,
                    0.3444,
                    0.3425,
                    0.3415,
                    0.3388,
                    0.3382,
                    0.3342,
                    0.3304,
                    0.3302,
                    0.329
                ],
                "neuron_alignment_indices": [
                    679,
                    45,
                    739
                ],
                "neuron_alignment_values": [
                    0.186,
                    0.094,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    679,
                    540,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.017,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.019,
                    0.017
                ],
                "correlated_features_indices": [
                    17865,
                    17869,
                    17870
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "bish",
                    "secution",
                    "buck",
                    "gets",
                    "oner",
                    " Mississ",
                    "prus",
                    "itus",
                    " Native",
                    " martyr"
                ],
                "neg_values": [
                    -0.654,
                    -0.63,
                    -0.584,
                    -0.576,
                    -0.576,
                    -0.573,
                    -0.572,
                    -0.568,
                    -0.552,
                    -0.547
                ],
                "pos_str": [
                    " manuals",
                    " booklet",
                    "eering",
                    " manual",
                    "auri",
                    " instruct",
                    " instructed",
                    " instructions",
                    "Instruct",
                    " Manual"
                ],
                "pos_values": [
                    1.043,
                    0.993,
                    0.963,
                    0.922,
                    0.882,
                    0.851,
                    0.846,
                    0.831,
                    0.798,
                    0.791
                ],
                "frac_nonzero": 0.00036,
                "freq_hist_data_bar_heights": [
                    297,
                    190,
                    126,
                    99,
                    55,
                    54,
                    46,
                    33,
                    22,
                    20,
                    17,
                    18,
                    10,
                    13,
                    10,
                    6,
                    5,
                    4,
                    4,
                    3,
                    2,
                    5,
                    5,
                    3,
                    0,
                    1,
                    1,
                    1,
                    3,
                    4,
                    2,
                    3,
                    4,
                    3,
                    2,
                    6,
                    7,
                    4,
                    7,
                    7,
                    6,
                    5,
                    5,
                    4,
                    3,
                    3,
                    3,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.424,
                    1.269,
                    2.113,
                    2.958,
                    3.802,
                    4.646,
                    5.491,
                    6.335,
                    7.18,
                    8.024,
                    8.869,
                    9.713,
                    10.558,
                    11.402,
                    12.247,
                    13.091,
                    13.936,
                    14.78,
                    15.624,
                    16.469,
                    17.313,
                    18.158,
                    19.002,
                    19.847,
                    20.691,
                    21.536,
                    22.38,
                    23.225,
                    24.069,
                    24.914,
                    25.758,
                    26.603,
                    27.447,
                    28.291,
                    29.136,
                    29.98,
                    30.825,
                    31.669,
                    32.514,
                    33.358,
                    34.203,
                    35.047,
                    35.892,
                    36.736,
                    37.581,
                    38.425,
                    39.269,
                    40.114,
                    40.958,
                    41.803
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    7,
                    21,
                    28,
                    70,
                    106,
                    190,
                    316,
                    466,
                    702,
                    1125,
                    1496,
                    2042,
                    2620,
                    3097,
                    3720,
                    4044,
                    4352,
                    4330,
                    4236,
                    3748,
                    3177,
                    2657,
                    2067,
                    1569,
                    1219,
                    867,
                    646,
                    462,
                    298,
                    184,
                    127,
                    101,
                    64,
                    29,
                    21,
                    14,
                    10,
                    5,
                    5,
                    5,
                    4,
                    1,
                    2,
                    1,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.637,
                    -0.603,
                    -0.569,
                    -0.535,
                    -0.501,
                    -0.467,
                    -0.433,
                    -0.399,
                    -0.365,
                    -0.331,
                    -0.297,
                    -0.263,
                    -0.23,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.094,
                    -0.06,
                    -0.026,
                    0.008,
                    0.042,
                    0.076,
                    0.11,
                    0.144,
                    0.178,
                    0.212,
                    0.246,
                    0.279,
                    0.313,
                    0.347,
                    0.381,
                    0.415,
                    0.449,
                    0.483,
                    0.517,
                    0.551,
                    0.585,
                    0.619,
                    0.653,
                    0.687,
                    0.721,
                    0.754,
                    0.788,
                    0.822,
                    0.856,
                    0.89,
                    0.924,
                    0.958,
                    0.992,
                    1.026
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions and guidelines",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmtvlih0wgi666uhde0vl2",
                        "tokens": [
                            " Protein",
                            " Dat",
                            "ab",
                            "ank",
                            ",",
                            " inter",
                            "disciplinary",
                            " researchers",
                            ",",
                            " and",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " located",
                            " in",
                            " Bi",
                            "otech",
                            " Beach",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "N",
                            "ano",
                            "-",
                            "one",
                            " is",
                            " now",
                            " being",
                            " tested",
                            " in",
                            " the",
                            " UC",
                            " San",
                            " Diego",
                            " Chemistry",
                            " Department",
                            " and",
                            " in",
                            " the",
                            " consumer",
                            " market",
                            " for",
                            " workflow",
                            " integration",
                            ",",
                            " modeling",
                            " precision",
                            ",",
                            " and",
                            " optimal",
                            " pattern",
                            "-",
                            "recogn",
                            "ition",
                            " and",
                            " discovery",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " nano",
                            "-",
                            "one",
                            " was",
                            " being",
                            " developed",
                            ",",
                            " McCl",
                            "os",
                            "key",
                            " and",
                            " his",
                            " colleagues",
                            " had",
                            " an",
                            " idea",
                            " for",
                            " another",
                            " VR",
                            " tool",
                            " that",
                            " would",
                            " help",
                            " engineers",
                            " with",
                            " math",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "When",
                            " I",
                            " was",
                            " in",
                            " Vector",
                            " Cal",
                            "culus",
                            " as",
                            " a",
                            " Nano",
                            "Engine",
                            "ering",
                            " major",
                            ",",
                            " I",
                            " wanted",
                            " better",
                            " 3",
                            "D",
                            " graphics",
                            " to",
                            " go",
                            " along",
                            " with",
                            " the",
                            " instruction",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said"
                        ],
                        "dataIndex": null,
                        "index": "17912",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.225,
                        "maxValueTokenIndex": 122,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.225,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:48.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.225,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtvljh0whi666bl3j5uof",
                        "tokens": [
                            "\u013b",
                            "t",
                            " working",
                            " and",
                            " that",
                            " the",
                            " front",
                            " part",
                            " of",
                            " a",
                            " chest",
                            " of",
                            " draw",
                            "ers",
                            " fell",
                            " off",
                            " then",
                            " they",
                            " opened",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " added",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " were",
                            " instructions",
                            " on",
                            " how",
                            " to",
                            " make",
                            " a",
                            " phone",
                            " call",
                            ",",
                            " we",
                            " would",
                            " have",
                            " had",
                            " a",
                            " job",
                            " as",
                            " there",
                            " was",
                            " no",
                            " phone",
                            "!!",
                            " The",
                            " wallpaper",
                            " was",
                            " pe",
                            "eling",
                            " off",
                            " the",
                            " walls",
                            ",",
                            " the",
                            " carpet",
                            " was",
                            " thin",
                            ",",
                            " dirty",
                            " and",
                            " stained",
                            ".",
                            " The",
                            " bed",
                            " was",
                            " something",
                            " else",
                            ",",
                            " it",
                            " must",
                            " have",
                            " come",
                            " out",
                            " of",
                            " the",
                            " ar",
                            "k",
                            ",",
                            " the",
                            " base",
                            " was",
                            " all",
                            " sc",
                            "uffed",
                            " and",
                            " dirty",
                            " and",
                            " the",
                            " springs",
                            " in",
                            " the",
                            " mattress",
                            " attacked",
                            " you",
                            " in",
                            " the",
                            " night",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "After",
                            " describing",
                            " the",
                            " breakfast",
                            " as",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "j",
                            "oke",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " he",
                            " concluded",
                            ":",
                            " \u00e2\u0122",
                            "\u013e"
                        ],
                        "dataIndex": null,
                        "index": "17912",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.934,
                        "maxValueTokenIndex": 30,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.934,
                            8.811,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:48.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.225,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtvllh0x0i666ntj1nkxh",
                        "tokens": [
                            "\u013b",
                            "t",
                            " working",
                            " and",
                            " that",
                            " the",
                            " front",
                            " part",
                            " of",
                            " a",
                            " chest",
                            " of",
                            " draw",
                            "ers",
                            " fell",
                            " off",
                            " then",
                            " they",
                            " opened",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " added",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " were",
                            " instructions",
                            " on",
                            " how",
                            " to",
                            " make",
                            " a",
                            " phone",
                            " call",
                            ",",
                            " we",
                            " would",
                            " have",
                            " had",
                            " a",
                            " job",
                            " as",
                            " there",
                            " was",
                            " no",
                            " phone",
                            "!!",
                            " The",
                            " wallpaper",
                            " was",
                            " pe",
                            "eling",
                            " off",
                            " the",
                            " walls",
                            ",",
                            " the",
                            " carpet",
                            " was",
                            " thin",
                            ",",
                            " dirty",
                            " and",
                            " stained",
                            ".",
                            " The",
                            " bed",
                            " was",
                            " something",
                            " else",
                            ",",
                            " it",
                            " must",
                            " have",
                            " come",
                            " out",
                            " of",
                            " the",
                            " ar",
                            "k",
                            ",",
                            " the",
                            " base",
                            " was",
                            " all",
                            " sc",
                            "uffed",
                            " and",
                            " dirty",
                            " and",
                            " the",
                            " springs",
                            " in",
                            " the",
                            " mattress",
                            " attacked",
                            " you",
                            " in",
                            " the",
                            " night",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "After",
                            " describing",
                            " the",
                            " breakfast",
                            " as",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "j",
                            "oke",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " he",
                            " concluded",
                            ":",
                            " \u00e2\u0122",
                            "\u013e"
                        ],
                        "dataIndex": null,
                        "index": "17912",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.934,
                        "maxValueTokenIndex": 30,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.934,
                            8.811,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:48.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 33.78,
                        "binMax": 42.225,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "6706",
            "description": "instructions and explanations",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7263651490211487,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "6706",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:25:06.504Z",
                "maxActApprox": 20.028,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    6706,
                    4106,
                    1199,
                    6514,
                    9396,
                    3569,
                    6414,
                    12220,
                    1220,
                    8638,
                    3343,
                    10917,
                    3965,
                    1500,
                    11989,
                    9285,
                    6163,
                    8138,
                    6142,
                    8249,
                    8909,
                    4158,
                    7092,
                    6488,
                    7578
                ],
                "topkCosSimValues": [
                    1,
                    0.5058,
                    0.5056,
                    0.4934,
                    0.4806,
                    0.4631,
                    0.462,
                    0.4552,
                    0.4471,
                    0.442,
                    0.4393,
                    0.4377,
                    0.432,
                    0.4275,
                    0.427,
                    0.4234,
                    0.4233,
                    0.4229,
                    0.4164,
                    0.4163,
                    0.411,
                    0.3993,
                    0.3988,
                    0.397,
                    0.3968
                ],
                "neuron_alignment_indices": [
                    517,
                    427,
                    43
                ],
                "neuron_alignment_values": [
                    0.103,
                    0.102,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    43,
                    297,
                    546
                ],
                "correlated_neurons_pearson": [
                    0.104,
                    0.084,
                    0.083
                ],
                "correlated_neurons_l1": [
                    0.094,
                    0.081,
                    0.082
                ],
                "correlated_features_indices": [
                    6750,
                    6703,
                    6667
                ],
                "correlated_features_pearson": [
                    0.045,
                    0.039,
                    0.025
                ],
                "correlated_features_l1": [
                    0.047,
                    0.043,
                    0.028
                ],
                "neg_str": [
                    "\u0143\u0136",
                    "olars",
                    "uscript",
                    "Newsletter",
                    "ument",
                    "\u2014",
                    ")\u2014",
                    "enance",
                    "itational",
                    "\u00c5\u00ab"
                ],
                "neg_values": [
                    -0.671,
                    -0.643,
                    -0.641,
                    -0.628,
                    -0.626,
                    -0.613,
                    -0.604,
                    -0.603,
                    -0.591,
                    -0.591
                ],
                "pos_str": [
                    " namely",
                    " ie",
                    " BUT",
                    " etc",
                    " haha",
                    " whereas",
                    " but",
                    " although",
                    "but",
                    " aka"
                ],
                "pos_values": [
                    1.275,
                    1.141,
                    1.134,
                    1.106,
                    1.098,
                    1.086,
                    1.033,
                    1.019,
                    0.985,
                    0.979
                ],
                "frac_nonzero": 0.006939999999999999,
                "freq_hist_data_bar_heights": [
                    2751,
                    2438,
                    2071,
                    1882,
                    1647,
                    1424,
                    1266,
                    1031,
                    885,
                    811,
                    688,
                    630,
                    564,
                    470,
                    442,
                    374,
                    338,
                    283,
                    188,
                    182,
                    187,
                    174,
                    163,
                    121,
                    111,
                    93,
                    87,
                    74,
                    59,
                    57,
                    50,
                    57,
                    39,
                    40,
                    17,
                    16,
                    20,
                    13,
                    21,
                    13,
                    7,
                    6,
                    6,
                    12,
                    3,
                    2,
                    3,
                    2,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.2,
                    0.601,
                    1.001,
                    1.402,
                    1.803,
                    2.203,
                    2.604,
                    3.004,
                    3.405,
                    3.805,
                    4.206,
                    4.606,
                    5.007,
                    5.408,
                    5.808,
                    6.209,
                    6.609,
                    7.01,
                    7.41,
                    7.811,
                    8.211,
                    8.612,
                    9.012,
                    9.413,
                    9.814,
                    10.214,
                    10.615,
                    11.015,
                    11.416,
                    11.816,
                    12.217,
                    12.617,
                    13.018,
                    13.419,
                    13.819,
                    14.22,
                    14.62,
                    15.021,
                    15.421,
                    15.822,
                    16.222,
                    16.623,
                    17.023,
                    17.424,
                    17.825,
                    18.225,
                    18.626,
                    19.026,
                    19.427,
                    19.827
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    17,
                    18,
                    36,
                    71,
                    135,
                    253,
                    456,
                    820,
                    1291,
                    1885,
                    2583,
                    3343,
                    4119,
                    4564,
                    4792,
                    4901,
                    4608,
                    4096,
                    3342,
                    2728,
                    2057,
                    1430,
                    956,
                    607,
                    394,
                    258,
                    153,
                    101,
                    57,
                    45,
                    32,
                    24,
                    16,
                    14,
                    14,
                    2,
                    5,
                    10,
                    1,
                    3,
                    4,
                    2,
                    0,
                    3,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.652,
                    -0.613,
                    -0.574,
                    -0.535,
                    -0.496,
                    -0.457,
                    -0.418,
                    -0.379,
                    -0.34,
                    -0.302,
                    -0.263,
                    -0.224,
                    -0.185,
                    -0.146,
                    -0.107,
                    -0.068,
                    -0.029,
                    0.01,
                    0.049,
                    0.088,
                    0.126,
                    0.165,
                    0.204,
                    0.243,
                    0.282,
                    0.321,
                    0.36,
                    0.399,
                    0.438,
                    0.477,
                    0.516,
                    0.555,
                    0.593,
                    0.632,
                    0.671,
                    0.71,
                    0.749,
                    0.788,
                    0.827,
                    0.866,
                    0.905,
                    0.944,
                    0.983,
                    1.022,
                    1.06,
                    1.099,
                    1.138,
                    1.177,
                    1.216,
                    1.255
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions and explanations",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtvpl24w6hi666hqlosaa5",
                        "tokens": [
                            "This",
                            " is",
                            " my",
                            " first",
                            " attempt",
                            " the",
                            " baby",
                            " fro",
                            "ck",
                            ",",
                            " this",
                            " is",
                            " for",
                            " the",
                            " 3",
                            " months",
                            " baby",
                            " girl",
                            " fro",
                            "ck",
                            "/",
                            "dress",
                            ".",
                            " its",
                            " very",
                            " easy",
                            " pattern",
                            " not",
                            " very",
                            " difficult",
                            ".",
                            " it",
                            " is",
                            " very",
                            " simple",
                            " and",
                            " easy",
                            " to",
                            " understand",
                            ".",
                            " Some",
                            " time",
                            " when",
                            " i",
                            " cro",
                            "che",
                            "ted",
                            " things",
                            " for",
                            " my",
                            " own",
                            " relatives",
                            " so",
                            ",",
                            " I",
                            " always",
                            " want",
                            " to",
                            " share",
                            " my",
                            " friends",
                            " also",
                            ",",
                            " this",
                            " is",
                            " very",
                            " perfect",
                            " item",
                            " for",
                            " yours",
                            " babies",
                            ".",
                            " And",
                            " also",
                            " you",
                            " gifted",
                            " to",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " have",
                            " to",
                            " need",
                            " some",
                            " different",
                            " colors",
                            " yarn",
                            " for",
                            " this",
                            " bay",
                            " girl",
                            " fro",
                            "ck",
                            ",",
                            " and",
                            " a",
                            " crochet",
                            " hook",
                            " to",
                            " fit",
                            " in",
                            " the",
                            " yarn",
                            " gauge",
                            ".",
                            " I",
                            " used",
                            " worst",
                            "ed",
                            " 4",
                            " ply",
                            " yarn",
                            "s",
                            " to",
                            " fit",
                            " gauge",
                            " for",
                            " this",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " need",
                            " to",
                            " share"
                        ],
                        "dataIndex": null,
                        "index": "6706",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.028,
                        "maxValueTokenIndex": 95,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.691,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.296,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.018,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.484,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.435,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.271,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.028,
                            1.878,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.765,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.849,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:11.726Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 20.028,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtvpl24w6ji6663j5jo7xo",
                        "tokens": [
                            " a",
                            " great",
                            " exercise",
                            " so",
                            " watch",
                            " the",
                            " movie",
                            " and",
                            " try",
                            " it",
                            " out",
                            " yourself",
                            "!",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            " if",
                            " you",
                            " have",
                            " any",
                            " questions",
                            ",",
                            " I",
                            " am",
                            " waiting",
                            " for",
                            " comments",
                            ",",
                            " I",
                            "'d",
                            " be",
                            " happy",
                            " to",
                            " give",
                            " additional",
                            " explanations",
                            ".",
                            "\n",
                            "\n",
                            "..",
                            "::",
                            " DOWN",
                            "LOAD",
                            " VIDEO",
                            "-",
                            "T",
                            "UT",
                            "OR",
                            "IAL",
                            " ::",
                            "..",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " for",
                            " download",
                            " is",
                            " in",
                            " much",
                            " better",
                            " quality",
                            ",",
                            " bigger",
                            " resolution",
                            " and",
                            " without",
                            " speed",
                            " up",
                            ",",
                            " so",
                            " you",
                            " can",
                            " see",
                            " clearly",
                            " what",
                            " I",
                            " am",
                            " doing",
                            " in",
                            " each",
                            " step",
                            ".",
                            " Just",
                            " download",
                            " it",
                            ",",
                            " watch",
                            " and",
                            " try",
                            " to",
                            " draw",
                            " the",
                            " bird",
                            " yourself",
                            "!",
                            "\n",
                            "\n",
                            "At",
                            " first",
                            " I",
                            " just",
                            " try",
                            " to",
                            " grasp",
                            " the",
                            " base",
                            " shape",
                            ",",
                            " only",
                            " after",
                            " I",
                            " can",
                            " see",
                            " it",
                            ",",
                            " I",
                            " add",
                            " new",
                            " layer",
                            " and",
                            " sketch",
                            " all",
                            " the",
                            " details",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "6706",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.399,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.988,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.399,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.81,
                            0,
                            0,
                            0,
                            10.086,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.35,
                            4.116,
                            0.2,
                            0,
                            0,
                            0,
                            0,
                            12.491,
                            0,
                            0,
                            0,
                            0,
                            0.956,
                            0,
                            0,
                            0,
                            0,
                            2.207
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:11.726Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 20.028,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtvpl24w6ii666it4hiro6",
                        "tokens": [
                            " a",
                            " great",
                            " exercise",
                            " so",
                            " watch",
                            " the",
                            " movie",
                            " and",
                            " try",
                            " it",
                            " out",
                            " yourself",
                            "!",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            " if",
                            " you",
                            " have",
                            " any",
                            " questions",
                            ",",
                            " I",
                            " am",
                            " waiting",
                            " for",
                            " comments",
                            ",",
                            " I",
                            "'d",
                            " be",
                            " happy",
                            " to",
                            " give",
                            " additional",
                            " explanations",
                            ".",
                            "\n",
                            "\n",
                            "..",
                            "::",
                            " DOWN",
                            "LOAD",
                            " VIDEO",
                            "-",
                            "T",
                            "UT",
                            "OR",
                            "IAL",
                            " ::",
                            "..",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " for",
                            " download",
                            " is",
                            " in",
                            " much",
                            " better",
                            " quality",
                            ",",
                            " bigger",
                            " resolution",
                            " and",
                            " without",
                            " speed",
                            " up",
                            ",",
                            " so",
                            " you",
                            " can",
                            " see",
                            " clearly",
                            " what",
                            " I",
                            " am",
                            " doing",
                            " in",
                            " each",
                            " step",
                            ".",
                            " Just",
                            " download",
                            " it",
                            ",",
                            " watch",
                            " and",
                            " try",
                            " to",
                            " draw",
                            " the",
                            " bird",
                            " yourself",
                            "!",
                            "\n",
                            "\n",
                            "At",
                            " first",
                            " I",
                            " just",
                            " try",
                            " to",
                            " grasp",
                            " the",
                            " base",
                            " shape",
                            ",",
                            " only",
                            " after",
                            " I",
                            " can",
                            " see",
                            " it",
                            ",",
                            " I",
                            " add",
                            " new",
                            " layer",
                            " and",
                            " sketch",
                            " all",
                            " the",
                            " details",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "6706",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.399,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.988,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.399,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.81,
                            0,
                            0,
                            0,
                            10.086,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.35,
                            4.116,
                            0.2,
                            0,
                            0,
                            0,
                            0,
                            12.491,
                            0,
                            0,
                            0,
                            0,
                            0.956,
                            0,
                            0,
                            0,
                            0,
                            2.207
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:11.726Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 20.028,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "5126",
            "description": "instructions or steps to follow",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7183077335357666,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "5126",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:22:53.083Z",
                "maxActApprox": 50.025,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5126,
                    11756,
                    6504,
                    8883,
                    6701,
                    6579,
                    9421,
                    10338,
                    6470,
                    77,
                    274,
                    6677,
                    6920,
                    1495,
                    10264,
                    12181,
                    2404,
                    3171,
                    1531,
                    12110,
                    778,
                    9924,
                    11101,
                    7229,
                    6616
                ],
                "topkCosSimValues": [
                    1,
                    0.4386,
                    0.4329,
                    0.4014,
                    0.39,
                    0.3839,
                    0.3735,
                    0.3706,
                    0.3612,
                    0.3445,
                    0.3421,
                    0.331,
                    0.3297,
                    0.329,
                    0.3231,
                    0.3185,
                    0.3138,
                    0.311,
                    0.3106,
                    0.3055,
                    0.2989,
                    0.2973,
                    0.2966,
                    0.2961,
                    0.294
                ],
                "neuron_alignment_indices": [
                    665,
                    151,
                    619
                ],
                "neuron_alignment_values": [
                    0.155,
                    0.11,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    271,
                    619
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.021,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.019,
                    0.019
                ],
                "correlated_features_indices": [
                    5241,
                    5186,
                    5220
                ],
                "correlated_features_pearson": [
                    0.031,
                    0.01,
                    0.004
                ],
                "correlated_features_l1": [
                    0.032,
                    0.011,
                    0.005
                ],
                "neg_str": [
                    "tek",
                    "ton",
                    "aez",
                    "bie",
                    "lder",
                    "tal",
                    "ty",
                    "cup",
                    "tu",
                    "aptic"
                ],
                "neg_values": [
                    -0.865,
                    -0.777,
                    -0.763,
                    -0.755,
                    -0.712,
                    -0.71,
                    -0.703,
                    -0.696,
                    -0.692,
                    -0.678
                ],
                "pos_str": [
                    " onward",
                    " cautiously",
                    " onwards",
                    " Proceed",
                    " through",
                    " blindly",
                    " withd",
                    " towards",
                    " smoothly",
                    " calmly"
                ],
                "pos_values": [
                    0.971,
                    0.915,
                    0.892,
                    0.869,
                    0.787,
                    0.776,
                    0.77,
                    0.769,
                    0.754,
                    0.74
                ],
                "frac_nonzero": 0.00083,
                "freq_hist_data_bar_heights": [
                    829,
                    528,
                    389,
                    257,
                    167,
                    88,
                    69,
                    54,
                    39,
                    23,
                    13,
                    9,
                    4,
                    7,
                    7,
                    9,
                    8,
                    7,
                    12,
                    4,
                    0,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    3,
                    0,
                    0,
                    1,
                    1,
                    3,
                    1,
                    1,
                    8,
                    7,
                    5,
                    10,
                    10,
                    8,
                    8,
                    5,
                    6,
                    4,
                    3,
                    2,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.501,
                    1.502,
                    2.502,
                    3.503,
                    4.503,
                    5.504,
                    6.504,
                    7.505,
                    8.505,
                    9.506,
                    10.506,
                    11.507,
                    12.507,
                    13.507,
                    14.508,
                    15.508,
                    16.509,
                    17.509,
                    18.51,
                    19.51,
                    20.511,
                    21.511,
                    22.512,
                    23.512,
                    24.513,
                    25.513,
                    26.514,
                    27.514,
                    28.515,
                    29.515,
                    30.516,
                    31.516,
                    32.516,
                    33.517,
                    34.517,
                    35.518,
                    36.518,
                    37.519,
                    38.519,
                    39.52,
                    40.52,
                    41.521,
                    42.521,
                    43.522,
                    44.522,
                    45.523,
                    46.523,
                    47.524,
                    48.524,
                    49.524
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    3,
                    0,
                    5,
                    9,
                    10,
                    15,
                    29,
                    58,
                    117,
                    174,
                    259,
                    389,
                    606,
                    946,
                    1221,
                    1763,
                    2262,
                    3001,
                    3487,
                    3978,
                    4366,
                    4431,
                    4387,
                    4019,
                    3586,
                    2992,
                    2395,
                    1796,
                    1307,
                    859,
                    666,
                    393,
                    237,
                    184,
                    95,
                    70,
                    55,
                    34,
                    17,
                    15,
                    7,
                    4,
                    5,
                    0,
                    0,
                    2,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.847,
                    -0.81,
                    -0.773,
                    -0.736,
                    -0.7,
                    -0.663,
                    -0.626,
                    -0.59,
                    -0.553,
                    -0.516,
                    -0.479,
                    -0.443,
                    -0.406,
                    -0.369,
                    -0.332,
                    -0.296,
                    -0.259,
                    -0.222,
                    -0.186,
                    -0.149,
                    -0.112,
                    -0.075,
                    -0.039,
                    -0.002,
                    0.035,
                    0.072,
                    0.108,
                    0.145,
                    0.182,
                    0.218,
                    0.255,
                    0.292,
                    0.329,
                    0.365,
                    0.402,
                    0.439,
                    0.476,
                    0.512,
                    0.549,
                    0.586,
                    0.622,
                    0.659,
                    0.696,
                    0.733,
                    0.769,
                    0.806,
                    0.843,
                    0.88,
                    0.916,
                    0.953
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or steps to follow",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtsr443dkzi66656ft32ak",
                        "tokens": [
                            " up",
                            " uses",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "pal",
                            "ms",
                            " in",
                            "\u00e2\u0122",
                            "\u013f",
                            " grip",
                            ".",
                            "\n",
                            "\n",
                            "Body",
                            "weight",
                            " R",
                            "ows",
                            "/",
                            " In",
                            "verted",
                            " R",
                            "ows",
                            ":",
                            " When",
                            " was",
                            " the",
                            " last",
                            " time",
                            " you",
                            " saw",
                            " someone",
                            " at",
                            " the",
                            " gym",
                            " using",
                            " this",
                            " exercise",
                            "?",
                            " Yeah",
                            ",",
                            " I",
                            " never",
                            " do",
                            " either",
                            ".",
                            " Simply",
                            " use",
                            " a",
                            " Smith",
                            " Machine",
                            " and",
                            " set",
                            " the",
                            " bar",
                            " below",
                            " your",
                            " waist",
                            ".",
                            " Proceed",
                            " to",
                            " sit",
                            " down",
                            " on",
                            " the",
                            " floor",
                            ",",
                            " grab",
                            " the",
                            " bar",
                            " and",
                            " with",
                            " your",
                            " back",
                            " flat",
                            " and",
                            " facing",
                            " the",
                            " floor",
                            " you",
                            " then",
                            " do",
                            " a",
                            " ro",
                            "wing",
                            " movement",
                            ".",
                            " For",
                            " the",
                            " easier",
                            " version",
                            " of",
                            " this",
                            " exercise",
                            " keep",
                            " your",
                            " heels",
                            " resting",
                            " on",
                            " the",
                            " floor",
                            ".",
                            " If",
                            " you",
                            " prefer",
                            " a",
                            " challenge",
                            " lift",
                            " your",
                            " feet",
                            " off",
                            " the",
                            " floor",
                            " and",
                            " leave",
                            " your",
                            " body",
                            " suspended",
                            ",",
                            " then",
                            " proceed",
                            " with",
                            " performing",
                            " a",
                            " row",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "5126",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.025,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.025,
                            8.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.334,
                            3.166,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:53.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.025,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtsr453dlbi66695zn51km",
                        "tokens": [
                            " up",
                            " uses",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "pal",
                            "ms",
                            " in",
                            "\u00e2\u0122",
                            "\u013f",
                            " grip",
                            ".",
                            "\n",
                            "\n",
                            "Body",
                            "weight",
                            " R",
                            "ows",
                            "/",
                            " In",
                            "verted",
                            " R",
                            "ows",
                            ":",
                            " When",
                            " was",
                            " the",
                            " last",
                            " time",
                            " you",
                            " saw",
                            " someone",
                            " at",
                            " the",
                            " gym",
                            " using",
                            " this",
                            " exercise",
                            "?",
                            " Yeah",
                            ",",
                            " I",
                            " never",
                            " do",
                            " either",
                            ".",
                            " Simply",
                            " use",
                            " a",
                            " Smith",
                            " Machine",
                            " and",
                            " set",
                            " the",
                            " bar",
                            " below",
                            " your",
                            " waist",
                            ".",
                            " Proceed",
                            " to",
                            " sit",
                            " down",
                            " on",
                            " the",
                            " floor",
                            ",",
                            " grab",
                            " the",
                            " bar",
                            " and",
                            " with",
                            " your",
                            " back",
                            " flat",
                            " and",
                            " facing",
                            " the",
                            " floor",
                            " you",
                            " then",
                            " do",
                            " a",
                            " ro",
                            "wing",
                            " movement",
                            ".",
                            " For",
                            " the",
                            " easier",
                            " version",
                            " of",
                            " this",
                            " exercise",
                            " keep",
                            " your",
                            " heels",
                            " resting",
                            " on",
                            " the",
                            " floor",
                            ".",
                            " If",
                            " you",
                            " prefer",
                            " a",
                            " challenge",
                            " lift",
                            " your",
                            " feet",
                            " off",
                            " the",
                            " floor",
                            " and",
                            " leave",
                            " your",
                            " body",
                            " suspended",
                            ",",
                            " then",
                            " proceed",
                            " with",
                            " performing",
                            " a",
                            " row",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "5126",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.025,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.025,
                            8.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.334,
                            3.166,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:53.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.025,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtsr443dl0i666v90cvstp",
                        "tokens": [
                            " period",
                            ".",
                            "\n",
                            "\n",
                            "2",
                            ")",
                            " Start",
                            " the",
                            " post",
                            " by",
                            " stating",
                            " the",
                            " approximate",
                            " number",
                            " of",
                            " years",
                            " you",
                            " trip",
                            " and",
                            " how",
                            " many",
                            " trips",
                            " you",
                            " estimate",
                            " to",
                            " have",
                            " had",
                            ".",
                            " If",
                            " you",
                            " don",
                            "'t",
                            " do",
                            " this",
                            ",",
                            " your",
                            " post",
                            " may",
                            " be",
                            " removed",
                            " immediately",
                            " as",
                            " we",
                            " do",
                            " not",
                            " want",
                            " speculation",
                            " but",
                            " actual",
                            " veteran",
                            " advice",
                            " from",
                            " actual",
                            " veterans",
                            ".",
                            "\n",
                            "\n",
                            "3",
                            ")",
                            " Proceed",
                            " to",
                            " give",
                            " your",
                            " advice",
                            ".",
                            " You",
                            " may",
                            " make",
                            " multiple",
                            " posts",
                            " throughout",
                            " the",
                            " thread",
                            " if",
                            " you",
                            " have",
                            " more",
                            " advice",
                            " to",
                            " share",
                            ",",
                            " but",
                            " start",
                            " it",
                            " off",
                            " by",
                            " stating",
                            " your",
                            " 2",
                            ")",
                            " experience",
                            " level",
                            " every",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "4",
                            ")",
                            " DO",
                            " NOT",
                            " reply",
                            " to",
                            " posts",
                            ",",
                            " do",
                            " not",
                            " ask",
                            " questions",
                            ",",
                            " simply",
                            " state",
                            " your",
                            " experience",
                            " level",
                            " and",
                            " advice",
                            " -",
                            " or",
                            " stick",
                            " to",
                            " reading",
                            " the",
                            " thread",
                            " only",
                            ".",
                            " Reply"
                        ],
                        "dataIndex": null,
                        "index": "5126",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.807,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.807,
                            7.347,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:53.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.025,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs3072-jb",
            "index": "2138",
            "description": "commands or instructional information",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7153505086898804,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs3072-jb",
                "index": "2138",
                "sourceSetName": "res_fs3072-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:42:39.109Z",
                "maxActApprox": 49.111,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2138,
                    1956,
                    1519,
                    87,
                    2183,
                    2135,
                    1164,
                    929,
                    1176,
                    558,
                    442,
                    861,
                    1006,
                    907,
                    74,
                    1148,
                    2739,
                    777,
                    677,
                    729,
                    459,
                    386,
                    256,
                    352,
                    258
                ],
                "topkCosSimValues": [
                    1,
                    0.3369,
                    0.2918,
                    0.242,
                    0.2036,
                    0.202,
                    0.1996,
                    0.1917,
                    0.1853,
                    0.1825,
                    0.1761,
                    0.1619,
                    0.1608,
                    0.1573,
                    0.1534,
                    0.1527,
                    0.1524,
                    0.1502,
                    0.1497,
                    0.1476,
                    0.1449,
                    0.1439,
                    0.1397,
                    0.1396,
                    0.1328
                ],
                "neuron_alignment_indices": [
                    767,
                    209,
                    160
                ],
                "neuron_alignment_values": [
                    0.101,
                    0.099,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    767,
                    354,
                    696
                ],
                "correlated_neurons_pearson": [
                    0.072,
                    0.065,
                    0.062
                ],
                "correlated_neurons_l1": [
                    0.066,
                    0.072,
                    0.077
                ],
                "correlated_features_indices": [
                    2135,
                    2140,
                    2124
                ],
                "correlated_features_pearson": [
                    0.107,
                    0.043,
                    0.038
                ],
                "correlated_features_l1": [
                    0.113,
                    0.063,
                    0.042
                ],
                "neg_str": [
                    " paperback",
                    " document",
                    " Airbnb",
                    " monopoly",
                    " guest",
                    " coax",
                    " charter",
                    " Garmin",
                    " horizont",
                    " primaries"
                ],
                "neg_values": [
                    -0.696,
                    -0.655,
                    -0.645,
                    -0.608,
                    -0.603,
                    -0.602,
                    -0.6,
                    -0.599,
                    -0.592,
                    -0.591
                ],
                "pos_str": [
                    "\u00e2\u0122",
                    "\u00c2\u00bb",
                    "\u00c2",
                    "^",
                    "\u00c2\u00ab",
                    "\"\"\"",
                    "*",
                    "\u00c2\u00b4",
                    "**",
                    "\"("
                ],
                "pos_values": [
                    1.783,
                    1.312,
                    1.311,
                    1.299,
                    1.286,
                    1.265,
                    1.25,
                    1.239,
                    1.237,
                    1.232
                ],
                "frac_nonzero": 0.02145,
                "freq_hist_data_bar_heights": [
                    25940,
                    13427,
                    7638,
                    4881,
                    3289,
                    2432,
                    1839,
                    1359,
                    1105,
                    921,
                    758,
                    619,
                    527,
                    453,
                    343,
                    330,
                    273,
                    209,
                    161,
                    155,
                    134,
                    103,
                    115,
                    73,
                    64,
                    53,
                    52,
                    34,
                    33,
                    28,
                    22,
                    19,
                    17,
                    12,
                    13,
                    13,
                    6,
                    8,
                    9,
                    4,
                    2,
                    3,
                    3,
                    4,
                    3,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.491,
                    1.473,
                    2.456,
                    3.438,
                    4.42,
                    5.402,
                    6.384,
                    7.367,
                    8.349,
                    9.331,
                    10.313,
                    11.296,
                    12.278,
                    13.26,
                    14.242,
                    15.224,
                    16.207,
                    17.189,
                    18.171,
                    19.153,
                    20.135,
                    21.118,
                    22.1,
                    23.082,
                    24.064,
                    25.047,
                    26.029,
                    27.011,
                    27.993,
                    28.975,
                    29.958,
                    30.94,
                    31.922,
                    32.904,
                    33.886,
                    34.869,
                    35.851,
                    36.833,
                    37.815,
                    38.798,
                    39.78,
                    40.762,
                    41.744,
                    42.726,
                    43.709,
                    44.691,
                    45.673,
                    46.655,
                    47.637,
                    48.62
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    6,
                    28,
                    72,
                    212,
                    453,
                    886,
                    1532,
                    2400,
                    3339,
                    4229,
                    4719,
                    5006,
                    4754,
                    4193,
                    3683,
                    3120,
                    2573,
                    2117,
                    1765,
                    1364,
                    1130,
                    830,
                    565,
                    398,
                    238,
                    177,
                    104,
                    77,
                    77,
                    49,
                    28,
                    32,
                    24,
                    26,
                    16,
                    12,
                    6,
                    7,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.671,
                    -0.622,
                    -0.572,
                    -0.523,
                    -0.473,
                    -0.423,
                    -0.374,
                    -0.324,
                    -0.275,
                    -0.225,
                    -0.175,
                    -0.126,
                    -0.076,
                    -0.027,
                    0.023,
                    0.072,
                    0.122,
                    0.172,
                    0.221,
                    0.271,
                    0.32,
                    0.37,
                    0.42,
                    0.469,
                    0.519,
                    0.568,
                    0.618,
                    0.668,
                    0.717,
                    0.767,
                    0.816,
                    0.866,
                    0.916,
                    0.965,
                    1.015,
                    1.064,
                    1.114,
                    1.164,
                    1.213,
                    1.263,
                    1.312,
                    1.362,
                    1.411,
                    1.461,
                    1.511,
                    1.56,
                    1.61,
                    1.659,
                    1.709,
                    1.759
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "commands or instructional information",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdo2tabrn1fi6666ju0j8lq",
                        "tokens": [
                            " consulted",
                            " with",
                            " thousands",
                            " of",
                            " professionals",
                            " and",
                            " clients",
                            " about",
                            " what",
                            " it",
                            " is",
                            " you",
                            " need",
                            " to",
                            " know",
                            ",",
                            " what",
                            " you",
                            " want",
                            " to",
                            " know",
                            ",",
                            " and",
                            " how",
                            " the",
                            " different",
                            " systems",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "Keep",
                            " a",
                            " Record",
                            " \u2013",
                            " It",
                            " is",
                            " good",
                            " mag",
                            "ick",
                            "al",
                            " practice",
                            " to",
                            " keep",
                            " track",
                            " of",
                            " your",
                            " readings",
                            ",",
                            " dreams",
                            ",",
                            " and",
                            " the",
                            " events",
                            " that",
                            " follow",
                            ".",
                            " You",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " need",
                            " to",
                            " get",
                            " obsess",
                            "ively",
                            " anal",
                            " about",
                            " it",
                            ",",
                            " but",
                            " if",
                            " you",
                            " keep",
                            " a",
                            " journal",
                            " you",
                            " can",
                            " begin",
                            " to",
                            " see",
                            " patterns",
                            " and",
                            " signs",
                            " that",
                            " you",
                            " may",
                            " not",
                            " have",
                            " recognized",
                            " otherwise",
                            ".",
                            "\n",
                            "\n",
                            "\u2013",
                            " It",
                            " is",
                            " good",
                            " mag",
                            "ick",
                            "al",
                            " practice",
                            " to",
                            " keep",
                            " track",
                            " of",
                            " your",
                            " readings",
                            ",",
                            " dreams",
                            ",",
                            " and",
                            " the",
                            " events",
                            " that",
                            " follow",
                            ".",
                            " You",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " need",
                            " to",
                            " get",
                            " obsess"
                        ],
                        "dataIndex": null,
                        "index": "2138",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.111,
                        "maxValueTokenIndex": 119,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.652,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.56,
                            49.111,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.392,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:45.395Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.111,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo2tabrn1gi666lbc0695u",
                        "tokens": [
                            " Federal",
                            " Reserve",
                            " can",
                            " be",
                            " seen",
                            " as",
                            " a",
                            " vote",
                            " for",
                            " continuity",
                            ",",
                            " as",
                            " Powell",
                            " is",
                            " widely",
                            " expected",
                            " to",
                            " maintain",
                            " the",
                            " policy",
                            " approach",
                            " of",
                            " current",
                            " Fed",
                            " Chair",
                            " Janet",
                            " L",
                            ".",
                            " Y",
                            "ellen",
                            ".",
                            " In",
                            " many",
                            " ways",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " good",
                            " thing",
                            ".",
                            " Recent",
                            " Fed",
                            " policy",
                            " has",
                            " produced",
                            " stable",
                            " growth",
                            " and",
                            " low",
                            " inflation",
                            ",",
                            " which",
                            " is",
                            " all",
                            " we",
                            " can",
                            " really",
                            " ask",
                            " from",
                            " monetary",
                            " policy",
                            ".",
                            " Powell",
                            " is",
                            " also",
                            " well",
                            "-",
                            "l",
                            "iked",
                            " and",
                            " President",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " appointment",
                            " of",
                            " Jerome",
                            " H",
                            ".",
                            " Powell",
                            " to",
                            " chair",
                            " the",
                            " Federal",
                            " Reserve",
                            " can",
                            " be",
                            " seen",
                            " as",
                            " a",
                            " vote",
                            " for",
                            " continuity",
                            ",",
                            " as",
                            " Powell",
                            " is",
                            " widely",
                            " expected",
                            " to",
                            " maintain",
                            " the",
                            " policy",
                            " approach",
                            " of",
                            " current",
                            " Fed",
                            " Chair",
                            " Janet",
                            " L",
                            ".",
                            " Y",
                            "ellen",
                            ".",
                            " In",
                            " many",
                            " ways",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " good",
                            " thing"
                        ],
                        "dataIndex": null,
                        "index": "2138",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.143,
                        "maxValueTokenIndex": 120,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.365,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.135,
                            0,
                            0.126,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.208,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.143,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:45.395Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.111,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo2tabrn1hi6665u74kgrc",
                        "tokens": [
                            "\u013b",
                            "s",
                            " simple",
                            " truths",
                            " of",
                            " love",
                            ",",
                            " hate",
                            ",",
                            " passion",
                            " and",
                            " remorse",
                            ".",
                            " So",
                            " we",
                            " have",
                            " a",
                            " pathetic",
                            " cycle",
                            ".",
                            " Students",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " enough",
                            " about",
                            " the",
                            " real",
                            " world",
                            " because",
                            " they",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " read",
                            " non",
                            "fiction",
                            " and",
                            " they",
                            " can",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " read",
                            " non",
                            "fiction",
                            " because",
                            " they",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " enough",
                            " about",
                            " the",
                            " real",
                            " world",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " dilemma",
                            " is",
                            " increasingly",
                            " discussed",
                            " in",
                            " English",
                            " Language",
                            " Arts",
                            " circles",
                            " as",
                            " more",
                            " and",
                            " more",
                            " E",
                            "LA",
                            " standards",
                            " are",
                            " oriented",
                            " toward",
                            " abstract",
                            " reading",
                            " skills",
                            ".",
                            " Those",
                            " standards",
                            " will",
                            " say",
                            " things",
                            " like",
                            " \u00e2\u0122",
                            "\u013e",
                            "Students",
                            " identify",
                            " the",
                            " main",
                            " thesis",
                            " in",
                            " a",
                            " text",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " \u00e2\u0122",
                            "\u013e",
                            "Students",
                            " detail",
                            " the",
                            " evidence",
                            " used",
                            " to",
                            " support",
                            " a",
                            " contention",
                            " in",
                            " a",
                            " text",
                            "\u00e2\u0122",
                            "\u013f",
                            " \u2014",
                            " essential"
                        ],
                        "dataIndex": null,
                        "index": "2138",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.125,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.149,
                            5.154,
                            0.358,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.469,
                            44.125,
                            0,
                            0,
                            0,
                            0,
                            2.446,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.069,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.886,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.766,
                            0,
                            0,
                            2.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.571,
                            1.885,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:45.395Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.111,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "33167",
            "description": " instructions or guidelines",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6956565380096436,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "33167",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:58:33.367Z",
                "maxActApprox": 40.344,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    33167,
                    47593,
                    22837,
                    23702,
                    14479,
                    21302,
                    32616,
                    9039,
                    15848,
                    12923,
                    44677,
                    44235,
                    31132,
                    30968,
                    3415,
                    18559,
                    9437,
                    35166,
                    37437,
                    4320,
                    45849,
                    16659,
                    12911,
                    22964,
                    36994
                ],
                "topkCosSimValues": [
                    1,
                    0.7662,
                    0.756,
                    0.6308,
                    0.6215,
                    0.598,
                    0.5777,
                    0.5767,
                    0.5159,
                    0.5065,
                    0.5059,
                    0.5055,
                    0.4633,
                    0.454,
                    0.4191,
                    0.4142,
                    0.3863,
                    0.3833,
                    0.3759,
                    0.3459,
                    0.3395,
                    0.337,
                    0.3289,
                    0.3265,
                    0.322
                ],
                "neuron_alignment_indices": [
                    665,
                    679,
                    218
                ],
                "neuron_alignment_values": [
                    0.129,
                    0.128,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    361,
                    290
                ],
                "correlated_neurons_pearson": [
                    0.027,
                    0.025,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.029,
                    0.025,
                    0.023
                ],
                "correlated_features_indices": [
                    33149,
                    33265,
                    33217
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "bodied",
                    "cer",
                    "inese",
                    "pite",
                    "grave",
                    "aez",
                    "aucas",
                    "intendent",
                    "owl",
                    "pressed"
                ],
                "neg_values": [
                    -0.879,
                    -0.834,
                    -0.735,
                    -0.704,
                    -0.7,
                    -0.692,
                    -0.687,
                    -0.684,
                    -0.684,
                    -0.67
                ],
                "pos_str": [
                    " directions",
                    " instructions",
                    " principles",
                    " protocols",
                    " closely",
                    " protocol",
                    " Principles",
                    " suit",
                    " strict",
                    " blindly"
                ],
                "pos_values": [
                    1.049,
                    0.976,
                    0.846,
                    0.824,
                    0.816,
                    0.788,
                    0.783,
                    0.778,
                    0.775,
                    0.775
                ],
                "frac_nonzero": 0.00028,
                "freq_hist_data_bar_heights": [
                    117,
                    86,
                    49,
                    54,
                    46,
                    44,
                    42,
                    31,
                    28,
                    25,
                    22,
                    27,
                    21,
                    21,
                    15,
                    17,
                    16,
                    14,
                    18,
                    11,
                    11,
                    9,
                    10,
                    9,
                    10,
                    8,
                    5,
                    16,
                    16,
                    7,
                    10,
                    3,
                    6,
                    4,
                    8,
                    5,
                    12,
                    5,
                    4,
                    5,
                    4,
                    3,
                    0,
                    1,
                    0,
                    3,
                    0,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.432,
                    1.238,
                    2.044,
                    2.851,
                    3.657,
                    4.463,
                    5.27,
                    6.076,
                    6.882,
                    7.689,
                    8.495,
                    9.301,
                    10.107,
                    10.914,
                    11.72,
                    12.526,
                    13.333,
                    14.139,
                    14.945,
                    15.752,
                    16.558,
                    17.364,
                    18.17,
                    18.977,
                    19.783,
                    20.589,
                    21.396,
                    22.202,
                    23.008,
                    23.815,
                    24.621,
                    25.427,
                    26.233,
                    27.04,
                    27.846,
                    28.652,
                    29.459,
                    30.265,
                    31.071,
                    31.878,
                    32.684,
                    33.49,
                    34.296,
                    35.103,
                    35.909,
                    36.715,
                    37.522,
                    38.328,
                    39.134,
                    39.941
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    1,
                    4,
                    4,
                    10,
                    19,
                    42,
                    61,
                    93,
                    184,
                    287,
                    446,
                    690,
                    1071,
                    1543,
                    2055,
                    2828,
                    3550,
                    4105,
                    4549,
                    4729,
                    4556,
                    4358,
                    3779,
                    3231,
                    2354,
                    1797,
                    1373,
                    935,
                    570,
                    401,
                    249,
                    138,
                    93,
                    61,
                    26,
                    19,
                    16,
                    7,
                    5,
                    9,
                    3,
                    2,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.86,
                    -0.821,
                    -0.783,
                    -0.744,
                    -0.706,
                    -0.667,
                    -0.629,
                    -0.59,
                    -0.551,
                    -0.513,
                    -0.474,
                    -0.436,
                    -0.397,
                    -0.359,
                    -0.32,
                    -0.281,
                    -0.243,
                    -0.204,
                    -0.166,
                    -0.127,
                    -0.089,
                    -0.05,
                    -0.012,
                    0.027,
                    0.066,
                    0.104,
                    0.143,
                    0.181,
                    0.22,
                    0.258,
                    0.297,
                    0.336,
                    0.374,
                    0.413,
                    0.451,
                    0.49,
                    0.528,
                    0.567,
                    0.606,
                    0.644,
                    0.683,
                    0.721,
                    0.76,
                    0.798,
                    0.837,
                    0.876,
                    0.914,
                    0.953,
                    0.991,
                    1.03
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " instructions or guidelines",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk69orj67tqi666wto1qb7e",
                        "tokens": [
                            " tiny",
                            " 65",
                            "mm",
                            " x",
                            " 30",
                            "mm",
                            " board",
                            " with",
                            " mini",
                            "-",
                            "HD",
                            "MI",
                            ",",
                            " micro",
                            "-",
                            "B",
                            " OT",
                            "G",
                            " USB",
                            ",",
                            " and",
                            " the",
                            " same",
                            " 40",
                            "-",
                            "pin",
                            " GPIO",
                            " it",
                            " still",
                            " has",
                            " great",
                            " connectivity",
                            " and",
                            " cost",
                            " only",
                            " $",
                            "5",
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "ence",
                            " turning",
                            " Lap",
                            "d",
                            "ock",
                            " to",
                            " actual",
                            " laptop",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " cost",
                            " you",
                            " much",
                            " money",
                            " if",
                            " you",
                            " follow",
                            " the",
                            " plans",
                            " laid",
                            " out",
                            " by",
                            " blogger",
                            " Ax",
                            "0",
                            "n",
                            " over",
                            " at",
                            " H",
                            "-",
                            "I",
                            "-",
                            "R",
                            ".",
                            "net",
                            ".",
                            "\n",
                            "\n",
                            "Also",
                            " Read",
                            " :",
                            " Now",
                            " Nintendo",
                            " 3",
                            "DS",
                            " XL",
                            " can",
                            " Run",
                            " Windows",
                            " 95",
                            "\n",
                            "\n",
                            "All",
                            " it",
                            " takes",
                            " is",
                            " a",
                            " Raspberry",
                            " Pi",
                            " Zero",
                            " and",
                            " a",
                            " couple",
                            " of",
                            " cables",
                            ".",
                            " Heck",
                            ",",
                            " even",
                            " if",
                            " you",
                            " have",
                            " to",
                            " go",
                            " out",
                            " and",
                            " buy",
                            " a",
                            " Lap",
                            "d",
                            "ock",
                            " this",
                            " still",
                            " isn"
                        ],
                        "dataIndex": null,
                        "index": "33167",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.344,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.344,
                            7.431,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:35.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk69orj67tri66685ajcs1c",
                        "tokens": [
                            " been",
                            " the",
                            " intended",
                            " purpose",
                            " for",
                            " this",
                            " product",
                            "!",
                            " I",
                            " live",
                            " in",
                            " Upper",
                            " Michigan",
                            " where",
                            " winters",
                            " are",
                            " very",
                            " cold",
                            ".",
                            " These",
                            " heat",
                            "ers",
                            " work",
                            " great",
                            "!",
                            " You",
                            " need",
                            " to",
                            " follow",
                            " the",
                            " instructions",
                            " in",
                            " order",
                            " for",
                            " proper",
                            " operation",
                            ".",
                            " Garage",
                            " applications",
                            " will",
                            " not",
                            " work",
                            " well",
                            ".",
                            " An",
                            " interior",
                            " room",
                            " of",
                            " a",
                            " home",
                            " will",
                            " work",
                            " perfect",
                            ".",
                            " \"",
                            "T",
                            "IP",
                            "\"",
                            " Mount",
                            " heater",
                            " to",
                            " interior",
                            " wall",
                            ",",
                            " not",
                            " a",
                            " wall",
                            " where",
                            " outside",
                            " temperatures",
                            " are",
                            " on",
                            " the",
                            " other",
                            " side",
                            "!",
                            " This",
                            " unit",
                            " WILL",
                            " draw",
                            " cold",
                            " air",
                            " from",
                            " the",
                            " floor",
                            " and",
                            " heat",
                            " it",
                            " causing",
                            " a",
                            " natural",
                            " rotation",
                            " of",
                            " air",
                            " in",
                            " the",
                            " room",
                            "!",
                            " You",
                            " will",
                            " not",
                            " be",
                            " disappointed",
                            "!",
                            " They",
                            " do",
                            " work",
                            "!",
                            " especially",
                            " if",
                            " you",
                            " have",
                            " a",
                            " \"",
                            "cold",
                            "\"",
                            " room",
                            " and",
                            " are",
                            " looking",
                            " to",
                            " supplement",
                            " your",
                            " existing",
                            " heat",
                            " source",
                            "!"
                        ],
                        "dataIndex": null,
                        "index": "33167",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.651,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.651,
                            8.374,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:35.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk69ork67tsi6660tskioqk",
                        "tokens": [
                            "ing",
                            " the",
                            " debates",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Through",
                            " some",
                            " of",
                            " my",
                            " research",
                            ",",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " found",
                            " documents",
                            " prepared",
                            " by",
                            " their",
                            " advisors",
                            " that",
                            " are",
                            " very",
                            " detailed",
                            " in",
                            " terms",
                            " of",
                            " strategic",
                            " considerations",
                            "\u2014",
                            "things",
                            " about",
                            " their",
                            " appearance",
                            ",",
                            " and",
                            " whether",
                            " or",
                            " not",
                            " they",
                            " should",
                            " wear",
                            " glasses",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "But",
                            " \u00e2\u0122",
                            "\u013e",
                            "there",
                            " is",
                            " such",
                            " a",
                            " thing",
                            " as",
                            " being",
                            " over",
                            "pre",
                            "pared",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " feel",
                            " you",
                            " have",
                            " to",
                            " follow",
                            " a",
                            " script",
                            ",",
                            " and",
                            " it",
                            " hurts",
                            " your",
                            " ability",
                            " to",
                            " respond",
                            " to",
                            " events",
                            " as",
                            " they",
                            " unfold",
                            " during",
                            " the",
                            " course",
                            " of",
                            " the",
                            " debate",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "H",
                            "ogan",
                            " points",
                            " to",
                            " Ronald",
                            " Reagan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " first",
                            " debate",
                            " in",
                            " 1984",
                            ",",
                            " during",
                            " which",
                            " the",
                            " incumbent",
                            " president",
                            " seemed",
                            " uncomfortable",
                            ".",
                            " The",
                            " speculation"
                        ],
                        "dataIndex": null,
                        "index": "33167",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.093,
                        "maxValueTokenIndex": 76,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.093,
                            7.052,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:35.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs768-jb",
            "index": "305",
            "description": "steps or instructions",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6752393245697021,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs768-jb",
                "index": "305",
                "sourceSetName": "res_fs768-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:35:57.806Z",
                "maxActApprox": 40.211,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    305,
                    4,
                    634,
                    697,
                    461,
                    115,
                    277,
                    493,
                    559,
                    516,
                    56,
                    42,
                    646,
                    213,
                    737,
                    125,
                    610,
                    329,
                    744,
                    86,
                    455,
                    189,
                    696,
                    148,
                    445
                ],
                "topkCosSimValues": [
                    1,
                    0.5888,
                    0.3941,
                    0.3032,
                    0.238,
                    0.2243,
                    0.2152,
                    0.1938,
                    0.1866,
                    0.1714,
                    0.1695,
                    0.1484,
                    0.1424,
                    0.1336,
                    0.1285,
                    0.1216,
                    0.1192,
                    0.1152,
                    0.1117,
                    0.108,
                    0.1044,
                    0.1043,
                    0.1037,
                    0.1037,
                    0.0996
                ],
                "neuron_alignment_indices": [
                    102,
                    566,
                    55
                ],
                "neuron_alignment_values": [
                    0.213,
                    0.182,
                    0.158
                ],
                "neuron_alignment_l1": [
                    0.011,
                    0.009,
                    0.008
                ],
                "correlated_neurons_indices": [
                    102,
                    55,
                    566
                ],
                "correlated_neurons_pearson": [
                    0.29,
                    0.276,
                    0.265
                ],
                "correlated_neurons_l1": [
                    0.313,
                    0.299,
                    0.267
                ],
                "correlated_features_indices": [
                    277,
                    300,
                    336
                ],
                "correlated_features_pearson": [
                    0.185,
                    0.069,
                    0.066
                ],
                "correlated_features_l1": [
                    0.202,
                    0.09,
                    0.081
                ],
                "neg_str": [
                    " occurs",
                    "osate",
                    "inav",
                    "ulence",
                    " Highlights",
                    " lasts",
                    " legality",
                    "ossom",
                    " Ensure",
                    " flourish"
                ],
                "neg_values": [
                    -0.808,
                    -0.781,
                    -0.769,
                    -0.739,
                    -0.718,
                    -0.71,
                    -0.703,
                    -0.701,
                    -0.697,
                    -0.685
                ],
                "pos_str": [
                    " aware",
                    " afraid",
                    " able",
                    " willing",
                    " unable",
                    " thankful",
                    " glad",
                    " unaware",
                    " obligated",
                    " fortunate"
                ],
                "pos_values": [
                    1.366,
                    1.341,
                    1.323,
                    1.267,
                    1.252,
                    1.211,
                    1.2,
                    1.164,
                    1.164,
                    1.156
                ],
                "frac_nonzero": 0.03432,
                "freq_hist_data_bar_heights": [
                    16442,
                    11872,
                    9353,
                    7350,
                    5919,
                    4813,
                    3932,
                    3417,
                    2874,
                    2569,
                    2384,
                    2193,
                    2098,
                    2087,
                    2036,
                    1977,
                    1903,
                    1893,
                    1823,
                    1775,
                    1689,
                    1571,
                    1511,
                    1268,
                    1264,
                    1261,
                    1147,
                    1111,
                    931,
                    903,
                    806,
                    703,
                    700,
                    625,
                    580,
                    487,
                    415,
                    355,
                    314,
                    273,
                    266,
                    257,
                    251,
                    219,
                    162,
                    102,
                    60,
                    13,
                    10,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.402,
                    1.206,
                    2.011,
                    2.815,
                    3.619,
                    4.423,
                    5.228,
                    6.032,
                    6.836,
                    7.64,
                    8.444,
                    9.249,
                    10.053,
                    10.857,
                    11.661,
                    12.466,
                    13.27,
                    14.074,
                    14.878,
                    15.682,
                    16.487,
                    17.291,
                    18.095,
                    18.899,
                    19.704,
                    20.508,
                    21.312,
                    22.116,
                    22.92,
                    23.725,
                    24.529,
                    25.333,
                    26.137,
                    26.942,
                    27.746,
                    28.55,
                    29.354,
                    30.158,
                    30.963,
                    31.767,
                    32.571,
                    33.375,
                    34.18,
                    34.984,
                    35.788,
                    36.592,
                    37.396,
                    38.201,
                    39.005,
                    39.809
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    6,
                    10,
                    11,
                    50,
                    75,
                    132,
                    266,
                    435,
                    786,
                    1223,
                    1902,
                    2622,
                    3468,
                    4210,
                    4765,
                    4928,
                    4860,
                    4218,
                    3562,
                    2816,
                    2183,
                    1726,
                    1252,
                    993,
                    836,
                    584,
                    497,
                    410,
                    356,
                    276,
                    196,
                    161,
                    105,
                    83,
                    64,
                    56,
                    31,
                    30,
                    21,
                    13,
                    9,
                    9,
                    6,
                    4,
                    2,
                    2,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.786,
                    -0.742,
                    -0.699,
                    -0.655,
                    -0.612,
                    -0.569,
                    -0.525,
                    -0.482,
                    -0.438,
                    -0.395,
                    -0.351,
                    -0.308,
                    -0.264,
                    -0.221,
                    -0.177,
                    -0.134,
                    -0.09,
                    -0.047,
                    -0.003,
                    0.04,
                    0.084,
                    0.127,
                    0.171,
                    0.214,
                    0.257,
                    0.301,
                    0.344,
                    0.388,
                    0.431,
                    0.475,
                    0.518,
                    0.562,
                    0.605,
                    0.649,
                    0.692,
                    0.736,
                    0.779,
                    0.823,
                    0.866,
                    0.91,
                    0.953,
                    0.997,
                    1.04,
                    1.084,
                    1.127,
                    1.17,
                    1.214,
                    1.257,
                    1.301,
                    1.344
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "steps or instructions",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdnu5rknnksi666pdsw7rrp",
                        "tokens": [
                            " for",
                            " another",
                            " 7",
                            "-",
                            "10",
                            " minutes",
                            " or",
                            " until",
                            " the",
                            " edges",
                            " of",
                            " the",
                            " cookies",
                            " are",
                            " lightly",
                            " brown",
                            "ed",
                            ".",
                            "\n",
                            "\n",
                            "Place",
                            " the",
                            " cookies",
                            " on",
                            " a",
                            " rack",
                            " to",
                            " cool",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " the",
                            " cookies",
                            " are",
                            " cool",
                            " fill",
                            " a",
                            " pastry",
                            " bag",
                            " with",
                            " the",
                            " Nut",
                            "ella",
                            " and",
                            " pipe",
                            " into",
                            " the",
                            " middle",
                            " of",
                            " each",
                            " cookie",
                            ".",
                            "<|endoftext|>",
                            "A",
                            " \u00e2\u0122",
                            "\u013e",
                            "T",
                            "ourt",
                            "i",
                            "\u00c3\u00a8re",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " a",
                            " meat",
                            " pie",
                            " from",
                            " Quebec",
                            ",",
                            " and",
                            " is",
                            " a",
                            " classic",
                            " part",
                            " of",
                            " the",
                            " Christmas",
                            "/",
                            "Christmas",
                            " Eve",
                            " r\u00c3\u00a9",
                            "ve",
                            "illon",
                            " and",
                            " New",
                            " Year",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Eve",
                            " meal",
                            " (",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " also",
                            " great",
                            " when",
                            " you",
                            " are",
                            " having",
                            " a",
                            " bunch",
                            " of",
                            " people",
                            " over",
                            " for",
                            " dinner",
                            " and",
                            " you",
                            " are",
                            " sick",
                            " of",
                            " making",
                            " \u00e2\u0122",
                            "\u013e",
                            "b",
                            "angers",
                            " in",
                            " a",
                            " cloud",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " another"
                        ],
                        "dataIndex": null,
                        "index": "305",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.211,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.666,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.576,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.563,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.838,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            3.129,
                            40.211,
                            5.075,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:01.688Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.211,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdnu5rlnnkti666yedknaeh",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Frank",
                            "ly",
                            ",",
                            " all",
                            " that",
                            " I",
                            " wanted",
                            " is",
                            " to",
                            " come",
                            " to",
                            " Tah",
                            "rir",
                            " Square",
                            ",",
                            " sit",
                            " down",
                            " and",
                            " eat",
                            ".",
                            " To",
                            " see",
                            " what",
                            " I",
                            " see",
                            " now",
                            ":",
                            " flowers",
                            ",",
                            " gardens",
                            ",",
                            " people",
                            " are",
                            " safe",
                            ".",
                            " I",
                            " want",
                            " to",
                            " feel",
                            " free",
                            " in",
                            " my",
                            " country",
                            ",\"",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Near",
                            "by",
                            ",",
                            " student",
                            " Mo",
                            "he",
                            "b",
                            " Em",
                            "ad",
                            " says",
                            " Tah",
                            "rir",
                            " doesn",
                            "'t",
                            " need",
                            " to",
                            " be",
                            " renovated",
                            " or",
                            " beaut",
                            "ified",
                            " because",
                            " it",
                            " will",
                            " always",
                            " be",
                            " a",
                            " symbol",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "To",
                            " us",
                            ",",
                            " Tah",
                            "rir",
                            " Square",
                            " is",
                            " sacred",
                            ",",
                            " because",
                            " people",
                            " died",
                            " here",
                            ".",
                            " It",
                            " will",
                            " not",
                            " lose",
                            " its",
                            " significance",
                            ",\"",
                            " Em",
                            "ad",
                            " says",
                            ".",
                            " \"",
                            "And",
                            " we",
                            " are",
                            " not",
                            " waiting",
                            " for",
                            " renovations",
                            ",",
                            " the",
                            " way",
                            " the",
                            " government",
                            " speaks",
                            " about",
                            " them",
                            ".\""
                        ],
                        "dataIndex": null,
                        "index": "305",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.617,
                        "maxValueTokenIndex": 113,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.356,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.024,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.095,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.617,
                            24.426,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:01.688Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.211,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdnu5rlnnkui6668phiqgkf",
                        "tokens": [
                            " engineers",
                            ",",
                            " for",
                            " some",
                            " odd",
                            " reason",
                            " it",
                            " has",
                            " not",
                            " occurred",
                            " to",
                            " look",
                            " with",
                            " the",
                            " same",
                            " eyes",
                            " upon",
                            " the",
                            " peculiar",
                            "ities",
                            " of",
                            " the",
                            " lunar",
                            " landscape",
                            " much",
                            " closer",
                            " at",
                            " hand",
                            ".",
                            "And",
                            " all",
                            " the",
                            " arguments",
                            " about",
                            " the",
                            " possibilities",
                            " of",
                            " intelligent",
                            " life",
                            " existing",
                            " on",
                            " other",
                            " celestial",
                            " bodies",
                            " have",
                            " been",
                            " confined",
                            " to",
                            " the",
                            " idea",
                            " that",
                            " other",
                            " civilizations",
                            " must",
                            " necessarily",
                            " live",
                            " on",
                            " the",
                            " surface",
                            " of",
                            " a",
                            " planet",
                            ",",
                            " and",
                            " that",
                            " the",
                            " interior",
                            " as",
                            " a",
                            " habitat",
                            " is",
                            " out",
                            " of",
                            " the",
                            " question",
                            ".",
                            " Abandon",
                            "ing",
                            " the",
                            " traditional",
                            " paths",
                            " of",
                            " \"",
                            "common",
                            " sense",
                            "\",",
                            " we",
                            " have",
                            " plunged",
                            " into",
                            " what",
                            " may",
                            " at",
                            " first",
                            " sight",
                            " seem",
                            " to",
                            " be",
                            " un",
                            "brid",
                            "led",
                            " and",
                            " irresponsible",
                            " fantasy",
                            ".",
                            "But",
                            " the",
                            " more",
                            " minute",
                            "ly",
                            " we",
                            " go",
                            " into",
                            " all",
                            " the",
                            " information",
                            " gathered",
                            " by",
                            " man",
                            " about",
                            " the",
                            " Moon",
                            ",",
                            " the",
                            " more",
                            " we",
                            " are"
                        ],
                        "dataIndex": null,
                        "index": "305",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.56,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.28,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.028,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.56
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:01.688Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.211,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "18561",
            "description": "steps or instructions",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6751781307213944,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "18561",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:08:39.107Z",
                "maxActApprox": 38.414,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    18561,
                    23438,
                    15600,
                    8231,
                    7734,
                    2922,
                    8286,
                    5605,
                    15318,
                    2706,
                    11135,
                    24413,
                    19163,
                    10934,
                    23757,
                    3615,
                    18944,
                    23652,
                    3417,
                    4238,
                    1313,
                    22801,
                    4439,
                    18067,
                    24055
                ],
                "topkCosSimValues": [
                    1,
                    0.7007,
                    0.6805,
                    0.6038,
                    0.5846,
                    0.5604,
                    0.5522,
                    0.539,
                    0.5325,
                    0.5309,
                    0.5305,
                    0.5224,
                    0.5151,
                    0.5108,
                    0.5105,
                    0.5087,
                    0.5086,
                    0.4993,
                    0.4979,
                    0.4972,
                    0.4951,
                    0.4882,
                    0.4872,
                    0.4854,
                    0.4743
                ],
                "neuron_alignment_indices": [
                    480,
                    87,
                    447
                ],
                "neuron_alignment_values": [
                    0.257,
                    0.137,
                    0.128
                ],
                "neuron_alignment_l1": [
                    0.012,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    273,
                    464,
                    99
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.031,
                    0.03
                ],
                "correlated_neurons_l1": [
                    0.032,
                    0.032,
                    0.029
                ],
                "correlated_features_indices": [
                    18667,
                    18598,
                    18652
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    " manif",
                    " administr",
                    " purs",
                    " prest",
                    " agre",
                    " misunder",
                    " Vaugh",
                    " Seym",
                    " neighb",
                    " destro"
                ],
                "neg_values": [
                    -0.847,
                    -0.804,
                    -0.684,
                    -0.666,
                    -0.65,
                    -0.649,
                    -0.644,
                    -0.639,
                    -0.636,
                    -0.635
                ],
                "pos_str": [
                    " SHARES",
                    " Expand",
                    " ][",
                    " Ingredients",
                    " Explicit",
                    " Registered",
                    " \u00c2\u00b7",
                    " Updated",
                    " Minutes",
                    "Rated"
                ],
                "pos_values": [
                    0.949,
                    0.858,
                    0.729,
                    0.725,
                    0.725,
                    0.723,
                    0.718,
                    0.708,
                    0.7,
                    0.692
                ],
                "frac_nonzero": 0.00068,
                "freq_hist_data_bar_heights": [
                    299,
                    271,
                    184,
                    162,
                    140,
                    136,
                    100,
                    74,
                    72,
                    47,
                    52,
                    45,
                    33,
                    40,
                    27,
                    23,
                    42,
                    28,
                    8,
                    19,
                    9,
                    12,
                    22,
                    11,
                    6,
                    12,
                    11,
                    10,
                    12,
                    11,
                    17,
                    6,
                    11,
                    8,
                    4,
                    17,
                    44,
                    20,
                    10,
                    12,
                    10,
                    5,
                    11,
                    4,
                    0,
                    5,
                    19,
                    0,
                    8,
                    19
                ],
                "freq_hist_data_bar_values": [
                    0.386,
                    1.154,
                    1.922,
                    2.691,
                    3.459,
                    4.227,
                    4.995,
                    5.764,
                    6.532,
                    7.3,
                    8.068,
                    8.837,
                    9.605,
                    10.373,
                    11.141,
                    11.91,
                    12.678,
                    13.446,
                    14.214,
                    14.983,
                    15.751,
                    16.519,
                    17.287,
                    18.056,
                    18.824,
                    19.592,
                    20.36,
                    21.129,
                    21.897,
                    22.665,
                    23.433,
                    24.202,
                    24.97,
                    25.738,
                    26.506,
                    27.275,
                    28.043,
                    28.811,
                    29.579,
                    30.348,
                    31.116,
                    31.884,
                    32.652,
                    33.42,
                    34.189,
                    34.957,
                    35.725,
                    36.493,
                    37.262,
                    38.03
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    0,
                    1,
                    8,
                    14,
                    14,
                    25,
                    64,
                    99,
                    192,
                    298,
                    454,
                    758,
                    1068,
                    1576,
                    2151,
                    2510,
                    3111,
                    3420,
                    3831,
                    3896,
                    3910,
                    3850,
                    3603,
                    3166,
                    2783,
                    2308,
                    1829,
                    1463,
                    1114,
                    820,
                    568,
                    418,
                    317,
                    222,
                    169,
                    103,
                    58,
                    31,
                    16,
                    8,
                    7,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.829,
                    -0.794,
                    -0.758,
                    -0.722,
                    -0.686,
                    -0.65,
                    -0.614,
                    -0.578,
                    -0.542,
                    -0.506,
                    -0.47,
                    -0.434,
                    -0.398,
                    -0.362,
                    -0.326,
                    -0.291,
                    -0.255,
                    -0.219,
                    -0.183,
                    -0.147,
                    -0.111,
                    -0.075,
                    -0.039,
                    -0.003,
                    0.033,
                    0.069,
                    0.105,
                    0.141,
                    0.177,
                    0.212,
                    0.248,
                    0.284,
                    0.32,
                    0.356,
                    0.392,
                    0.428,
                    0.464,
                    0.5,
                    0.536,
                    0.572,
                    0.608,
                    0.644,
                    0.68,
                    0.716,
                    0.751,
                    0.787,
                    0.823,
                    0.859,
                    0.895,
                    0.931
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "steps or instructions",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmuytuhn1xi666jx7lm1p9",
                        "tokens": [
                            " 5",
                            ".",
                            "71",
                            "per",
                            " lit",
                            "re",
                            " in",
                            " Chennai",
                            ".",
                            "On",
                            " Tuesday",
                            ",",
                            " petrol",
                            " cost",
                            " Rs",
                            " 79",
                            ".",
                            "48",
                            " per",
                            " lit",
                            "re",
                            " in",
                            " Mumbai",
                            " and",
                            " Rs",
                            " 70",
                            ".",
                            "38",
                            " per",
                            " lit",
                            "re",
                            " in",
                            " Delhi",
                            " while",
                            " diesel",
                            " was",
                            " priced",
                            " at",
                            " Rs",
                            " 62",
                            ".",
                            "37",
                            " per",
                            " lit",
                            "re",
                            " in",
                            " Mumbai",
                            " and",
                            " Rs",
                            " 58",
                            ".",
                            "72",
                            " per",
                            " lit",
                            "re",
                            " in",
                            " Delhi",
                            ".",
                            " Prices",
                            " vary",
                            " according",
                            " to",
                            " local",
                            " lev",
                            "ies",
                            " imposed",
                            " by",
                            " different",
                            " states",
                            ".",
                            " Pet",
                            "rol",
                            " and",
                            " diesel",
                            " aren",
                            "'t",
                            " in",
                            " the",
                            " am",
                            "bit",
                            " of",
                            " the",
                            " goods",
                            " and",
                            " services",
                            " tax",
                            " and",
                            " the",
                            " rate",
                            " of",
                            " taxes",
                            " imposed",
                            " by",
                            " states",
                            " vary",
                            ".",
                            "Indian",
                            " fuel",
                            " retailers",
                            " such",
                            " as",
                            " Indian",
                            " Oil",
                            ",",
                            " Bhar",
                            "at",
                            " Petroleum",
                            " and",
                            " Hind",
                            "ust",
                            "an",
                            " Petroleum",
                            " started",
                            " daily",
                            " revision",
                            " of",
                            " prices",
                            " of",
                            " petrol",
                            " and",
                            " diesel",
                            " from",
                            " the",
                            " middle",
                            " of",
                            " June",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "18561",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.414,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            38.414,
                            0.654,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:39.742Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.414,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmuytuhn1yi666hvocgetr",
                        "tokens": [
                            " 5",
                            " to",
                            " 7",
                            " hours",
                            ".",
                            " Replace",
                            " water",
                            " as",
                            " needed",
                            ",",
                            " 2",
                            " or",
                            " 3",
                            " times",
                            ",",
                            " by",
                            " pouring",
                            " more",
                            " water",
                            " down",
                            " the",
                            " inside",
                            " of",
                            " the",
                            " pot",
                            ".",
                            " 3",
                            ".",
                            " Remove",
                            " stock",
                            " from",
                            " heat",
                            ",",
                            " and",
                            " strain",
                            ".",
                            " Press",
                            " all",
                            " liquid",
                            " from",
                            " the",
                            " shells",
                            " and",
                            " vegetables",
                            ",",
                            " then",
                            " discard",
                            " them",
                            ".",
                            " Return",
                            " liquid",
                            " to",
                            " heat",
                            ",",
                            " and",
                            " reduce",
                            " to",
                            " 2",
                            " to",
                            " 3",
                            " qu",
                            "arts",
                            ",",
                            " or",
                            " to",
                            " taste",
                            ".",
                            " For",
                            " G",
                            "umbo",
                            " 1",
                            ".",
                            " Pre",
                            "heat",
                            " the",
                            " oven",
                            " to",
                            " 350",
                            " degrees",
                            " F",
                            ".",
                            " 2",
                            ".",
                            " Place",
                            " the",
                            " vegetable",
                            " oil",
                            " and",
                            " flour",
                            " into",
                            " a",
                            " 5",
                            " to",
                            " 6",
                            "-",
                            "quart",
                            " cast",
                            " iron",
                            " Dutch",
                            " oven",
                            " and",
                            " whisk",
                            " together",
                            " to",
                            " combine",
                            ".",
                            " Place",
                            " on",
                            " the",
                            " middle",
                            " shelf",
                            " of",
                            " the",
                            " oven",
                            ",",
                            " uncovered",
                            ",",
                            " and",
                            " bake",
                            " for",
                            " 1",
                            " 1",
                            "/",
                            "2",
                            " hours",
                            ",",
                            " whisk"
                        ],
                        "dataIndex": null,
                        "index": "18561",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.414,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            38.414,
                            0,
                            10.709,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.748,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:39.742Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.414,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmuytuhn1wi666h8t8gi2c",
                        "tokens": [
                            " 5",
                            ",",
                            "283",
                            " 5",
                            ",",
                            "179",
                            " 6",
                            ",",
                            "184",
                            " 4",
                            ",",
                            "487",
                            " Saint",
                            " Louis",
                            " FC",
                            " 5",
                            " 24",
                            ",",
                            "154",
                            " 4",
                            ",",
                            "8",
                            "31",
                            " 4",
                            ",",
                            "994",
                            " 5",
                            ",",
                            "280",
                            " 4",
                            ",",
                            "09",
                            "6",
                            " Charleston",
                            " Battery",
                            " 6",
                            " 24",
                            ",",
                            "649",
                            " 4",
                            ",",
                            "108",
                            " 4",
                            ",",
                            "253",
                            " 5",
                            ",",
                            "455",
                            " 3",
                            ",",
                            "026",
                            " OK",
                            "C",
                            " Energy",
                            " FC",
                            " 4",
                            " 16",
                            ",",
                            "399",
                            " 4",
                            ",",
                            "100",
                            " 4",
                            ",",
                            "050",
                            " 6",
                            ",",
                            "797",
                            " 1",
                            ",",
                            "502",
                            " Arizona",
                            " United",
                            " SC",
                            " 4",
                            " 15",
                            ",",
                            "283",
                            " 3",
                            ",",
                            "8",
                            "21",
                            " 3",
                            ",",
                            "159",
                            " 6",
                            ",",
                            "108",
                            " 2",
                            ",",
                            "8",
                            "58",
                            " Portland",
                            " Timbers",
                            " 2",
                            " 4",
                            " 14",
                            ",",
                            "207",
                            " 3",
                            ",",
                            "552",
                            " 3",
                            ",",
                            "381",
                            " 4",
                            ",",
                            "9",
                            "44",
                            " 2",
                            ",",
                            "501",
                            " Richmond",
                            " Kick",
                            "ers",
                            " 6",
                            " 18",
                            ",",
                            "833",
                            " 3",
                            ",",
                            "139",
                            " 3",
                            ",",
                            "059",
                            " 4",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "18561",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.414,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            38.414,
                            0,
                            0,
                            9.148,
                            0,
                            0,
                            2.233,
                            0,
                            0,
                            0.108,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:39.742Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.414,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "2935",
            "description": "technical instructions in the text",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6718475017729447,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "2935",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:48:14.352Z",
                "maxActApprox": 34.844,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2935,
                    16199,
                    13559,
                    14290,
                    7245,
                    7116,
                    16429,
                    17146,
                    2121,
                    21880,
                    19126,
                    12582,
                    13506,
                    16823,
                    24180,
                    16752,
                    13500,
                    13370,
                    22726,
                    19500,
                    5447,
                    15433,
                    23159,
                    4095,
                    17175
                ],
                "topkCosSimValues": [
                    1,
                    0.4996,
                    0.4201,
                    0.3653,
                    0.3444,
                    0.3218,
                    0.3172,
                    0.304,
                    0.3014,
                    0.2731,
                    0.2722,
                    0.2706,
                    0.2678,
                    0.2459,
                    0.2449,
                    0.2409,
                    0.236,
                    0.2355,
                    0.2307,
                    0.2292,
                    0.2251,
                    0.2219,
                    0.2202,
                    0.2151,
                    0.2137
                ],
                "neuron_alignment_indices": [
                    442,
                    160,
                    426
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    160,
                    426,
                    314
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.012,
                    0.003
                ],
                "correlated_features_indices": [
                    2896,
                    2827,
                    2822
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.001
                ],
                "neg_str": [
                    " Nunes",
                    " Hoo",
                    " Kear",
                    " Chak",
                    " Kin",
                    " retali",
                    " Liver",
                    " Kelvin",
                    " RC",
                    " Hemisphere"
                ],
                "neg_values": [
                    -0.743,
                    -0.659,
                    -0.657,
                    -0.638,
                    -0.631,
                    -0.624,
                    -0.622,
                    -0.617,
                    -0.616,
                    -0.615
                ],
                "pos_str": [
                    "wcsstore",
                    "tnc",
                    "catentry",
                    "Hello",
                    "dogs",
                    "SELECT",
                    "rag",
                    "some",
                    "antic",
                    "english"
                ],
                "pos_values": [
                    0.905,
                    0.883,
                    0.855,
                    0.784,
                    0.777,
                    0.763,
                    0.756,
                    0.756,
                    0.754,
                    0.74
                ],
                "frac_nonzero": 0.00012,
                "freq_hist_data_bar_heights": [
                    55,
                    43,
                    42,
                    18,
                    21,
                    20,
                    15,
                    15,
                    5,
                    12,
                    6,
                    5,
                    3,
                    6,
                    4,
                    5,
                    4,
                    2,
                    3,
                    4,
                    1,
                    1,
                    0,
                    2,
                    1,
                    0,
                    4,
                    3,
                    2,
                    4,
                    4,
                    5,
                    3,
                    1,
                    6,
                    3,
                    5,
                    7,
                    7,
                    5,
                    8,
                    5,
                    4,
                    0,
                    4,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.382,
                    1.078,
                    1.774,
                    2.47,
                    3.166,
                    3.863,
                    4.559,
                    5.255,
                    5.951,
                    6.648,
                    7.344,
                    8.04,
                    8.736,
                    9.432,
                    10.129,
                    10.825,
                    11.521,
                    12.217,
                    12.914,
                    13.61,
                    14.306,
                    15.002,
                    15.698,
                    16.395,
                    17.091,
                    17.787,
                    18.483,
                    19.18,
                    19.876,
                    20.572,
                    21.268,
                    21.964,
                    22.661,
                    23.357,
                    24.053,
                    24.749,
                    25.445,
                    26.142,
                    26.838,
                    27.534,
                    28.23,
                    28.927,
                    29.623,
                    30.319,
                    31.015,
                    31.711,
                    32.408,
                    33.104,
                    33.8,
                    34.496
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    9,
                    9,
                    17,
                    46,
                    60,
                    106,
                    172,
                    304,
                    483,
                    787,
                    1061,
                    1454,
                    1982,
                    2436,
                    2820,
                    3256,
                    3519,
                    3483,
                    3339,
                    3394,
                    2991,
                    2720,
                    2384,
                    2172,
                    1920,
                    1592,
                    1493,
                    1238,
                    1089,
                    912,
                    797,
                    615,
                    494,
                    368,
                    252,
                    192,
                    118,
                    65,
                    49,
                    16,
                    17,
                    14,
                    4,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.727,
                    -0.694,
                    -0.661,
                    -0.628,
                    -0.595,
                    -0.562,
                    -0.529,
                    -0.496,
                    -0.463,
                    -0.43,
                    -0.397,
                    -0.364,
                    -0.331,
                    -0.298,
                    -0.265,
                    -0.232,
                    -0.199,
                    -0.166,
                    -0.133,
                    -0.1,
                    -0.067,
                    -0.034,
                    -0.001,
                    0.032,
                    0.065,
                    0.098,
                    0.131,
                    0.164,
                    0.196,
                    0.229,
                    0.262,
                    0.295,
                    0.328,
                    0.361,
                    0.394,
                    0.427,
                    0.46,
                    0.493,
                    0.526,
                    0.559,
                    0.592,
                    0.625,
                    0.658,
                    0.691,
                    0.724,
                    0.757,
                    0.79,
                    0.823,
                    0.856,
                    0.889
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "technical instructions in the text",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm4uu42scti666zmeob1xp",
                        "tokens": [
                            " Roth",
                            ".",
                            " (\"",
                            "If",
                            " you",
                            " see",
                            " only",
                            " one",
                            " version",
                            " of",
                            " Forrest",
                            " G",
                            "ump",
                            " this",
                            " year",
                            ",\"",
                            " int",
                            "oned",
                            " the",
                            " announcer",
                            " in",
                            " a",
                            " viral",
                            " parody",
                            " of",
                            " the",
                            " film",
                            ",",
                            " \"",
                            "make",
                            " it",
                            " The",
                            " Curious",
                            " Case",
                            " of",
                            " Benjamin",
                            " Button",
                            ".",
                            " It",
                            "'s",
                            " exactly",
                            " like",
                            " G",
                            "ump",
                            ",",
                            " except",
                            " no",
                            " AIDS",
                            ".\"",
                            " Yet",
                            " the",
                            " Button",
                            " man",
                            " from",
                            " New",
                            " Orleans",
                            " might",
                            " have",
                            " been",
                            " the",
                            " one",
                            " to",
                            " beat",
                            " this",
                            " year",
                            ",",
                            " if",
                            " the",
                            " kid",
                            " from",
                            " Mumbai",
                            " hadn",
                            "'t",
                            " shown",
                            " up",
                            " and",
                            " seized",
                            " movie",
                            "goers",
                            "'",
                            " hearts",
                            ".",
                            " Which",
                            " proves",
                            " that",
                            " movies",
                            ",",
                            " like",
                            " politics",
                            ",",
                            " aren",
                            "'t",
                            " always",
                            " predictable",
                            ".",
                            " Benjamin",
                            " B",
                            ".",
                            " is",
                            " Hillary",
                            " to",
                            " Sl",
                            "um",
                            "dog",
                            "'s",
                            " Obama",
                            ".",
                            " Odd",
                            "s",
                            " of",
                            " winning",
                            ":",
                            " 10",
                            " to",
                            " 1",
                            "\n",
                            "\n",
                            "Director",
                            ":",
                            " David",
                            " F",
                            "inc",
                            "her",
                            "\n",
                            "\n",
                            "An",
                            " impossible"
                        ],
                        "dataIndex": null,
                        "index": "2935",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.844,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            34.844,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:21.464Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 34.844,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm4uu42scui6663aoxaks3",
                        "tokens": [
                            " separated",
                            " in",
                            " their",
                            " own",
                            " sub",
                            "order",
                            " (\"",
                            "Al",
                            "c",
                            "ae",
                            "\"),",
                            " but",
                            " are",
                            " considered",
                            " part",
                            " of",
                            " the",
                            " L",
                            "ari",
                            " sub",
                            "order",
                            " which",
                            " otherwise",
                            " contains",
                            " gull",
                            "s",
                            " and",
                            " similar",
                            " birds",
                            ".",
                            " Judging",
                            " from",
                            " genetic",
                            " data",
                            ",",
                            " their",
                            " closest",
                            " living",
                            " relatives",
                            " appear",
                            " to",
                            " be",
                            " the",
                            " sk",
                            "u",
                            "as",
                            ",",
                            " with",
                            " these",
                            " two",
                            " line",
                            "ages",
                            " separating",
                            " about",
                            " 30",
                            " million",
                            " years",
                            " ago",
                            " (",
                            "my",
                            "a",
                            ").[",
                            "1",
                            "][",
                            "2",
                            "][",
                            "3",
                            "]",
                            " Alternatively",
                            ",",
                            " au",
                            "ks",
                            " may",
                            " have",
                            " split",
                            " off",
                            " far",
                            " earlier",
                            " from",
                            " the",
                            " rest",
                            " of",
                            " the",
                            " L",
                            "ari",
                            " and",
                            " undergone",
                            " strong",
                            " morph",
                            "ological",
                            ",",
                            " but",
                            " slow",
                            " genetic",
                            " evolution",
                            ",",
                            " which",
                            " would",
                            " require",
                            " a",
                            " very",
                            " high",
                            " evolutionary",
                            " pressure",
                            ",",
                            " coupled",
                            " with",
                            " a",
                            " long",
                            " lifespan",
                            " and",
                            " slow",
                            " reproduction",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " earliest",
                            " unequiv",
                            "ocal",
                            " fossils",
                            " of",
                            " au",
                            "ks",
                            " are",
                            " from",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "2935",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.912,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            32.912,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:21.464Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 34.844,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm4uu72sdgi666orkzx4qr",
                        "tokens": [
                            " separated",
                            " in",
                            " their",
                            " own",
                            " sub",
                            "order",
                            " (\"",
                            "Al",
                            "c",
                            "ae",
                            "\"),",
                            " but",
                            " are",
                            " considered",
                            " part",
                            " of",
                            " the",
                            " L",
                            "ari",
                            " sub",
                            "order",
                            " which",
                            " otherwise",
                            " contains",
                            " gull",
                            "s",
                            " and",
                            " similar",
                            " birds",
                            ".",
                            " Judging",
                            " from",
                            " genetic",
                            " data",
                            ",",
                            " their",
                            " closest",
                            " living",
                            " relatives",
                            " appear",
                            " to",
                            " be",
                            " the",
                            " sk",
                            "u",
                            "as",
                            ",",
                            " with",
                            " these",
                            " two",
                            " line",
                            "ages",
                            " separating",
                            " about",
                            " 30",
                            " million",
                            " years",
                            " ago",
                            " (",
                            "my",
                            "a",
                            ").[",
                            "1",
                            "][",
                            "2",
                            "][",
                            "3",
                            "]",
                            " Alternatively",
                            ",",
                            " au",
                            "ks",
                            " may",
                            " have",
                            " split",
                            " off",
                            " far",
                            " earlier",
                            " from",
                            " the",
                            " rest",
                            " of",
                            " the",
                            " L",
                            "ari",
                            " and",
                            " undergone",
                            " strong",
                            " morph",
                            "ological",
                            ",",
                            " but",
                            " slow",
                            " genetic",
                            " evolution",
                            ",",
                            " which",
                            " would",
                            " require",
                            " a",
                            " very",
                            " high",
                            " evolutionary",
                            " pressure",
                            ",",
                            " coupled",
                            " with",
                            " a",
                            " long",
                            " lifespan",
                            " and",
                            " slow",
                            " reproduction",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " earliest",
                            " unequiv",
                            "ocal",
                            " fossils",
                            " of",
                            " au",
                            "ks",
                            " are",
                            " from",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "2935",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.912,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            32.912,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:21.464Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 27.876,
                        "binMax": 34.844,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "4246",
            "description": "instructions or procedures",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6709603667259216,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "4246",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:12:06.834Z",
                "maxActApprox": 18.376,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4246,
                    867,
                    5492,
                    2892,
                    602,
                    2963,
                    2513,
                    1986,
                    3734,
                    2659,
                    3556,
                    612,
                    5168,
                    2013,
                    1900,
                    2577,
                    1453,
                    5896,
                    3036,
                    4264,
                    1686,
                    5775,
                    842,
                    4431,
                    2114
                ],
                "topkCosSimValues": [
                    1,
                    0.4697,
                    0.3986,
                    0.3863,
                    0.3605,
                    0.2988,
                    0.2899,
                    0.2869,
                    0.2856,
                    0.2849,
                    0.2672,
                    0.2667,
                    0.2592,
                    0.2572,
                    0.2551,
                    0.2525,
                    0.2488,
                    0.2249,
                    0.2128,
                    0.2077,
                    0.206,
                    0.1984,
                    0.1967,
                    0.1958,
                    0.1952
                ],
                "neuron_alignment_indices": [
                    70,
                    678,
                    103
                ],
                "neuron_alignment_values": [
                    0.115,
                    0.109,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.09,
                    0.083,
                    0.073
                ],
                "correlated_neurons_l1": [
                    0.106,
                    0.103,
                    0.023
                ],
                "correlated_features_indices": [
                    4307,
                    4285,
                    4226
                ],
                "correlated_features_pearson": [
                    0.033,
                    0.032,
                    0.016
                ],
                "correlated_features_l1": [
                    0.04,
                    0.035,
                    0.021
                ],
                "neg_str": [
                    "\u0138\u013c",
                    "BuyableInstoreAndOnline",
                    "\\\":",
                    "Defense",
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "\u00aa",
                    "rium",
                    "Hung",
                    "\u00e3\u0124\u00a9",
                    "Champ"
                ],
                "neg_values": [
                    -0.788,
                    -0.729,
                    -0.673,
                    -0.667,
                    -0.652,
                    -0.652,
                    -0.628,
                    -0.62,
                    -0.618,
                    -0.613
                ],
                "pos_str": [
                    " easily",
                    " safely",
                    " anytime",
                    " freely",
                    " depending",
                    " anonymously",
                    " cheaply",
                    " anywhere",
                    " arbitrarily",
                    " indefinitely"
                ],
                "pos_values": [
                    1.177,
                    1.081,
                    1.054,
                    1.044,
                    1.035,
                    1,
                    0.968,
                    0.954,
                    0.933,
                    0.932
                ],
                "frac_nonzero": 0.01659,
                "freq_hist_data_bar_heights": [
                    8581,
                    6772,
                    5580,
                    4488,
                    3827,
                    3102,
                    2605,
                    2255,
                    1972,
                    1730,
                    1386,
                    1237,
                    1162,
                    1005,
                    881,
                    740,
                    658,
                    592,
                    494,
                    418,
                    392,
                    352,
                    317,
                    273,
                    243,
                    199,
                    182,
                    131,
                    113,
                    102,
                    78,
                    71,
                    52,
                    30,
                    27,
                    31,
                    23,
                    15,
                    15,
                    13,
                    9,
                    2,
                    3,
                    6,
                    4,
                    6,
                    2,
                    3,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.184,
                    0.551,
                    0.919,
                    1.286,
                    1.654,
                    2.021,
                    2.389,
                    2.756,
                    3.124,
                    3.492,
                    3.859,
                    4.227,
                    4.594,
                    4.962,
                    5.329,
                    5.697,
                    6.064,
                    6.432,
                    6.799,
                    7.167,
                    7.534,
                    7.902,
                    8.269,
                    8.637,
                    9.004,
                    9.372,
                    9.74,
                    10.107,
                    10.475,
                    10.842,
                    11.21,
                    11.577,
                    11.945,
                    12.312,
                    12.68,
                    13.047,
                    13.415,
                    13.782,
                    14.15,
                    14.517,
                    14.885,
                    15.252,
                    15.62,
                    15.988,
                    16.355,
                    16.723,
                    17.09,
                    17.458,
                    17.825,
                    18.193
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    3,
                    5,
                    8,
                    19,
                    66,
                    109,
                    200,
                    354,
                    631,
                    932,
                    1447,
                    2097,
                    2755,
                    3407,
                    3972,
                    4465,
                    4723,
                    4675,
                    4466,
                    3918,
                    3178,
                    2605,
                    2059,
                    1449,
                    966,
                    653,
                    415,
                    242,
                    126,
                    93,
                    69,
                    44,
                    30,
                    15,
                    14,
                    12,
                    2,
                    13,
                    6,
                    1,
                    2,
                    2,
                    1,
                    3,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.769,
                    -0.729,
                    -0.69,
                    -0.651,
                    -0.612,
                    -0.572,
                    -0.533,
                    -0.494,
                    -0.454,
                    -0.415,
                    -0.376,
                    -0.336,
                    -0.297,
                    -0.258,
                    -0.218,
                    -0.179,
                    -0.14,
                    -0.101,
                    -0.061,
                    -0.022,
                    0.017,
                    0.057,
                    0.096,
                    0.135,
                    0.175,
                    0.214,
                    0.253,
                    0.292,
                    0.332,
                    0.371,
                    0.41,
                    0.45,
                    0.489,
                    0.528,
                    0.568,
                    0.607,
                    0.646,
                    0.685,
                    0.725,
                    0.764,
                    0.803,
                    0.843,
                    0.882,
                    0.921,
                    0.961,
                    1,
                    1.039,
                    1.078,
                    1.118,
                    1.157
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or procedures",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtex27wmndi666ae6es86y",
                        "tokens": [
                            " when",
                            " a",
                            " given",
                            " application",
                            " is",
                            " active",
                            " (",
                            "incre",
                            "ase",
                            " sensitivity",
                            " when",
                            " Counter",
                            "strike",
                            " is",
                            " active",
                            ",",
                            " glow",
                            " blue",
                            " when",
                            " Starcraft",
                            " II",
                            " is",
                            " active",
                            ").",
                            "\n",
                            "\n",
                            "Like",
                            " all",
                            " worthwhile",
                            " pro",
                            " gaming",
                            " m",
                            "ouses",
                            ",",
                            " it",
                            " has",
                            " a",
                            " button",
                            " that",
                            " lets",
                            " you",
                            " swap",
                            " between",
                            " low",
                            " and",
                            " high",
                            " sensitivity",
                            ".",
                            " These",
                            " can",
                            " be",
                            " modified",
                            " through",
                            " the",
                            " accompanying",
                            " software",
                            " package",
                            ",",
                            " but",
                            " the",
                            " default",
                            " specs",
                            " were",
                            " more",
                            " than",
                            " refined",
                            ".",
                            " Unlike",
                            " my",
                            " previous",
                            " mouse",
                            " (",
                            "Log",
                            "itech",
                            " MX",
                            "518",
                            "),",
                            " I",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " find",
                            " the",
                            " high",
                            " sensitivity",
                            " setting",
                            " to",
                            " be",
                            " uncontroll",
                            "able",
                            ".",
                            " It",
                            " is",
                            " definitely",
                            " the",
                            " setting",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " want",
                            " to",
                            " use",
                            " on",
                            " a",
                            " twitch",
                            " shooter",
                            ",",
                            " and",
                            " you",
                            " will",
                            " be",
                            " used",
                            " to",
                            " the",
                            " higher",
                            " sensitivity",
                            " in",
                            " 5",
                            "-",
                            "10",
                            " minutes",
                            ".",
                            " You",
                            "\u00e2\u0122",
                            "\u013b"
                        ],
                        "dataIndex": null,
                        "index": "4246",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.376,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.493,
                            8.912,
                            6.491,
                            0.646,
                            1.274,
                            1.329,
                            0,
                            0,
                            0,
                            0,
                            4.041,
                            18.376,
                            9.507,
                            1.897,
                            0,
                            0,
                            0.325,
                            1.083,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:12:08.224Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.376,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtex27wmnei666ac2khlxc",
                        "tokens": [
                            " Please",
                            " re",
                            "-",
                            "enter",
                            ".",
                            " You",
                            " must",
                            " select",
                            " a",
                            " newsletter",
                            " to",
                            " subscribe",
                            " to",
                            ".",
                            " Sign",
                            " Up",
                            " You",
                            " will",
                            " receive",
                            " emails",
                            " containing",
                            " news",
                            " content",
                            " ,",
                            " updates",
                            " and",
                            " promotions",
                            " from",
                            " The",
                            " New",
                            " York",
                            " Times",
                            ".",
                            " You",
                            " may",
                            " opt",
                            "-",
                            "out",
                            " at",
                            " any",
                            " time",
                            ".",
                            " You",
                            " agree",
                            " to",
                            " receive",
                            " occasional",
                            " updates",
                            " and",
                            " special",
                            " offers",
                            " for",
                            " The",
                            " New",
                            " York",
                            " Times",
                            "'s",
                            " products",
                            " and",
                            " services",
                            ".",
                            " Thank",
                            " you",
                            " for",
                            " subscribing",
                            ".",
                            " An",
                            " error",
                            " has",
                            " occurred",
                            ".",
                            " Please",
                            " try",
                            " again",
                            " later",
                            ".",
                            " View",
                            " all",
                            " New",
                            " York",
                            " Times",
                            " newsletters",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            " the",
                            " law",
                            " would",
                            " crack",
                            " down",
                            " on",
                            " abusive",
                            " practices",
                            " in",
                            " the",
                            " mortgage",
                            " industry",
                            ",",
                            " simpl",
                            "ifying",
                            " contracts",
                            " and",
                            " ending",
                            " hidden",
                            " fees",
                            " and",
                            " penalties",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "so",
                            " folks",
                            " know",
                            " what",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " signing",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Advertisement"
                        ],
                        "dataIndex": null,
                        "index": "4246",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.399,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.664,
                            9.307,
                            17.399,
                            8.611,
                            9.85,
                            9.087,
                            7.182,
                            3.182,
                            0,
                            1.136,
                            2.907,
                            0,
                            0.313,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.288,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:12:08.224Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.376,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtex27wmnfi6669jik1qoj",
                        "tokens": [
                            "-",
                            "l",
                            "apse",
                            " monitoring",
                            " indicates",
                            " that",
                            " the",
                            " depicted",
                            " creatures",
                            " appear",
                            " to",
                            " be",
                            " acting",
                            " in",
                            " a",
                            " non",
                            "-",
                            "violent",
                            " play",
                            " behavior",
                            " with",
                            " each",
                            " other",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " an",
                            " individual",
                            " age",
                            " 10",
                            " or",
                            " older",
                            " opens",
                            " the",
                            " h",
                            "inged",
                            " lid",
                            ",",
                            " SCP",
                            "-",
                            "190",
                            " contains",
                            " 17",
                            " mar",
                            "bles",
                            " of",
                            " assorted",
                            " size",
                            " and",
                            " color",
                            ",",
                            " 2",
                            " sticks",
                            " of",
                            " lightly",
                            " used",
                            " green",
                            " sidewalk",
                            " chalk",
                            ",",
                            " and",
                            " 1",
                            " deck",
                            " of",
                            " Bicycle",
                            " brand",
                            " playing",
                            " cards",
                            ".",
                            " These",
                            " objects",
                            " can",
                            " be",
                            " manipulated",
                            " within",
                            " the",
                            " confines",
                            " of",
                            " SCP",
                            "-",
                            "190",
                            ",",
                            " but",
                            " cannot",
                            " be",
                            " removed",
                            " from",
                            " it",
                            ".",
                            " Attempt",
                            "s",
                            " to",
                            " remove",
                            " these",
                            " objects",
                            " encounter",
                            " an",
                            " otherwise",
                            " undet",
                            "ect",
                            "able",
                            ",",
                            " imp",
                            "en",
                            "etr",
                            "able",
                            " barrier",
                            " stretching",
                            " across",
                            " the",
                            " opening",
                            " to",
                            " the",
                            " box",
                            ".",
                            " Individuals",
                            " age",
                            " 10",
                            " or",
                            " older",
                            " who",
                            " interact",
                            " with",
                            " SCP",
                            "-",
                            "190"
                        ],
                        "dataIndex": null,
                        "index": "4246",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.363,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.056,
                            17.363,
                            8.862,
                            3.905,
                            3.412,
                            3.773,
                            0,
                            0,
                            0.402,
                            5.739,
                            1.538,
                            0,
                            0,
                            7.378,
                            3.287,
                            2.196,
                            0,
                            0,
                            0,
                            0,
                            2.852,
                            0,
                            2.748,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:12:08.224Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.376,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "19",
            "description": "instructions or procedures",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6709603667259216,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "19",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:44:25.019Z",
                "maxActApprox": 55.094,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    19,
                    3077,
                    15189,
                    214,
                    10349,
                    12136,
                    17419,
                    20482,
                    10406,
                    1816,
                    9872,
                    5228,
                    8906,
                    18906,
                    2001,
                    12966,
                    6415,
                    6201,
                    3316,
                    4585,
                    13491,
                    22906,
                    2464,
                    18551,
                    15635
                ],
                "topkCosSimValues": [
                    1,
                    0.7027,
                    0.546,
                    0.5456,
                    0.4917,
                    0.4684,
                    0.4566,
                    0.4492,
                    0.4228,
                    0.4174,
                    0.4143,
                    0.402,
                    0.4001,
                    0.395,
                    0.3614,
                    0.3613,
                    0.3597,
                    0.354,
                    0.3508,
                    0.3414,
                    0.3339,
                    0.3253,
                    0.3241,
                    0.3238,
                    0.3234
                ],
                "neuron_alignment_indices": [
                    373,
                    36,
                    683
                ],
                "neuron_alignment_values": [
                    0.176,
                    0.117,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    466,
                    373,
                    683
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.022,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.023,
                    -0.006,
                    0.018
                ],
                "correlated_features_indices": [
                    16,
                    31,
                    8
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.004,
                    0.003,
                    0.003
                ],
                "neg_str": [
                    "enegger",
                    "jah",
                    " Mara",
                    "schild",
                    " emanc",
                    "azeera",
                    "alf",
                    "\u00e3\u0125\u0137",
                    " Mercy",
                    "Introduced"
                ],
                "neg_values": [
                    -0.772,
                    -0.663,
                    -0.61,
                    -0.6,
                    -0.579,
                    -0.562,
                    -0.556,
                    -0.551,
                    -0.549,
                    -0.542
                ],
                "pos_str": [
                    "ongyang",
                    "\u0135\u013a",
                    "ople",
                    " Lovecraft",
                    "ivot",
                    "ciation",
                    "sylvania",
                    "cipled",
                    "iddy",
                    "irie"
                ],
                "pos_values": [
                    0.929,
                    0.813,
                    0.743,
                    0.735,
                    0.692,
                    0.69,
                    0.677,
                    0.648,
                    0.638,
                    0.631
                ],
                "frac_nonzero": 0.00044,
                "freq_hist_data_bar_heights": [
                    431,
                    248,
                    167,
                    132,
                    95,
                    59,
                    30,
                    23,
                    18,
                    15,
                    15,
                    7,
                    17,
                    10,
                    7,
                    14,
                    9,
                    11,
                    11,
                    4,
                    3,
                    6,
                    6,
                    1,
                    7,
                    5,
                    2,
                    3,
                    1,
                    4,
                    1,
                    1,
                    5,
                    2,
                    2,
                    0,
                    1,
                    1,
                    2,
                    1,
                    0,
                    6,
                    1,
                    5,
                    4,
                    1,
                    2,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.551,
                    1.653,
                    2.755,
                    3.857,
                    4.959,
                    6.061,
                    7.162,
                    8.264,
                    9.366,
                    10.468,
                    11.57,
                    12.672,
                    13.774,
                    14.876,
                    15.977,
                    17.079,
                    18.181,
                    19.283,
                    20.385,
                    21.487,
                    22.589,
                    23.691,
                    24.793,
                    25.894,
                    26.996,
                    28.098,
                    29.2,
                    30.302,
                    31.404,
                    32.506,
                    33.608,
                    34.709,
                    35.811,
                    36.913,
                    38.015,
                    39.117,
                    40.219,
                    41.321,
                    42.423,
                    43.524,
                    44.626,
                    45.728,
                    46.83,
                    47.932,
                    49.034,
                    50.136,
                    51.238,
                    52.34,
                    53.441,
                    54.543
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    1,
                    2,
                    8,
                    14,
                    29,
                    52,
                    82,
                    169,
                    249,
                    460,
                    753,
                    1123,
                    1642,
                    2240,
                    2957,
                    3481,
                    4180,
                    4628,
                    4855,
                    4497,
                    4212,
                    3718,
                    3054,
                    2392,
                    1805,
                    1257,
                    849,
                    550,
                    361,
                    243,
                    155,
                    94,
                    56,
                    32,
                    22,
                    15,
                    6,
                    5,
                    2,
                    1,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.721,
                    -0.687,
                    -0.653,
                    -0.619,
                    -0.585,
                    -0.551,
                    -0.517,
                    -0.483,
                    -0.449,
                    -0.415,
                    -0.381,
                    -0.347,
                    -0.313,
                    -0.279,
                    -0.245,
                    -0.211,
                    -0.177,
                    -0.143,
                    -0.109,
                    -0.075,
                    -0.041,
                    -0.007,
                    0.027,
                    0.061,
                    0.095,
                    0.129,
                    0.163,
                    0.197,
                    0.231,
                    0.265,
                    0.299,
                    0.333,
                    0.367,
                    0.401,
                    0.435,
                    0.469,
                    0.504,
                    0.538,
                    0.572,
                    0.606,
                    0.64,
                    0.674,
                    0.708,
                    0.742,
                    0.776,
                    0.81,
                    0.844,
                    0.878,
                    0.912
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or procedures",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdlzwkj00ngi666608crjqh",
                        "tokens": [
                            " your",
                            " P",
                            ".",
                            "A",
                            " right",
                            " before",
                            " you",
                            " are",
                            " about",
                            " to",
                            " start",
                            ".",
                            " If",
                            " you",
                            " go",
                            " on",
                            " at",
                            " 9",
                            "PM",
                            ",",
                            " start",
                            " to",
                            " set",
                            " it",
                            " up",
                            " at",
                            " 8",
                            ":",
                            "57",
                            ".",
                            " At",
                            " 9",
                            ":",
                            "45",
                            " when",
                            " you",
                            " have",
                            " just",
                            " finished",
                            " running",
                            " your",
                            " last",
                            " mic",
                            " cable",
                            ",",
                            " proceed",
                            " to",
                            " do",
                            " a",
                            " sound",
                            " check",
                            ".",
                            " The",
                            " perfect",
                            " thing",
                            " to",
                            " say",
                            " into",
                            " the",
                            " mic",
                            " \u00e2\u0122",
                            "\u013e",
                            "Testing",
                            ",",
                            " one",
                            " two",
                            " three",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " After",
                            " that",
                            " say",
                            " \u00e2\u0122",
                            "\u013e",
                            "test",
                            "ies",
                            ",",
                            " one",
                            " two",
                            "\u00e2\u0122\u00a6",
                            " three",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " No",
                            " one",
                            " has",
                            " ever",
                            " heard",
                            " this",
                            " joke",
                            " before",
                            " and",
                            " will",
                            " know",
                            " your",
                            " band",
                            " means",
                            " business",
                            ".",
                            " After",
                            " three",
                            " hours",
                            " of",
                            " sound",
                            " check",
                            ",",
                            " pack",
                            " up",
                            " and",
                            " go",
                            " get",
                            " your",
                            " money",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " liked",
                            " this",
                            " art",
                            "c",
                            "ile",
                            ",",
                            " try"
                        ],
                        "dataIndex": null,
                        "index": "19",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.094,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            55.094,
                            13.802,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:44:30.449Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.094,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdlzwkj00nhi666ozdwymui",
                        "tokens": [
                            " testing",
                            " improved",
                            " after",
                            " resh",
                            "oots",
                            " were",
                            " incorporated",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " Greatest",
                            " Show",
                            "man",
                            "\u00e2\u0122",
                            "\u013f",
                            " opened",
                            " Wednesday",
                            " and",
                            " is",
                            " one",
                            " of",
                            " Fox",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " big",
                            " holiday",
                            " season",
                            " offerings",
                            ".",
                            " It",
                            " centers",
                            " on",
                            " P",
                            ".",
                            "T",
                            ".",
                            " Barn",
                            "um",
                            ",",
                            " the",
                            " legendary",
                            " circus",
                            " promoter",
                            ",",
                            " and",
                            " his",
                            " rise",
                            " from",
                            " street",
                            " ",
                            "urch",
                            "in",
                            " to",
                            " society",
                            " fixture",
                            ".",
                            " Along",
                            " with",
                            " Jack",
                            "man",
                            ",",
                            " the",
                            " cast",
                            " includes",
                            " Zac",
                            " E",
                            "f",
                            "ron",
                            ",",
                            " Z",
                            "end",
                            "aya",
                            ",",
                            " and",
                            " Michelle",
                            " Williams",
                            ".",
                            " Reviews",
                            " for",
                            " the",
                            " film",
                            " have",
                            " been",
                            " mixed",
                            ",",
                            " with",
                            " some",
                            " critics",
                            " d",
                            "inging",
                            " the",
                            " picture",
                            " for",
                            " its",
                            " plotting",
                            " and",
                            " pacing",
                            ",",
                            " but",
                            " it",
                            " did",
                            " pick",
                            " up",
                            " three",
                            " Golden",
                            " Globe",
                            " nominations",
                            ",",
                            " including",
                            " a",
                            " nod",
                            " for",
                            " best",
                            " musical",
                            " or",
                            " comedy",
                            ".",
                            " Aud",
                            "iences",
                            " also",
                            " seem",
                            " to",
                            " like"
                        ],
                        "dataIndex": null,
                        "index": "19",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.723,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.723,
                            17.172,
                            20.518,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:44:30.449Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.094,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdlzwkl00o0i666juncavd0",
                        "tokens": [
                            " testing",
                            " improved",
                            " after",
                            " resh",
                            "oots",
                            " were",
                            " incorporated",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " Greatest",
                            " Show",
                            "man",
                            "\u00e2\u0122",
                            "\u013f",
                            " opened",
                            " Wednesday",
                            " and",
                            " is",
                            " one",
                            " of",
                            " Fox",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " big",
                            " holiday",
                            " season",
                            " offerings",
                            ".",
                            " It",
                            " centers",
                            " on",
                            " P",
                            ".",
                            "T",
                            ".",
                            " Barn",
                            "um",
                            ",",
                            " the",
                            " legendary",
                            " circus",
                            " promoter",
                            ",",
                            " and",
                            " his",
                            " rise",
                            " from",
                            " street",
                            " ",
                            "urch",
                            "in",
                            " to",
                            " society",
                            " fixture",
                            ".",
                            " Along",
                            " with",
                            " Jack",
                            "man",
                            ",",
                            " the",
                            " cast",
                            " includes",
                            " Zac",
                            " E",
                            "f",
                            "ron",
                            ",",
                            " Z",
                            "end",
                            "aya",
                            ",",
                            " and",
                            " Michelle",
                            " Williams",
                            ".",
                            " Reviews",
                            " for",
                            " the",
                            " film",
                            " have",
                            " been",
                            " mixed",
                            ",",
                            " with",
                            " some",
                            " critics",
                            " d",
                            "inging",
                            " the",
                            " picture",
                            " for",
                            " its",
                            " plotting",
                            " and",
                            " pacing",
                            ",",
                            " but",
                            " it",
                            " did",
                            " pick",
                            " up",
                            " three",
                            " Golden",
                            " Globe",
                            " nominations",
                            ",",
                            " including",
                            " a",
                            " nod",
                            " for",
                            " best",
                            " musical",
                            " or",
                            " comedy",
                            ".",
                            " Aud",
                            "iences",
                            " also",
                            " seem",
                            " to",
                            " like"
                        ],
                        "dataIndex": null,
                        "index": "19",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.723,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.723,
                            17.172,
                            20.518,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:44:30.449Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 44.075,
                        "binMax": 55.094,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "3117",
            "description": "instructions or procedures",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6709231338180048,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "3117",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:48:33.602Z",
                "maxActApprox": 16.96,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3117,
                    14043,
                    10529,
                    5869,
                    8743,
                    19040,
                    5084,
                    21005,
                    11942,
                    4603,
                    9433,
                    19387,
                    11744,
                    8318,
                    11508,
                    19674,
                    135,
                    14524,
                    11128,
                    9890,
                    17534,
                    16493,
                    8764,
                    14255,
                    20453
                ],
                "topkCosSimValues": [
                    1,
                    0.516,
                    0.4959,
                    0.4739,
                    0.4461,
                    0.4378,
                    0.4165,
                    0.4002,
                    0.3875,
                    0.3816,
                    0.3804,
                    0.3771,
                    0.3539,
                    0.3467,
                    0.3458,
                    0.3452,
                    0.3443,
                    0.3321,
                    0.3312,
                    0.3273,
                    0.3253,
                    0.322,
                    0.3175,
                    0.3166,
                    0.3149
                ],
                "neuron_alignment_indices": [
                    678,
                    658,
                    690
                ],
                "neuron_alignment_values": [
                    0.142,
                    0.093,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    678,
                    35,
                    594
                ],
                "correlated_neurons_pearson": [
                    0.063,
                    0.036,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.061,
                    0.032,
                    0.032
                ],
                "correlated_features_indices": [
                    3130,
                    3174,
                    3156
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.007
                ],
                "neg_str": [
                    "vernment",
                    "\u00e5\u00a5\u00b3",
                    " tickets",
                    " successors",
                    "ticket",
                    "ijah",
                    "alien",
                    "IRD",
                    " emblem",
                    "isphere"
                ],
                "neg_values": [
                    -0.718,
                    -0.707,
                    -0.7,
                    -0.697,
                    -0.683,
                    -0.671,
                    -0.656,
                    -0.654,
                    -0.649,
                    -0.649
                ],
                "pos_str": [
                    " pH",
                    " cooled",
                    " drying",
                    " fermentation",
                    " dried",
                    " electroly",
                    " boiling",
                    " rinse",
                    " soak",
                    " curing"
                ],
                "pos_values": [
                    1.445,
                    1.359,
                    1.272,
                    1.25,
                    1.227,
                    1.214,
                    1.207,
                    1.201,
                    1.193,
                    1.175
                ],
                "frac_nonzero": 0.00288,
                "freq_hist_data_bar_heights": [
                    1424,
                    1153,
                    993,
                    787,
                    662,
                    557,
                    478,
                    399,
                    356,
                    305,
                    260,
                    225,
                    184,
                    148,
                    169,
                    127,
                    95,
                    103,
                    82,
                    78,
                    58,
                    43,
                    42,
                    42,
                    27,
                    29,
                    27,
                    22,
                    27,
                    28,
                    18,
                    14,
                    11,
                    13,
                    13,
                    8,
                    6,
                    9,
                    5,
                    8,
                    5,
                    8,
                    2,
                    1,
                    3,
                    0,
                    3,
                    2,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.17,
                    0.509,
                    0.848,
                    1.187,
                    1.527,
                    1.866,
                    2.205,
                    2.544,
                    2.883,
                    3.223,
                    3.562,
                    3.901,
                    4.24,
                    4.579,
                    4.919,
                    5.258,
                    5.597,
                    5.936,
                    6.275,
                    6.615,
                    6.954,
                    7.293,
                    7.632,
                    7.971,
                    8.31,
                    8.65,
                    8.989,
                    9.328,
                    9.667,
                    10.006,
                    10.346,
                    10.685,
                    11.024,
                    11.363,
                    11.702,
                    12.042,
                    12.381,
                    12.72,
                    13.059,
                    13.398,
                    13.738,
                    14.077,
                    14.416,
                    14.755,
                    15.094,
                    15.434,
                    15.773,
                    16.112,
                    16.451,
                    16.79
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    15,
                    54,
                    80,
                    163,
                    306,
                    593,
                    977,
                    1422,
                    2113,
                    2664,
                    3459,
                    4068,
                    4335,
                    4449,
                    4314,
                    3993,
                    3440,
                    2894,
                    2369,
                    1966,
                    1500,
                    1126,
                    909,
                    671,
                    543,
                    428,
                    309,
                    266,
                    204,
                    146,
                    134,
                    80,
                    59,
                    57,
                    40,
                    28,
                    17,
                    13,
                    11,
                    13,
                    3,
                    5,
                    5,
                    1,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.697,
                    -0.653,
                    -0.61,
                    -0.567,
                    -0.524,
                    -0.48,
                    -0.437,
                    -0.394,
                    -0.35,
                    -0.307,
                    -0.264,
                    -0.221,
                    -0.177,
                    -0.134,
                    -0.091,
                    -0.048,
                    -0.004,
                    0.039,
                    0.082,
                    0.125,
                    0.169,
                    0.212,
                    0.255,
                    0.298,
                    0.342,
                    0.385,
                    0.428,
                    0.472,
                    0.515,
                    0.558,
                    0.601,
                    0.645,
                    0.688,
                    0.731,
                    0.774,
                    0.818,
                    0.861,
                    0.904,
                    0.947,
                    0.991,
                    1.034,
                    1.077,
                    1.12,
                    1.164,
                    1.207,
                    1.25,
                    1.293,
                    1.337,
                    1.38,
                    1.423
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or procedures",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm56gm2yk2i666if4co1al",
                        "tokens": [
                            " L",
                            "OV",
                            "ES",
                            ",",
                            " then",
                            " why",
                            " not",
                            "?",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " my",
                            " opinion",
                            ",",
                            " the",
                            " more",
                            " ice",
                            " cream",
                            " in",
                            " my",
                            " freezer",
                            ",",
                            " the",
                            " better",
                            ".",
                            " \u00f0\u0141\u013b\u0124",
                            "\n",
                            "\n",
                            "Course",
                            ",",
                            " as",
                            " with",
                            " most",
                            " dairy",
                            " free",
                            ",",
                            " egg",
                            " free",
                            " ice",
                            " cream",
                            " recipes",
                            ",",
                            " this",
                            " Vegan",
                            " &",
                            " Paleo",
                            " F",
                            "udge",
                            " Tracks",
                            " Ice",
                            " Cream",
                            " will",
                            " be",
                            " cre",
                            "ami",
                            "est",
                            " when",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " at",
                            " a",
                            " soft",
                            " serve",
                            " consistency",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " how",
                            " I",
                            " prefer",
                            " to",
                            " eat",
                            " it",
                            ".",
                            " If",
                            " your",
                            " ice",
                            " cream",
                            " has",
                            " been",
                            " sitting",
                            " in",
                            " the",
                            " freezer",
                            " for",
                            " a",
                            " while",
                            " and",
                            " is",
                            " hard",
                            ",",
                            " simply",
                            " let",
                            " it",
                            " warm",
                            " up",
                            " for",
                            " a",
                            " while",
                            " on",
                            " the",
                            " counter",
                            ",",
                            " maybe",
                            " 15",
                            "-",
                            "30",
                            " minutes",
                            ";",
                            " or",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " super",
                            " impatient",
                            " like",
                            " me",
                            ",",
                            " you",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "3117",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.96,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.232,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.378,
                            0.598,
                            0,
                            1.449,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.083,
                            4.841,
                            4.866,
                            5.277,
                            9.608,
                            5.34,
                            6.93,
                            3.683,
                            0,
                            1.234,
                            0,
                            0,
                            0,
                            11.47,
                            13.119,
                            16.96,
                            15.193,
                            7.628,
                            7.964,
                            8.874,
                            9.064,
                            4.756,
                            10.402,
                            5.37,
                            3.639,
                            4.507,
                            0,
                            1.149,
                            3.579,
                            0,
                            0.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:36.544Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.96,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm56gn2ykbi666ewrlum4m",
                        "tokens": [
                            " L",
                            "OV",
                            "ES",
                            ",",
                            " then",
                            " why",
                            " not",
                            "?",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " my",
                            " opinion",
                            ",",
                            " the",
                            " more",
                            " ice",
                            " cream",
                            " in",
                            " my",
                            " freezer",
                            ",",
                            " the",
                            " better",
                            ".",
                            " \u00f0\u0141\u013b\u0124",
                            "\n",
                            "\n",
                            "Course",
                            ",",
                            " as",
                            " with",
                            " most",
                            " dairy",
                            " free",
                            ",",
                            " egg",
                            " free",
                            " ice",
                            " cream",
                            " recipes",
                            ",",
                            " this",
                            " Vegan",
                            " &",
                            " Paleo",
                            " F",
                            "udge",
                            " Tracks",
                            " Ice",
                            " Cream",
                            " will",
                            " be",
                            " cre",
                            "ami",
                            "est",
                            " when",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " at",
                            " a",
                            " soft",
                            " serve",
                            " consistency",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " how",
                            " I",
                            " prefer",
                            " to",
                            " eat",
                            " it",
                            ".",
                            " If",
                            " your",
                            " ice",
                            " cream",
                            " has",
                            " been",
                            " sitting",
                            " in",
                            " the",
                            " freezer",
                            " for",
                            " a",
                            " while",
                            " and",
                            " is",
                            " hard",
                            ",",
                            " simply",
                            " let",
                            " it",
                            " warm",
                            " up",
                            " for",
                            " a",
                            " while",
                            " on",
                            " the",
                            " counter",
                            ",",
                            " maybe",
                            " 15",
                            "-",
                            "30",
                            " minutes",
                            ";",
                            " or",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " super",
                            " impatient",
                            " like",
                            " me",
                            ",",
                            " you",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "3117",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.96,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.232,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.378,
                            0.598,
                            0,
                            1.449,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.083,
                            4.841,
                            4.866,
                            5.277,
                            9.608,
                            5.34,
                            6.93,
                            3.683,
                            0,
                            1.234,
                            0,
                            0,
                            0,
                            11.47,
                            13.119,
                            16.96,
                            15.193,
                            7.628,
                            7.964,
                            8.874,
                            9.064,
                            4.756,
                            10.402,
                            5.37,
                            3.639,
                            4.507,
                            0,
                            1.149,
                            3.579,
                            0,
                            0.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:36.544Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.96,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm56gm2yk3i666sao2a9ul",
                        "tokens": [
                            " flask",
                            " can",
                            " be",
                            " r",
                            "ins",
                            "ed",
                            " out",
                            " with",
                            " ether",
                            " an",
                            " poured",
                            " into",
                            " the",
                            " 1000",
                            " ml",
                            " flask",
                            ".",
                            " once",
                            " again",
                            " this",
                            " flask",
                            " is",
                            " set",
                            " up",
                            " for",
                            " a",
                            " simple",
                            " dist",
                            "illation",
                            " and",
                            " full",
                            " aspir",
                            "ator",
                            " is",
                            " applied",
                            " to",
                            " it",
                            ".",
                            " the",
                            " last",
                            " of",
                            " the",
                            " tri",
                            "ethy",
                            "lam",
                            "ine",
                            " and",
                            " ether",
                            " (",
                            "bp",
                            " 88",
                            " C",
                            "\u00c2\u00b0",
                            ")",
                            " will",
                            " be",
                            " gone",
                            " shortly",
                            ".",
                            "\n",
                            "\n",
                            "now",
                            " a",
                            " vacuum",
                            " from",
                            " a",
                            " good",
                            " quality",
                            " vacuum",
                            " pump",
                            " is",
                            " applied",
                            " to",
                            " the",
                            " dist",
                            "illation",
                            ".",
                            " A",
                            " vacuum",
                            " of",
                            " less",
                            " 1",
                            " mm",
                            "H",
                            "g",
                            " is",
                            " to",
                            " be",
                            " preferred",
                            " here",
                            " to",
                            " keep",
                            " the",
                            " dist",
                            "illation",
                            " temperatures",
                            " reasonable",
                            " and",
                            " to",
                            " avoid",
                            " burning",
                            " product",
                            ".",
                            " BE",
                            " CARE",
                            "FUL",
                            " THE",
                            " P",
                            "UMP",
                            " MUST",
                            " NOT",
                            " BE",
                            " STOP",
                            "P",
                            "ED",
                            " D",
                            "UR",
                            "ING",
                            " THE",
                            " D",
                            "IST",
                            "ILL",
                            "ATION",
                            ".",
                            " IF",
                            " THE",
                            " P"
                        ],
                        "dataIndex": null,
                        "index": "3117",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.632,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0.992,
                            3.428,
                            16.632,
                            11.101,
                            7.838,
                            7.376,
                            4.261,
                            4.053,
                            5.161,
                            4.263,
                            0.116,
                            6.747,
                            1.55,
                            3.956,
                            2.286,
                            0,
                            0,
                            0,
                            0,
                            1.932,
                            0,
                            0,
                            0.643,
                            0,
                            0.488,
                            2.557,
                            1.347,
                            2.739,
                            1.805,
                            2.617,
                            0.122,
                            2.221,
                            3.574,
                            0.738,
                            0.504,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.091,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.657,
                            8.933,
                            1.466,
                            0,
                            0,
                            0,
                            0,
                            1.906,
                            0,
                            1.669,
                            0,
                            0,
                            1.551,
                            0,
                            1.22,
                            0,
                            0,
                            0.707,
                            0,
                            0.207,
                            2.378,
                            1.374,
                            1.094,
                            2.561,
                            3.943,
                            0.434,
                            0,
                            0,
                            4.678,
                            0,
                            2.332,
                            0,
                            2.116,
                            3.413,
                            2.051,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.501,
                            1.019,
                            2.508,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.838,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.684,
                            0,
                            1.436,
                            0,
                            3.034,
                            0.602,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:48:36.544Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.96,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "13621",
            "description": "technical instructions or steps",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6590245366096497,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "13621",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:02:12.925Z",
                "maxActApprox": 9.581,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13621,
                    16849,
                    14829,
                    1933,
                    2718,
                    11559,
                    23014,
                    1174,
                    17386,
                    17200,
                    19649,
                    2095,
                    8027,
                    1377,
                    17278,
                    1714,
                    1217,
                    12523,
                    9458,
                    20396,
                    16392,
                    8657,
                    22135,
                    13700,
                    22888
                ],
                "topkCosSimValues": [
                    1,
                    0.5092,
                    0.5031,
                    0.4831,
                    0.4829,
                    0.48,
                    0.4778,
                    0.4619,
                    0.4596,
                    0.4522,
                    0.45,
                    0.4445,
                    0.4445,
                    0.4441,
                    0.4438,
                    0.4429,
                    0.4409,
                    0.4379,
                    0.4354,
                    0.4349,
                    0.4325,
                    0.4317,
                    0.4281,
                    0.4251,
                    0.4248
                ],
                "neuron_alignment_indices": [
                    87,
                    447,
                    255
                ],
                "neuron_alignment_values": [
                    0.418,
                    0.107,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.023,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    87,
                    326,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.059,
                    0.047,
                    0.034
                ],
                "correlated_neurons_l1": [
                    -0.009,
                    0.059,
                    0.007
                ],
                "correlated_features_indices": [
                    13571,
                    13574,
                    13688
                ],
                "correlated_features_pearson": [
                    0.038,
                    0.022,
                    0.016
                ],
                "correlated_features_l1": [
                    0.045,
                    0.023,
                    0.018
                ],
                "neg_str": [
                    " Tate",
                    "fashion",
                    " Huss",
                    "knit",
                    "aughs",
                    "Girls",
                    "onne",
                    "endon",
                    "rosse",
                    " Durham"
                ],
                "neg_values": [
                    -0.711,
                    -0.624,
                    -0.599,
                    -0.583,
                    -0.575,
                    -0.569,
                    -0.551,
                    -0.548,
                    -0.534,
                    -0.534
                ],
                "pos_str": [
                    " DHCP",
                    " IPv",
                    " DNS",
                    " permissions",
                    " initialization",
                    " login",
                    " caching",
                    " SSH",
                    " Password",
                    " debug"
                ],
                "pos_values": [
                    1.038,
                    0.974,
                    0.967,
                    0.95,
                    0.939,
                    0.934,
                    0.93,
                    0.917,
                    0.903,
                    0.9
                ],
                "frac_nonzero": 0.00449,
                "freq_hist_data_bar_heights": [
                    1771,
                    1569,
                    1394,
                    1288,
                    1027,
                    867,
                    834,
                    720,
                    609,
                    553,
                    497,
                    417,
                    379,
                    314,
                    300,
                    225,
                    207,
                    190,
                    148,
                    134,
                    97,
                    94,
                    78,
                    55,
                    55,
                    48,
                    40,
                    27,
                    30,
                    29,
                    23,
                    23,
                    17,
                    11,
                    6,
                    10,
                    3,
                    2,
                    6,
                    7,
                    7,
                    3,
                    4,
                    1,
                    1,
                    2,
                    1,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.287,
                    0.479,
                    0.671,
                    0.862,
                    1.054,
                    1.246,
                    1.437,
                    1.629,
                    1.82,
                    2.012,
                    2.204,
                    2.395,
                    2.587,
                    2.778,
                    2.97,
                    3.162,
                    3.353,
                    3.545,
                    3.737,
                    3.928,
                    4.12,
                    4.311,
                    4.503,
                    4.695,
                    4.886,
                    5.078,
                    5.269,
                    5.461,
                    5.653,
                    5.844,
                    6.036,
                    6.228,
                    6.419,
                    6.611,
                    6.802,
                    6.994,
                    7.186,
                    7.377,
                    7.569,
                    7.76,
                    7.952,
                    8.144,
                    8.335,
                    8.527,
                    8.719,
                    8.91,
                    9.102,
                    9.293,
                    9.485
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    3,
                    3,
                    11,
                    42,
                    78,
                    140,
                    291,
                    473,
                    827,
                    1314,
                    1815,
                    2477,
                    3133,
                    3565,
                    3870,
                    4149,
                    4190,
                    3847,
                    3479,
                    3053,
                    2563,
                    2117,
                    1706,
                    1405,
                    1169,
                    971,
                    746,
                    630,
                    513,
                    386,
                    291,
                    239,
                    165,
                    145,
                    126,
                    93,
                    72,
                    48,
                    36,
                    29,
                    15,
                    16,
                    4,
                    4,
                    4,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.694,
                    -0.659,
                    -0.624,
                    -0.589,
                    -0.554,
                    -0.519,
                    -0.484,
                    -0.449,
                    -0.414,
                    -0.379,
                    -0.344,
                    -0.309,
                    -0.274,
                    -0.239,
                    -0.204,
                    -0.169,
                    -0.134,
                    -0.099,
                    -0.064,
                    -0.029,
                    0.006,
                    0.041,
                    0.076,
                    0.111,
                    0.146,
                    0.181,
                    0.216,
                    0.251,
                    0.286,
                    0.321,
                    0.356,
                    0.391,
                    0.426,
                    0.461,
                    0.496,
                    0.531,
                    0.566,
                    0.601,
                    0.636,
                    0.671,
                    0.706,
                    0.741,
                    0.776,
                    0.811,
                    0.846,
                    0.881,
                    0.916,
                    0.95,
                    0.985,
                    1.02
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "technical instructions or steps",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmmrb4cy0ki666wsbinnjc",
                        "tokens": [
                            " hit",
                            " the",
                            " Subscribe",
                            " button",
                            ".",
                            "<|endoftext|>",
                            "This",
                            " post",
                            " details",
                            " the",
                            " process",
                            " for",
                            " align",
                            "ing",
                            " V",
                            "MD",
                            "K",
                            " files",
                            " properly",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " great",
                            " post",
                            " from",
                            " Duncan",
                            " E",
                            "pping",
                            " on",
                            " why",
                            " you",
                            " need",
                            " to",
                            " do",
                            " this",
                            " here",
                            ".",
                            " In",
                            " these",
                            " notes",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " dealing",
                            " with",
                            " Net",
                            "App",
                            " storage",
                            ".",
                            " Duncan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " post",
                            " details",
                            " some",
                            " other",
                            " tools",
                            " for",
                            " other",
                            " storage",
                            " vendors",
                            " (",
                            "like",
                            " Uber",
                            "Al",
                            "ign",
                            " from",
                            " Nick",
                            " Weaver",
                            ").",
                            "\n",
                            "\n",
                            "Before",
                            " beginning",
                            " this",
                            " process",
                            ",",
                            " ensure",
                            " that",
                            ":",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " with",
                            " mis",
                            "aligned",
                            " V",
                            "MD",
                            "K",
                            " is",
                            " powered",
                            " off",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " has",
                            " no",
                            " snapshots",
                            "\n",
                            "\n",
                            "Ac",
                            "quire",
                            " the",
                            " file",
                            " \u00e2\u0122",
                            "\u013e",
                            "m",
                            "br",
                            "tools",
                            "_",
                            "es",
                            "xi",
                            ".",
                            "tg",
                            "z",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " SCP"
                        ],
                        "dataIndex": null,
                        "index": "13621",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.581,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.616,
                            0.07,
                            0,
                            0,
                            0.084,
                            1.073,
                            5.865,
                            7.826,
                            4.421,
                            4.485,
                            3.863,
                            0.599,
                            0,
                            6.137,
                            6.034,
                            4.751,
                            3.314,
                            1.895,
                            7.515,
                            9.581,
                            8.767,
                            7.672,
                            3.885,
                            4.061,
                            2.992,
                            7.359,
                            8.402,
                            5.691,
                            3.906,
                            1.219,
                            0,
                            5.65,
                            3.321,
                            2.27,
                            4.006,
                            6.074,
                            3.961,
                            0.372,
                            0.781,
                            2.407,
                            0.552,
                            0.392,
                            4.633,
                            4.42
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:16.727Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 9.581,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmmrb5cy0pi666v4cyf4z9",
                        "tokens": [
                            " hit",
                            " the",
                            " Subscribe",
                            " button",
                            ".",
                            "<|endoftext|>",
                            "This",
                            " post",
                            " details",
                            " the",
                            " process",
                            " for",
                            " align",
                            "ing",
                            " V",
                            "MD",
                            "K",
                            " files",
                            " properly",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " great",
                            " post",
                            " from",
                            " Duncan",
                            " E",
                            "pping",
                            " on",
                            " why",
                            " you",
                            " need",
                            " to",
                            " do",
                            " this",
                            " here",
                            ".",
                            " In",
                            " these",
                            " notes",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " dealing",
                            " with",
                            " Net",
                            "App",
                            " storage",
                            ".",
                            " Duncan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " post",
                            " details",
                            " some",
                            " other",
                            " tools",
                            " for",
                            " other",
                            " storage",
                            " vendors",
                            " (",
                            "like",
                            " Uber",
                            "Al",
                            "ign",
                            " from",
                            " Nick",
                            " Weaver",
                            ").",
                            "\n",
                            "\n",
                            "Before",
                            " beginning",
                            " this",
                            " process",
                            ",",
                            " ensure",
                            " that",
                            ":",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " with",
                            " mis",
                            "aligned",
                            " V",
                            "MD",
                            "K",
                            " is",
                            " powered",
                            " off",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " has",
                            " no",
                            " snapshots",
                            "\n",
                            "\n",
                            "Ac",
                            "quire",
                            " the",
                            " file",
                            " \u00e2\u0122",
                            "\u013e",
                            "m",
                            "br",
                            "tools",
                            "_",
                            "es",
                            "xi",
                            ".",
                            "tg",
                            "z",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " SCP"
                        ],
                        "dataIndex": null,
                        "index": "13621",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.581,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.616,
                            0.07,
                            0,
                            0,
                            0.084,
                            1.073,
                            5.865,
                            7.826,
                            4.421,
                            4.485,
                            3.863,
                            0.599,
                            0,
                            6.137,
                            6.034,
                            4.751,
                            3.314,
                            1.895,
                            7.515,
                            9.581,
                            8.767,
                            7.672,
                            3.885,
                            4.061,
                            2.992,
                            7.359,
                            8.402,
                            5.691,
                            3.906,
                            1.219,
                            0,
                            5.65,
                            3.321,
                            2.27,
                            4.006,
                            6.074,
                            3.961,
                            0.372,
                            0.781,
                            2.407,
                            0.552,
                            0.392,
                            4.633,
                            4.42
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:16.727Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 9.581,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmmrb5cy0si6667l9q7kjd",
                        "tokens": [
                            " hit",
                            " the",
                            " Subscribe",
                            " button",
                            ".",
                            "<|endoftext|>",
                            "This",
                            " post",
                            " details",
                            " the",
                            " process",
                            " for",
                            " align",
                            "ing",
                            " V",
                            "MD",
                            "K",
                            " files",
                            " properly",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " great",
                            " post",
                            " from",
                            " Duncan",
                            " E",
                            "pping",
                            " on",
                            " why",
                            " you",
                            " need",
                            " to",
                            " do",
                            " this",
                            " here",
                            ".",
                            " In",
                            " these",
                            " notes",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " dealing",
                            " with",
                            " Net",
                            "App",
                            " storage",
                            ".",
                            " Duncan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " post",
                            " details",
                            " some",
                            " other",
                            " tools",
                            " for",
                            " other",
                            " storage",
                            " vendors",
                            " (",
                            "like",
                            " Uber",
                            "Al",
                            "ign",
                            " from",
                            " Nick",
                            " Weaver",
                            ").",
                            "\n",
                            "\n",
                            "Before",
                            " beginning",
                            " this",
                            " process",
                            ",",
                            " ensure",
                            " that",
                            ":",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " with",
                            " mis",
                            "aligned",
                            " V",
                            "MD",
                            "K",
                            " is",
                            " powered",
                            " off",
                            "\n",
                            "\n",
                            "\u2013",
                            " VM",
                            " has",
                            " no",
                            " snapshots",
                            "\n",
                            "\n",
                            "Ac",
                            "quire",
                            " the",
                            " file",
                            " \u00e2\u0122",
                            "\u013e",
                            "m",
                            "br",
                            "tools",
                            "_",
                            "es",
                            "xi",
                            ".",
                            "tg",
                            "z",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " SCP"
                        ],
                        "dataIndex": null,
                        "index": "13621",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.581,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.616,
                            0.07,
                            0,
                            0,
                            0.084,
                            1.073,
                            5.865,
                            7.826,
                            4.421,
                            4.485,
                            3.863,
                            0.599,
                            0,
                            6.137,
                            6.034,
                            4.751,
                            3.314,
                            1.895,
                            7.515,
                            9.581,
                            8.767,
                            7.672,
                            3.885,
                            4.061,
                            2.992,
                            7.359,
                            8.402,
                            5.691,
                            3.906,
                            1.219,
                            0,
                            5.65,
                            3.321,
                            2.27,
                            4.006,
                            6.074,
                            3.961,
                            0.372,
                            0.781,
                            2.407,
                            0.552,
                            0.392,
                            4.633,
                            4.42
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:16.727Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 9.581,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "1192",
            "description": "technical instructions or steps",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6589875221252441,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "1192",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:16:42.036Z",
                "maxActApprox": 32.758,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1192,
                    3327,
                    2929,
                    11610,
                    3866,
                    66,
                    10164,
                    8980,
                    3726,
                    11354,
                    2328,
                    4195,
                    362,
                    10047,
                    735,
                    6406,
                    2179,
                    8472,
                    7057,
                    8591,
                    3837,
                    1905,
                    8732,
                    1101,
                    8767
                ],
                "topkCosSimValues": [
                    1,
                    0.464,
                    0.4272,
                    0.4259,
                    0.4116,
                    0.406,
                    0.3955,
                    0.3609,
                    0.3468,
                    0.3323,
                    0.3314,
                    0.3164,
                    0.3068,
                    0.3032,
                    0.3024,
                    0.2877,
                    0.2815,
                    0.2813,
                    0.2761,
                    0.274,
                    0.269,
                    0.2652,
                    0.2544,
                    0.2425,
                    0.2369
                ],
                "neuron_alignment_indices": [
                    373,
                    745,
                    534
                ],
                "neuron_alignment_values": [
                    0.182,
                    0.096,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    326,
                    450,
                    89
                ],
                "correlated_neurons_pearson": [
                    0.043,
                    0.037,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.045,
                    0.033,
                    0.031
                ],
                "correlated_features_indices": [
                    1227,
                    1234,
                    1207
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.01,
                    0.008
                ],
                "correlated_features_l1": [
                    0.033,
                    0.012,
                    0.01
                ],
                "neg_str": [
                    " feud",
                    " cousins",
                    " frail",
                    " funeral",
                    " weddings",
                    " starving",
                    " veiled",
                    " dope",
                    " outwe",
                    " marches"
                ],
                "neg_values": [
                    -0.725,
                    -0.689,
                    -0.669,
                    -0.668,
                    -0.663,
                    -0.661,
                    -0.658,
                    -0.653,
                    -0.647,
                    -0.644
                ],
                "pos_str": [
                    " Config",
                    " Settings",
                    " Properties",
                    " Activate",
                    " Verify",
                    "cknow",
                    " Enable",
                    " Insert",
                    " Create",
                    " Preferences"
                ],
                "pos_values": [
                    1.006,
                    0.973,
                    0.954,
                    0.944,
                    0.884,
                    0.882,
                    0.874,
                    0.858,
                    0.854,
                    0.853
                ],
                "frac_nonzero": 0.00323,
                "freq_hist_data_bar_heights": [
                    2711,
                    1855,
                    1252,
                    983,
                    716,
                    521,
                    384,
                    299,
                    235,
                    199,
                    155,
                    128,
                    100,
                    82,
                    75,
                    51,
                    48,
                    43,
                    30,
                    42,
                    31,
                    21,
                    29,
                    17,
                    18,
                    16,
                    16,
                    6,
                    9,
                    8,
                    8,
                    8,
                    8,
                    4,
                    3,
                    3,
                    6,
                    4,
                    3,
                    2,
                    3,
                    0,
                    3,
                    3,
                    1,
                    1,
                    2,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.328,
                    0.983,
                    1.638,
                    2.293,
                    2.948,
                    3.603,
                    4.259,
                    4.914,
                    5.569,
                    6.224,
                    6.879,
                    7.534,
                    8.19,
                    8.845,
                    9.5,
                    10.155,
                    10.81,
                    11.465,
                    12.121,
                    12.776,
                    13.431,
                    14.086,
                    14.741,
                    15.396,
                    16.052,
                    16.707,
                    17.362,
                    18.017,
                    18.672,
                    19.327,
                    19.983,
                    20.638,
                    21.293,
                    21.948,
                    22.603,
                    23.258,
                    23.914,
                    24.569,
                    25.224,
                    25.879,
                    26.534,
                    27.189,
                    27.845,
                    28.5,
                    29.155,
                    29.81,
                    30.465,
                    31.12,
                    31.776,
                    32.431
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    6,
                    7,
                    13,
                    26,
                    55,
                    93,
                    152,
                    251,
                    356,
                    579,
                    812,
                    1096,
                    1572,
                    1985,
                    2431,
                    2849,
                    3215,
                    3558,
                    3642,
                    3640,
                    3603,
                    3307,
                    3068,
                    2740,
                    2229,
                    1978,
                    1643,
                    1332,
                    976,
                    783,
                    587,
                    468,
                    339,
                    251,
                    170,
                    137,
                    78,
                    73,
                    49,
                    37,
                    18,
                    21,
                    9,
                    8,
                    7,
                    3,
                    0,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.708,
                    -0.673,
                    -0.638,
                    -0.604,
                    -0.569,
                    -0.534,
                    -0.5,
                    -0.465,
                    -0.431,
                    -0.396,
                    -0.361,
                    -0.327,
                    -0.292,
                    -0.258,
                    -0.223,
                    -0.188,
                    -0.154,
                    -0.119,
                    -0.084,
                    -0.05,
                    -0.015,
                    0.019,
                    0.054,
                    0.089,
                    0.123,
                    0.158,
                    0.192,
                    0.227,
                    0.262,
                    0.296,
                    0.331,
                    0.365,
                    0.4,
                    0.435,
                    0.469,
                    0.504,
                    0.539,
                    0.573,
                    0.608,
                    0.642,
                    0.677,
                    0.712,
                    0.746,
                    0.781,
                    0.815,
                    0.85,
                    0.885,
                    0.919,
                    0.954,
                    0.988
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "technical instructions or steps",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtkuuizln7i666owo8aga4",
                        "tokens": [
                            "ch",
                            "mitt",
                            ".",
                            "\n",
                            "\n",
                            "Ben",
                            " Sch",
                            "mitt",
                            " is",
                            " a",
                            " Tribune",
                            "-",
                            "Review",
                            " assistant",
                            " news",
                            " editor",
                            ".",
                            " You",
                            " can",
                            " contact",
                            " Ben",
                            " at",
                            " 412",
                            "-",
                            "320",
                            "-",
                            "799",
                            "1",
                            ",",
                            " b",
                            "sch",
                            "mitt",
                            "@",
                            "t",
                            "rib",
                            "web",
                            ".",
                            "com",
                            " or",
                            " via",
                            " Twitter",
                            " .",
                            "<|endoftext|>",
                            "To",
                            " everyone",
                            " having",
                            " difficulties",
                            " downloading",
                            " this",
                            " map",
                            ",",
                            "\n",
                            "\n",
                            "I",
                            " was",
                            " able",
                            " to",
                            " get",
                            " it",
                            " working",
                            " following",
                            " these",
                            " steps",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " Launch",
                            " Steam",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " Go",
                            " to",
                            " your",
                            " Library",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Right",
                            " click",
                            " AR",
                            "K",
                            ":",
                            " Survival",
                            " Ev",
                            "olved",
                            "\n",
                            "\n",
                            "4",
                            ".",
                            " Select",
                            " '",
                            "View",
                            " Download",
                            "able",
                            " Content",
                            "'",
                            " in",
                            " the",
                            " popup",
                            " menu",
                            "\n",
                            "\n",
                            "(",
                            "For",
                            " me",
                            " at",
                            " this",
                            " point",
                            ",",
                            " '",
                            "The",
                            " Center",
                            "'",
                            " map",
                            " was",
                            " displayed",
                            " on",
                            " a",
                            " list",
                            " in",
                            " a",
                            " new"
                        ],
                        "dataIndex": null,
                        "index": "1192",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.758,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.808,
                            4.223,
                            9.374,
                            0,
                            11.957,
                            10.747,
                            6.08,
                            16.847,
                            18.442,
                            24.113,
                            17.751,
                            5.33,
                            15.706,
                            8.708,
                            7.989,
                            22.139,
                            23.609,
                            26.222,
                            5.117,
                            2.394,
                            0.141,
                            0,
                            0,
                            0,
                            17.147,
                            14.289,
                            9.851,
                            28.782,
                            32.758,
                            20.852,
                            4.891,
                            0,
                            0,
                            0,
                            21.218,
                            21.427,
                            19.127,
                            15.049,
                            19.592,
                            15.619,
                            11.634,
                            12.385,
                            4.982,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.926,
                            0,
                            0,
                            1.59,
                            1.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.487
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:45.318Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 32.758,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtkuujzlnei666ha8xmqqg",
                        "tokens": [
                            "ch",
                            "mitt",
                            ".",
                            "\n",
                            "\n",
                            "Ben",
                            " Sch",
                            "mitt",
                            " is",
                            " a",
                            " Tribune",
                            "-",
                            "Review",
                            " assistant",
                            " news",
                            " editor",
                            ".",
                            " You",
                            " can",
                            " contact",
                            " Ben",
                            " at",
                            " 412",
                            "-",
                            "320",
                            "-",
                            "799",
                            "1",
                            ",",
                            " b",
                            "sch",
                            "mitt",
                            "@",
                            "t",
                            "rib",
                            "web",
                            ".",
                            "com",
                            " or",
                            " via",
                            " Twitter",
                            " .",
                            "<|endoftext|>",
                            "To",
                            " everyone",
                            " having",
                            " difficulties",
                            " downloading",
                            " this",
                            " map",
                            ",",
                            "\n",
                            "\n",
                            "I",
                            " was",
                            " able",
                            " to",
                            " get",
                            " it",
                            " working",
                            " following",
                            " these",
                            " steps",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " Launch",
                            " Steam",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " Go",
                            " to",
                            " your",
                            " Library",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Right",
                            " click",
                            " AR",
                            "K",
                            ":",
                            " Survival",
                            " Ev",
                            "olved",
                            "\n",
                            "\n",
                            "4",
                            ".",
                            " Select",
                            " '",
                            "View",
                            " Download",
                            "able",
                            " Content",
                            "'",
                            " in",
                            " the",
                            " popup",
                            " menu",
                            "\n",
                            "\n",
                            "(",
                            "For",
                            " me",
                            " at",
                            " this",
                            " point",
                            ",",
                            " '",
                            "The",
                            " Center",
                            "'",
                            " map",
                            " was",
                            " displayed",
                            " on",
                            " a",
                            " list",
                            " in",
                            " a",
                            " new"
                        ],
                        "dataIndex": null,
                        "index": "1192",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.758,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.808,
                            4.223,
                            9.374,
                            0,
                            11.957,
                            10.747,
                            6.08,
                            16.847,
                            18.442,
                            24.113,
                            17.751,
                            5.33,
                            15.706,
                            8.708,
                            7.989,
                            22.139,
                            23.609,
                            26.222,
                            5.117,
                            2.394,
                            0.141,
                            0,
                            0,
                            0,
                            17.147,
                            14.289,
                            9.851,
                            28.782,
                            32.758,
                            20.852,
                            4.891,
                            0,
                            0,
                            0,
                            21.218,
                            21.427,
                            19.127,
                            15.049,
                            19.592,
                            15.619,
                            11.634,
                            12.385,
                            4.982,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.926,
                            0,
                            0,
                            1.59,
                            1.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.487
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:45.318Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 32.758,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtkuukzlnmi666jovzva40",
                        "tokens": [
                            "ch",
                            "mitt",
                            ".",
                            "\n",
                            "\n",
                            "Ben",
                            " Sch",
                            "mitt",
                            " is",
                            " a",
                            " Tribune",
                            "-",
                            "Review",
                            " assistant",
                            " news",
                            " editor",
                            ".",
                            " You",
                            " can",
                            " contact",
                            " Ben",
                            " at",
                            " 412",
                            "-",
                            "320",
                            "-",
                            "799",
                            "1",
                            ",",
                            " b",
                            "sch",
                            "mitt",
                            "@",
                            "t",
                            "rib",
                            "web",
                            ".",
                            "com",
                            " or",
                            " via",
                            " Twitter",
                            " .",
                            "<|endoftext|>",
                            "To",
                            " everyone",
                            " having",
                            " difficulties",
                            " downloading",
                            " this",
                            " map",
                            ",",
                            "\n",
                            "\n",
                            "I",
                            " was",
                            " able",
                            " to",
                            " get",
                            " it",
                            " working",
                            " following",
                            " these",
                            " steps",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " Launch",
                            " Steam",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " Go",
                            " to",
                            " your",
                            " Library",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Right",
                            " click",
                            " AR",
                            "K",
                            ":",
                            " Survival",
                            " Ev",
                            "olved",
                            "\n",
                            "\n",
                            "4",
                            ".",
                            " Select",
                            " '",
                            "View",
                            " Download",
                            "able",
                            " Content",
                            "'",
                            " in",
                            " the",
                            " popup",
                            " menu",
                            "\n",
                            "\n",
                            "(",
                            "For",
                            " me",
                            " at",
                            " this",
                            " point",
                            ",",
                            " '",
                            "The",
                            " Center",
                            "'",
                            " map",
                            " was",
                            " displayed",
                            " on",
                            " a",
                            " list",
                            " in",
                            " a",
                            " new"
                        ],
                        "dataIndex": null,
                        "index": "1192",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.758,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.808,
                            4.223,
                            9.374,
                            0,
                            11.957,
                            10.747,
                            6.08,
                            16.847,
                            18.442,
                            24.113,
                            17.751,
                            5.33,
                            15.706,
                            8.708,
                            7.989,
                            22.139,
                            23.609,
                            26.222,
                            5.117,
                            2.394,
                            0.141,
                            0,
                            0,
                            0,
                            17.147,
                            14.289,
                            9.851,
                            28.782,
                            32.758,
                            20.852,
                            4.891,
                            0,
                            0,
                            0,
                            21.218,
                            21.427,
                            19.127,
                            15.049,
                            19.592,
                            15.619,
                            11.634,
                            12.385,
                            4.982,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.926,
                            0,
                            0,
                            1.59,
                            1.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.487
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:16:45.318Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 32.758,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12525",
            "description": "instructions or calls to action",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6565789785040046,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12525",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:00:43.987Z",
                "maxActApprox": 57.894,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12525,
                    3322,
                    14067,
                    4657,
                    12132,
                    24361,
                    11864,
                    15454,
                    21335,
                    23111,
                    21679,
                    7793,
                    15056,
                    12143,
                    1015,
                    3800,
                    7934,
                    19662,
                    15870,
                    1870,
                    12657,
                    4122,
                    24344,
                    667,
                    19086
                ],
                "topkCosSimValues": [
                    1,
                    0.6184,
                    0.4249,
                    0.4227,
                    0.4195,
                    0.4015,
                    0.3992,
                    0.3938,
                    0.3914,
                    0.3876,
                    0.3781,
                    0.3775,
                    0.3758,
                    0.363,
                    0.3624,
                    0.3595,
                    0.3548,
                    0.3533,
                    0.3505,
                    0.3482,
                    0.3408,
                    0.3262,
                    0.3217,
                    0.3075,
                    0.3063
                ],
                "neuron_alignment_indices": [
                    4,
                    373,
                    75
                ],
                "neuron_alignment_values": [
                    0.133,
                    0.113,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    4,
                    75,
                    258
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.018,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.019,
                    0.017
                ],
                "correlated_features_indices": [
                    12459,
                    12525,
                    12450
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MpServer",
                    "TPPStreamerBot",
                    "impl",
                    "Imagine",
                    "\u00e2\u0138\u00ac",
                    "oub",
                    "ells",
                    "Orig",
                    "Beck",
                    "bled"
                ],
                "neg_values": [
                    -0.807,
                    -0.75,
                    -0.709,
                    -0.664,
                    -0.638,
                    -0.637,
                    -0.629,
                    -0.624,
                    -0.614,
                    -0.603
                ],
                "pos_str": [
                    " checking",
                    " beforehand",
                    " patience",
                    " clicking",
                    "!:",
                    " Shogun",
                    "rity",
                    " careful",
                    "nir",
                    " check"
                ],
                "pos_values": [
                    0.819,
                    0.712,
                    0.687,
                    0.663,
                    0.658,
                    0.643,
                    0.636,
                    0.623,
                    0.621,
                    0.621
                ],
                "frac_nonzero": 0.00023,
                "freq_hist_data_bar_heights": [
                    232,
                    118,
                    83,
                    58,
                    30,
                    35,
                    19,
                    21,
                    14,
                    12,
                    6,
                    5,
                    5,
                    2,
                    2,
                    5,
                    1,
                    1,
                    1,
                    1,
                    3,
                    4,
                    2,
                    4,
                    3,
                    1,
                    2,
                    2,
                    3,
                    0,
                    1,
                    5,
                    5,
                    6,
                    1,
                    2,
                    4,
                    2,
                    2,
                    4,
                    3,
                    4,
                    4,
                    1,
                    4,
                    1,
                    4,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.583,
                    1.741,
                    2.899,
                    4.057,
                    5.215,
                    6.372,
                    7.53,
                    8.688,
                    9.846,
                    11.004,
                    12.161,
                    13.319,
                    14.477,
                    15.635,
                    16.793,
                    17.95,
                    19.108,
                    20.266,
                    21.424,
                    22.582,
                    23.739,
                    24.897,
                    26.055,
                    27.213,
                    28.37,
                    29.528,
                    30.686,
                    31.844,
                    33.002,
                    34.159,
                    35.317,
                    36.475,
                    37.633,
                    38.791,
                    39.948,
                    41.106,
                    42.264,
                    43.422,
                    44.58,
                    45.737,
                    46.895,
                    48.053,
                    49.211,
                    50.369,
                    51.526,
                    52.684,
                    53.842,
                    55,
                    56.158,
                    57.315
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    1,
                    1,
                    5,
                    8,
                    6,
                    25,
                    45,
                    63,
                    113,
                    195,
                    272,
                    407,
                    614,
                    899,
                    1270,
                    1750,
                    2195,
                    2633,
                    3315,
                    3691,
                    4090,
                    4289,
                    4167,
                    3929,
                    3711,
                    3061,
                    2547,
                    1999,
                    1544,
                    1158,
                    746,
                    562,
                    341,
                    245,
                    146,
                    78,
                    56,
                    32,
                    17,
                    12,
                    10,
                    2,
                    3,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.791,
                    -0.758,
                    -0.726,
                    -0.693,
                    -0.661,
                    -0.628,
                    -0.596,
                    -0.563,
                    -0.531,
                    -0.498,
                    -0.466,
                    -0.433,
                    -0.401,
                    -0.368,
                    -0.336,
                    -0.303,
                    -0.271,
                    -0.238,
                    -0.205,
                    -0.173,
                    -0.14,
                    -0.108,
                    -0.075,
                    -0.043,
                    -0.01,
                    0.022,
                    0.055,
                    0.087,
                    0.12,
                    0.152,
                    0.185,
                    0.217,
                    0.25,
                    0.282,
                    0.315,
                    0.347,
                    0.38,
                    0.412,
                    0.445,
                    0.477,
                    0.51,
                    0.542,
                    0.575,
                    0.607,
                    0.64,
                    0.672,
                    0.705,
                    0.737,
                    0.77,
                    0.802
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or calls to action",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmkxs1bwgri666cehhehwk",
                        "tokens": [
                            "The",
                            " IRS",
                            " announced",
                            " on",
                            " January",
                            " 28",
                            "th",
                            ",",
                            " that",
                            " individual",
                            " fil",
                            "ers",
                            " who",
                            " use",
                            " form",
                            " 8",
                            "86",
                            "3",
                            " for",
                            " Education",
                            " Credits",
                            " (",
                            "Hope",
                            " Credit",
                            ",",
                            " Lifetime",
                            " Learning",
                            " Credit",
                            " and",
                            " other",
                            " Education",
                            " Credits",
                            ")",
                            " have",
                            " to",
                            " wait",
                            " until",
                            " at",
                            " least",
                            " \u00e2\u0122",
                            "\u013a",
                            "Mid",
                            " February",
                            "\u00e2\u0122",
                            "\u013b",
                            " before",
                            " filing",
                            ".",
                            " The",
                            " IRS",
                            " notice",
                            ",",
                            " along",
                            " with",
                            " a",
                            " listing",
                            " of",
                            " other",
                            " forms",
                            " that",
                            " can",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " be",
                            " filed",
                            " until",
                            " late",
                            " February",
                            " or",
                            " early",
                            " March",
                            " can",
                            " be",
                            " found",
                            " at",
                            " this",
                            " link",
                            ".",
                            " Be",
                            " sure",
                            " to",
                            " check",
                            " it",
                            " out",
                            " to",
                            " see",
                            " when",
                            " you",
                            " can",
                            " file",
                            " your",
                            " return",
                            ".",
                            "\n",
                            "\n",
                            "Looks",
                            " like",
                            " tomorrow",
                            " is",
                            " going",
                            " to",
                            " be",
                            " a",
                            " big",
                            " day",
                            " for",
                            " e",
                            "-",
                            "f",
                            "iling",
                            " returns",
                            " so",
                            " expect",
                            " some",
                            " delays",
                            ".",
                            " Also",
                            ",",
                            " the",
                            " IRS",
                            " announced",
                            " earlier",
                            " there",
                            " would",
                            " be",
                            " delays"
                        ],
                        "dataIndex": null,
                        "index": "12525",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.894,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.894,
                            6.268,
                            5.202,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:51.818Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.894,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmkxs1bwgsi666vw1xe2sv",
                        "tokens": [
                            " soft",
                            " launch",
                            ".",
                            " If",
                            " you",
                            " missed",
                            " out",
                            " on",
                            " our",
                            " previous",
                            " report",
                            ",",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " deal",
                            ":",
                            " by",
                            " purchasing",
                            " one",
                            " (",
                            "or",
                            " more",
                            "!)",
                            " of",
                            " the",
                            " clothing",
                            " items",
                            " available",
                            " via",
                            " Te",
                            "es",
                            "pring",
                            ",",
                            " you",
                            " will",
                            " be",
                            " able",
                            " to",
                            " either",
                            " support",
                            " the",
                            " entire",
                            " tournament",
                            " or",
                            " directly",
                            " fund",
                            " the",
                            " prize",
                            " pool",
                            " for",
                            " one",
                            " of",
                            " the",
                            " event",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " eleven",
                            " official",
                            " games",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " addition",
                            " to",
                            " t",
                            "-",
                            "shirts",
                            ",",
                            " they",
                            " are",
                            " also",
                            " offering",
                            " tanks",
                            " and",
                            " hood",
                            "ies",
                            " for",
                            " those",
                            " of",
                            " you",
                            " looking",
                            " for",
                            " something",
                            " outside",
                            " the",
                            " normal",
                            " tops",
                            " most",
                            " tournaments",
                            " offer",
                            ".",
                            "\n",
                            "\n",
                            "Should",
                            " you",
                            " be",
                            " interested",
                            " in",
                            " taking",
                            " part",
                            " in",
                            " this",
                            " promotion",
                            ",",
                            " be",
                            " sure",
                            " to",
                            " do",
                            " so",
                            " before",
                            " it",
                            " ends",
                            " on",
                            " April",
                            " 14",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " individual"
                        ],
                        "dataIndex": null,
                        "index": "12525",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.322,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.322,
                            2.113,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:51.818Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.894,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmkxs1bwgti666js9iq96z",
                        "tokens": [
                            " Gardens",
                            " bot",
                            "anical",
                            " wonder",
                            "land",
                            ",",
                            " which",
                            " recently",
                            " celebrated",
                            " its",
                            " 80",
                            "th",
                            " anniversary",
                            ".",
                            "\n",
                            "\n",
                            "With",
                            " all",
                            " of",
                            " these",
                            " additions",
                            " the",
                            " park",
                            " has",
                            " definitely",
                            " given",
                            " us",
                            " plenty",
                            " to",
                            " talk",
                            " about",
                            "!",
                            " Look",
                            " for",
                            " more",
                            " coming",
                            " soon",
                            " on",
                            " each",
                            " of",
                            " these",
                            " projects",
                            "!",
                            "\n",
                            "\n",
                            "Be",
                            " sure",
                            " to",
                            " follow",
                            " our",
                            " various",
                            " social",
                            " media",
                            " channels",
                            " for",
                            " more",
                            " on",
                            " these",
                            " exciting",
                            " additions",
                            ":",
                            "<|endoftext|>",
                            "Times",
                            " Square",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " b",
                            "rawling",
                            " Spider",
                            "-",
                            "Men",
                            " and",
                            " extortion",
                            "ist",
                            " El",
                            "mos",
                            " bes",
                            "mir",
                            "ch",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "Cross",
                            "roads",
                            " of",
                            " the",
                            " World",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "But",
                            " a",
                            " more",
                            " stomach",
                            "-",
                            "turn",
                            "ing",
                            " scourge",
                            " is",
                            " the",
                            " tourist",
                            "-",
                            "t",
                            "ram",
                            "pled",
                            " district",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " chain",
                            " restaurants",
                            ",",
                            " which",
                            " conveniently",
                            " concentrate",
                            " Manhattan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " terrible",
                            " food",
                            " in",
                            " every"
                        ],
                        "dataIndex": null,
                        "index": "12525",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.898,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.898,
                            1.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:51.818Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.894,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12430",
            "description": "commands or instructions",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6562257409095764,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12430",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:00:43.987Z",
                "maxActApprox": 46.692,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12430,
                    17857,
                    862,
                    17007,
                    8089,
                    15090,
                    7267,
                    8786,
                    4263,
                    10557,
                    3571,
                    12826,
                    16094,
                    3876,
                    4827,
                    21959,
                    20213,
                    8533,
                    23639,
                    21655,
                    17802,
                    13749,
                    143,
                    1281,
                    16886
                ],
                "topkCosSimValues": [
                    1,
                    0.8101,
                    0.7891,
                    0.7648,
                    0.7086,
                    0.6896,
                    0.6784,
                    0.6562,
                    0.572,
                    0.4169,
                    0.3918,
                    0.342,
                    0.3375,
                    0.3308,
                    0.303,
                    0.2849,
                    0.2842,
                    0.2783,
                    0.2652,
                    0.2633,
                    0.262,
                    0.2564,
                    0.2533,
                    0.2527,
                    0.2458
                ],
                "neuron_alignment_indices": [
                    240,
                    611,
                    566
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.107,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    240,
                    611,
                    183
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.032,
                    0.031
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.034,
                    0.03
                ],
                "correlated_features_indices": [
                    12533,
                    12456,
                    12476
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " accompanies",
                    " livest",
                    " constitu",
                    " advertised",
                    " agre",
                    "idding",
                    "nesota",
                    "nar",
                    " coerc",
                    " dissatisf"
                ],
                "neg_values": [
                    -0.792,
                    -0.693,
                    -0.684,
                    -0.658,
                    -0.644,
                    -0.607,
                    -0.593,
                    -0.588,
                    -0.585,
                    -0.574
                ],
                "pos_str": [
                    "aways",
                    " advantage",
                    "away",
                    " heed",
                    "uchi",
                    " aback",
                    " care",
                    "overs",
                    "prising",
                    "frey"
                ],
                "pos_values": [
                    1.264,
                    1.096,
                    0.938,
                    0.929,
                    0.906,
                    0.894,
                    0.837,
                    0.818,
                    0.804,
                    0.751
                ],
                "frac_nonzero": 0.00042,
                "freq_hist_data_bar_heights": [
                    227,
                    180,
                    161,
                    126,
                    71,
                    57,
                    45,
                    49,
                    32,
                    33,
                    29,
                    29,
                    19,
                    18,
                    14,
                    16,
                    20,
                    9,
                    17,
                    19,
                    11,
                    4,
                    7,
                    11,
                    3,
                    8,
                    3,
                    4,
                    6,
                    11,
                    8,
                    6,
                    6,
                    8,
                    5,
                    3,
                    3,
                    1,
                    5,
                    1,
                    17,
                    10,
                    6,
                    1,
                    1,
                    3,
                    2,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.477,
                    1.41,
                    2.344,
                    3.278,
                    4.211,
                    5.145,
                    6.079,
                    7.012,
                    7.946,
                    8.879,
                    9.813,
                    10.747,
                    11.68,
                    12.614,
                    13.548,
                    14.481,
                    15.415,
                    16.349,
                    17.282,
                    18.216,
                    19.149,
                    20.083,
                    21.017,
                    21.95,
                    22.884,
                    23.818,
                    24.751,
                    25.685,
                    26.618,
                    27.552,
                    28.486,
                    29.419,
                    30.353,
                    31.287,
                    32.22,
                    33.154,
                    34.088,
                    35.021,
                    35.955,
                    36.888,
                    37.822,
                    38.756,
                    39.689,
                    40.623,
                    41.557,
                    42.49,
                    43.424,
                    44.357,
                    45.291,
                    46.225
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    3,
                    14,
                    27,
                    52,
                    121,
                    235,
                    440,
                    704,
                    1158,
                    1760,
                    2594,
                    3308,
                    4033,
                    4697,
                    4980,
                    5093,
                    4768,
                    4181,
                    3520,
                    2709,
                    1993,
                    1410,
                    930,
                    590,
                    349,
                    226,
                    152,
                    79,
                    44,
                    31,
                    19,
                    11,
                    7,
                    5,
                    1,
                    2,
                    0,
                    3,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.771,
                    -0.73,
                    -0.689,
                    -0.648,
                    -0.607,
                    -0.566,
                    -0.525,
                    -0.484,
                    -0.443,
                    -0.401,
                    -0.36,
                    -0.319,
                    -0.278,
                    -0.237,
                    -0.196,
                    -0.155,
                    -0.114,
                    -0.072,
                    -0.031,
                    0.01,
                    0.051,
                    0.092,
                    0.133,
                    0.174,
                    0.215,
                    0.256,
                    0.298,
                    0.339,
                    0.38,
                    0.421,
                    0.462,
                    0.503,
                    0.544,
                    0.585,
                    0.626,
                    0.668,
                    0.709,
                    0.75,
                    0.791,
                    0.832,
                    0.873,
                    0.914,
                    0.955,
                    0.996,
                    1.038,
                    1.079,
                    1.12,
                    1.161,
                    1.202,
                    1.243
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "commands or instructions",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmkt03bt78i666jyt9zg5k",
                        "tokens": [
                            " by",
                            ".",
                            " The",
                            " information",
                            " age",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " biggest",
                            " flaw",
                            " is",
                            " how",
                            " all",
                            " information",
                            " is",
                            " treated",
                            " as",
                            " equal",
                            " in",
                            " value",
                            ".",
                            " Take",
                            ",",
                            " for",
                            " example",
                            ",",
                            " the",
                            " recent",
                            " Planned",
                            " Parenthood",
                            " scandal",
                            ":",
                            "\n",
                            "\n",
                            "A",
                            " group",
                            " known",
                            " as",
                            " the",
                            " Center",
                            " for",
                            " Medical",
                            " Progress",
                            " published",
                            " videos",
                            " which",
                            " claimed",
                            " to",
                            " show",
                            " Planned",
                            " Parenthood",
                            " associates",
                            " engaging",
                            " in",
                            " the",
                            " sale",
                            " of",
                            " body",
                            " parts",
                            " from",
                            " aborted",
                            " fet",
                            "uses",
                            ".",
                            " The",
                            " videos",
                            " were",
                            " proven",
                            " to",
                            " be",
                            " edited",
                            " and",
                            " fals",
                            "ified",
                            ",",
                            " with",
                            " members",
                            " of",
                            " C",
                            "MP",
                            " imperson",
                            "ating",
                            " government",
                            " officials",
                            " and",
                            " having",
                            " created",
                            " a",
                            " dummy",
                            " corporation",
                            " that",
                            " pretended",
                            " to",
                            " deal",
                            " in",
                            " the",
                            " very",
                            " same",
                            " body",
                            " parts",
                            " PP",
                            " was",
                            " accused",
                            " of",
                            " selling",
                            ".",
                            "\n",
                            "\n",
                            "Texas",
                            " held",
                            " a",
                            " grand",
                            " jury",
                            " to",
                            " potentially",
                            " indict",
                            " Planned",
                            " Parenthood",
                            ".",
                            " Instead",
                            ",",
                            " the",
                            " creators",
                            " of",
                            " the",
                            " videos",
                            " were"
                        ],
                        "dataIndex": null,
                        "index": "12430",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.692,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.692,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:45.625Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.692,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmkt03bt79i666q5osdwgz",
                        "tokens": [
                            ",",
                            " and",
                            " how",
                            " does",
                            " it",
                            " actually",
                            " compare",
                            " to",
                            " other",
                            " countries",
                            ",",
                            " particularly",
                            " the",
                            " US",
                            "?",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " look",
                            " at",
                            " the",
                            " data",
                            ":",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " Wolf",
                            "ram",
                            " Alpha",
                            " [",
                            "1",
                            "]",
                            "\n",
                            "\n",
                            "China",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " per",
                            " capita",
                            " coal",
                            " consumption",
                            " only",
                            " reached",
                            " parity",
                            " with",
                            " US",
                            " levels",
                            " for",
                            " the",
                            " first",
                            " time",
                            " in",
                            " 2012",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " case",
                            " anybody",
                            " is",
                            " thinking",
                            " that",
                            " things",
                            " may",
                            " have",
                            " changed",
                            " substantially",
                            " in",
                            " the",
                            " last",
                            " couple",
                            " years",
                            " (",
                            "be",
                            "yond",
                            " the",
                            " range",
                            " of",
                            " Wolf",
                            "ram",
                            " Alpha",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " dataset",
                            "),",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " latest",
                            " snapshot",
                            " (",
                            "2014",
                            ")",
                            " [",
                            "2",
                            ",",
                            " 3",
                            "]:",
                            "\n",
                            "\n",
                            "2014",
                            " per",
                            " Cap",
                            "ita",
                            " Coal",
                            " Consumption",
                            "\n",
                            "\n",
                            "China",
                            ":",
                            " 2",
                            ".",
                            "53",
                            " t",
                            " /",
                            " person",
                            " year",
                            "\n",
                            "\n",
                            "US"
                        ],
                        "dataIndex": null,
                        "index": "12430",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.466,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.466,
                            0.013,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:45.625Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.692,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmkt05bt7si666o7hvbe59",
                        "tokens": [
                            ",",
                            " and",
                            " how",
                            " does",
                            " it",
                            " actually",
                            " compare",
                            " to",
                            " other",
                            " countries",
                            ",",
                            " particularly",
                            " the",
                            " US",
                            "?",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " look",
                            " at",
                            " the",
                            " data",
                            ":",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " Wolf",
                            "ram",
                            " Alpha",
                            " [",
                            "1",
                            "]",
                            "\n",
                            "\n",
                            "China",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " per",
                            " capita",
                            " coal",
                            " consumption",
                            " only",
                            " reached",
                            " parity",
                            " with",
                            " US",
                            " levels",
                            " for",
                            " the",
                            " first",
                            " time",
                            " in",
                            " 2012",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " case",
                            " anybody",
                            " is",
                            " thinking",
                            " that",
                            " things",
                            " may",
                            " have",
                            " changed",
                            " substantially",
                            " in",
                            " the",
                            " last",
                            " couple",
                            " years",
                            " (",
                            "be",
                            "yond",
                            " the",
                            " range",
                            " of",
                            " Wolf",
                            "ram",
                            " Alpha",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " dataset",
                            "),",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " latest",
                            " snapshot",
                            " (",
                            "2014",
                            ")",
                            " [",
                            "2",
                            ",",
                            " 3",
                            "]:",
                            "\n",
                            "\n",
                            "2014",
                            " per",
                            " Cap",
                            "ita",
                            " Coal",
                            " Consumption",
                            "\n",
                            "\n",
                            "China",
                            ":",
                            " 2",
                            ".",
                            "53",
                            " t",
                            " /",
                            " person",
                            " year",
                            "\n",
                            "\n",
                            "US"
                        ],
                        "dataIndex": null,
                        "index": "12430",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.466,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.466,
                            0.013,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:00:45.625Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 37.353,
                        "binMax": 46.692,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "1434",
            "description": "technical instruction steps or procedures",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6497735589877641,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "1434",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:08:26.153Z",
                "maxActApprox": 30.992,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1434,
                    4989,
                    2021,
                    5337,
                    732,
                    2382,
                    1405,
                    2992,
                    5399,
                    3679,
                    4959,
                    1930,
                    1254,
                    3953,
                    2100,
                    467,
                    5647,
                    5470,
                    3866,
                    4887,
                    963,
                    2995,
                    3964,
                    5498,
                    3645
                ],
                "topkCosSimValues": [
                    1,
                    0.4089,
                    0.4006,
                    0.3989,
                    0.3392,
                    0.3369,
                    0.3259,
                    0.2772,
                    0.2734,
                    0.2693,
                    0.2611,
                    0.2536,
                    0.2476,
                    0.2412,
                    0.2389,
                    0.2363,
                    0.2361,
                    0.2211,
                    0.2204,
                    0.2152,
                    0.2143,
                    0.2122,
                    0.2092,
                    0.204,
                    0.2019
                ],
                "neuron_alignment_indices": [
                    300,
                    172,
                    58
                ],
                "neuron_alignment_values": [
                    0.108,
                    0.101,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    300,
                    545,
                    566
                ],
                "correlated_neurons_pearson": [
                    0.066,
                    0.053,
                    0.048
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.048,
                    0.05
                ],
                "correlated_features_indices": [
                    1527,
                    1516,
                    1475
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.009,
                    0.007
                ],
                "correlated_features_l1": [
                    0.023,
                    0.011,
                    0.017
                ],
                "neg_str": [
                    " envy",
                    "ILY",
                    " nevertheless",
                    " understatement",
                    "always",
                    "ItemImage",
                    " advoc",
                    " differently",
                    " nonetheless",
                    " curiously"
                ],
                "neg_values": [
                    -0.723,
                    -0.667,
                    -0.643,
                    -0.636,
                    -0.63,
                    -0.607,
                    -0.607,
                    -0.598,
                    -0.596,
                    -0.592
                ],
                "pos_str": [
                    " finished",
                    " completes",
                    " completed",
                    " mastered",
                    " stabilized",
                    "acqu",
                    " finalized",
                    " perfected",
                    " completion",
                    " sufficiently"
                ],
                "pos_values": [
                    0.972,
                    0.942,
                    0.939,
                    0.927,
                    0.897,
                    0.877,
                    0.859,
                    0.847,
                    0.845,
                    0.818
                ],
                "frac_nonzero": 0.00614,
                "freq_hist_data_bar_heights": [
                    4702,
                    3398,
                    2456,
                    1736,
                    1351,
                    1043,
                    718,
                    589,
                    469,
                    389,
                    300,
                    232,
                    188,
                    180,
                    174,
                    176,
                    124,
                    99,
                    115,
                    89,
                    98,
                    82,
                    78,
                    61,
                    56,
                    40,
                    49,
                    41,
                    24,
                    26,
                    27,
                    31,
                    21,
                    20,
                    19,
                    19,
                    12,
                    13,
                    12,
                    9,
                    7,
                    7,
                    4,
                    4,
                    1,
                    4,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.31,
                    0.93,
                    1.55,
                    2.17,
                    2.789,
                    3.409,
                    4.029,
                    4.649,
                    5.269,
                    5.889,
                    6.508,
                    7.128,
                    7.748,
                    8.368,
                    8.988,
                    9.608,
                    10.227,
                    10.847,
                    11.467,
                    12.087,
                    12.707,
                    13.327,
                    13.947,
                    14.566,
                    15.186,
                    15.806,
                    16.426,
                    17.046,
                    17.666,
                    18.285,
                    18.905,
                    19.525,
                    20.145,
                    20.765,
                    21.385,
                    22.004,
                    22.624,
                    23.244,
                    23.864,
                    24.484,
                    25.104,
                    25.724,
                    26.343,
                    26.963,
                    27.583,
                    28.203,
                    28.823,
                    29.443,
                    30.062,
                    30.682
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    5,
                    14,
                    22,
                    38,
                    56,
                    95,
                    182,
                    309,
                    489,
                    754,
                    1124,
                    1561,
                    2022,
                    2618,
                    3329,
                    3765,
                    4098,
                    4328,
                    4195,
                    4108,
                    3574,
                    2964,
                    2415,
                    1954,
                    1578,
                    1227,
                    894,
                    690,
                    540,
                    391,
                    287,
                    180,
                    131,
                    101,
                    67,
                    58,
                    30,
                    24,
                    11,
                    8,
                    5,
                    1,
                    1,
                    3,
                    2,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.706,
                    -0.672,
                    -0.638,
                    -0.604,
                    -0.57,
                    -0.536,
                    -0.502,
                    -0.468,
                    -0.434,
                    -0.401,
                    -0.367,
                    -0.333,
                    -0.299,
                    -0.265,
                    -0.231,
                    -0.197,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.062,
                    -0.028,
                    0.006,
                    0.04,
                    0.074,
                    0.108,
                    0.142,
                    0.176,
                    0.21,
                    0.244,
                    0.277,
                    0.311,
                    0.345,
                    0.379,
                    0.413,
                    0.447,
                    0.481,
                    0.515,
                    0.549,
                    0.583,
                    0.616,
                    0.65,
                    0.684,
                    0.718,
                    0.752,
                    0.786,
                    0.82,
                    0.854,
                    0.888,
                    0.922,
                    0.956
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "technical instruction steps or procedures",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdta7igtx59i666dw50hqfg",
                        "tokens": [
                            " new",
                            " watch",
                            " faces",
                            " after",
                            " I",
                            "'d",
                            " installed",
                            " the",
                            " watch",
                            "OS",
                            " beta",
                            " on",
                            " my",
                            " Apple",
                            " Watch",
                            ".",
                            " But",
                            " they",
                            " are",
                            " not",
                            " available",
                            " by",
                            " default",
                            ",",
                            " you",
                            " have",
                            " to",
                            " add",
                            " them",
                            " yourself",
                            ".",
                            " Press",
                            " down",
                            " using",
                            " Force",
                            " Touch",
                            " to",
                            " bring",
                            " up",
                            " the",
                            " watch",
                            " face",
                            " selection",
                            " screen",
                            ",",
                            " then",
                            " scroll",
                            " to",
                            " the",
                            " right",
                            " and",
                            " tap",
                            " on",
                            " New",
                            ".",
                            " Then",
                            " just",
                            " look",
                            " for",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " face",
                            " option",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " you",
                            "'ve",
                            " added",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            ",",
                            " you",
                            " can",
                            " use",
                            " Force",
                            " Touch",
                            " to",
                            " select",
                            " which",
                            " one",
                            " to",
                            " have",
                            " running",
                            " on",
                            " your",
                            " Apple",
                            " Watch",
                            ".",
                            " The",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            " look",
                            " very",
                            " cool",
                            " indeed",
                            ",",
                            " and",
                            " they",
                            " are",
                            " definitely",
                            " different",
                            " than",
                            " the",
                            " other",
                            " watch",
                            " faces",
                            " on",
                            " the",
                            " Apple",
                            " Watch",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "1434",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.992,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            3.267,
                            2.92,
                            0.224,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.459,
                            25.313,
                            30.992,
                            12.143,
                            6.158,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:28.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.992,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdta7iitx5ti666rx7wk3rq",
                        "tokens": [
                            " new",
                            " watch",
                            " faces",
                            " after",
                            " I",
                            "'d",
                            " installed",
                            " the",
                            " watch",
                            "OS",
                            " beta",
                            " on",
                            " my",
                            " Apple",
                            " Watch",
                            ".",
                            " But",
                            " they",
                            " are",
                            " not",
                            " available",
                            " by",
                            " default",
                            ",",
                            " you",
                            " have",
                            " to",
                            " add",
                            " them",
                            " yourself",
                            ".",
                            " Press",
                            " down",
                            " using",
                            " Force",
                            " Touch",
                            " to",
                            " bring",
                            " up",
                            " the",
                            " watch",
                            " face",
                            " selection",
                            " screen",
                            ",",
                            " then",
                            " scroll",
                            " to",
                            " the",
                            " right",
                            " and",
                            " tap",
                            " on",
                            " New",
                            ".",
                            " Then",
                            " just",
                            " look",
                            " for",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " face",
                            " option",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " you",
                            "'ve",
                            " added",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            ",",
                            " you",
                            " can",
                            " use",
                            " Force",
                            " Touch",
                            " to",
                            " select",
                            " which",
                            " one",
                            " to",
                            " have",
                            " running",
                            " on",
                            " your",
                            " Apple",
                            " Watch",
                            ".",
                            " The",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            " look",
                            " very",
                            " cool",
                            " indeed",
                            ",",
                            " and",
                            " they",
                            " are",
                            " definitely",
                            " different",
                            " than",
                            " the",
                            " other",
                            " watch",
                            " faces",
                            " on",
                            " the",
                            " Apple",
                            " Watch",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "1434",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.992,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            3.267,
                            2.92,
                            0.224,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.459,
                            25.313,
                            30.992,
                            12.143,
                            6.158,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:28.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 24.794,
                        "binMax": 30.992,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdta7iitx5wi66650itqxpi",
                        "tokens": [
                            " new",
                            " watch",
                            " faces",
                            " after",
                            " I",
                            "'d",
                            " installed",
                            " the",
                            " watch",
                            "OS",
                            " beta",
                            " on",
                            " my",
                            " Apple",
                            " Watch",
                            ".",
                            " But",
                            " they",
                            " are",
                            " not",
                            " available",
                            " by",
                            " default",
                            ",",
                            " you",
                            " have",
                            " to",
                            " add",
                            " them",
                            " yourself",
                            ".",
                            " Press",
                            " down",
                            " using",
                            " Force",
                            " Touch",
                            " to",
                            " bring",
                            " up",
                            " the",
                            " watch",
                            " face",
                            " selection",
                            " screen",
                            ",",
                            " then",
                            " scroll",
                            " to",
                            " the",
                            " right",
                            " and",
                            " tap",
                            " on",
                            " New",
                            ".",
                            " Then",
                            " just",
                            " look",
                            " for",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " face",
                            " option",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " you",
                            "'ve",
                            " added",
                            " the",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            ",",
                            " you",
                            " can",
                            " use",
                            " Force",
                            " Touch",
                            " to",
                            " select",
                            " which",
                            " one",
                            " to",
                            " have",
                            " running",
                            " on",
                            " your",
                            " Apple",
                            " Watch",
                            ".",
                            " The",
                            " time",
                            "-",
                            "l",
                            "apse",
                            " watch",
                            " faces",
                            " look",
                            " very",
                            " cool",
                            " indeed",
                            ",",
                            " and",
                            " they",
                            " are",
                            " definitely",
                            " different",
                            " than",
                            " the",
                            " other",
                            " watch",
                            " faces",
                            " on",
                            " the",
                            " Apple",
                            " Watch",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "1434",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.992,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            3.267,
                            2.92,
                            0.224,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.459,
                            25.313,
                            30.992,
                            12.143,
                            6.158,
                            0,
                            0,
                            0,
                            0.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:28.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 24.794,
                        "binMax": 30.992,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "2278",
            "description": "technical instructions and details",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6446201205253601,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "2278",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:09:28.228Z",
                "maxActApprox": 27.68,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2278,
                    4574,
                    407,
                    2419,
                    1370,
                    723,
                    3647,
                    4191,
                    1460,
                    4560,
                    2255,
                    5747,
                    4347,
                    4188,
                    1154,
                    1174,
                    4634,
                    924,
                    3878,
                    663,
                    1308,
                    5011,
                    3057,
                    4088,
                    5368
                ],
                "topkCosSimValues": [
                    1,
                    0.5719,
                    0.565,
                    0.5639,
                    0.5591,
                    0.5514,
                    0.5306,
                    0.5154,
                    0.5153,
                    0.4941,
                    0.4816,
                    0.4422,
                    0.4382,
                    0.4363,
                    0.4148,
                    0.4087,
                    0.4025,
                    0.401,
                    0.3793,
                    0.3738,
                    0.3661,
                    0.3436,
                    0.3387,
                    0.3363,
                    0.3274
                ],
                "neuron_alignment_indices": [
                    48,
                    496,
                    255
                ],
                "neuron_alignment_values": [
                    0.107,
                    0.106,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    43,
                    546,
                    297
                ],
                "correlated_neurons_pearson": [
                    0.137,
                    0.131,
                    0.114
                ],
                "correlated_neurons_l1": [
                    0.125,
                    0.129,
                    0.11
                ],
                "correlated_features_indices": [
                    2255,
                    2283,
                    2208
                ],
                "correlated_features_pearson": [
                    0.225,
                    0.149,
                    0.091
                ],
                "correlated_features_l1": [
                    0.228,
                    0.154,
                    0.095
                ],
                "neg_str": [
                    "rio",
                    "yon",
                    "ForgeModLoader",
                    "ire",
                    "ocl",
                    "\u00aa",
                    "ong",
                    "leground",
                    "uber",
                    "onse"
                ],
                "neg_values": [
                    -0.712,
                    -0.708,
                    -0.658,
                    -0.639,
                    -0.633,
                    -0.609,
                    -0.607,
                    -0.598,
                    -0.587,
                    -0.582
                ],
                "pos_str": [
                    " whereas",
                    " although",
                    " but",
                    " hence",
                    " namely",
                    " regardless",
                    " irrespective",
                    " BUT",
                    "but",
                    " albeit"
                ],
                "pos_values": [
                    1.529,
                    1.352,
                    1.259,
                    1.204,
                    1.195,
                    1.123,
                    1.104,
                    1.097,
                    1.09,
                    1.085
                ],
                "frac_nonzero": 0.01124,
                "freq_hist_data_bar_heights": [
                    4516,
                    3726,
                    3396,
                    2834,
                    2519,
                    2184,
                    1993,
                    1704,
                    1514,
                    1351,
                    1216,
                    1046,
                    965,
                    826,
                    795,
                    623,
                    574,
                    485,
                    429,
                    366,
                    308,
                    324,
                    264,
                    237,
                    187,
                    165,
                    120,
                    141,
                    92,
                    86,
                    60,
                    72,
                    50,
                    48,
                    34,
                    24,
                    25,
                    14,
                    7,
                    12,
                    12,
                    9,
                    0,
                    7,
                    1,
                    3,
                    2,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.277,
                    0.831,
                    1.385,
                    1.938,
                    2.492,
                    3.045,
                    3.599,
                    4.152,
                    4.706,
                    5.26,
                    5.813,
                    6.367,
                    6.92,
                    7.474,
                    8.028,
                    8.581,
                    9.135,
                    9.688,
                    10.242,
                    10.796,
                    11.349,
                    11.903,
                    12.456,
                    13.01,
                    13.564,
                    14.117,
                    14.671,
                    15.224,
                    15.778,
                    16.332,
                    16.885,
                    17.439,
                    17.992,
                    18.546,
                    19.1,
                    19.653,
                    20.207,
                    20.76,
                    21.314,
                    21.868,
                    22.421,
                    22.975,
                    23.528,
                    24.082,
                    24.636,
                    25.189,
                    25.743,
                    26.296,
                    26.85,
                    27.404
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    10,
                    21,
                    50,
                    91,
                    168,
                    304,
                    584,
                    1003,
                    1640,
                    2454,
                    3613,
                    4767,
                    5747,
                    6021,
                    5934,
                    5208,
                    4060,
                    2986,
                    2058,
                    1317,
                    803,
                    522,
                    275,
                    169,
                    113,
                    81,
                    58,
                    50,
                    32,
                    32,
                    18,
                    12,
                    6,
                    9,
                    5,
                    8,
                    10,
                    3,
                    5,
                    0,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.689,
                    -0.644,
                    -0.599,
                    -0.555,
                    -0.51,
                    -0.465,
                    -0.42,
                    -0.375,
                    -0.331,
                    -0.286,
                    -0.241,
                    -0.196,
                    -0.151,
                    -0.106,
                    -0.062,
                    -0.017,
                    0.028,
                    0.073,
                    0.118,
                    0.162,
                    0.207,
                    0.252,
                    0.297,
                    0.342,
                    0.387,
                    0.431,
                    0.476,
                    0.521,
                    0.566,
                    0.611,
                    0.655,
                    0.7,
                    0.745,
                    0.79,
                    0.835,
                    0.88,
                    0.924,
                    0.969,
                    1.014,
                    1.059,
                    1.104,
                    1.148,
                    1.193,
                    1.238,
                    1.283,
                    1.328,
                    1.373,
                    1.417,
                    1.462,
                    1.507
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "technical instructions and details",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtbn5fuqeii666exae4z6k",
                        "tokens": [
                            " the",
                            " environment",
                            " is",
                            " going",
                            " looking",
                            " good",
                            " in",
                            " Unity",
                            " 5",
                            ",",
                            " every",
                            " building",
                            " can",
                            " be",
                            " visited",
                            ".",
                            " This",
                            " is",
                            " a",
                            " screenshot",
                            " of",
                            " the",
                            " commercial",
                            " area",
                            ".",
                            " Every",
                            " building",
                            " will",
                            " have",
                            " inter",
                            "iors",
                            " and",
                            " its",
                            " own",
                            " set",
                            " of",
                            " puzzles",
                            ".",
                            "\n",
                            "\n",
                            "Every",
                            " texture",
                            " in",
                            " the",
                            " world",
                            " will",
                            " have",
                            " that",
                            " \"",
                            "hand",
                            " painted",
                            " look",
                            "\"",
                            " as",
                            " you",
                            " can",
                            " see",
                            " in",
                            " the",
                            " image",
                            ",",
                            " there",
                            " still",
                            " some",
                            " filters",
                            " to",
                            " make",
                            " it",
                            " look",
                            " more",
                            " like",
                            " a",
                            " living",
                            " art",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " think",
                            " thats",
                            " all",
                            " i",
                            " have",
                            " to",
                            " share",
                            " with",
                            " you",
                            " today",
                            ".",
                            " We",
                            " dont",
                            " want",
                            " to",
                            " spoil",
                            " the",
                            " gameplay",
                            " or",
                            " anything",
                            " until",
                            " the",
                            " demo",
                            " but",
                            " be",
                            " sure",
                            " to",
                            " stay",
                            " tune",
                            " to",
                            " our",
                            " site",
                            " we",
                            " will",
                            " release",
                            " better",
                            " updates",
                            " and",
                            " more",
                            " screen",
                            " images",
                            " of",
                            " what",
                            " we",
                            " are",
                            " doing",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "2278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.68,
                        "maxValueTokenIndex": 60,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.092,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.147,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.68,
                            4.493,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.032,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:09:35.429Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.68,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtbn5fuqeji6669k7fl484",
                        "tokens": [
                            " If",
                            " Mercy",
                            "'s",
                            " resurrect",
                            " is",
                            " off",
                            " cooldown",
                            " /",
                            " available",
                            " for",
                            " use",
                            ",",
                            " pressing",
                            " the",
                            " bound",
                            " key",
                            " (",
                            "by",
                            " default",
                            " that",
                            "'s",
                            " E",
                            ")",
                            " will",
                            " let",
                            " the",
                            " player",
                            " ping",
                            " to",
                            " their",
                            " team",
                            " that",
                            " Mercy",
                            " can",
                            " resurrect",
                            " (",
                            "if",
                            " there",
                            " is",
                            " no",
                            " resurrection",
                            " target",
                            " in",
                            " range",
                            " of",
                            " course",
                            ").",
                            " Also",
                            " with",
                            " the",
                            " current",
                            " Valkyrie",
                            ",",
                            " this",
                            " p",
                            "inging",
                            " could",
                            " also",
                            " report",
                            " the",
                            " amount",
                            " of",
                            " resurrect",
                            "s",
                            " (",
                            "1",
                            " or",
                            " 2",
                            ")",
                            " available",
                            ",",
                            " just",
                            " like",
                            " Sy",
                            "mm",
                            "et",
                            "ra",
                            " with",
                            " her",
                            " tele",
                            "porter",
                            " charges",
                            ".",
                            " An",
                            " other",
                            " idea",
                            " could",
                            " be",
                            " adding",
                            " the",
                            " amount",
                            " of",
                            " seconds",
                            " left",
                            " until",
                            " the",
                            " next",
                            " resurrect",
                            " is",
                            " available",
                            " to",
                            " this",
                            " ping",
                            " message",
                            ".",
                            "Also",
                            ",",
                            " with",
                            " this",
                            " feature",
                            " the",
                            " existing",
                            " voice",
                            " lines",
                            " of",
                            " Mercy",
                            "'s",
                            " former",
                            " ultimate",
                            ",",
                            " could",
                            " be",
                            " used",
                            " again",
                            " (\"",
                            "I",
                            " am"
                        ],
                        "dataIndex": null,
                        "index": "2278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 26.442,
                        "maxValueTokenIndex": 70,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.445,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.228,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.114,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            26.442,
                            6.17,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.679,
                            0.183,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.923,
                            0.772,
                            0.064,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:09:35.429Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.68,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtbn5fuqeki666j64swdtv",
                        "tokens": [
                            " on",
                            " how",
                            " this",
                            " d",
                            "umper",
                            " works",
                            " when",
                            " address",
                            "-",
                            "space",
                            " layout",
                            " random",
                            "ization",
                            " (",
                            "AS",
                            "LR",
                            ")",
                            " is",
                            " in",
                            " use",
                            ".",
                            " Current",
                            " Emacs",
                            " binaries",
                            " must",
                            " disable",
                            " AS",
                            "LR",
                            " entirely",
                            ",",
                            " thus",
                            " losing",
                            " the",
                            " security",
                            " benefits",
                            " that",
                            " AS",
                            "LR",
                            " is",
                            " meant",
                            " to",
                            " provide",
                            ".",
                            " The",
                            " new",
                            " d",
                            "umper",
                            " does",
                            " not",
                            " require",
                            " disabling",
                            " AS",
                            "LR",
                            ",",
                            " but",
                            " it",
                            " does",
                            " contain",
                            " an",
                            " optimization",
                            " that",
                            " can",
                            " be",
                            " applied",
                            " if",
                            " the",
                            " dump",
                            " file",
                            " can",
                            " be",
                            " successfully",
                            " mapped",
                            " at",
                            " a",
                            " specific",
                            " address",
                            ":",
                            " most",
                            " of",
                            " the",
                            " data",
                            " therein",
                            " can",
                            " be",
                            " used",
                            " directly",
                            " from",
                            " the",
                            " mapped",
                            " image",
                            ",",
                            " without",
                            " the",
                            " need",
                            " to",
                            " allocate",
                            " storage",
                            " for",
                            " and",
                            " copy",
                            " it",
                            ".",
                            " That",
                            " should",
                            " speed",
                            " the",
                            " startup",
                            " process",
                            " considerably",
                            ",",
                            " at",
                            " the",
                            " cost",
                            " of",
                            " always",
                            " mapping",
                            " the",
                            " dump",
                            " image",
                            " at",
                            " the",
                            " same",
                            " location",
                            ".",
                            "\n",
                            "\n",
                            "Paul"
                        ],
                        "dataIndex": null,
                        "index": "2278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.786,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.944,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.306,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.786,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.422,
                            2.469,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:09:35.429Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.68,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "10510",
            "description": "instructions or step-by-step procedures",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6425306797027588,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "10510",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:30:28.406Z",
                "maxActApprox": 31.398,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    10510,
                    4468,
                    2397,
                    6778,
                    1365,
                    2902,
                    11333,
                    5138,
                    7247,
                    12216,
                    9494,
                    2736,
                    1318,
                    633,
                    10431,
                    5062,
                    2382,
                    10425,
                    1573,
                    1227,
                    66,
                    11936,
                    7084,
                    11304,
                    11926
                ],
                "topkCosSimValues": [
                    1,
                    0.3974,
                    0.3319,
                    0.3242,
                    0.3204,
                    0.3154,
                    0.3084,
                    0.2969,
                    0.2924,
                    0.2863,
                    0.2848,
                    0.277,
                    0.2696,
                    0.267,
                    0.2668,
                    0.2523,
                    0.2488,
                    0.2479,
                    0.2463,
                    0.2442,
                    0.242,
                    0.2416,
                    0.2292,
                    0.2246,
                    0.2245
                ],
                "neuron_alignment_indices": [
                    519,
                    194,
                    536
                ],
                "neuron_alignment_values": [
                    0.101,
                    0.092,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    519,
                    354,
                    566
                ],
                "correlated_neurons_pearson": [
                    0.048,
                    0.041,
                    0.038
                ],
                "correlated_neurons_l1": [
                    0.047,
                    0.044,
                    0.04
                ],
                "correlated_features_indices": [
                    10502,
                    10595,
                    10514
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.01,
                    0.009
                ],
                "correlated_features_l1": [
                    0.02,
                    0.013,
                    0.012
                ],
                "neg_str": [
                    "Therefore",
                    " Therefore",
                    "inventoryQuantity",
                    "Various",
                    "Recently",
                    "govtrack",
                    "TL",
                    " )]",
                    " Due",
                    "malink"
                ],
                "neg_values": [
                    -0.801,
                    -0.718,
                    -0.693,
                    -0.608,
                    -0.597,
                    -0.584,
                    -0.576,
                    -0.574,
                    -0.572,
                    -0.566
                ],
                "pos_str": [
                    " prest",
                    " instantly",
                    " vo",
                    " magically",
                    " reap",
                    " explodes",
                    "'ll",
                    " invariably",
                    " shalt",
                    "arts"
                ],
                "pos_values": [
                    1.108,
                    0.941,
                    0.85,
                    0.842,
                    0.832,
                    0.751,
                    0.749,
                    0.74,
                    0.699,
                    0.664
                ],
                "frac_nonzero": 0.00481,
                "freq_hist_data_bar_heights": [
                    5125,
                    3284,
                    2025,
                    1348,
                    854,
                    613,
                    446,
                    323,
                    266,
                    214,
                    135,
                    92,
                    92,
                    51,
                    39,
                    30,
                    22,
                    19,
                    19,
                    7,
                    13,
                    16,
                    12,
                    2,
                    7,
                    4,
                    4,
                    5,
                    12,
                    2,
                    2,
                    4,
                    3,
                    6,
                    6,
                    4,
                    4,
                    1,
                    2,
                    2,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.314,
                    0.942,
                    1.57,
                    2.198,
                    2.826,
                    3.454,
                    4.082,
                    4.71,
                    5.338,
                    5.966,
                    6.594,
                    7.221,
                    7.849,
                    8.477,
                    9.105,
                    9.733,
                    10.361,
                    10.989,
                    11.617,
                    12.245,
                    12.873,
                    13.501,
                    14.129,
                    14.757,
                    15.385,
                    16.013,
                    16.641,
                    17.269,
                    17.897,
                    18.525,
                    19.153,
                    19.78,
                    20.408,
                    21.036,
                    21.664,
                    22.292,
                    22.92,
                    23.548,
                    24.176,
                    24.804,
                    25.432,
                    26.06,
                    26.688,
                    27.316,
                    27.944,
                    28.572,
                    29.2,
                    29.828,
                    30.456,
                    31.084
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    0,
                    0,
                    6,
                    14,
                    24,
                    33,
                    69,
                    147,
                    295,
                    533,
                    899,
                    1403,
                    2087,
                    2868,
                    3529,
                    4282,
                    4793,
                    5029,
                    4770,
                    4456,
                    3760,
                    3157,
                    2446,
                    1767,
                    1310,
                    942,
                    598,
                    414,
                    258,
                    146,
                    84,
                    62,
                    30,
                    20,
                    10,
                    4,
                    1,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.782,
                    -0.743,
                    -0.705,
                    -0.667,
                    -0.629,
                    -0.591,
                    -0.553,
                    -0.514,
                    -0.476,
                    -0.438,
                    -0.4,
                    -0.362,
                    -0.323,
                    -0.285,
                    -0.247,
                    -0.209,
                    -0.171,
                    -0.133,
                    -0.094,
                    -0.056,
                    -0.018,
                    0.02,
                    0.058,
                    0.097,
                    0.135,
                    0.173,
                    0.211,
                    0.249,
                    0.287,
                    0.326,
                    0.364,
                    0.402,
                    0.44,
                    0.478,
                    0.516,
                    0.555,
                    0.593,
                    0.631,
                    0.669,
                    0.707,
                    0.746,
                    0.784,
                    0.822,
                    0.86,
                    0.898,
                    0.936,
                    0.975,
                    1.013,
                    1.051,
                    1.089
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instructions or step-by-step procedures",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu2j0f8jo4i666ytljvf7n",
                        "tokens": [
                            " Sea",
                            " work",
                            ".",
                            " The",
                            " Labrador",
                            " fishermen",
                            " value",
                            " the",
                            " helmets",
                            " equally",
                            " with",
                            " their",
                            " North",
                            " Sea",
                            " breath",
                            "ren",
                            ",",
                            " and",
                            " thus",
                            " there",
                            " is",
                            " an",
                            " ample",
                            " output",
                            " for",
                            " them",
                            ",",
                            " but",
                            " we",
                            " shall",
                            " be",
                            " glad",
                            " if",
                            " friends",
                            " will",
                            " bear",
                            " the",
                            " hint",
                            " in",
                            " mind",
                            ",",
                            " and",
                            " make",
                            " some",
                            " of",
                            " the",
                            " other",
                            " things",
                            " in",
                            " preference",
                            " to",
                            " the",
                            " helmets",
                            " and",
                            " Uh",
                            "lan",
                            " caps",
                            ".",
                            "\n",
                            "\n",
                            "All",
                            " of",
                            " the",
                            " books",
                            " in",
                            " the",
                            " Kn",
                            "itting",
                            " Reference",
                            " Library",
                            " are",
                            " open",
                            " access",
                            ",",
                            " though",
                            " many",
                            " of",
                            " the",
                            " patterns",
                            " and",
                            " magazines",
                            " are",
                            " dependent",
                            " on",
                            " copyright",
                            " clearance",
                            ".",
                            " Give",
                            " a",
                            " prow",
                            "l",
                            ",",
                            " and",
                            " you",
                            "'ll",
                            " find",
                            " that",
                            " a",
                            " few",
                            " of",
                            " the",
                            " older",
                            " patterns",
                            " are",
                            " available",
                            " as",
                            " downloadable",
                            ",",
                            " print",
                            "able",
                            " PDF",
                            "s",
                            " ,",
                            " such",
                            " as",
                            " this",
                            " handsome",
                            " gent",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " cable",
                            " knit",
                            " pull",
                            "over",
                            " or",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "10510",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.398,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            13.436,
                            31.398,
                            25.105,
                            8.188,
                            2.719,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:29.799Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.398,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu2j0g8jofi666t8cjtft8",
                        "tokens": [
                            " Sea",
                            " work",
                            ".",
                            " The",
                            " Labrador",
                            " fishermen",
                            " value",
                            " the",
                            " helmets",
                            " equally",
                            " with",
                            " their",
                            " North",
                            " Sea",
                            " breath",
                            "ren",
                            ",",
                            " and",
                            " thus",
                            " there",
                            " is",
                            " an",
                            " ample",
                            " output",
                            " for",
                            " them",
                            ",",
                            " but",
                            " we",
                            " shall",
                            " be",
                            " glad",
                            " if",
                            " friends",
                            " will",
                            " bear",
                            " the",
                            " hint",
                            " in",
                            " mind",
                            ",",
                            " and",
                            " make",
                            " some",
                            " of",
                            " the",
                            " other",
                            " things",
                            " in",
                            " preference",
                            " to",
                            " the",
                            " helmets",
                            " and",
                            " Uh",
                            "lan",
                            " caps",
                            ".",
                            "\n",
                            "\n",
                            "All",
                            " of",
                            " the",
                            " books",
                            " in",
                            " the",
                            " Kn",
                            "itting",
                            " Reference",
                            " Library",
                            " are",
                            " open",
                            " access",
                            ",",
                            " though",
                            " many",
                            " of",
                            " the",
                            " patterns",
                            " and",
                            " magazines",
                            " are",
                            " dependent",
                            " on",
                            " copyright",
                            " clearance",
                            ".",
                            " Give",
                            " a",
                            " prow",
                            "l",
                            ",",
                            " and",
                            " you",
                            "'ll",
                            " find",
                            " that",
                            " a",
                            " few",
                            " of",
                            " the",
                            " older",
                            " patterns",
                            " are",
                            " available",
                            " as",
                            " downloadable",
                            ",",
                            " print",
                            "able",
                            " PDF",
                            "s",
                            " ,",
                            " such",
                            " as",
                            " this",
                            " handsome",
                            " gent",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " cable",
                            " knit",
                            " pull",
                            "over",
                            " or",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "10510",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.398,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            13.436,
                            31.398,
                            25.105,
                            8.188,
                            2.719,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:29.799Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.398,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu2j0h8josi666mdjdkyus",
                        "tokens": [
                            " Sea",
                            " work",
                            ".",
                            " The",
                            " Labrador",
                            " fishermen",
                            " value",
                            " the",
                            " helmets",
                            " equally",
                            " with",
                            " their",
                            " North",
                            " Sea",
                            " breath",
                            "ren",
                            ",",
                            " and",
                            " thus",
                            " there",
                            " is",
                            " an",
                            " ample",
                            " output",
                            " for",
                            " them",
                            ",",
                            " but",
                            " we",
                            " shall",
                            " be",
                            " glad",
                            " if",
                            " friends",
                            " will",
                            " bear",
                            " the",
                            " hint",
                            " in",
                            " mind",
                            ",",
                            " and",
                            " make",
                            " some",
                            " of",
                            " the",
                            " other",
                            " things",
                            " in",
                            " preference",
                            " to",
                            " the",
                            " helmets",
                            " and",
                            " Uh",
                            "lan",
                            " caps",
                            ".",
                            "\n",
                            "\n",
                            "All",
                            " of",
                            " the",
                            " books",
                            " in",
                            " the",
                            " Kn",
                            "itting",
                            " Reference",
                            " Library",
                            " are",
                            " open",
                            " access",
                            ",",
                            " though",
                            " many",
                            " of",
                            " the",
                            " patterns",
                            " and",
                            " magazines",
                            " are",
                            " dependent",
                            " on",
                            " copyright",
                            " clearance",
                            ".",
                            " Give",
                            " a",
                            " prow",
                            "l",
                            ",",
                            " and",
                            " you",
                            "'ll",
                            " find",
                            " that",
                            " a",
                            " few",
                            " of",
                            " the",
                            " older",
                            " patterns",
                            " are",
                            " available",
                            " as",
                            " downloadable",
                            ",",
                            " print",
                            "able",
                            " PDF",
                            "s",
                            " ,",
                            " such",
                            " as",
                            " this",
                            " handsome",
                            " gent",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " cable",
                            " knit",
                            " pull",
                            "over",
                            " or",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "10510",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.398,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            13.436,
                            31.398,
                            25.105,
                            8.188,
                            2.719,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:29.799Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 25.118,
                        "binMax": 31.398,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "13836",
            "description": "actions related to following step-by-step instructions",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6414185976136578,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "13836",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:02:33.597Z",
                "maxActApprox": 22.288,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13836,
                    2676,
                    8495,
                    20073,
                    7999,
                    8691,
                    19773,
                    15830,
                    12354,
                    5193,
                    14992,
                    5947,
                    9236,
                    15477,
                    14042,
                    10263,
                    16363,
                    1815,
                    23761,
                    6848,
                    14860,
                    12428,
                    23829,
                    10484,
                    2394
                ],
                "topkCosSimValues": [
                    1,
                    0.4943,
                    0.4901,
                    0.4816,
                    0.4805,
                    0.4776,
                    0.4655,
                    0.4594,
                    0.434,
                    0.4295,
                    0.4268,
                    0.4253,
                    0.4199,
                    0.4129,
                    0.3995,
                    0.3981,
                    0.3908,
                    0.3835,
                    0.3806,
                    0.3794,
                    0.3776,
                    0.3767,
                    0.3728,
                    0.3717,
                    0.3717
                ],
                "neuron_alignment_indices": [
                    481,
                    55,
                    16
                ],
                "neuron_alignment_values": [
                    0.14,
                    0.109,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    469,
                    125,
                    274
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.034,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.03,
                    0.033,
                    0.034
                ],
                "correlated_features_indices": [
                    13880,
                    13934,
                    13834
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.012,
                    0.002
                ],
                "correlated_features_l1": [
                    0.016,
                    0.012,
                    0.003
                ],
                "neg_str": [
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "yip",
                    "RESULTS",
                    "MAL",
                    " Flavoring",
                    "\u00e3\u0125\u00b4\u00e3\u0124\u00a1",
                    "icipated",
                    "ierre",
                    "\u00e9\u00be\u012f\u00e5",
                    "asel"
                ],
                "neg_values": [
                    -0.783,
                    -0.642,
                    -0.641,
                    -0.627,
                    -0.626,
                    -0.625,
                    -0.621,
                    -0.618,
                    -0.615,
                    -0.608
                ],
                "pos_str": [
                    " by",
                    " upon",
                    " BY",
                    " prominently",
                    " alongside",
                    " anew",
                    " therein",
                    " throughout",
                    "abouts",
                    " squarely"
                ],
                "pos_values": [
                    0.925,
                    0.839,
                    0.838,
                    0.741,
                    0.74,
                    0.711,
                    0.7,
                    0.696,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00147,
                "freq_hist_data_bar_heights": [
                    754,
                    592,
                    464,
                    392,
                    288,
                    273,
                    230,
                    182,
                    156,
                    114,
                    133,
                    92,
                    99,
                    63,
                    76,
                    59,
                    62,
                    59,
                    45,
                    37,
                    46,
                    45,
                    37,
                    38,
                    33,
                    40,
                    28,
                    22,
                    33,
                    17,
                    18,
                    13,
                    18,
                    14,
                    9,
                    6,
                    13,
                    7,
                    3,
                    8,
                    5,
                    1,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.224,
                    0.669,
                    1.115,
                    1.561,
                    2.007,
                    2.452,
                    2.898,
                    3.344,
                    3.79,
                    4.235,
                    4.681,
                    5.127,
                    5.573,
                    6.018,
                    6.464,
                    6.91,
                    7.356,
                    7.801,
                    8.247,
                    8.693,
                    9.139,
                    9.584,
                    10.03,
                    10.476,
                    10.922,
                    11.367,
                    11.813,
                    12.259,
                    12.705,
                    13.15,
                    13.596,
                    14.042,
                    14.488,
                    14.933,
                    15.379,
                    15.825,
                    16.27,
                    16.716,
                    17.162,
                    17.608,
                    18.053,
                    18.499,
                    18.945,
                    19.391,
                    19.836,
                    20.282,
                    20.728,
                    21.174,
                    21.619,
                    22.065
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    8,
                    6,
                    8,
                    13,
                    26,
                    52,
                    100,
                    155,
                    234,
                    398,
                    739,
                    993,
                    1529,
                    2125,
                    2822,
                    3428,
                    4138,
                    4457,
                    4724,
                    4619,
                    4264,
                    3778,
                    3096,
                    2461,
                    1833,
                    1401,
                    913,
                    634,
                    423,
                    314,
                    191,
                    135,
                    86,
                    46,
                    30,
                    29,
                    20,
                    8,
                    8,
                    7,
                    2,
                    0,
                    0,
                    2,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.766,
                    -0.732,
                    -0.697,
                    -0.663,
                    -0.629,
                    -0.595,
                    -0.561,
                    -0.527,
                    -0.493,
                    -0.458,
                    -0.424,
                    -0.39,
                    -0.356,
                    -0.322,
                    -0.288,
                    -0.253,
                    -0.219,
                    -0.185,
                    -0.151,
                    -0.117,
                    -0.083,
                    -0.048,
                    -0.014,
                    0.02,
                    0.054,
                    0.088,
                    0.122,
                    0.156,
                    0.191,
                    0.225,
                    0.259,
                    0.293,
                    0.327,
                    0.361,
                    0.396,
                    0.43,
                    0.464,
                    0.498,
                    0.532,
                    0.566,
                    0.6,
                    0.635,
                    0.669,
                    0.703,
                    0.737,
                    0.771,
                    0.805,
                    0.84,
                    0.874,
                    0.908
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "actions related to following step-by-step instructions",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmn5gmd5e7i666onr3ysnm",
                        "tokens": [
                            "Hung",
                            "ry",
                            "?",
                            " You",
                            " will",
                            " be",
                            " eventually",
                            ".",
                            " And",
                            " when",
                            " those",
                            " grinding",
                            " stomach",
                            " noises",
                            " rise",
                            " up",
                            " from",
                            " within",
                            ",",
                            " you",
                            "'ll",
                            " have",
                            " this",
                            " list",
                            " printed",
                            " out",
                            " at",
                            " the",
                            " ready",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " 10",
                            " restaurants",
                            " that",
                            " I",
                            "'ve",
                            " d",
                            "ined",
                            " in",
                            ",",
                            " reviewed",
                            ",",
                            " or",
                            " otherwise",
                            " written",
                            " about",
                            " and",
                            " enjoyed",
                            " in",
                            " recent",
                            " months",
                            ".",
                            " Put",
                            " them",
                            " in",
                            " your",
                            " regular",
                            " rotation",
                            ",",
                            " and",
                            " never",
                            " go",
                            " hungry",
                            " for",
                            " great",
                            " food",
                            " again",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "BD",
                            " Prov",
                            "isions",
                            " (",
                            "pictured",
                            " above",
                            ")",
                            " This",
                            " downtown",
                            " o",
                            "de",
                            " to",
                            " pig",
                            " parts",
                            " offers",
                            " one",
                            " of",
                            " the",
                            " best",
                            " hunger",
                            " bust",
                            "ers",
                            " in",
                            " Dallas",
                            ".",
                            " Order",
                            " the",
                            " carn",
                            "itas",
                            " and",
                            " receive",
                            " half",
                            " the",
                            " face",
                            " of",
                            " a",
                            " young",
                            " pig",
                            ",",
                            " while",
                            " the",
                            " other",
                            " half",
                            " undoubtedly",
                            " rests",
                            " on",
                            " nearby",
                            " table",
                            ".",
                            " Both",
                            " will",
                            " be",
                            " gone"
                        ],
                        "dataIndex": null,
                        "index": "13836",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.288,
                        "maxValueTokenIndex": 24,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.288,
                            11.882,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:35.094Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 22.288,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmn5gmd5e8i666dav5lqgn",
                        "tokens": [
                            " in",
                            " the",
                            " tragedy",
                            ".",
                            " They",
                            " will",
                            " lay",
                            " more",
                            " flowers",
                            " and",
                            " light",
                            " candles",
                            " at",
                            " the",
                            " walls",
                            " of",
                            " the",
                            " ruined",
                            " school",
                            " building",
                            " and",
                            " a",
                            " recently",
                            " opened",
                            " monument",
                            ":",
                            " a",
                            " 50",
                            "-",
                            "meter",
                            " long",
                            " granite",
                            " memorial",
                            " with",
                            " the",
                            " names",
                            " of",
                            " all",
                            " the",
                            " victims",
                            " carved",
                            " on",
                            " it",
                            ".",
                            " Toys",
                            " and",
                            " bottles",
                            " with",
                            " water",
                            " will",
                            " be",
                            " brought",
                            " in",
                            ":",
                            " the",
                            " captives",
                            " were",
                            " held",
                            " in",
                            " the",
                            " cramped",
                            ",",
                            " stuff",
                            "y",
                            " school",
                            " gym",
                            " and",
                            " suffered",
                            " from",
                            " unbearable",
                            " heat",
                            " and",
                            " thirst",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " September",
                            " 2",
                            ",",
                            " a",
                            " requ",
                            "iem",
                            " concert",
                            " will",
                            " be",
                            " held",
                            " on",
                            " the",
                            " stage",
                            " of",
                            " Bes",
                            "lan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " culture",
                            " center",
                            ".",
                            " On",
                            " Wednesday",
                            ",",
                            " at",
                            " a",
                            " ceremony",
                            " in",
                            " the",
                            " sch",
                            "oo",
                            "ly",
                            "ard",
                            ",",
                            " students",
                            " will",
                            " release",
                            " into",
                            " the",
                            " air",
                            " 334",
                            " white",
                            " balloons",
                            " -",
                            " the",
                            " number",
                            " of",
                            " people",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13836",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.109,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.109,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:35.094Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 22.288,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmn5god5eti66659pzajvl",
                        "tokens": [
                            " in",
                            " the",
                            " tragedy",
                            ".",
                            " They",
                            " will",
                            " lay",
                            " more",
                            " flowers",
                            " and",
                            " light",
                            " candles",
                            " at",
                            " the",
                            " walls",
                            " of",
                            " the",
                            " ruined",
                            " school",
                            " building",
                            " and",
                            " a",
                            " recently",
                            " opened",
                            " monument",
                            ":",
                            " a",
                            " 50",
                            "-",
                            "meter",
                            " long",
                            " granite",
                            " memorial",
                            " with",
                            " the",
                            " names",
                            " of",
                            " all",
                            " the",
                            " victims",
                            " carved",
                            " on",
                            " it",
                            ".",
                            " Toys",
                            " and",
                            " bottles",
                            " with",
                            " water",
                            " will",
                            " be",
                            " brought",
                            " in",
                            ":",
                            " the",
                            " captives",
                            " were",
                            " held",
                            " in",
                            " the",
                            " cramped",
                            ",",
                            " stuff",
                            "y",
                            " school",
                            " gym",
                            " and",
                            " suffered",
                            " from",
                            " unbearable",
                            " heat",
                            " and",
                            " thirst",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " September",
                            " 2",
                            ",",
                            " a",
                            " requ",
                            "iem",
                            " concert",
                            " will",
                            " be",
                            " held",
                            " on",
                            " the",
                            " stage",
                            " of",
                            " Bes",
                            "lan",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " culture",
                            " center",
                            ".",
                            " On",
                            " Wednesday",
                            ",",
                            " at",
                            " a",
                            " ceremony",
                            " in",
                            " the",
                            " sch",
                            "oo",
                            "ly",
                            "ard",
                            ",",
                            " students",
                            " will",
                            " release",
                            " into",
                            " the",
                            " air",
                            " 334",
                            " white",
                            " balloons",
                            " -",
                            " the",
                            " number",
                            " of",
                            " people",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13836",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.109,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.109,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:35.094Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 17.83,
                        "binMax": 22.288,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}