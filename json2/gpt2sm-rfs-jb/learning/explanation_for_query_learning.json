{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "7283",
            "description": "verbs related to learning or acquiring new skills",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5843900093799834,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "7283",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:25:47.675Z",
                "maxActApprox": 54.917,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7283,
                    4647,
                    2769,
                    695,
                    7481,
                    10075,
                    8159,
                    620,
                    7496,
                    6878,
                    4161,
                    10494,
                    315,
                    4454,
                    8052,
                    10344,
                    2795,
                    5646,
                    5753,
                    11334,
                    1070,
                    9109,
                    2082,
                    7766,
                    8961
                ],
                "topkCosSimValues": [
                    1,
                    0.5407,
                    0.4572,
                    0.444,
                    0.4403,
                    0.4161,
                    0.416,
                    0.4155,
                    0.4032,
                    0.3849,
                    0.3846,
                    0.3815,
                    0.3785,
                    0.3771,
                    0.3764,
                    0.3744,
                    0.3627,
                    0.3593,
                    0.3541,
                    0.3512,
                    0.3488,
                    0.3484,
                    0.3471,
                    0.3452,
                    0.3449
                ],
                "neuron_alignment_indices": [
                    665,
                    718,
                    608
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.107,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    718,
                    49
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.034,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.042,
                    0.037,
                    0.037
                ],
                "correlated_features_indices": [
                    7173,
                    7289,
                    7172
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.01,
                    0.004
                ],
                "correlated_features_l1": [
                    0.013,
                    0.01,
                    0.006
                ],
                "neg_str": [
                    "lights",
                    "listed",
                    "teen",
                    "holder",
                    "termination",
                    " Hartford",
                    " Appears",
                    "hra",
                    "nces",
                    " revelations"
                ],
                "neg_values": [
                    -0.834,
                    -0.725,
                    -0.705,
                    -0.68,
                    -0.666,
                    -0.653,
                    -0.647,
                    -0.645,
                    -0.632,
                    -0.624
                ],
                "pos_str": [
                    " behave",
                    " cope",
                    " differentiate",
                    " recognize",
                    " wrestle",
                    " manipulate",
                    " tolerate",
                    " imitate",
                    " navigate",
                    " cultivate"
                ],
                "pos_values": [
                    1.222,
                    1.208,
                    1.162,
                    1.156,
                    1.149,
                    1.125,
                    1.108,
                    1.069,
                    1.034,
                    1.019
                ],
                "frac_nonzero": 0.00163,
                "freq_hist_data_bar_heights": [
                    2067,
                    1175,
                    651,
                    405,
                    205,
                    156,
                    86,
                    68,
                    32,
                    43,
                    27,
                    16,
                    9,
                    15,
                    16,
                    16,
                    8,
                    6,
                    7,
                    9,
                    10,
                    9,
                    7,
                    4,
                    5,
                    7,
                    5,
                    2,
                    6,
                    4,
                    0,
                    3,
                    5,
                    3,
                    1,
                    2,
                    3,
                    1,
                    2,
                    5,
                    2,
                    3,
                    1,
                    7,
                    5,
                    4,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.549,
                    1.648,
                    2.746,
                    3.844,
                    4.943,
                    6.041,
                    7.139,
                    8.238,
                    9.336,
                    10.434,
                    11.533,
                    12.631,
                    13.729,
                    14.828,
                    15.926,
                    17.024,
                    18.123,
                    19.221,
                    20.319,
                    21.418,
                    22.516,
                    23.614,
                    24.713,
                    25.811,
                    26.909,
                    28.008,
                    29.106,
                    30.204,
                    31.303,
                    32.401,
                    33.499,
                    34.598,
                    35.696,
                    36.794,
                    37.893,
                    38.991,
                    40.089,
                    41.188,
                    42.286,
                    43.384,
                    44.483,
                    45.581,
                    46.679,
                    47.778,
                    48.876,
                    49.974,
                    51.073,
                    52.171,
                    53.269,
                    54.368
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    2,
                    5,
                    11,
                    26,
                    57,
                    108,
                    227,
                    362,
                    669,
                    1120,
                    1588,
                    2133,
                    2988,
                    3680,
                    4005,
                    4280,
                    4366,
                    4259,
                    3818,
                    3478,
                    2955,
                    2411,
                    1844,
                    1477,
                    1106,
                    831,
                    605,
                    457,
                    294,
                    237,
                    179,
                    155,
                    135,
                    100,
                    74,
                    59,
                    50,
                    32,
                    24,
                    19,
                    9,
                    10,
                    2,
                    1,
                    2,
                    3,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.813,
                    -0.772,
                    -0.731,
                    -0.69,
                    -0.649,
                    -0.608,
                    -0.567,
                    -0.526,
                    -0.485,
                    -0.443,
                    -0.402,
                    -0.361,
                    -0.32,
                    -0.279,
                    -0.238,
                    -0.197,
                    -0.156,
                    -0.114,
                    -0.073,
                    -0.032,
                    0.009,
                    0.05,
                    0.091,
                    0.132,
                    0.173,
                    0.214,
                    0.256,
                    0.297,
                    0.338,
                    0.379,
                    0.42,
                    0.461,
                    0.502,
                    0.543,
                    0.584,
                    0.626,
                    0.667,
                    0.708,
                    0.749,
                    0.79,
                    0.831,
                    0.872,
                    0.913,
                    0.955,
                    0.996,
                    1.037,
                    1.078,
                    1.119,
                    1.16,
                    1.201
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "verbs related to learning or acquiring new skills",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtwn415g53i6668wz8rpmc",
                        "tokens": [
                            "When",
                            " we",
                            " enter",
                            " the",
                            " political",
                            " debate",
                            " sphere",
                            " of",
                            " the",
                            " online",
                            " world",
                            ",",
                            " I",
                            " think",
                            " we",
                            " consider",
                            " people",
                            " holding",
                            " these",
                            " beliefs",
                            " to",
                            " be",
                            " unreal",
                            ".",
                            " The",
                            " information",
                            " age",
                            " means",
                            " almost",
                            " anybody",
                            " can",
                            " become",
                            " informed",
                            " about",
                            " any",
                            " topic",
                            ",",
                            " right",
                            "?",
                            " Someone",
                            " who",
                            " believes",
                            " in",
                            " these",
                            " conspir",
                            "acies",
                            " has",
                            " got",
                            " to",
                            " be",
                            " a",
                            " troll",
                            " or",
                            " using",
                            " their",
                            " anonymity",
                            " to",
                            " esp",
                            "ouse",
                            " harmful",
                            " beliefs",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " never",
                            " talk",
                            " about",
                            " in",
                            "-",
                            "person",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " ed",
                            "gy",
                            " teenager",
                            ",",
                            " a",
                            " kid",
                            " who",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " learned",
                            " to",
                            " navigate",
                            " the",
                            " harmful",
                            " tra",
                            "ppings",
                            " of",
                            " the",
                            " internet",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " old",
                            " cod",
                            "ger",
                            ",",
                            " still",
                            " holding",
                            " onto",
                            " the",
                            " good",
                            " old",
                            " days",
                            " where",
                            " they",
                            " had",
                            " all",
                            " the",
                            " privilege",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.917,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.917,
                            0.521,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtwn415g54i666ao9t8r0t",
                        "tokens": [
                            "\u013b",
                            "t",
                            " reapp",
                            "ear",
                            " for",
                            " about",
                            " 20",
                            " years",
                            ".",
                            " Compos",
                            "ers",
                            " or",
                            " performers",
                            " of",
                            " concert",
                            "os",
                            " could",
                            " hire",
                            " theater",
                            " orchestr",
                            "as",
                            " in",
                            " Vienna",
                            ",",
                            " but",
                            " they",
                            " played",
                            " badly",
                            ".",
                            "\n",
                            "\n",
                            "No",
                            " other",
                            " cities",
                            " in",
                            " Europe",
                            " had",
                            " enough",
                            " influence",
                            " to",
                            " put",
                            " their",
                            " resident",
                            " compos",
                            "ers",
                            " on",
                            " the",
                            " international",
                            " stage",
                            ".",
                            "\n",
                            "\n",
                            "By",
                            " the",
                            " time",
                            " concert",
                            " life",
                            " revived",
                            " in",
                            " these",
                            " capitals",
                            ",",
                            " Hay",
                            "dn",
                            " and",
                            " Moz",
                            "art",
                            " were",
                            " dead",
                            ".",
                            " There",
                            " was",
                            " no",
                            " logical",
                            " successor",
                            " to",
                            " Be",
                            "eth",
                            "oven",
                            ".",
                            " After",
                            " all",
                            ",",
                            " why",
                            " would",
                            " anyone",
                            " learn",
                            " to",
                            " compose",
                            " that",
                            " kind",
                            " of",
                            " music",
                            "?",
                            " They",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " get",
                            " it",
                            " heard",
                            " with",
                            " no",
                            " concert",
                            " life",
                            ".",
                            "\n",
                            "\n",
                            "Twenty",
                            " years",
                            " later",
                            ",",
                            " mass",
                            " audiences",
                            " no",
                            " longer",
                            " remembered",
                            " how",
                            " to",
                            " listen",
                            " to",
                            " that",
                            " music",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.496,
                        "maxValueTokenIndex": 87,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.496,
                            2.579,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.06,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtwn415g55i6665qwdc36q",
                        "tokens": [
                            "The",
                            " gold",
                            "il",
                            "ocks",
                            " economy",
                            " Buffett",
                            " describes",
                            ",",
                            " in",
                            " which",
                            " we",
                            " can",
                            " have",
                            " \u00e2\u0122",
                            "\u013e",
                            "re",
                            "co",
                            "very",
                            "\u00e2\u0122",
                            "\u013f",
                            " without",
                            " increasing",
                            " debt",
                            ",",
                            " is",
                            " a",
                            " fantasy",
                            ".",
                            "\n",
                            "\n",
                            "My",
                            " point",
                            " is",
                            " that",
                            " in",
                            " order",
                            " to",
                            " reduce",
                            " debt",
                            " we",
                            " have",
                            " to",
                            " endure",
                            " some",
                            " sort",
                            " of",
                            " deflation",
                            "ary",
                            " recession",
                            ".",
                            " The",
                            " alternative",
                            " is",
                            " to",
                            " spend",
                            " and",
                            " print",
                            " perpetually",
                            ",",
                            " which",
                            " Buffett",
                            " points",
                            " out",
                            " is",
                            " the",
                            " worse",
                            " option",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " Buffett",
                            " should",
                            " have",
                            " said",
                            "?",
                            " S",
                            "uck",
                            " it",
                            " up",
                            " folks",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " no",
                            " choice",
                            " but",
                            " to",
                            " learn",
                            " to",
                            " live",
                            " with",
                            " less",
                            ".",
                            "\n",
                            "\n",
                            "\u2014\u2014",
                            "\n",
                            "\n",
                            "P",
                            ".",
                            "s",
                            ".:",
                            " I",
                            " think",
                            " Buffett",
                            " actually",
                            " knows",
                            " this",
                            ",",
                            " but",
                            " being",
                            " asset",
                            "-",
                            "rich",
                            ",",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " boxed",
                            " in",
                            ".",
                            " Def",
                            "lation"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.432,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.432,
                            15.167,
                            1.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13254",
            "description": " phrases indicating the act of learning or acquiring knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5678723027668092,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13254",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:32.988Z",
                "maxActApprox": 43.262,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13254,
                    44064,
                    77000,
                    32386,
                    1477,
                    65225,
                    20609,
                    23576,
                    17480,
                    62592,
                    44115,
                    46440,
                    27303,
                    32890,
                    38800,
                    3406,
                    48787,
                    71639,
                    39551,
                    55992,
                    79250,
                    23047,
                    22861,
                    44214,
                    93447
                ],
                "topkCosSimValues": [
                    1,
                    0.7969,
                    0.7182,
                    0.6674,
                    0.624,
                    0.5667,
                    0.5423,
                    0.5277,
                    0.5258,
                    0.4518,
                    0.4509,
                    0.4498,
                    0.4343,
                    0.4322,
                    0.4289,
                    0.4224,
                    0.4214,
                    0.4165,
                    0.4077,
                    0.4018,
                    0.4005,
                    0.3997,
                    0.3992,
                    0.398,
                    0.3973
                ],
                "neuron_alignment_indices": [
                    285,
                    756,
                    171
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.105,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.023,
                    0.02
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.022,
                    0.018
                ],
                "correlated_features_indices": [
                    13120,
                    13237,
                    13268
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.008,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "ordered",
                    "peror",
                    "ordering",
                    "adjusted",
                    " Yugoslavia",
                    "\u00e3\u0125\u00a4",
                    "ugal",
                    "jan",
                    "senal",
                    "amination"
                ],
                "neg_values": [
                    -0.753,
                    -0.676,
                    -0.64,
                    -0.631,
                    -0.612,
                    -0.601,
                    -0.6,
                    -0.595,
                    -0.593,
                    -0.586
                ],
                "pos_str": [
                    " firsthand",
                    " ABOUT",
                    " about",
                    "natureconservancy",
                    "learn",
                    " lessons",
                    " how",
                    " aloud",
                    "lege",
                    "omed"
                ],
                "pos_values": [
                    0.867,
                    0.859,
                    0.846,
                    0.792,
                    0.762,
                    0.758,
                    0.743,
                    0.742,
                    0.731,
                    0.711
                ],
                "frac_nonzero": 0.00015,
                "freq_hist_data_bar_heights": [
                    44,
                    35,
                    40,
                    35,
                    17,
                    20,
                    13,
                    28,
                    22,
                    21,
                    17,
                    19,
                    12,
                    12,
                    17,
                    4,
                    8,
                    6,
                    6,
                    7,
                    12,
                    2,
                    7,
                    4,
                    4,
                    3,
                    3,
                    1,
                    3,
                    0,
                    2,
                    3,
                    2,
                    4,
                    2,
                    8,
                    3,
                    1,
                    1,
                    4,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.455,
                    1.32,
                    2.184,
                    3.049,
                    3.914,
                    4.779,
                    5.644,
                    6.508,
                    7.373,
                    8.238,
                    9.103,
                    9.968,
                    10.832,
                    11.697,
                    12.562,
                    13.427,
                    14.292,
                    15.156,
                    16.021,
                    16.886,
                    17.751,
                    18.616,
                    19.48,
                    20.345,
                    21.21,
                    22.075,
                    22.94,
                    23.804,
                    24.669,
                    25.534,
                    26.399,
                    27.263,
                    28.128,
                    28.993,
                    29.858,
                    30.723,
                    31.587,
                    32.452,
                    33.317,
                    34.182,
                    35.047,
                    35.911,
                    36.776,
                    37.641,
                    38.506,
                    39.371,
                    40.235,
                    41.1,
                    41.965,
                    42.83
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    2,
                    5,
                    11,
                    13,
                    20,
                    33,
                    78,
                    132,
                    198,
                    299,
                    485,
                    707,
                    1030,
                    1551,
                    1989,
                    2525,
                    3179,
                    3676,
                    4124,
                    4383,
                    4367,
                    4164,
                    3692,
                    3292,
                    2701,
                    2104,
                    1573,
                    1210,
                    842,
                    641,
                    383,
                    284,
                    195,
                    121,
                    69,
                    67,
                    26,
                    30,
                    21,
                    13,
                    5,
                    5,
                    2,
                    4,
                    1,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.737,
                    -0.705,
                    -0.672,
                    -0.64,
                    -0.607,
                    -0.575,
                    -0.543,
                    -0.51,
                    -0.478,
                    -0.445,
                    -0.413,
                    -0.381,
                    -0.348,
                    -0.316,
                    -0.283,
                    -0.251,
                    -0.218,
                    -0.186,
                    -0.154,
                    -0.121,
                    -0.089,
                    -0.056,
                    -0.024,
                    0.008,
                    0.041,
                    0.073,
                    0.106,
                    0.138,
                    0.171,
                    0.203,
                    0.235,
                    0.268,
                    0.3,
                    0.333,
                    0.365,
                    0.397,
                    0.43,
                    0.462,
                    0.495,
                    0.527,
                    0.56,
                    0.592,
                    0.624,
                    0.657,
                    0.689,
                    0.722,
                    0.754,
                    0.786,
                    0.819,
                    0.851
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases indicating the act of learning or acquiring knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "instances of the word \"learn\" and variations of it",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfgrgrlcl410exajvamjvv",
                        "tokens": [
                            ",",
                            " click",
                            " the",
                            " Ask",
                            " a",
                            " Question",
                            " button",
                            " below",
                            ".",
                            " For",
                            " post",
                            "-",
                            "p",
                            "urchase",
                            " inquiries",
                            ",",
                            " please",
                            " contact",
                            " Group",
                            "on",
                            " customer",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "Good",
                            "s",
                            " sold",
                            " by",
                            " Group",
                            "on",
                            " Goods",
                            ".",
                            " View",
                            " the",
                            " Group",
                            "on",
                            " Goods",
                            " FAQ",
                            " to",
                            " learn",
                            " more",
                            ".",
                            "<|endoftext|>",
                            "A",
                            "head",
                            " of",
                            " her",
                            " meeting",
                            " with",
                            " Trump",
                            " tomorrow",
                            ",",
                            " British",
                            " Prime",
                            " Minister",
                            " Theresa",
                            " May",
                            " joked",
                            " that",
                            " \"",
                            "opp",
                            "os",
                            "ites",
                            " attract",
                            "\"",
                            " and",
                            " called",
                            " on",
                            " the",
                            " US",
                            " President",
                            " to",
                            " renew",
                            " the",
                            " \"",
                            "special",
                            " relationship",
                            "\"",
                            " between",
                            " Britain",
                            " and",
                            " the",
                            " United",
                            " States",
                            " and",
                            " lead",
                            " in",
                            " a",
                            " new",
                            ",",
                            " changed",
                            " world",
                            ".",
                            " In",
                            " the",
                            " United",
                            " States",
                            " for",
                            " what",
                            " will",
                            " be",
                            " Trump",
                            "'s",
                            " first",
                            " meeting",
                            " with",
                            " a",
                            " foreign",
                            " leader",
                            " since",
                            " he",
                            " took",
                            " office",
                            " last",
                            " week",
                            ",",
                            " May",
                            " signaled",
                            " a",
                            " shift",
                            " in",
                            " foreign",
                            " policy",
                            ",",
                            " bringing",
                            " her"
                        ],
                        "dataIndex": null,
                        "index": "13254",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.262,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.262,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:40.539Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 43.262,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfgrgtlclq10ex64gz9o7o",
                        "tokens": [
                            ",",
                            " click",
                            " the",
                            " Ask",
                            " a",
                            " Question",
                            " button",
                            " below",
                            ".",
                            " For",
                            " post",
                            "-",
                            "p",
                            "urchase",
                            " inquiries",
                            ",",
                            " please",
                            " contact",
                            " Group",
                            "on",
                            " customer",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "Good",
                            "s",
                            " sold",
                            " by",
                            " Group",
                            "on",
                            " Goods",
                            ".",
                            " View",
                            " the",
                            " Group",
                            "on",
                            " Goods",
                            " FAQ",
                            " to",
                            " learn",
                            " more",
                            ".",
                            "<|endoftext|>",
                            "A",
                            "head",
                            " of",
                            " her",
                            " meeting",
                            " with",
                            " Trump",
                            " tomorrow",
                            ",",
                            " British",
                            " Prime",
                            " Minister",
                            " Theresa",
                            " May",
                            " joked",
                            " that",
                            " \"",
                            "opp",
                            "os",
                            "ites",
                            " attract",
                            "\"",
                            " and",
                            " called",
                            " on",
                            " the",
                            " US",
                            " President",
                            " to",
                            " renew",
                            " the",
                            " \"",
                            "special",
                            " relationship",
                            "\"",
                            " between",
                            " Britain",
                            " and",
                            " the",
                            " United",
                            " States",
                            " and",
                            " lead",
                            " in",
                            " a",
                            " new",
                            ",",
                            " changed",
                            " world",
                            ".",
                            " In",
                            " the",
                            " United",
                            " States",
                            " for",
                            " what",
                            " will",
                            " be",
                            " Trump",
                            "'s",
                            " first",
                            " meeting",
                            " with",
                            " a",
                            " foreign",
                            " leader",
                            " since",
                            " he",
                            " took",
                            " office",
                            " last",
                            " week",
                            ",",
                            " May",
                            " signaled",
                            " a",
                            " shift",
                            " in",
                            " foreign",
                            " policy",
                            ",",
                            " bringing",
                            " her"
                        ],
                        "dataIndex": null,
                        "index": "13254",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.262,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.262,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:40.539Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.61,
                        "binMax": 43.262,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfgrgrlcl510exghmb0ke7",
                        "tokens": [
                            " review",
                            " to",
                            " learn",
                            " more",
                            " about",
                            " nuclear",
                            " thunder",
                            "storms",
                            " and",
                            " apocalyptic",
                            " base",
                            "-",
                            "building",
                            ".",
                            "\n",
                            "\n",
                            "Exit",
                            " Theatre",
                            " Mode",
                            "\n",
                            "\n",
                            "Cass",
                            "ide",
                            "e",
                            " is",
                            " a",
                            " freelance",
                            " writer",
                            " and",
                            " the",
                            " co",
                            "-",
                            "host",
                            " of",
                            " a",
                            " freel",
                            "ancing",
                            " podcast",
                            " and",
                            " a",
                            " geek",
                            " culture",
                            " podcast",
                            ".",
                            " You",
                            " can",
                            " chat",
                            " with",
                            " her",
                            " about",
                            " comics",
                            ",",
                            " video",
                            " games",
                            ",",
                            " and",
                            " C",
                            "org",
                            "is",
                            " on",
                            " Twitter",
                            ".",
                            "<|endoftext|>",
                            "242",
                            "nd",
                            " Independence",
                            " Day",
                            " celebration",
                            " in",
                            " the",
                            " USA",
                            "\n",
                            "\n",
                            "About",
                            " US",
                            " Independence",
                            " Day",
                            " (",
                            "4",
                            "th",
                            " July",
                            ")",
                            "\n",
                            "\n",
                            "4",
                            "th",
                            " of",
                            " July",
                            " Celebr",
                            "ations",
                            " and",
                            " Fire",
                            "works",
                            "\n",
                            "\n",
                            "Ind",
                            "ependence",
                            " Day",
                            " Facts",
                            "\n",
                            "\n",
                            "Why",
                            " is",
                            " the",
                            " Fourth",
                            " of",
                            " July",
                            " the",
                            " national",
                            " holiday",
                            " of",
                            " the",
                            " United",
                            " States",
                            "?",
                            "\n",
                            "\n",
                            "What",
                            " was",
                            " the",
                            " Continental",
                            " Congress",
                            "?",
                            "\n",
                            "\n",
                            "Who",
                            " signed"
                        ],
                        "dataIndex": null,
                        "index": "13254",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.864,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            39.864,
                            4.226,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:40.539Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 43.262,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "14572",
            "description": "terms related to learning and valuable lessons",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5576536391767059,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "14572",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:24:35.724Z",
                "maxActApprox": 36.977,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14572,
                    46722,
                    33219,
                    19723,
                    37022,
                    35811,
                    33871,
                    7882,
                    41576,
                    39623,
                    2599,
                    9870,
                    785,
                    20747,
                    23357,
                    15624,
                    15480,
                    27850,
                    35043,
                    3993,
                    22563,
                    26719,
                    26441,
                    47084,
                    46953
                ],
                "topkCosSimValues": [
                    1,
                    0.5684,
                    0.5247,
                    0.5194,
                    0.502,
                    0.4875,
                    0.4688,
                    0.4173,
                    0.417,
                    0.409,
                    0.3907,
                    0.3858,
                    0.3748,
                    0.3624,
                    0.3602,
                    0.3526,
                    0.3475,
                    0.3453,
                    0.3358,
                    0.3322,
                    0.3247,
                    0.3243,
                    0.3208,
                    0.3199,
                    0.319
                ],
                "neuron_alignment_indices": [
                    154,
                    415,
                    567
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    567,
                    154,
                    568
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.017,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.019,
                    0.014
                ],
                "correlated_features_indices": [
                    14568,
                    14530,
                    14575
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "vertisement",
                    "ItemImage",
                    "ocument",
                    "cohol",
                    "istent",
                    "lished",
                    "IUM",
                    "enance",
                    "athi",
                    "ilitary"
                ],
                "neg_values": [
                    -0.704,
                    -0.666,
                    -0.664,
                    -0.652,
                    -0.646,
                    -0.643,
                    -0.609,
                    -0.601,
                    -0.596,
                    -0.59
                ],
                "pos_str": [
                    " lesson",
                    " lessons",
                    " tricks",
                    " firsthand",
                    " Lessons",
                    " ropes",
                    " basics",
                    " valuable",
                    " skills",
                    " invaluable"
                ],
                "pos_values": [
                    1.36,
                    1.172,
                    1.003,
                    0.966,
                    0.918,
                    0.866,
                    0.853,
                    0.841,
                    0.837,
                    0.789
                ],
                "frac_nonzero": 0.0006,
                "freq_hist_data_bar_heights": [
                    457,
                    308,
                    223,
                    161,
                    100,
                    96,
                    81,
                    63,
                    52,
                    44,
                    37,
                    22,
                    23,
                    19,
                    18,
                    12,
                    18,
                    11,
                    8,
                    9,
                    8,
                    7,
                    8,
                    10,
                    7,
                    8,
                    3,
                    8,
                    8,
                    5,
                    5,
                    4,
                    3,
                    4,
                    4,
                    5,
                    7,
                    3,
                    2,
                    3,
                    2,
                    4,
                    1,
                    2,
                    2,
                    0,
                    3,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.37,
                    1.11,
                    1.849,
                    2.589,
                    3.328,
                    4.068,
                    4.808,
                    5.547,
                    6.287,
                    7.026,
                    7.766,
                    8.505,
                    9.245,
                    9.984,
                    10.724,
                    11.463,
                    12.203,
                    12.942,
                    13.682,
                    14.421,
                    15.161,
                    15.9,
                    16.64,
                    17.379,
                    18.119,
                    18.858,
                    19.598,
                    20.337,
                    21.077,
                    21.816,
                    22.556,
                    23.295,
                    24.035,
                    24.775,
                    25.514,
                    26.254,
                    26.993,
                    27.733,
                    28.472,
                    29.212,
                    29.951,
                    30.691,
                    31.43,
                    32.17,
                    32.909,
                    33.649,
                    34.388,
                    35.128,
                    35.867,
                    36.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    6,
                    15,
                    34,
                    61,
                    128,
                    254,
                    487,
                    778,
                    1137,
                    1701,
                    2612,
                    3378,
                    4370,
                    5011,
                    5269,
                    5141,
                    4818,
                    4051,
                    3325,
                    2526,
                    1831,
                    1251,
                    789,
                    514,
                    307,
                    190,
                    108,
                    61,
                    36,
                    17,
                    17,
                    10,
                    6,
                    2,
                    1,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.643,
                    -0.601,
                    -0.56,
                    -0.519,
                    -0.477,
                    -0.436,
                    -0.395,
                    -0.354,
                    -0.312,
                    -0.271,
                    -0.23,
                    -0.188,
                    -0.147,
                    -0.106,
                    -0.065,
                    -0.023,
                    0.018,
                    0.059,
                    0.1,
                    0.142,
                    0.183,
                    0.224,
                    0.266,
                    0.307,
                    0.348,
                    0.389,
                    0.431,
                    0.472,
                    0.513,
                    0.555,
                    0.596,
                    0.637,
                    0.678,
                    0.72,
                    0.761,
                    0.802,
                    0.844,
                    0.885,
                    0.926,
                    0.967,
                    1.009,
                    1.05,
                    1.091,
                    1.132,
                    1.174,
                    1.215,
                    1.256,
                    1.298,
                    1.339
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to learning and valuable lessons",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5222xp36ei6667oroi4dk",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222vp35vi6664i76pr01",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222wp35wi6660ecwqa69",
                        "tokens": [
                            ",",
                            " but",
                            " then",
                            " you",
                            " use",
                            " that",
                            " to",
                            " fight",
                            " Meg",
                            "ac",
                            "orp",
                            " B",
                            " and",
                            " probably",
                            " learn",
                            " a",
                            " little",
                            " more",
                            " about",
                            " A",
                            " to",
                            " begin",
                            " with",
                            " and",
                            "...",
                            "\n",
                            "\n",
                            "Add",
                            " to",
                            " this",
                            " the",
                            " \"",
                            "self",
                            "-",
                            "trained",
                            "\"",
                            " element",
                            " of",
                            " punk",
                            " music",
                            ".",
                            " Don",
                            "'t",
                            " use",
                            " the",
                            " corp",
                            " cyber",
                            "deck",
                            " loaded",
                            " with",
                            " spy",
                            "ware",
                            " and",
                            " apps",
                            " you",
                            " won",
                            "'t",
                            " need",
                            ",",
                            " build",
                            " one",
                            " yourself",
                            " with",
                            " eight",
                            " old",
                            " cell",
                            "phones",
                            " and",
                            " a",
                            " keyboard",
                            " you",
                            " found",
                            " at",
                            " a",
                            " recycling",
                            " plant",
                            ".",
                            " Don",
                            "'t",
                            " get",
                            " the",
                            " flesh",
                            "like",
                            " cyber",
                            " arm",
                            "--",
                            "get",
                            " the",
                            " one",
                            " that",
                            "'s",
                            " been",
                            " jail",
                            "bre",
                            "aked",
                            " and",
                            " uploaded",
                            " with",
                            " new",
                            " moves",
                            " and",
                            " works",
                            " better",
                            " so",
                            " fuck",
                            " the",
                            " warranty",
                            ".",
                            " Don",
                            "'t",
                            " summon",
                            " that",
                            " elemental",
                            "--",
                            "every",
                            " time",
                            " you",
                            " do",
                            " a",
                            " tiny",
                            " bit",
                            " of",
                            " mo",
                            "jo",
                            " is",
                            " going",
                            " back"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.822,
                        "maxValueTokenIndex": 15,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.822,
                            26.566,
                            17.44,
                            2.595,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "44122",
            "description": "references to learning and acquiring new information",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5561088919639587,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "44122",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:17:40.156Z",
                "maxActApprox": 29.216,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44122,
                    43458,
                    6130,
                    43250,
                    46603,
                    38746,
                    31212,
                    2271,
                    19287,
                    40465,
                    12421,
                    34100,
                    44012,
                    17861,
                    1122,
                    35811,
                    46512,
                    31664,
                    1523,
                    31090,
                    14652,
                    3524,
                    42509,
                    30199,
                    47894
                ],
                "topkCosSimValues": [
                    1,
                    0.5457,
                    0.5132,
                    0.4244,
                    0.4157,
                    0.4111,
                    0.4047,
                    0.3899,
                    0.3875,
                    0.3831,
                    0.3813,
                    0.3782,
                    0.3714,
                    0.3703,
                    0.3559,
                    0.3558,
                    0.3502,
                    0.348,
                    0.3456,
                    0.3452,
                    0.3325,
                    0.3316,
                    0.331,
                    0.329,
                    0.3267
                ],
                "neuron_alignment_indices": [
                    722,
                    340,
                    642
                ],
                "neuron_alignment_values": [
                    0.103,
                    0.097,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    715,
                    70,
                    765
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.018,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.02,
                    0.019
                ],
                "correlated_features_indices": [
                    44163,
                    44120,
                    44110
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.003,
                    0.001
                ],
                "neg_str": [
                    "alach",
                    "uay",
                    " watershed",
                    "onding",
                    " vend",
                    "taboola",
                    " burner",
                    " spaced",
                    " Bul",
                    "awar"
                ],
                "neg_values": [
                    -0.741,
                    -0.717,
                    -0.695,
                    -0.664,
                    -0.611,
                    -0.604,
                    -0.6,
                    -0.596,
                    -0.595,
                    -0.592
                ],
                "pos_str": [
                    "enance",
                    "biz",
                    "adays",
                    "stadt",
                    " congratulations",
                    "rists",
                    "eers",
                    "dylib",
                    "IENT",
                    " therein"
                ],
                "pos_values": [
                    0.984,
                    0.744,
                    0.711,
                    0.691,
                    0.673,
                    0.669,
                    0.652,
                    0.644,
                    0.638,
                    0.634
                ],
                "frac_nonzero": 0.00041,
                "freq_hist_data_bar_heights": [
                    334,
                    207,
                    166,
                    105,
                    79,
                    62,
                    49,
                    40,
                    34,
                    25,
                    16,
                    19,
                    19,
                    19,
                    11,
                    3,
                    5,
                    3,
                    9,
                    10,
                    4,
                    2,
                    5,
                    6,
                    2,
                    5,
                    5,
                    6,
                    2,
                    2,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    3,
                    0,
                    1,
                    0,
                    1,
                    2,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.292,
                    0.877,
                    1.461,
                    2.045,
                    2.63,
                    3.214,
                    3.798,
                    4.383,
                    4.967,
                    5.551,
                    6.136,
                    6.72,
                    7.304,
                    7.889,
                    8.473,
                    9.057,
                    9.641,
                    10.226,
                    10.81,
                    11.394,
                    11.979,
                    12.563,
                    13.147,
                    13.732,
                    14.316,
                    14.9,
                    15.485,
                    16.069,
                    16.653,
                    17.238,
                    17.822,
                    18.406,
                    18.991,
                    19.575,
                    20.159,
                    20.743,
                    21.328,
                    21.912,
                    22.496,
                    23.081,
                    23.665,
                    24.249,
                    24.834,
                    25.418,
                    26.002,
                    26.587,
                    27.171,
                    27.755,
                    28.34,
                    28.924
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    1,
                    2,
                    6,
                    13,
                    20,
                    53,
                    78,
                    140,
                    235,
                    438,
                    635,
                    926,
                    1359,
                    1839,
                    2393,
                    3108,
                    3488,
                    4091,
                    4409,
                    4279,
                    4248,
                    3980,
                    3522,
                    3055,
                    2345,
                    1750,
                    1307,
                    860,
                    622,
                    414,
                    245,
                    151,
                    100,
                    61,
                    27,
                    26,
                    16,
                    4,
                    3,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.723,
                    -0.689,
                    -0.654,
                    -0.62,
                    -0.585,
                    -0.551,
                    -0.516,
                    -0.482,
                    -0.447,
                    -0.413,
                    -0.378,
                    -0.344,
                    -0.31,
                    -0.275,
                    -0.241,
                    -0.206,
                    -0.172,
                    -0.137,
                    -0.103,
                    -0.068,
                    -0.034,
                    0.001,
                    0.035,
                    0.07,
                    0.104,
                    0.139,
                    0.173,
                    0.208,
                    0.242,
                    0.277,
                    0.311,
                    0.346,
                    0.38,
                    0.415,
                    0.449,
                    0.484,
                    0.518,
                    0.553,
                    0.587,
                    0.621,
                    0.656,
                    0.69,
                    0.725,
                    0.759,
                    0.794,
                    0.828,
                    0.863,
                    0.897,
                    0.932,
                    0.966
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to learning and acquiring new information",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6ybdtgbcqi666z204keb6",
                        "tokens": [
                            " career",
                            "\n",
                            "\n",
                            "After",
                            " an",
                            " extensive",
                            " investigation",
                            ",",
                            " Mr",
                            " S",
                            "ettle",
                            " \u2013",
                            " who",
                            " was",
                            " appointed",
                            " head",
                            " of",
                            " the",
                            " Met",
                            "'s",
                            " VIP",
                            " sex",
                            " abuse",
                            " inquiry",
                            " Operation",
                            " Fair",
                            "bank",
                            " in",
                            " 2012",
                            " -",
                            " concluded",
                            " there",
                            " was",
                            " no",
                            " evidence",
                            " to",
                            " support",
                            " the",
                            " woman",
                            "'s",
                            " allegations",
                            " and",
                            " that",
                            " the",
                            " investigation",
                            " should",
                            " be",
                            " closed",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " in",
                            " May",
                            " 2014",
                            ",",
                            " three",
                            " months",
                            " after",
                            " meeting",
                            " her",
                            " to",
                            " explain",
                            " his",
                            " decision",
                            ",",
                            " Mr",
                            " S",
                            "ettle",
                            " was",
                            " suddenly",
                            " removed",
                            " from",
                            " his",
                            " post",
                            ".",
                            "\n",
                            "\n",
                            "Police",
                            " carried",
                            " out",
                            " a",
                            " protracted",
                            " inquiry",
                            " into",
                            " the",
                            " discredited",
                            " allegations",
                            " against",
                            " Lord",
                            " Britt",
                            "an",
                            " (",
                            "pictured",
                            ")",
                            "\n",
                            "\n",
                            "He",
                            " was",
                            " '",
                            "dis",
                            "g",
                            "usted",
                            "'",
                            " to",
                            " learn",
                            " that",
                            " a",
                            " month",
                            " earlier",
                            ",",
                            " Mr",
                            " Watson",
                            " had",
                            " written",
                            " directly",
                            " to",
                            " the",
                            " Director",
                            " of",
                            " Public",
                            " Pro",
                            "sec",
                            "utions",
                            ",",
                            " Alison",
                            " Saunders"
                        ],
                        "dataIndex": null,
                        "index": "44122",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.216,
                        "maxValueTokenIndex": 105,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.216,
                            7.57,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:45.288Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 29.216,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ybdwgbdbi6663lw4wunq",
                        "tokens": [
                            " career",
                            "\n",
                            "\n",
                            "After",
                            " an",
                            " extensive",
                            " investigation",
                            ",",
                            " Mr",
                            " S",
                            "ettle",
                            " \u2013",
                            " who",
                            " was",
                            " appointed",
                            " head",
                            " of",
                            " the",
                            " Met",
                            "'s",
                            " VIP",
                            " sex",
                            " abuse",
                            " inquiry",
                            " Operation",
                            " Fair",
                            "bank",
                            " in",
                            " 2012",
                            " -",
                            " concluded",
                            " there",
                            " was",
                            " no",
                            " evidence",
                            " to",
                            " support",
                            " the",
                            " woman",
                            "'s",
                            " allegations",
                            " and",
                            " that",
                            " the",
                            " investigation",
                            " should",
                            " be",
                            " closed",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " in",
                            " May",
                            " 2014",
                            ",",
                            " three",
                            " months",
                            " after",
                            " meeting",
                            " her",
                            " to",
                            " explain",
                            " his",
                            " decision",
                            ",",
                            " Mr",
                            " S",
                            "ettle",
                            " was",
                            " suddenly",
                            " removed",
                            " from",
                            " his",
                            " post",
                            ".",
                            "\n",
                            "\n",
                            "Police",
                            " carried",
                            " out",
                            " a",
                            " protracted",
                            " inquiry",
                            " into",
                            " the",
                            " discredited",
                            " allegations",
                            " against",
                            " Lord",
                            " Britt",
                            "an",
                            " (",
                            "pictured",
                            ")",
                            "\n",
                            "\n",
                            "He",
                            " was",
                            " '",
                            "dis",
                            "g",
                            "usted",
                            "'",
                            " to",
                            " learn",
                            " that",
                            " a",
                            " month",
                            " earlier",
                            ",",
                            " Mr",
                            " Watson",
                            " had",
                            " written",
                            " directly",
                            " to",
                            " the",
                            " Director",
                            " of",
                            " Public",
                            " Pro",
                            "sec",
                            "utions",
                            ",",
                            " Alison",
                            " Saunders"
                        ],
                        "dataIndex": null,
                        "index": "44122",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.216,
                        "maxValueTokenIndex": 105,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.216,
                            7.57,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:45.288Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 23.373,
                        "binMax": 29.216,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ybdugbcri666035teyso",
                        "tokens": [
                            " nurse",
                            ".",
                            " She",
                            " said",
                            " working",
                            " first",
                            "-",
                            "hand",
                            " in",
                            " an",
                            " environment",
                            " that",
                            " deals",
                            " with",
                            " transpl",
                            "ants",
                            ",",
                            " she",
                            " was",
                            " shocked",
                            " to",
                            " learn",
                            " of",
                            " the",
                            " money",
                            " not",
                            " being",
                            " used",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " would",
                            " be",
                            " a",
                            " waste",
                            " for",
                            " those",
                            " that",
                            " are",
                            " waiting",
                            ",\"",
                            " said",
                            " Kn",
                            "ut",
                            "zen",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "A",
                            " million",
                            " dollars",
                            " is",
                            " big",
                            " chunk",
                            " of",
                            " change",
                            " for",
                            " anybody",
                            ",\"",
                            " said",
                            " Sean",
                            " Anne",
                            ".",
                            " He",
                            "'s",
                            " been",
                            " working",
                            " as",
                            " a",
                            " volunteer",
                            " firefighter",
                            " and",
                            " ambulance",
                            " companies",
                            " his",
                            " entire",
                            " life",
                            ".",
                            " \"",
                            "I",
                            " think",
                            " it",
                            "'s",
                            " a",
                            " great",
                            " time",
                            " that",
                            " we",
                            " look",
                            " into",
                            " education",
                            " and",
                            " be",
                            " at",
                            " the",
                            " forefront",
                            " and",
                            " do",
                            " something",
                            " big",
                            " with",
                            " it",
                            ".\"",
                            "\n",
                            "\n",
                            "O",
                            "'",
                            "M",
                            "ally",
                            " said",
                            " New",
                            " York",
                            " State",
                            " has",
                            " taken",
                            " steps",
                            " to",
                            " increase",
                            " low",
                            " don",
                            "orship",
                            " numbers",
                            ",",
                            " but"
                        ],
                        "dataIndex": null,
                        "index": "44122",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.395,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.311,
                            28.395,
                            6.042,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:45.288Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 29.216,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "7187",
            "description": "phrases related to learning or acquiring new information",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5531560182571411,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "7187",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:53:54.469Z",
                "maxActApprox": 47.31,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7187,
                    20008,
                    9225,
                    2687,
                    15540,
                    1994,
                    12849,
                    12495,
                    21986,
                    13057,
                    10325,
                    14797,
                    11272,
                    17920,
                    10953,
                    7776,
                    11695,
                    17064,
                    5509,
                    24462,
                    1368,
                    8581,
                    10171,
                    2092,
                    667
                ],
                "topkCosSimValues": [
                    1,
                    0.6717,
                    0.528,
                    0.4781,
                    0.4685,
                    0.4573,
                    0.4568,
                    0.4459,
                    0.4437,
                    0.4314,
                    0.4191,
                    0.4153,
                    0.4103,
                    0.4011,
                    0.398,
                    0.3979,
                    0.3946,
                    0.3887,
                    0.3856,
                    0.3832,
                    0.3768,
                    0.3623,
                    0.3592,
                    0.3509,
                    0.3424
                ],
                "neuron_alignment_indices": [
                    679,
                    483,
                    271
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.092,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    610
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.023,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.02,
                    0.02
                ],
                "correlated_features_indices": [
                    7175,
                    7248,
                    7184
                ],
                "correlated_features_pearson": [
                    0.011,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.011,
                    0.007,
                    0.004
                ],
                "neg_str": [
                    "ciating",
                    "ataka",
                    "cise",
                    "idity",
                    "oided",
                    "etrical",
                    "hur",
                    "ipping",
                    "charge",
                    "etric"
                ],
                "neg_values": [
                    -0.722,
                    -0.706,
                    -0.631,
                    -0.63,
                    -0.627,
                    -0.627,
                    -0.61,
                    -0.61,
                    -0.606,
                    -0.602
                ],
                "pos_str": [
                    " firsthand",
                    " srfAttach",
                    " anecd",
                    " Lauder",
                    " about",
                    "llor",
                    "ledge",
                    " nothing",
                    " Curve",
                    " beforehand"
                ],
                "pos_values": [
                    1.072,
                    0.859,
                    0.819,
                    0.728,
                    0.657,
                    0.656,
                    0.655,
                    0.65,
                    0.648,
                    0.628
                ],
                "frac_nonzero": 0.00031,
                "freq_hist_data_bar_heights": [
                    207,
                    127,
                    95,
                    75,
                    46,
                    26,
                    18,
                    27,
                    15,
                    19,
                    16,
                    15,
                    22,
                    16,
                    13,
                    14,
                    15,
                    13,
                    11,
                    14,
                    11,
                    19,
                    8,
                    15,
                    16,
                    8,
                    9,
                    14,
                    8,
                    9,
                    6,
                    6,
                    5,
                    5,
                    3,
                    4,
                    1,
                    3,
                    3,
                    1,
                    4,
                    1,
                    6,
                    2,
                    1,
                    1,
                    4,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.48,
                    1.426,
                    2.372,
                    3.318,
                    4.264,
                    5.21,
                    6.156,
                    7.102,
                    8.048,
                    8.994,
                    9.94,
                    10.887,
                    11.833,
                    12.779,
                    13.725,
                    14.671,
                    15.617,
                    16.563,
                    17.509,
                    18.455,
                    19.401,
                    20.347,
                    21.293,
                    22.239,
                    23.186,
                    24.132,
                    25.078,
                    26.024,
                    26.97,
                    27.916,
                    28.862,
                    29.808,
                    30.754,
                    31.7,
                    32.646,
                    33.592,
                    34.538,
                    35.485,
                    36.431,
                    37.377,
                    38.323,
                    39.269,
                    40.215,
                    41.161,
                    42.107,
                    43.053,
                    43.999,
                    44.945,
                    45.891,
                    46.837
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    4,
                    10,
                    17,
                    22,
                    40,
                    63,
                    147,
                    212,
                    345,
                    595,
                    927,
                    1234,
                    1932,
                    2550,
                    3239,
                    3878,
                    4462,
                    4792,
                    4909,
                    4514,
                    4092,
                    3569,
                    2708,
                    2010,
                    1378,
                    990,
                    622,
                    415,
                    221,
                    151,
                    89,
                    49,
                    29,
                    18,
                    7,
                    6,
                    5,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.704,
                    -0.668,
                    -0.632,
                    -0.596,
                    -0.56,
                    -0.524,
                    -0.489,
                    -0.453,
                    -0.417,
                    -0.381,
                    -0.345,
                    -0.309,
                    -0.273,
                    -0.237,
                    -0.202,
                    -0.166,
                    -0.13,
                    -0.094,
                    -0.058,
                    -0.022,
                    0.014,
                    0.049,
                    0.085,
                    0.121,
                    0.157,
                    0.193,
                    0.229,
                    0.265,
                    0.3,
                    0.336,
                    0.372,
                    0.408,
                    0.444,
                    0.48,
                    0.516,
                    0.552,
                    0.587,
                    0.623,
                    0.659,
                    0.695,
                    0.731,
                    0.767,
                    0.803,
                    0.838,
                    0.874,
                    0.91,
                    0.946,
                    0.982,
                    1.018,
                    1.054
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning or acquiring new information",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmc0vl6tsoi666ge6h43f1",
                        "tokens": [
                            " down",
                            " of",
                            " email",
                            " servers",
                            " and",
                            " other",
                            " platforms",
                            " is",
                            " the",
                            " exact",
                            " reason",
                            " the",
                            " gir",
                            "affe",
                            " cam",
                            " will",
                            " need",
                            " be",
                            " pulled",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " zoo",
                            " said",
                            " it",
                            " appreci",
                            "ates",
                            " the",
                            " concerns",
                            " of",
                            " viewers",
                            ",",
                            " but",
                            " it",
                            " has",
                            " affected",
                            " operations",
                            ".",
                            "\n",
                            "\n",
                            "Photos",
                            ":",
                            " Baby",
                            " gir",
                            "aff",
                            "es",
                            " around",
                            " the",
                            " world",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " is",
                            " interfering",
                            " with",
                            " normal",
                            " park",
                            " operations",
                            " and",
                            " preparation",
                            " for",
                            " opening",
                            ";",
                            " at",
                            " a",
                            " period",
                            " when",
                            " our",
                            " resource",
                            " of",
                            " time",
                            " is",
                            " limited",
                            " and",
                            " cannot",
                            " be",
                            " hindered",
                            ",\"",
                            " the",
                            " Animal",
                            " Adventure",
                            " Park",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " of",
                            " Monday",
                            " evening",
                            ",",
                            " the",
                            " stream",
                            " was",
                            " still",
                            " active",
                            ".",
                            "<|endoftext|>",
                            "\u2013",
                            " CBS",
                            "4",
                            " has",
                            " learned",
                            " that",
                            " an",
                            " internal",
                            " investigation",
                            " is",
                            " underway",
                            " into",
                            " the",
                            " interim",
                            " head",
                            " of",
                            " the",
                            " Denver",
                            " Sheriff",
                            " Department",
                            ",",
                            " Elias",
                            " D",
                            "iggins",
                            ",",
                            " and",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "7187",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.31,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.31,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:55.902Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 47.311,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc0vo6ttci666vms475qg",
                        "tokens": [
                            " down",
                            " of",
                            " email",
                            " servers",
                            " and",
                            " other",
                            " platforms",
                            " is",
                            " the",
                            " exact",
                            " reason",
                            " the",
                            " gir",
                            "affe",
                            " cam",
                            " will",
                            " need",
                            " be",
                            " pulled",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " zoo",
                            " said",
                            " it",
                            " appreci",
                            "ates",
                            " the",
                            " concerns",
                            " of",
                            " viewers",
                            ",",
                            " but",
                            " it",
                            " has",
                            " affected",
                            " operations",
                            ".",
                            "\n",
                            "\n",
                            "Photos",
                            ":",
                            " Baby",
                            " gir",
                            "aff",
                            "es",
                            " around",
                            " the",
                            " world",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " is",
                            " interfering",
                            " with",
                            " normal",
                            " park",
                            " operations",
                            " and",
                            " preparation",
                            " for",
                            " opening",
                            ";",
                            " at",
                            " a",
                            " period",
                            " when",
                            " our",
                            " resource",
                            " of",
                            " time",
                            " is",
                            " limited",
                            " and",
                            " cannot",
                            " be",
                            " hindered",
                            ",\"",
                            " the",
                            " Animal",
                            " Adventure",
                            " Park",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " of",
                            " Monday",
                            " evening",
                            ",",
                            " the",
                            " stream",
                            " was",
                            " still",
                            " active",
                            ".",
                            "<|endoftext|>",
                            "\u2013",
                            " CBS",
                            "4",
                            " has",
                            " learned",
                            " that",
                            " an",
                            " internal",
                            " investigation",
                            " is",
                            " underway",
                            " into",
                            " the",
                            " interim",
                            " head",
                            " of",
                            " the",
                            " Denver",
                            " Sheriff",
                            " Department",
                            ",",
                            " Elias",
                            " D",
                            "iggins",
                            ",",
                            " and",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "7187",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.31,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.31,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:55.902Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 37.848,
                        "binMax": 47.311,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc0vl6tspi666wwt782jk",
                        "tokens": [
                            "a",
                            " in",
                            " retribution",
                            " for",
                            " being",
                            " shot",
                            " in",
                            " the",
                            " head",
                            " by",
                            " persons",
                            " associated",
                            " with",
                            " D",
                            "ags",
                            "a",
                            " during",
                            " a",
                            " shootout",
                            " months",
                            " earlier",
                            ",[",
                            "4",
                            "]",
                            " while",
                            " police",
                            " attributed",
                            " a",
                            " motive",
                            " to",
                            " D",
                            "ags",
                            "a",
                            "'s",
                            " peace",
                            "keeping",
                            " efforts",
                            " in",
                            " the",
                            " bar",
                            "ang",
                            "ay",
                            ".[",
                            "5",
                            "]",
                            "\n",
                            "\n",
                            "References",
                            " [",
                            " edit",
                            " ]",
                            "<|endoftext|>",
                            "Mill",
                            "ions",
                            " of",
                            " people",
                            " walk",
                            " into",
                            " Toronto",
                            " public",
                            " libraries",
                            " each",
                            " year",
                            ".",
                            " The",
                            " majority",
                            " have",
                            " a",
                            " safe",
                            ",",
                            " educational",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " recent",
                            " disturbing",
                            ",",
                            " and",
                            " at",
                            " times",
                            ",",
                            " violent",
                            " incidents",
                            " at",
                            " multiple",
                            " libraries",
                            " in",
                            " the",
                            " city",
                            " has",
                            " the",
                            " union",
                            " sounding",
                            " the",
                            " alarm",
                            " for",
                            " increased",
                            " security",
                            ".",
                            "\n",
                            "\n",
                            "However",
                            ",",
                            " City",
                            "News",
                            " has",
                            " learned",
                            " a",
                            " staff",
                            "-",
                            "less",
                            " public",
                            " library",
                            " pilot",
                            " project",
                            " is",
                            " coming",
                            " to",
                            " Toronto",
                            " and",
                            " that",
                            " has",
                            " raised",
                            " even",
                            " more"
                        ],
                        "dataIndex": null,
                        "index": "7187",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.582,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:55.902Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 47.311,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5528402061963215,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "1278",
            "description": "phrases related to learning or teaching new skills",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5493515893623709,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "1278",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:08:06.054Z",
                "maxActApprox": 27.852,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1278,
                    1446,
                    1238,
                    5719,
                    4460,
                    1280,
                    5581,
                    2474,
                    1719,
                    6075,
                    3673,
                    2601,
                    5922,
                    1517,
                    5900,
                    4078,
                    5760,
                    2740,
                    5738,
                    2953,
                    3902,
                    4613,
                    1314,
                    2898,
                    5723
                ],
                "topkCosSimValues": [
                    1,
                    0.4381,
                    0.3824,
                    0.3453,
                    0.2857,
                    0.2845,
                    0.2711,
                    0.2711,
                    0.2661,
                    0.2514,
                    0.2437,
                    0.2346,
                    0.23,
                    0.2232,
                    0.2171,
                    0.2152,
                    0.2145,
                    0.2107,
                    0.207,
                    0.206,
                    0.2054,
                    0.1977,
                    0.1958,
                    0.1941,
                    0.1928
                ],
                "neuron_alignment_indices": [
                    80,
                    255,
                    331
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.096,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    97,
                    641,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.056,
                    0.054,
                    0.049
                ],
                "correlated_neurons_l1": [
                    0.043,
                    0.064,
                    0.035
                ],
                "correlated_features_indices": [
                    1238,
                    1227,
                    1208
                ],
                "correlated_features_pearson": [
                    0.214,
                    0.022,
                    0.018
                ],
                "correlated_features_l1": [
                    0.216,
                    0.026,
                    0.02
                ],
                "neg_str": [
                    "ocument",
                    "isSpecialOrderable",
                    "holder",
                    "vertisement",
                    "ported",
                    "iture",
                    "atform",
                    "iversary",
                    " claimant",
                    "announced"
                ],
                "neg_values": [
                    -0.822,
                    -0.75,
                    -0.678,
                    -0.678,
                    -0.676,
                    -0.668,
                    -0.668,
                    -0.663,
                    -0.661,
                    -0.653
                ],
                "pos_str": [
                    " basics",
                    " ropes",
                    " lesson",
                    " skills",
                    " fundamentals",
                    " tricks",
                    " techniques",
                    " maths",
                    " nuances",
                    " rudimentary"
                ],
                "pos_values": [
                    1.159,
                    1.137,
                    1.076,
                    1.058,
                    1.025,
                    0.996,
                    0.991,
                    0.97,
                    0.959,
                    0.956
                ],
                "frac_nonzero": 0.009559999999999999,
                "freq_hist_data_bar_heights": [
                    7974,
                    5513,
                    3762,
                    2698,
                    1952,
                    1524,
                    1100,
                    949,
                    755,
                    597,
                    466,
                    384,
                    334,
                    294,
                    231,
                    192,
                    151,
                    152,
                    116,
                    113,
                    94,
                    87,
                    80,
                    75,
                    54,
                    48,
                    50,
                    36,
                    28,
                    34,
                    30,
                    25,
                    28,
                    27,
                    14,
                    21,
                    5,
                    8,
                    10,
                    14,
                    8,
                    3,
                    7,
                    4,
                    4,
                    6,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.279,
                    0.836,
                    1.393,
                    1.95,
                    2.507,
                    3.064,
                    3.621,
                    4.178,
                    4.735,
                    5.292,
                    5.849,
                    6.406,
                    6.963,
                    7.52,
                    8.077,
                    8.634,
                    9.191,
                    9.748,
                    10.305,
                    10.862,
                    11.419,
                    11.976,
                    12.533,
                    13.09,
                    13.647,
                    14.204,
                    14.761,
                    15.318,
                    15.875,
                    16.432,
                    16.989,
                    17.546,
                    18.103,
                    18.66,
                    19.218,
                    19.775,
                    20.332,
                    20.889,
                    21.446,
                    22.003,
                    22.56,
                    23.117,
                    23.674,
                    24.231,
                    24.788,
                    25.345,
                    25.902,
                    26.459,
                    27.016,
                    27.573
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    5,
                    13,
                    9,
                    32,
                    64,
                    103,
                    177,
                    315,
                    535,
                    834,
                    1320,
                    1772,
                    2439,
                    3009,
                    3741,
                    3969,
                    4254,
                    4386,
                    4339,
                    3865,
                    3451,
                    2903,
                    2231,
                    1854,
                    1359,
                    961,
                    703,
                    467,
                    346,
                    232,
                    160,
                    120,
                    80,
                    56,
                    49,
                    32,
                    18,
                    22,
                    5,
                    6,
                    7,
                    4,
                    3,
                    1,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.802,
                    -0.763,
                    -0.723,
                    -0.684,
                    -0.644,
                    -0.604,
                    -0.565,
                    -0.525,
                    -0.485,
                    -0.446,
                    -0.406,
                    -0.367,
                    -0.327,
                    -0.287,
                    -0.248,
                    -0.208,
                    -0.168,
                    -0.129,
                    -0.089,
                    -0.05,
                    -0.01,
                    0.03,
                    0.069,
                    0.109,
                    0.148,
                    0.188,
                    0.228,
                    0.267,
                    0.307,
                    0.347,
                    0.386,
                    0.426,
                    0.465,
                    0.505,
                    0.545,
                    0.584,
                    0.624,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.822,
                    0.862,
                    0.901,
                    0.941,
                    0.98,
                    1.02,
                    1.06,
                    1.099,
                    1.139
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning or teaching new skills",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdt9wvvtrqci66674hkr8mc",
                        "tokens": [
                            "When",
                            " we",
                            " enter",
                            " the",
                            " political",
                            " debate",
                            " sphere",
                            " of",
                            " the",
                            " online",
                            " world",
                            ",",
                            " I",
                            " think",
                            " we",
                            " consider",
                            " people",
                            " holding",
                            " these",
                            " beliefs",
                            " to",
                            " be",
                            " unreal",
                            ".",
                            " The",
                            " information",
                            " age",
                            " means",
                            " almost",
                            " anybody",
                            " can",
                            " become",
                            " informed",
                            " about",
                            " any",
                            " topic",
                            ",",
                            " right",
                            "?",
                            " Someone",
                            " who",
                            " believes",
                            " in",
                            " these",
                            " conspir",
                            "acies",
                            " has",
                            " got",
                            " to",
                            " be",
                            " a",
                            " troll",
                            " or",
                            " using",
                            " their",
                            " anonymity",
                            " to",
                            " esp",
                            "ouse",
                            " harmful",
                            " beliefs",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " never",
                            " talk",
                            " about",
                            " in",
                            "-",
                            "person",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " ed",
                            "gy",
                            " teenager",
                            ",",
                            " a",
                            " kid",
                            " who",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " learned",
                            " to",
                            " navigate",
                            " the",
                            " harmful",
                            " tra",
                            "ppings",
                            " of",
                            " the",
                            " internet",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " old",
                            " cod",
                            "ger",
                            ",",
                            " still",
                            " holding",
                            " onto",
                            " the",
                            " good",
                            " old",
                            " days",
                            " where",
                            " they",
                            " had",
                            " all",
                            " the",
                            " privilege",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.852,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.985,
                            6.58,
                            0.302,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.191,
                            0.036,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.25,
                            27.852,
                            12.248,
                            6.684,
                            0,
                            0,
                            1.034,
                            1.505,
                            1.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.361,
                            0,
                            1.375,
                            0,
                            0,
                            0,
                            0,
                            2.266,
                            2.624,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdt9wvvtrqdi666wiv2q6fs",
                        "tokens": [
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Apple",
                            " said",
                            " of",
                            " how",
                            " he",
                            " has",
                            " handled",
                            " the",
                            " poor",
                            " performance",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " want",
                            " to",
                            " lean",
                            " on",
                            " your",
                            " teammates",
                            " because",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " to",
                            " give",
                            " you",
                            " the",
                            " real",
                            " talk",
                            " that",
                            " you",
                            " need",
                            ".",
                            " So",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " been",
                            " doing",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Pick",
                            " my",
                            " head",
                            " up",
                            " a",
                            " little",
                            " bit",
                            " and",
                            " play",
                            " with",
                            " the",
                            " confidence",
                            " I",
                            " played",
                            " with",
                            " in",
                            " college",
                            ".",
                            " Be",
                            " more",
                            " comfortable",
                            ".",
                            " That",
                            " is",
                            " the",
                            " main",
                            " thing",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Apple",
                            " insists",
                            " the",
                            " comfort",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " there",
                            " because",
                            " his",
                            " rookie",
                            " season",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " gone",
                            " smoothly",
                            " because",
                            " of",
                            " injuries",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " learning",
                            " to",
                            " play",
                            " in",
                            " the",
                            " NFL",
                            " in",
                            " st",
                            "acc",
                            "ato",
                            " style",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.985,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.232,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.478,
                            25.985,
                            8.548,
                            5.713,
                            2.621,
                            0,
                            5.678,
                            0,
                            0,
                            0,
                            0.782,
                            0.664
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdt9wvvtrqei666lzn9lzle",
                        "tokens": [
                            "Bob",
                            " Hunt",
                            "ley",
                            " wrest",
                            "led",
                            " with",
                            " the",
                            " limitations",
                            " of",
                            " the",
                            " written",
                            " recipe",
                            " before",
                            " founding",
                            " his",
                            " Houston",
                            "-",
                            "based",
                            " software",
                            " company",
                            " called",
                            " C",
                            "ulin",
                            "App",
                            ".",
                            " In",
                            " the",
                            " 1990",
                            "s",
                            ",",
                            " Mr",
                            ".",
                            " Hunt",
                            "ley",
                            " had",
                            " little",
                            " time",
                            " for",
                            " cooking",
                            ";",
                            " he",
                            " was",
                            " busy",
                            " building",
                            " the",
                            " network",
                            " for",
                            " Doom",
                            ",",
                            " the",
                            " first",
                            " international",
                            " online",
                            " gaming",
                            " network",
                            ".",
                            " But",
                            " after",
                            " he",
                            " sold",
                            " that",
                            " business",
                            " and",
                            " retired",
                            " to",
                            " a",
                            " ranch",
                            " outside",
                            " the",
                            " small",
                            " town",
                            " of",
                            " Mason",
                            ",",
                            " Tex",
                            ".,",
                            " with",
                            " his",
                            " pet",
                            " l",
                            "ongh",
                            "orns",
                            " and",
                            " a",
                            " T",
                            "1",
                            " data",
                            " line",
                            " that",
                            " Verizon",
                            " built",
                            " just",
                            " for",
                            " him",
                            ",",
                            " he",
                            " tried",
                            " teaching",
                            " himself",
                            " to",
                            " cook",
                            " from",
                            " cook",
                            "books",
                            " and",
                            " online",
                            " recipes",
                            ".",
                            " It",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " struggled",
                            " with",
                            " getting",
                            " the",
                            " whole",
                            " recipe",
                            " downloaded"
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.638,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.051,
                            2.704,
                            25.638,
                            22.113,
                            5.512,
                            1.116,
                            0,
                            2.79,
                            1.019,
                            0,
                            0.512,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.138,
                            0,
                            0,
                            0,
                            0.949,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "92910",
            "description": "verbs and actions related to learning, familiarization, and surrounding oneself with new experiences or knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.544103741645813,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "92910",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:23:32.378Z",
                "maxActApprox": 20.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    92910,
                    73770,
                    40088,
                    63993,
                    8313,
                    61226,
                    2719,
                    71497,
                    67636,
                    4045,
                    68269,
                    84187,
                    41634,
                    49721,
                    57293,
                    65153,
                    69929,
                    47637,
                    14622,
                    38082,
                    7269,
                    78863,
                    84761,
                    79142,
                    16346
                ],
                "topkCosSimValues": [
                    1,
                    0.5337,
                    0.473,
                    0.4666,
                    0.4641,
                    0.4559,
                    0.449,
                    0.4472,
                    0.4414,
                    0.4386,
                    0.428,
                    0.4106,
                    0.405,
                    0.4023,
                    0.4021,
                    0.3962,
                    0.3962,
                    0.3955,
                    0.3949,
                    0.393,
                    0.39,
                    0.3884,
                    0.386,
                    0.3858,
                    0.3823
                ],
                "neuron_alignment_indices": [
                    59,
                    184,
                    456
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.103,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    59,
                    184,
                    761
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.021,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.016,
                    0.019
                ],
                "correlated_features_indices": [
                    92956,
                    92927,
                    92930
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    " opp",
                    "rogens",
                    "estate",
                    " STAND",
                    " intervening",
                    " disadvant",
                    " rapp",
                    " patented",
                    " prevailing",
                    " whereas"
                ],
                "neg_values": [
                    -0.564,
                    -0.556,
                    -0.544,
                    -0.524,
                    -0.52,
                    -0.516,
                    -0.516,
                    -0.511,
                    -0.506,
                    -0.505
                ],
                "pos_str": [
                    " yourselves",
                    " yourself",
                    " ourselves",
                    " us",
                    " him",
                    " oneself",
                    "him",
                    "ingly",
                    " themselves",
                    "phas"
                ],
                "pos_values": [
                    0.952,
                    0.937,
                    0.937,
                    0.935,
                    0.922,
                    0.902,
                    0.875,
                    0.855,
                    0.812,
                    0.793
                ],
                "frac_nonzero": 0.00053,
                "freq_hist_data_bar_heights": [
                    413,
                    292,
                    218,
                    176,
                    135,
                    93,
                    70,
                    39,
                    43,
                    37,
                    21,
                    26,
                    25,
                    9,
                    9,
                    9,
                    11,
                    5,
                    7,
                    7,
                    2,
                    2,
                    1,
                    1,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.21,
                    0.629,
                    1.048,
                    1.467,
                    1.885,
                    2.304,
                    2.723,
                    3.142,
                    3.561,
                    3.98,
                    4.398,
                    4.817,
                    5.236,
                    5.655,
                    6.074,
                    6.493,
                    6.912,
                    7.33,
                    7.749,
                    8.168,
                    8.587,
                    9.006,
                    9.425,
                    9.843,
                    10.262,
                    10.681,
                    11.1,
                    11.519,
                    11.938,
                    12.357,
                    12.775,
                    13.194,
                    13.613,
                    14.032,
                    14.451,
                    14.87,
                    15.288,
                    15.707,
                    16.126,
                    16.545,
                    16.964,
                    17.383,
                    17.802,
                    18.22,
                    18.639,
                    19.058,
                    19.477,
                    19.896,
                    20.315,
                    20.733
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    7,
                    23,
                    38,
                    78,
                    109,
                    236,
                    362,
                    614,
                    801,
                    1186,
                    1596,
                    2174,
                    2597,
                    3069,
                    3425,
                    3709,
                    3842,
                    3734,
                    3622,
                    3272,
                    2957,
                    2632,
                    2212,
                    1883,
                    1591,
                    1229,
                    909,
                    722,
                    511,
                    314,
                    235,
                    192,
                    132,
                    72,
                    47,
                    46,
                    24,
                    13,
                    9,
                    7,
                    4,
                    4,
                    4,
                    2,
                    1,
                    1,
                    1,
                    1,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.549,
                    -0.519,
                    -0.489,
                    -0.458,
                    -0.428,
                    -0.398,
                    -0.367,
                    -0.337,
                    -0.307,
                    -0.276,
                    -0.246,
                    -0.216,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.094,
                    -0.064,
                    -0.034,
                    -0.003,
                    0.027,
                    0.057,
                    0.088,
                    0.118,
                    0.148,
                    0.179,
                    0.209,
                    0.239,
                    0.27,
                    0.3,
                    0.33,
                    0.361,
                    0.391,
                    0.421,
                    0.452,
                    0.482,
                    0.512,
                    0.542,
                    0.573,
                    0.603,
                    0.633,
                    0.664,
                    0.694,
                    0.724,
                    0.755,
                    0.785,
                    0.815,
                    0.846,
                    0.876,
                    0.906,
                    0.937
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to familiarity and recognition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "verbs and actions related to learning, familiarization, and surrounding oneself with new experiences or knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj011x9pkc10exn2to1s7y",
                        "tokens": [
                            " Collection",
                            " -",
                            " free",
                            " -",
                            " through",
                            " Kan",
                            "opy",
                            ",",
                            " which",
                            " is",
                            " in",
                            " many",
                            " schools",
                            " too",
                            ".",
                            " https",
                            "://",
                            "t",
                            ".",
                            "co",
                            "/",
                            "k",
                            "EH",
                            "x",
                            "PL",
                            "f",
                            "rd",
                            "j",
                            " \u2014",
                            " Man",
                            "oh",
                            "la",
                            " D",
                            "arg",
                            "is",
                            " (@",
                            "Man",
                            "oh",
                            "la",
                            "D",
                            "arg",
                            "is",
                            ")",
                            " July",
                            " 13",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "Pull",
                            " up",
                            " a",
                            " chair",
                            " and",
                            " stream",
                            " French",
                            " New",
                            " Wave",
                            " gems",
                            " like",
                            " Breath",
                            "less",
                            ",",
                            " The",
                            " 400",
                            " Bl",
                            "ows",
                            ",",
                            " J",
                            "ules",
                            " and",
                            " Jim",
                            ",",
                            " and",
                            " Viv",
                            "re",
                            " Sa",
                            " Vie",
                            ",",
                            " none",
                            " of",
                            " which",
                            " are",
                            " available",
                            " for",
                            " streaming",
                            " on",
                            " Netflix",
                            ".",
                            " Or",
                            " delve",
                            " into",
                            " the",
                            " classics",
                            " of",
                            " American",
                            " independent",
                            " film",
                            ",",
                            " and",
                            " acquaint",
                            " yourself",
                            " with",
                            " the",
                            " work",
                            " of",
                            " Jim",
                            " J",
                            "arm",
                            "us",
                            "ch",
                            " and",
                            " John",
                            " Cass",
                            "ave",
                            "tes",
                            " (",
                            "also",
                            " not",
                            " available",
                            " for",
                            " streaming",
                            " on",
                            " Netflix",
                            ").",
                            " The",
                            " possibilities"
                        ],
                        "dataIndex": null,
                        "index": "92910",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.943,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.943,
                            0.39,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:23:38.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 20.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj01209pkw10ex1uq2cxol",
                        "tokens": [
                            " Collection",
                            " -",
                            " free",
                            " -",
                            " through",
                            " Kan",
                            "opy",
                            ",",
                            " which",
                            " is",
                            " in",
                            " many",
                            " schools",
                            " too",
                            ".",
                            " https",
                            "://",
                            "t",
                            ".",
                            "co",
                            "/",
                            "k",
                            "EH",
                            "x",
                            "PL",
                            "f",
                            "rd",
                            "j",
                            " \u2014",
                            " Man",
                            "oh",
                            "la",
                            " D",
                            "arg",
                            "is",
                            " (@",
                            "Man",
                            "oh",
                            "la",
                            "D",
                            "arg",
                            "is",
                            ")",
                            " July",
                            " 13",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "Pull",
                            " up",
                            " a",
                            " chair",
                            " and",
                            " stream",
                            " French",
                            " New",
                            " Wave",
                            " gems",
                            " like",
                            " Breath",
                            "less",
                            ",",
                            " The",
                            " 400",
                            " Bl",
                            "ows",
                            ",",
                            " J",
                            "ules",
                            " and",
                            " Jim",
                            ",",
                            " and",
                            " Viv",
                            "re",
                            " Sa",
                            " Vie",
                            ",",
                            " none",
                            " of",
                            " which",
                            " are",
                            " available",
                            " for",
                            " streaming",
                            " on",
                            " Netflix",
                            ".",
                            " Or",
                            " delve",
                            " into",
                            " the",
                            " classics",
                            " of",
                            " American",
                            " independent",
                            " film",
                            ",",
                            " and",
                            " acquaint",
                            " yourself",
                            " with",
                            " the",
                            " work",
                            " of",
                            " Jim",
                            " J",
                            "arm",
                            "us",
                            "ch",
                            " and",
                            " John",
                            " Cass",
                            "ave",
                            "tes",
                            " (",
                            "also",
                            " not",
                            " available",
                            " for",
                            " streaming",
                            " on",
                            " Netflix",
                            ").",
                            " The",
                            " possibilities"
                        ],
                        "dataIndex": null,
                        "index": "92910",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.943,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.943,
                            0.39,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:23:38.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 16.754,
                        "binMax": 20.943,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj011x9pkd10exnzpxj00m",
                        "tokens": [
                            " outcomes",
                            " rely",
                            " on",
                            " \"",
                            "screen",
                            " time",
                            "\"",
                            " also",
                            " being",
                            " \"",
                            "together",
                            " time",
                            ".\"",
                            "\n",
                            "\n",
                            "Much",
                            " of",
                            " screen",
                            " time",
                            "'s",
                            " potential",
                            " for",
                            " good",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " hinges",
                            " on",
                            " the",
                            " parents",
                            ",",
                            " whether",
                            " the",
                            " child",
                            " is",
                            " 3",
                            " or",
                            " 13",
                            ".",
                            " The",
                            " AAP",
                            " recommends",
                            " parents",
                            " join",
                            " their",
                            " kids",
                            " in",
                            " the",
                            " digital",
                            " world",
                            " when",
                            " possible",
                            ",",
                            " and",
                            " familiar",
                            "ize",
                            " themselves",
                            " with",
                            " their",
                            " kids",
                            "'",
                            " media",
                            " of",
                            " choice",
                            " even",
                            " if",
                            " they",
                            " don",
                            "'t",
                            " share",
                            " the",
                            " activity",
                            ".",
                            "\n",
                            "\n",
                            "Parents",
                            " should",
                            " also",
                            " lay",
                            " ground",
                            " rules",
                            " for",
                            " when",
                            ",",
                            " where",
                            " and",
                            " how",
                            " long",
                            " kids",
                            " can",
                            " engage",
                            " in",
                            " screen",
                            " time",
                            ",",
                            " establish",
                            " \"",
                            "screen",
                            "-",
                            "free",
                            " zones",
                            "\"",
                            " (",
                            "h",
                            "int",
                            ":",
                            " dinner",
                            " table",
                            ")",
                            " and",
                            ",",
                            " of",
                            " course",
                            ",",
                            " monitor",
                            " all",
                            " content",
                            ".",
                            " The",
                            " potential",
                            " benefits",
                            " of",
                            " screen",
                            " time",
                            " don",
                            "'t"
                        ],
                        "dataIndex": null,
                        "index": "92910",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.277,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.277,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:23:38.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 20.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "43239",
            "description": " phrases related to learning and discovery",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5406758785247803,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "43239",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:26:49.080Z",
                "maxActApprox": 28.086,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43239,
                    49906,
                    78255,
                    9332,
                    40642,
                    15406,
                    49437,
                    51672,
                    21510,
                    96054,
                    27376,
                    11780,
                    14700,
                    21719,
                    76035,
                    27464,
                    95621,
                    45539,
                    80299,
                    52023,
                    21334,
                    16705,
                    50503,
                    41857,
                    14876
                ],
                "topkCosSimValues": [
                    1,
                    0.605,
                    0.4965,
                    0.4765,
                    0.4597,
                    0.4322,
                    0.4179,
                    0.4074,
                    0.4028,
                    0.3998,
                    0.3954,
                    0.3941,
                    0.3921,
                    0.3859,
                    0.381,
                    0.38,
                    0.3763,
                    0.3756,
                    0.3745,
                    0.374,
                    0.3728,
                    0.371,
                    0.3677,
                    0.3658,
                    0.3655
                ],
                "neuron_alignment_indices": [
                    510,
                    722,
                    483
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.095,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    70,
                    510,
                    417
                ],
                "correlated_neurons_pearson": [
                    0.016,
                    0.015,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.015,
                    0.014
                ],
                "correlated_features_indices": [
                    43163,
                    43198,
                    43151
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.008,
                    0.001,
                    0
                ],
                "neg_str": [
                    "onding",
                    "uay",
                    " watershed",
                    "alach",
                    "\u012a\u0134",
                    "taboola",
                    " ****",
                    "idation",
                    " backbone",
                    " bu"
                ],
                "neg_values": [
                    -0.764,
                    -0.722,
                    -0.625,
                    -0.622,
                    -0.621,
                    -0.603,
                    -0.601,
                    -0.587,
                    -0.58,
                    -0.57
                ],
                "pos_str": [
                    "enance",
                    "stadt",
                    "biz",
                    "ername",
                    "clude",
                    "adays",
                    "that",
                    " oneself",
                    "dylib",
                    " that"
                ],
                "pos_values": [
                    1.06,
                    0.674,
                    0.662,
                    0.642,
                    0.64,
                    0.638,
                    0.631,
                    0.626,
                    0.622,
                    0.621
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    132,
                    118,
                    75,
                    49,
                    46,
                    36,
                    34,
                    22,
                    19,
                    13,
                    19,
                    12,
                    12,
                    6,
                    4,
                    7,
                    4,
                    7,
                    6,
                    2,
                    5,
                    2,
                    1,
                    0,
                    2,
                    0,
                    1,
                    3,
                    1,
                    3,
                    2,
                    3,
                    1,
                    1,
                    4,
                    4,
                    2,
                    1,
                    3,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.282,
                    0.844,
                    1.405,
                    1.967,
                    2.529,
                    3.09,
                    3.652,
                    4.214,
                    4.775,
                    5.337,
                    5.899,
                    6.461,
                    7.022,
                    7.584,
                    8.146,
                    8.707,
                    9.269,
                    9.831,
                    10.392,
                    10.954,
                    11.516,
                    12.078,
                    12.639,
                    13.201,
                    13.763,
                    14.324,
                    14.886,
                    15.448,
                    16.009,
                    16.571,
                    17.133,
                    17.695,
                    18.256,
                    18.818,
                    19.38,
                    19.941,
                    20.503,
                    21.065,
                    21.626,
                    22.188,
                    22.75,
                    23.312,
                    23.873,
                    24.435,
                    24.997,
                    25.558,
                    26.12,
                    26.682,
                    27.243,
                    27.805
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    3,
                    3,
                    6,
                    24,
                    33,
                    88,
                    132,
                    275,
                    434,
                    631,
                    1031,
                    1510,
                    2091,
                    2836,
                    3380,
                    3951,
                    4443,
                    4622,
                    4566,
                    4352,
                    3925,
                    3274,
                    2628,
                    1974,
                    1410,
                    1055,
                    605,
                    390,
                    230,
                    142,
                    98,
                    45,
                    31,
                    17,
                    12,
                    5,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.746,
                    -0.71,
                    -0.673,
                    -0.637,
                    -0.6,
                    -0.564,
                    -0.527,
                    -0.491,
                    -0.454,
                    -0.418,
                    -0.381,
                    -0.345,
                    -0.308,
                    -0.272,
                    -0.235,
                    -0.199,
                    -0.162,
                    -0.126,
                    -0.089,
                    -0.053,
                    -0.016,
                    0.02,
                    0.057,
                    0.093,
                    0.13,
                    0.166,
                    0.203,
                    0.239,
                    0.276,
                    0.312,
                    0.349,
                    0.385,
                    0.422,
                    0.458,
                    0.495,
                    0.531,
                    0.568,
                    0.604,
                    0.641,
                    0.677,
                    0.714,
                    0.75,
                    0.787,
                    0.823,
                    0.86,
                    0.896,
                    0.933,
                    0.969,
                    1.006,
                    1.042
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases related to learning and discovery of information",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " expressions related to discovery and learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and discovery",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggz1qs81xu10ex5rddcvoo",
                        "tokens": [
                            ".",
                            " Cream",
                            " or",
                            " jam",
                            " is",
                            " fine",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " So",
                            " says",
                            " 34",
                            "-",
                            "year",
                            "-",
                            "old",
                            " T",
                            "ing",
                            "ting",
                            " He",
                            ",",
                            " in",
                            " answer",
                            " to",
                            " the",
                            " question",
                            " of",
                            " which",
                            " to",
                            " spread",
                            " on",
                            " the",
                            " sc",
                            "one",
                            " first",
                            " in",
                            " a",
                            " British",
                            " cream",
                            " tea",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " relief",
                            " to",
                            " learn",
                            " that",
                            " I",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " doing",
                            " the",
                            " wrong",
                            " thing",
                            " all",
                            " my",
                            " life",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " in",
                            " the",
                            " Essex",
                            " tea",
                            " room",
                            " of",
                            " an",
                            " up",
                            "market",
                            " British",
                            " jam",
                            " maker",
                            " and",
                            " on",
                            " the",
                            " table",
                            " before",
                            " us",
                            " is",
                            " a",
                            " plate",
                            " of",
                            " fluffy",
                            " sc",
                            "ones",
                            ",",
                            " a",
                            " bowl",
                            " of",
                            " cl",
                            "otted",
                            " cream",
                            " and",
                            " miniature",
                            " jars",
                            " of",
                            " strawberry",
                            " jam",
                            ".",
                            " T",
                            "ing",
                            "ting",
                            " may",
                            " be",
                            " Shan",
                            "gh",
                            "ain",
                            "ese",
                            " but",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " giving",
                            " me",
                            " a",
                            " lesson",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.086,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.086,
                            3.429,
                            0.91,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.086,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggz1qs81xv10exl65nn2jv",
                        "tokens": [
                            " you",
                            " wouldn",
                            "'t",
                            " have",
                            " really",
                            " been",
                            " able",
                            " to",
                            " guess",
                            " which",
                            " team",
                            " won",
                            " or",
                            " lost",
                            ";",
                            " both",
                            " guys",
                            " on",
                            " the",
                            " winning",
                            " team",
                            " sounded",
                            " like",
                            " they",
                            " really",
                            " felt",
                            " sorry",
                            " for",
                            " their",
                            " brothers",
                            ".",
                            "\n",
                            "\n",
                            "Philadelphia",
                            " Flyers",
                            ":",
                            " I",
                            "'m",
                            " surprised",
                            " to",
                            " learn",
                            " that",
                            " Michael",
                            " Del",
                            " Z",
                            "otto",
                            "'s",
                            " career",
                            "-",
                            "best",
                            " point",
                            " streak",
                            " isn",
                            "'t",
                            " \u00e2\u0122",
                            "\u013e",
                            "two",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Pitt",
                            "sburgh",
                            " Penguins",
                            ":",
                            " If",
                            " the",
                            " Penguins",
                            " trade",
                            " for",
                            " Jar",
                            "om",
                            "ir",
                            " Jag",
                            "r",
                            ",",
                            " Pittsburgh",
                            " dissolve",
                            " into",
                            " two",
                            " war",
                            "ring",
                            " factions",
                            " of",
                            " fans",
                            ".",
                            " I",
                            " hope",
                            " so",
                            " badly",
                            " that",
                            " this",
                            " happens",
                            ".",
                            "\n",
                            "\n",
                            "San",
                            " Jose",
                            " Sharks",
                            ":",
                            " The",
                            " d",
                            "ang",
                            " Sharks",
                            " are",
                            " looking",
                            " pretty",
                            " good",
                            " these",
                            " days",
                            ".",
                            " Ant",
                            "ti",
                            " Ni",
                            "emi",
                            " with",
                            " a",
                            " 31",
                            "-",
                            "save",
                            " shut",
                            "out",
                            ",",
                            " the",
                            " 31",
                            "st"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.825,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.825,
                            1.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.086,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggz1qv81yi10exr4t834ny",
                        "tokens": [
                            " you",
                            " wouldn",
                            "'t",
                            " have",
                            " really",
                            " been",
                            " able",
                            " to",
                            " guess",
                            " which",
                            " team",
                            " won",
                            " or",
                            " lost",
                            ";",
                            " both",
                            " guys",
                            " on",
                            " the",
                            " winning",
                            " team",
                            " sounded",
                            " like",
                            " they",
                            " really",
                            " felt",
                            " sorry",
                            " for",
                            " their",
                            " brothers",
                            ".",
                            "\n",
                            "\n",
                            "Philadelphia",
                            " Flyers",
                            ":",
                            " I",
                            "'m",
                            " surprised",
                            " to",
                            " learn",
                            " that",
                            " Michael",
                            " Del",
                            " Z",
                            "otto",
                            "'s",
                            " career",
                            "-",
                            "best",
                            " point",
                            " streak",
                            " isn",
                            "'t",
                            " \u00e2\u0122",
                            "\u013e",
                            "two",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Pitt",
                            "sburgh",
                            " Penguins",
                            ":",
                            " If",
                            " the",
                            " Penguins",
                            " trade",
                            " for",
                            " Jar",
                            "om",
                            "ir",
                            " Jag",
                            "r",
                            ",",
                            " Pittsburgh",
                            " dissolve",
                            " into",
                            " two",
                            " war",
                            "ring",
                            " factions",
                            " of",
                            " fans",
                            ".",
                            " I",
                            " hope",
                            " so",
                            " badly",
                            " that",
                            " this",
                            " happens",
                            ".",
                            "\n",
                            "\n",
                            "San",
                            " Jose",
                            " Sharks",
                            ":",
                            " The",
                            " d",
                            "ang",
                            " Sharks",
                            " are",
                            " looking",
                            " pretty",
                            " good",
                            " these",
                            " days",
                            ".",
                            " Ant",
                            "ti",
                            " Ni",
                            "emi",
                            " with",
                            " a",
                            " 31",
                            "-",
                            "save",
                            " shut",
                            "out",
                            ",",
                            " the",
                            " 31",
                            "st"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.825,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.825,
                            1.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 22.469,
                        "binMax": 28.086,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "3597",
            "description": "action words related to learning or discovering something",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5371258899123575,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "3597",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:11:18.777Z",
                "maxActApprox": 44.724,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3597,
                    4460,
                    2764,
                    5215,
                    5900,
                    2162,
                    1446,
                    5855,
                    1517,
                    1183,
                    2554,
                    5899,
                    2733,
                    5719,
                    909,
                    632,
                    3399,
                    4997,
                    2182,
                    5605,
                    5072,
                    846,
                    4639,
                    1834,
                    1526
                ],
                "topkCosSimValues": [
                    1,
                    0.5241,
                    0.49,
                    0.4464,
                    0.4123,
                    0.398,
                    0.3817,
                    0.3308,
                    0.3259,
                    0.3114,
                    0.3102,
                    0.3053,
                    0.305,
                    0.2977,
                    0.2946,
                    0.2894,
                    0.2853,
                    0.2763,
                    0.2742,
                    0.2626,
                    0.2481,
                    0.2446,
                    0.2441,
                    0.2441,
                    0.2441
                ],
                "neuron_alignment_indices": [
                    505,
                    610,
                    133
                ],
                "neuron_alignment_values": [
                    0.095,
                    0.09,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    672,
                    271,
                    97
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.049,
                    0.048
                ],
                "correlated_neurons_l1": [
                    0.04,
                    0.045,
                    0.04
                ],
                "correlated_features_indices": [
                    3611,
                    3665,
                    3654
                ],
                "correlated_features_pearson": [
                    0.014,
                    0.009,
                    0.006
                ],
                "correlated_features_l1": [
                    0.016,
                    0.013,
                    0.013
                ],
                "neg_str": [
                    "ortunately",
                    "Nik",
                    "ovie",
                    "interstitial",
                    " Stra",
                    "ItemTracker",
                    "onding",
                    "iche",
                    "jam",
                    "jan"
                ],
                "neg_values": [
                    -0.661,
                    -0.656,
                    -0.643,
                    -0.631,
                    -0.587,
                    -0.58,
                    -0.573,
                    -0.568,
                    -0.561,
                    -0.558
                ],
                "pos_str": [
                    " how",
                    " why",
                    " WHY",
                    " whether",
                    "ledge",
                    " HOW",
                    "why",
                    " whats",
                    "how",
                    " ABOUT"
                ],
                "pos_values": [
                    1.22,
                    1.139,
                    1.099,
                    1.031,
                    1.021,
                    0.998,
                    0.985,
                    0.951,
                    0.945,
                    0.918
                ],
                "frac_nonzero": 0.00393,
                "freq_hist_data_bar_heights": [
                    3140,
                    2225,
                    1536,
                    1118,
                    851,
                    600,
                    491,
                    412,
                    306,
                    236,
                    202,
                    176,
                    145,
                    115,
                    118,
                    86,
                    81,
                    59,
                    63,
                    53,
                    40,
                    25,
                    23,
                    18,
                    15,
                    15,
                    5,
                    10,
                    6,
                    23,
                    16,
                    11,
                    9,
                    10,
                    7,
                    6,
                    6,
                    6,
                    9,
                    9,
                    7,
                    10,
                    9,
                    12,
                    12,
                    7,
                    6,
                    2,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.448,
                    1.342,
                    2.236,
                    3.131,
                    4.025,
                    4.92,
                    5.814,
                    6.709,
                    7.603,
                    8.498,
                    9.392,
                    10.287,
                    11.181,
                    12.076,
                    12.97,
                    13.865,
                    14.759,
                    15.654,
                    16.548,
                    17.443,
                    18.337,
                    19.231,
                    20.126,
                    21.02,
                    21.915,
                    22.809,
                    23.704,
                    24.598,
                    25.493,
                    26.387,
                    27.282,
                    28.176,
                    29.071,
                    29.965,
                    30.86,
                    31.754,
                    32.649,
                    33.543,
                    34.438,
                    35.332,
                    36.226,
                    37.121,
                    38.015,
                    38.91,
                    39.804,
                    40.699,
                    41.593,
                    42.488,
                    43.382,
                    44.277
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    9,
                    16,
                    29,
                    120,
                    104,
                    192,
                    343,
                    549,
                    1024,
                    1526,
                    2240,
                    2972,
                    3881,
                    4596,
                    5013,
                    5239,
                    4869,
                    4474,
                    3655,
                    2908,
                    2168,
                    1460,
                    989,
                    648,
                    444,
                    298,
                    186,
                    107,
                    70,
                    43,
                    22,
                    16,
                    8,
                    6,
                    2,
                    3,
                    0,
                    6,
                    5,
                    3,
                    2,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.642,
                    -0.604,
                    -0.567,
                    -0.529,
                    -0.491,
                    -0.454,
                    -0.416,
                    -0.379,
                    -0.341,
                    -0.303,
                    -0.266,
                    -0.228,
                    -0.191,
                    -0.153,
                    -0.115,
                    -0.078,
                    -0.04,
                    -0.002,
                    0.035,
                    0.073,
                    0.11,
                    0.148,
                    0.186,
                    0.223,
                    0.261,
                    0.298,
                    0.336,
                    0.374,
                    0.411,
                    0.449,
                    0.486,
                    0.524,
                    0.562,
                    0.599,
                    0.637,
                    0.674,
                    0.712,
                    0.75,
                    0.787,
                    0.825,
                    0.863,
                    0.9,
                    0.938,
                    0.975,
                    1.013,
                    1.051,
                    1.088,
                    1.126,
                    1.163,
                    1.201
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "action words related to learning or discovering something",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtdvxyw053i666agqp069r",
                        "tokens": [
                            " pre",
                            "-",
                            "ordered",
                            " my",
                            " copy",
                            " back",
                            " in",
                            " September",
                            ",",
                            " I",
                            " was",
                            " quite",
                            " keen",
                            " to",
                            " find",
                            " out",
                            " what",
                            " Patterns",
                            " is",
                            " like",
                            " \u2013",
                            " and",
                            " provide",
                            " some",
                            " initial",
                            " feedback",
                            ".",
                            "\n",
                            "\n",
                            "Download",
                            "ing",
                            " and",
                            " Inst",
                            "alling",
                            "\n",
                            "\n",
                            "Pattern",
                            "s",
                            " is",
                            " being",
                            " made",
                            " available",
                            " through",
                            " Steam",
                            ",",
                            " so",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " need",
                            " to",
                            " sign",
                            "-",
                            "up",
                            " there",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " planning",
                            " to",
                            " try",
                            " the",
                            " Genesis",
                            " Release",
                            " for",
                            " yourself",
                            ".",
                            " To",
                            " download",
                            " the",
                            " software",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " need",
                            " an",
                            " activation",
                            " code",
                            ",",
                            " which",
                            " will",
                            " be",
                            " e",
                            "-",
                            "mail",
                            "ed",
                            " to",
                            " you",
                            ".",
                            " Use",
                            " this",
                            " with",
                            " the",
                            " Product",
                            " Activ",
                            "ation",
                            " process",
                            " within",
                            " the",
                            " Steam",
                            " client",
                            " to",
                            " initiate",
                            " download",
                            " and",
                            " installation",
                            " \u2013",
                            " full",
                            " instructions",
                            " accompany",
                            " the",
                            " activation",
                            " key",
                            ".",
                            " Installation",
                            " is",
                            " an",
                            " automated",
                            " process",
                            ",",
                            " leaving",
                            " you"
                        ],
                        "dataIndex": null,
                        "index": "3597",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.724,
                        "maxValueTokenIndex": 15,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.573,
                            44.724,
                            5.812,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:20.161Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.724,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtdvxyw054i666fwdehxnh",
                        "tokens": [
                            " at",
                            " Snapchat",
                            " claim",
                            " that",
                            " sound",
                            " is",
                            " a",
                            " massive",
                            " element",
                            " of",
                            " what",
                            " makes",
                            " Snapchat",
                            " videos",
                            " so",
                            " appealing",
                            ".",
                            "\n",
                            "\n",
                            "Everyone",
                            " who",
                            " has",
                            " worked",
                            " on",
                            " this",
                            " app",
                            " has",
                            " had",
                            " at",
                            " least",
                            " 10",
                            " years",
                            " of",
                            " understanding",
                            " &",
                            " expertise",
                            " in",
                            " hacking",
                            ",",
                            " from",
                            " working",
                            " in",
                            " the",
                            " specialist",
                            " field",
                            " all",
                            " the",
                            " way",
                            " to",
                            " the",
                            " dark",
                            " side",
                            " of",
                            " the",
                            " community",
                            ".",
                            " Hack",
                            "ers",
                            " seem",
                            " to",
                            " have",
                            " posted",
                            " account",
                            " information",
                            " for",
                            " four",
                            ".",
                            "six",
                            " million",
                            " customers",
                            " of",
                            " quick",
                            "ie",
                            " social",
                            "-",
                            "sharing",
                            " app",
                            " Snapchat",
                            ",",
                            " generating",
                            " us",
                            "ern",
                            "ames",
                            " and",
                            " at",
                            " least",
                            " partial",
                            " telephone",
                            " numbers",
                            " accessible",
                            " for",
                            " download",
                            ".",
                            "\n",
                            "\n",
                            "Like",
                            " I",
                            " said",
                            " earlier",
                            ",",
                            " I",
                            " produced",
                            " the",
                            " hack",
                            " for",
                            " myself",
                            " in",
                            " order",
                            " to",
                            " see",
                            " what",
                            " my",
                            " girlfriend",
                            " was",
                            " doing",
                            ".",
                            " Hold",
                            " reading",
                            " to",
                            " find",
                            " out",
                            " 15",
                            " hacks",
                            " to",
                            " assist",
                            " you",
                            " master"
                        ],
                        "dataIndex": null,
                        "index": "3597",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.565,
                        "maxValueTokenIndex": 120,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.96,
                            1.73,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.317,
                            44.565,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:20.161Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.724,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtdvxzw055i666n2w3j0dj",
                        "tokens": [
                            "re",
                            " incredibly",
                            " excited",
                            " at",
                            " how",
                            " the",
                            " partnership",
                            " will",
                            " come",
                            " to",
                            " life",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " \u00e2\u0122",
                            "\u013e",
                            "sw",
                            "ear",
                            "ist",
                            "\u00e2\u0122",
                            "\u013f",
                            " Trailer",
                            " Park",
                            " Boys",
                            " will",
                            " receive",
                            " a",
                            " combination",
                            " of",
                            " cash",
                            " royalties",
                            " and",
                            " other",
                            " non",
                            "-",
                            "mon",
                            "etary",
                            " considerations",
                            ".",
                            " Is",
                            " Canada",
                            " ready",
                            " for",
                            " Trailer",
                            " Park",
                            " Boys",
                            " Marijuana",
                            "?",
                            " Will",
                            " the",
                            " first",
                            " strain",
                            " be",
                            " called",
                            " \u00e2\u0122",
                            "\u013e",
                            "Sw",
                            "ear",
                            "ist",
                            " Sat",
                            "iva",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "Sh",
                            "itism",
                            " Sat",
                            "iva",
                            "\u00e2\u0122",
                            "\u013f",
                            "?",
                            " Will",
                            " we",
                            " ever",
                            " get",
                            " official",
                            " TP",
                            "B",
                            " Hash",
                            " Coins",
                            "?",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " about",
                            " to",
                            " find",
                            " out",
                            ",",
                            " and",
                            " I",
                            " guarantee",
                            " that",
                            " Ricky",
                            ",",
                            " Julian",
                            ",",
                            " Bub",
                            "bles",
                            ",",
                            " and",
                            " J",
                            "-",
                            "R",
                            "oc",
                            " will",
                            " be",
                            " over",
                            " the",
                            " moon",
                            " when",
                            " their",
                            " marijuana",
                            " royalties",
                            " start",
                            " rolling",
                            " in",
                            ".",
                            "<|endoftext|>",
                            "Why",
                            " not",
                            " us",
                            "?"
                        ],
                        "dataIndex": null,
                        "index": "3597",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.114,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.605,
                            43.114,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:20.161Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.724,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "43122",
            "description": " phrases indicating the learning and application of skills or concepts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5349762439727783,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "43122",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:26:34.871Z",
                "maxActApprox": 9.554,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43122,
                    52484,
                    71577,
                    70356,
                    63113,
                    79545,
                    98024,
                    57938,
                    41142,
                    7937,
                    55004,
                    29194,
                    26647,
                    83399,
                    27815,
                    43712,
                    15818,
                    34679,
                    17495,
                    9873,
                    42810,
                    60433,
                    68178,
                    84593,
                    13797
                ],
                "topkCosSimValues": [
                    1,
                    0.3592,
                    0.3534,
                    0.351,
                    0.3384,
                    0.3351,
                    0.3311,
                    0.3275,
                    0.3272,
                    0.325,
                    0.3192,
                    0.3169,
                    0.3116,
                    0.3107,
                    0.3105,
                    0.303,
                    0.3017,
                    0.3001,
                    0.2975,
                    0.2945,
                    0.2932,
                    0.292,
                    0.2914,
                    0.2894,
                    0.2892
                ],
                "neuron_alignment_indices": [
                    283,
                    154,
                    192
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.095,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    283,
                    362,
                    526
                ],
                "correlated_neurons_pearson": [
                    0.038,
                    0.037,
                    0.035
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.043,
                    0.002
                ],
                "correlated_features_indices": [
                    42998,
                    43042,
                    43138
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "ampire",
                    "Virgin",
                    " denotes",
                    "moon",
                    " Warning",
                    "itar",
                    "icter",
                    " commemor",
                    " denote",
                    " Bri"
                ],
                "neg_values": [
                    -0.725,
                    -0.682,
                    -0.663,
                    -0.656,
                    -0.654,
                    -0.637,
                    -0.629,
                    -0.618,
                    -0.606,
                    -0.606
                ],
                "pos_str": [
                    " painstaking",
                    " exped",
                    " homework",
                    " subconscious",
                    " timetable",
                    " timelines",
                    "\u00bb\u0134",
                    " digest",
                    " timely",
                    " runtime"
                ],
                "pos_values": [
                    0.795,
                    0.768,
                    0.761,
                    0.758,
                    0.748,
                    0.734,
                    0.729,
                    0.726,
                    0.711,
                    0.703
                ],
                "frac_nonzero": 0.00234,
                "freq_hist_data_bar_heights": [
                    1059,
                    858,
                    730,
                    710,
                    576,
                    491,
                    433,
                    352,
                    298,
                    266,
                    221,
                    190,
                    181,
                    166,
                    131,
                    114,
                    78,
                    67,
                    53,
                    66,
                    50,
                    35,
                    40,
                    33,
                    27,
                    16,
                    21,
                    16,
                    15,
                    12,
                    13,
                    6,
                    9,
                    6,
                    1,
                    5,
                    6,
                    6,
                    0,
                    1,
                    1,
                    2,
                    1,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.287,
                    0.478,
                    0.669,
                    0.86,
                    1.051,
                    1.242,
                    1.433,
                    1.624,
                    1.815,
                    2.006,
                    2.197,
                    2.389,
                    2.58,
                    2.771,
                    2.962,
                    3.153,
                    3.344,
                    3.535,
                    3.726,
                    3.917,
                    4.108,
                    4.299,
                    4.49,
                    4.681,
                    4.873,
                    5.064,
                    5.255,
                    5.446,
                    5.637,
                    5.828,
                    6.019,
                    6.21,
                    6.401,
                    6.592,
                    6.783,
                    6.974,
                    7.165,
                    7.357,
                    7.548,
                    7.739,
                    7.93,
                    8.121,
                    8.312,
                    8.503,
                    8.694,
                    8.885,
                    9.076,
                    9.267,
                    9.458
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    4,
                    5,
                    10,
                    20,
                    33,
                    57,
                    84,
                    129,
                    195,
                    296,
                    441,
                    626,
                    862,
                    1185,
                    1647,
                    1933,
                    2404,
                    2816,
                    3186,
                    3364,
                    3444,
                    3513,
                    3546,
                    3338,
                    2988,
                    2698,
                    2351,
                    2016,
                    1609,
                    1329,
                    1087,
                    789,
                    615,
                    474,
                    352,
                    260,
                    170,
                    124,
                    85,
                    66,
                    34,
                    27,
                    16,
                    7,
                    11,
                    4,
                    3,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.71,
                    -0.68,
                    -0.649,
                    -0.619,
                    -0.588,
                    -0.558,
                    -0.527,
                    -0.497,
                    -0.467,
                    -0.436,
                    -0.406,
                    -0.375,
                    -0.345,
                    -0.315,
                    -0.284,
                    -0.254,
                    -0.223,
                    -0.193,
                    -0.163,
                    -0.132,
                    -0.102,
                    -0.071,
                    -0.041,
                    -0.01,
                    0.02,
                    0.05,
                    0.081,
                    0.111,
                    0.142,
                    0.172,
                    0.202,
                    0.233,
                    0.263,
                    0.294,
                    0.324,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.476,
                    0.506,
                    0.537,
                    0.567,
                    0.598,
                    0.628,
                    0.659,
                    0.689,
                    0.719,
                    0.75,
                    0.78
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning and educational processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and development in game design",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases indicating the learning and application of skills or concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggytrc7z4j10exsu95j5kf",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggytrd7z4t10ex7nmgztaz",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggytre7z5310ex78lhno9q",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.643,
                        "binMax": 9.554,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "20609",
            "description": " phrases related to learning or acquiring knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.534394041728796,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "20609",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:54:11.913Z",
                "maxActApprox": 35.196,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    20609,
                    13254,
                    44064,
                    84196,
                    93447,
                    17880,
                    51602,
                    77000,
                    5763,
                    25027,
                    96362,
                    1477,
                    1989,
                    2264,
                    47966,
                    10949,
                    28235,
                    7570,
                    24296,
                    83600,
                    32386,
                    62592,
                    38800,
                    1105,
                    65225
                ],
                "topkCosSimValues": [
                    1,
                    0.5423,
                    0.4901,
                    0.4663,
                    0.4646,
                    0.4452,
                    0.4324,
                    0.4224,
                    0.4076,
                    0.4024,
                    0.3986,
                    0.3955,
                    0.3921,
                    0.3855,
                    0.3797,
                    0.3786,
                    0.3744,
                    0.3723,
                    0.366,
                    0.3601,
                    0.3564,
                    0.3542,
                    0.3516,
                    0.351,
                    0.3493
                ],
                "neuron_alignment_indices": [
                    285,
                    755,
                    679
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.117,
                    0.114
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    285,
                    62,
                    755
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    20563,
                    20581,
                    20609
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.007,
                    0.001,
                    0
                ],
                "neg_str": [
                    "bour",
                    "cffffcc",
                    " outl",
                    "76561",
                    " noses",
                    "liament",
                    " unaccount",
                    "iets",
                    "opped",
                    "ordered"
                ],
                "neg_values": [
                    -0.789,
                    -0.742,
                    -0.684,
                    -0.663,
                    -0.646,
                    -0.636,
                    -0.628,
                    -0.614,
                    -0.606,
                    -0.604
                ],
                "pos_str": [
                    "Learn",
                    " Yourself",
                    " Learn",
                    " Reasons",
                    " More",
                    " Explain",
                    "ipedia",
                    " Difference",
                    "ings",
                    " Fib"
                ],
                "pos_values": [
                    0.854,
                    0.828,
                    0.815,
                    0.748,
                    0.746,
                    0.74,
                    0.731,
                    0.726,
                    0.724,
                    0.722
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    89,
                    52,
                    30,
                    29,
                    20,
                    17,
                    17,
                    3,
                    6,
                    3,
                    4,
                    2,
                    2,
                    2,
                    5,
                    3,
                    3,
                    0,
                    6,
                    0,
                    3,
                    0,
                    3,
                    2,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    2,
                    1,
                    2,
                    2,
                    1,
                    0,
                    1,
                    3,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.361,
                    1.065,
                    1.769,
                    2.473,
                    3.176,
                    3.88,
                    4.584,
                    5.287,
                    5.991,
                    6.695,
                    7.399,
                    8.102,
                    8.806,
                    9.51,
                    10.213,
                    10.917,
                    11.621,
                    12.325,
                    13.028,
                    13.732,
                    14.436,
                    15.139,
                    15.843,
                    16.547,
                    17.251,
                    17.954,
                    18.658,
                    19.362,
                    20.066,
                    20.769,
                    21.473,
                    22.177,
                    22.88,
                    23.584,
                    24.288,
                    24.992,
                    25.695,
                    26.399,
                    27.103,
                    27.806,
                    28.51,
                    29.214,
                    29.918,
                    30.621,
                    31.325,
                    32.029,
                    32.732,
                    33.436,
                    34.14,
                    34.844
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    2,
                    3,
                    6,
                    15,
                    15,
                    29,
                    44,
                    90,
                    155,
                    281,
                    414,
                    663,
                    989,
                    1367,
                    1798,
                    2396,
                    2875,
                    3358,
                    3846,
                    3931,
                    3914,
                    3786,
                    3472,
                    3178,
                    2725,
                    2445,
                    1950,
                    1675,
                    1271,
                    962,
                    732,
                    546,
                    386,
                    325,
                    214,
                    127,
                    89,
                    69,
                    49,
                    16,
                    27,
                    8,
                    3,
                    6,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.773,
                    -0.74,
                    -0.707,
                    -0.674,
                    -0.641,
                    -0.609,
                    -0.576,
                    -0.543,
                    -0.51,
                    -0.477,
                    -0.444,
                    -0.411,
                    -0.378,
                    -0.346,
                    -0.313,
                    -0.28,
                    -0.247,
                    -0.214,
                    -0.181,
                    -0.148,
                    -0.116,
                    -0.083,
                    -0.05,
                    -0.017,
                    0.016,
                    0.049,
                    0.082,
                    0.114,
                    0.147,
                    0.18,
                    0.213,
                    0.246,
                    0.279,
                    0.312,
                    0.344,
                    0.377,
                    0.41,
                    0.443,
                    0.476,
                    0.509,
                    0.542,
                    0.574,
                    0.607,
                    0.64,
                    0.673,
                    0.706,
                    0.739,
                    0.772,
                    0.805,
                    0.837
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases encouraging learning or gaining knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning or acquiring knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygft7djqxl610ex0cnxc6xl",
                        "tokens": [
                            " when",
                            " a",
                            " reporter",
                            " of",
                            " interest",
                            " updates",
                            " their",
                            " Qu",
                            "ora",
                            " profile",
                            ".",
                            "\n",
                            "\n",
                            "Learn",
                            " More",
                            " About",
                            " Your",
                            " Own",
                            " Website",
                            ",",
                            " Customers",
                            ",",
                            " or",
                            " Industry",
                            "\n",
                            "\n",
                            "Keep",
                            " Track",
                            " of",
                            " Open",
                            " Site",
                            " Explorer",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Just",
                            " Disc",
                            "overed",
                            " Links",
                            "\n",
                            "\n",
                            "WHAT",
                            " IT",
                            " ME",
                            "ANS",
                            ":",
                            " Get",
                            " an",
                            " alert",
                            " when",
                            " a",
                            " new",
                            " website",
                            " links",
                            " to",
                            " yours",
                            " without",
                            " having",
                            " to",
                            " manually",
                            " check",
                            " on",
                            " a",
                            " regular",
                            " basis",
                            ".",
                            "\n",
                            "\n",
                            "HOW",
                            " TO",
                            " DO",
                            " IT",
                            ":",
                            "\n",
                            "\n",
                            "Search",
                            " for",
                            " your",
                            " website",
                            " or",
                            " page",
                            " on",
                            " Moz",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Open",
                            " Site",
                            " Explorer",
                            ".",
                            " When",
                            " the",
                            " results",
                            " come",
                            " up",
                            ",",
                            " click",
                            " on",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "Just",
                            " Disc",
                            "overed",
                            "\u00e2\u0122",
                            "\u013f",
                            " tab",
                            " Copy",
                            " the",
                            " URL",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "Just",
                            " Disc",
                            "overed",
                            "\u00e2\u0122",
                            "\u013f",
                            " tab",
                            " Go",
                            " to",
                            " Page",
                            "2",
                            "R",
                            "SS",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.196,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.196,
                            1.384,
                            0.617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.195,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft7djqxl710exwcoai8r7",
                        "tokens": [
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " Scientific",
                            " Revolution",
                            " began",
                            " to",
                            " dispro",
                            "ve",
                            " past",
                            " ideals",
                            " and",
                            " new",
                            " ideas",
                            " were",
                            " shown",
                            " to",
                            " the",
                            " masses",
                            ",",
                            " many",
                            " Europeans",
                            " experienced",
                            " tre",
                            "p",
                            "idation",
                            ".",
                            " Despite",
                            " the",
                            " advances",
                            " in",
                            " science",
                            " and",
                            " the",
                            " efforts",
                            " of",
                            " the",
                            " scientists",
                            " of",
                            " the",
                            " six",
                            "teenth",
                            " and",
                            " sevent",
                            "eenth",
                            " century",
                            " to",
                            " demonstrate",
                            " that",
                            " the",
                            " world",
                            " and",
                            " universe",
                            " were",
                            " governed",
                            " by",
                            " discern",
                            "ible",
                            " laws",
                            ",",
                            " the",
                            " Scientific",
                            " Revolution",
                            " had",
                            " little",
                            " impact",
                            " on",
                            " the",
                            " everyday",
                            " lives",
                            " and",
                            " thoughts",
                            " of",
                            " the",
                            " mass",
                            " of",
                            " European",
                            " citizens",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " breakthrough",
                            "s",
                            " made",
                            " in",
                            " astronomy",
                            " and",
                            " physics",
                            ",",
                            " most",
                            " Europeans",
                            " retained",
                            " a",
                            " belief",
                            " in",
                            " ast",
                            "rology",
                            ",",
                            " mystical",
                            " processes",
                            ",",
                            " ghosts",
                            ",",
                            " and",
                            " magic",
                            ".",
                            " German",
                            " princes",
                            " often",
                            " relied",
                            " on",
                            " court",
                            " ast"
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.458,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.458,
                            2.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.195,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft7dlqxlr10ex6w9wqygx",
                        "tokens": [
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " Scientific",
                            " Revolution",
                            " began",
                            " to",
                            " dispro",
                            "ve",
                            " past",
                            " ideals",
                            " and",
                            " new",
                            " ideas",
                            " were",
                            " shown",
                            " to",
                            " the",
                            " masses",
                            ",",
                            " many",
                            " Europeans",
                            " experienced",
                            " tre",
                            "p",
                            "idation",
                            ".",
                            " Despite",
                            " the",
                            " advances",
                            " in",
                            " science",
                            " and",
                            " the",
                            " efforts",
                            " of",
                            " the",
                            " scientists",
                            " of",
                            " the",
                            " six",
                            "teenth",
                            " and",
                            " sevent",
                            "eenth",
                            " century",
                            " to",
                            " demonstrate",
                            " that",
                            " the",
                            " world",
                            " and",
                            " universe",
                            " were",
                            " governed",
                            " by",
                            " discern",
                            "ible",
                            " laws",
                            ",",
                            " the",
                            " Scientific",
                            " Revolution",
                            " had",
                            " little",
                            " impact",
                            " on",
                            " the",
                            " everyday",
                            " lives",
                            " and",
                            " thoughts",
                            " of",
                            " the",
                            " mass",
                            " of",
                            " European",
                            " citizens",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " breakthrough",
                            "s",
                            " made",
                            " in",
                            " astronomy",
                            " and",
                            " physics",
                            ",",
                            " most",
                            " Europeans",
                            " retained",
                            " a",
                            " belief",
                            " in",
                            " ast",
                            "rology",
                            ",",
                            " mystical",
                            " processes",
                            ",",
                            " ghosts",
                            ",",
                            " and",
                            " magic",
                            ".",
                            " German",
                            " princes",
                            " often",
                            " relied",
                            " on",
                            " court",
                            " ast"
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.458,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.458,
                            2.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 28.156,
                        "binMax": 35.195,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "32386",
            "description": "words related to the concept of learning and lessons",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5327650587102746,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "32386",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:11:50.846Z",
                "maxActApprox": 39.684,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    32386,
                    44064,
                    77000,
                    13254,
                    62592,
                    1477,
                    71639,
                    39551,
                    27303,
                    73782,
                    38528,
                    67784,
                    17480,
                    5909,
                    71766,
                    19017,
                    46440,
                    44115,
                    77660,
                    31896,
                    20609,
                    38332,
                    69115,
                    93215,
                    32890
                ],
                "topkCosSimValues": [
                    1,
                    0.751,
                    0.7363,
                    0.6674,
                    0.6082,
                    0.5935,
                    0.5525,
                    0.4862,
                    0.4828,
                    0.4107,
                    0.4102,
                    0.3957,
                    0.39,
                    0.3881,
                    0.3787,
                    0.3711,
                    0.3706,
                    0.3653,
                    0.3594,
                    0.3575,
                    0.3564,
                    0.3563,
                    0.3556,
                    0.3545,
                    0.354
                ],
                "neuron_alignment_indices": [
                    756,
                    80,
                    271
                ],
                "neuron_alignment_values": [
                    0.109,
                    0.103,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    748
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.027,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.03,
                    0.026,
                    0.019
                ],
                "correlated_features_indices": [
                    32507,
                    32462,
                    32392
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "govtrack",
                    "zzi",
                    "dq",
                    "lished",
                    "heads",
                    "cour",
                    "agic",
                    "etry",
                    "head",
                    "pei"
                ],
                "neg_values": [
                    -0.722,
                    -0.709,
                    -0.658,
                    -0.655,
                    -0.632,
                    -0.619,
                    -0.587,
                    -0.582,
                    -0.582,
                    -0.58
                ],
                "pos_str": [
                    " lessons",
                    " lesson",
                    " humility",
                    "iencies",
                    " patience",
                    "itudinal",
                    " Curve",
                    "ience",
                    " laure",
                    " unfocusedRange"
                ],
                "pos_values": [
                    1.053,
                    1.01,
                    0.986,
                    0.916,
                    0.844,
                    0.839,
                    0.799,
                    0.795,
                    0.747,
                    0.728
                ],
                "frac_nonzero": 0.00023,
                "freq_hist_data_bar_heights": [
                    87,
                    74,
                    47,
                    47,
                    34,
                    37,
                    36,
                    32,
                    25,
                    31,
                    22,
                    21,
                    19,
                    15,
                    16,
                    15,
                    17,
                    14,
                    11,
                    11,
                    9,
                    19,
                    9,
                    7,
                    6,
                    4,
                    12,
                    6,
                    5,
                    4,
                    3,
                    6,
                    6,
                    3,
                    2,
                    3,
                    2,
                    0,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    3,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.195,
                    1.988,
                    2.782,
                    3.575,
                    4.369,
                    5.163,
                    5.956,
                    6.75,
                    7.543,
                    8.337,
                    9.131,
                    9.924,
                    10.718,
                    11.511,
                    12.305,
                    13.099,
                    13.892,
                    14.686,
                    15.479,
                    16.273,
                    17.067,
                    17.86,
                    18.654,
                    19.447,
                    20.241,
                    21.035,
                    21.828,
                    22.622,
                    23.415,
                    24.209,
                    25.002,
                    25.796,
                    26.59,
                    27.383,
                    28.177,
                    28.97,
                    29.764,
                    30.558,
                    31.351,
                    32.145,
                    32.938,
                    33.732,
                    34.526,
                    35.319,
                    36.113,
                    36.906,
                    37.7,
                    38.494,
                    39.287
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    2,
                    5,
                    12,
                    18,
                    31,
                    60,
                    98,
                    166,
                    302,
                    496,
                    803,
                    1236,
                    1732,
                    2479,
                    3123,
                    3984,
                    4619,
                    4837,
                    4930,
                    4498,
                    4049,
                    3520,
                    2606,
                    2077,
                    1463,
                    1078,
                    723,
                    447,
                    327,
                    198,
                    118,
                    83,
                    48,
                    31,
                    13,
                    13,
                    11,
                    4,
                    4,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.704,
                    -0.668,
                    -0.633,
                    -0.597,
                    -0.562,
                    -0.526,
                    -0.491,
                    -0.455,
                    -0.42,
                    -0.384,
                    -0.349,
                    -0.313,
                    -0.278,
                    -0.242,
                    -0.207,
                    -0.171,
                    -0.136,
                    -0.1,
                    -0.065,
                    -0.029,
                    0.006,
                    0.041,
                    0.077,
                    0.112,
                    0.148,
                    0.183,
                    0.219,
                    0.254,
                    0.29,
                    0.325,
                    0.361,
                    0.396,
                    0.432,
                    0.467,
                    0.503,
                    0.538,
                    0.574,
                    0.609,
                    0.645,
                    0.68,
                    0.716,
                    0.751,
                    0.787,
                    0.822,
                    0.858,
                    0.893,
                    0.929,
                    0.964,
                    1,
                    1.035
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to the concept of learning and lessons",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "words related to the concept of learning or knowledge acquisition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggfskeztyr10ex79o61se8",
                        "tokens": [
                            " but",
                            " it",
                            " wasn",
                            "'t",
                            " always",
                            " so",
                            ".",
                            " Back",
                            " in",
                            " the",
                            " mid",
                            "-",
                            "1980",
                            "s",
                            ",",
                            " inflation",
                            " was",
                            " hovering",
                            " around",
                            " 4",
                            " percent",
                            ",",
                            " a",
                            " major",
                            " achievement",
                            " following",
                            " the",
                            " stag",
                            "flation",
                            " of",
                            " the",
                            " previous",
                            " decade",
                            ",",
                            " but",
                            " the",
                            " Fed",
                            " wanted",
                            " it",
                            " to",
                            " go",
                            " lower",
                            " --",
                            " here",
                            "'s",
                            " the",
                            " crucial",
                            " bit",
                            " --",
                            " without",
                            " taking",
                            " the",
                            " blame",
                            " for",
                            " it",
                            ".",
                            " The",
                            " Vol",
                            "cker",
                            " Fed",
                            " had",
                            " come",
                            " in",
                            " for",
                            " quite",
                            " a",
                            " bit",
                            " of",
                            " abuse",
                            " when",
                            " it",
                            " whipped",
                            " inflation",
                            " at",
                            " the",
                            " expense",
                            " of",
                            " the",
                            " severe",
                            " 1981",
                            "-",
                            "82",
                            " downturn",
                            ",",
                            " and",
                            " the",
                            " Fed",
                            " seems",
                            " to",
                            " have",
                            " learned",
                            " it",
                            " was",
                            " better",
                            " not",
                            " to",
                            " leave",
                            " its",
                            " fingerprints",
                            " on",
                            " the",
                            " business",
                            " cycle",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " other",
                            " words",
                            ",",
                            " Let",
                            " rec",
                            "essions",
                            " do",
                            " their",
                            " dirty",
                            " work",
                            " for",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Wall",
                            " Street",
                            " Journal",
                            " leaked",
                            " an"
                        ],
                        "dataIndex": null,
                        "index": "32386",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.684,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.684,
                            4.402,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:54.951Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.684,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggfskhztzf10ex9ym9tq5b",
                        "tokens": [
                            " but",
                            " it",
                            " wasn",
                            "'t",
                            " always",
                            " so",
                            ".",
                            " Back",
                            " in",
                            " the",
                            " mid",
                            "-",
                            "1980",
                            "s",
                            ",",
                            " inflation",
                            " was",
                            " hovering",
                            " around",
                            " 4",
                            " percent",
                            ",",
                            " a",
                            " major",
                            " achievement",
                            " following",
                            " the",
                            " stag",
                            "flation",
                            " of",
                            " the",
                            " previous",
                            " decade",
                            ",",
                            " but",
                            " the",
                            " Fed",
                            " wanted",
                            " it",
                            " to",
                            " go",
                            " lower",
                            " --",
                            " here",
                            "'s",
                            " the",
                            " crucial",
                            " bit",
                            " --",
                            " without",
                            " taking",
                            " the",
                            " blame",
                            " for",
                            " it",
                            ".",
                            " The",
                            " Vol",
                            "cker",
                            " Fed",
                            " had",
                            " come",
                            " in",
                            " for",
                            " quite",
                            " a",
                            " bit",
                            " of",
                            " abuse",
                            " when",
                            " it",
                            " whipped",
                            " inflation",
                            " at",
                            " the",
                            " expense",
                            " of",
                            " the",
                            " severe",
                            " 1981",
                            "-",
                            "82",
                            " downturn",
                            ",",
                            " and",
                            " the",
                            " Fed",
                            " seems",
                            " to",
                            " have",
                            " learned",
                            " it",
                            " was",
                            " better",
                            " not",
                            " to",
                            " leave",
                            " its",
                            " fingerprints",
                            " on",
                            " the",
                            " business",
                            " cycle",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " other",
                            " words",
                            ",",
                            " Let",
                            " rec",
                            "essions",
                            " do",
                            " their",
                            " dirty",
                            " work",
                            " for",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Wall",
                            " Street",
                            " Journal",
                            " leaked",
                            " an"
                        ],
                        "dataIndex": null,
                        "index": "32386",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.684,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.684,
                            4.402,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:54.951Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 31.747,
                        "binMax": 39.684,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggfskeztys10exq9mktdsq",
                        "tokens": [
                            " a",
                            " General",
                            " Election",
                            " because",
                            " the",
                            " opinion",
                            " polls",
                            " told",
                            " her",
                            " that",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " get",
                            " a",
                            " whopping",
                            " majority",
                            ",",
                            " only",
                            " to",
                            " discover",
                            " once",
                            " the",
                            " votes",
                            " were",
                            " in",
                            " that",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " lost",
                            " the",
                            " slender",
                            " majority",
                            " that",
                            " she",
                            " had",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " think",
                            " that",
                            " Ruth",
                            " Davidson",
                            " would",
                            " be",
                            " a",
                            " bit",
                            " more",
                            " circum",
                            "spect",
                            " about",
                            " demanding",
                            " that",
                            " parties",
                            " in",
                            " power",
                            " make",
                            " decisions",
                            " based",
                            " on",
                            " opinion",
                            " polls",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " no",
                            ",",
                            " Ruth",
                            " Davidson",
                            " wants",
                            " the",
                            " Scottish",
                            " Government",
                            " to",
                            " drop",
                            " the",
                            " bill",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " already",
                            " been",
                            " passed",
                            " by",
                            " the",
                            " Scottish",
                            " Parliament",
                            ",",
                            " and",
                            " she",
                            " wants",
                            " them",
                            " to",
                            " drop",
                            " it",
                            " on",
                            " the",
                            " basis",
                            " of",
                            " an",
                            " opinion",
                            " poll",
                            ".",
                            " You",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " have",
                            " thought",
                            " a",
                            " Tory",
                            " would",
                            " have",
                            " learned",
                            " their",
                            " lesson",
                            " about",
                            " relying",
                            " on",
                            " opinion"
                        ],
                        "dataIndex": null,
                        "index": "32386",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.603,
                        "maxValueTokenIndex": 120,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.603,
                            5.332,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:54.951Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.684,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "20609",
            "description": " phrases encouraging learning or gaining knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.530225396156311,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "20609",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:54:11.913Z",
                "maxActApprox": 35.196,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    20609,
                    13254,
                    44064,
                    84196,
                    93447,
                    17880,
                    51602,
                    77000,
                    5763,
                    25027,
                    96362,
                    1477,
                    1989,
                    2264,
                    47966,
                    10949,
                    28235,
                    7570,
                    24296,
                    83600,
                    32386,
                    62592,
                    38800,
                    1105,
                    65225
                ],
                "topkCosSimValues": [
                    1,
                    0.5423,
                    0.4901,
                    0.4663,
                    0.4646,
                    0.4452,
                    0.4324,
                    0.4224,
                    0.4076,
                    0.4024,
                    0.3986,
                    0.3955,
                    0.3921,
                    0.3855,
                    0.3797,
                    0.3786,
                    0.3744,
                    0.3723,
                    0.366,
                    0.3601,
                    0.3564,
                    0.3542,
                    0.3516,
                    0.351,
                    0.3493
                ],
                "neuron_alignment_indices": [
                    285,
                    755,
                    679
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.117,
                    0.114
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    285,
                    62,
                    755
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    20563,
                    20581,
                    20609
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.007,
                    0.001,
                    0
                ],
                "neg_str": [
                    "bour",
                    "cffffcc",
                    " outl",
                    "76561",
                    " noses",
                    "liament",
                    " unaccount",
                    "iets",
                    "opped",
                    "ordered"
                ],
                "neg_values": [
                    -0.789,
                    -0.742,
                    -0.684,
                    -0.663,
                    -0.646,
                    -0.636,
                    -0.628,
                    -0.614,
                    -0.606,
                    -0.604
                ],
                "pos_str": [
                    "Learn",
                    " Yourself",
                    " Learn",
                    " Reasons",
                    " More",
                    " Explain",
                    "ipedia",
                    " Difference",
                    "ings",
                    " Fib"
                ],
                "pos_values": [
                    0.854,
                    0.828,
                    0.815,
                    0.748,
                    0.746,
                    0.74,
                    0.731,
                    0.726,
                    0.724,
                    0.722
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    89,
                    52,
                    30,
                    29,
                    20,
                    17,
                    17,
                    3,
                    6,
                    3,
                    4,
                    2,
                    2,
                    2,
                    5,
                    3,
                    3,
                    0,
                    6,
                    0,
                    3,
                    0,
                    3,
                    2,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    2,
                    1,
                    2,
                    2,
                    1,
                    0,
                    1,
                    3,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.361,
                    1.065,
                    1.769,
                    2.473,
                    3.176,
                    3.88,
                    4.584,
                    5.287,
                    5.991,
                    6.695,
                    7.399,
                    8.102,
                    8.806,
                    9.51,
                    10.213,
                    10.917,
                    11.621,
                    12.325,
                    13.028,
                    13.732,
                    14.436,
                    15.139,
                    15.843,
                    16.547,
                    17.251,
                    17.954,
                    18.658,
                    19.362,
                    20.066,
                    20.769,
                    21.473,
                    22.177,
                    22.88,
                    23.584,
                    24.288,
                    24.992,
                    25.695,
                    26.399,
                    27.103,
                    27.806,
                    28.51,
                    29.214,
                    29.918,
                    30.621,
                    31.325,
                    32.029,
                    32.732,
                    33.436,
                    34.14,
                    34.844
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    2,
                    3,
                    6,
                    15,
                    15,
                    29,
                    44,
                    90,
                    155,
                    281,
                    414,
                    663,
                    989,
                    1367,
                    1798,
                    2396,
                    2875,
                    3358,
                    3846,
                    3931,
                    3914,
                    3786,
                    3472,
                    3178,
                    2725,
                    2445,
                    1950,
                    1675,
                    1271,
                    962,
                    732,
                    546,
                    386,
                    325,
                    214,
                    127,
                    89,
                    69,
                    49,
                    16,
                    27,
                    8,
                    3,
                    6,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.773,
                    -0.74,
                    -0.707,
                    -0.674,
                    -0.641,
                    -0.609,
                    -0.576,
                    -0.543,
                    -0.51,
                    -0.477,
                    -0.444,
                    -0.411,
                    -0.378,
                    -0.346,
                    -0.313,
                    -0.28,
                    -0.247,
                    -0.214,
                    -0.181,
                    -0.148,
                    -0.116,
                    -0.083,
                    -0.05,
                    -0.017,
                    0.016,
                    0.049,
                    0.082,
                    0.114,
                    0.147,
                    0.18,
                    0.213,
                    0.246,
                    0.279,
                    0.312,
                    0.344,
                    0.377,
                    0.41,
                    0.443,
                    0.476,
                    0.509,
                    0.542,
                    0.574,
                    0.607,
                    0.64,
                    0.673,
                    0.706,
                    0.739,
                    0.772,
                    0.805,
                    0.837
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases encouraging learning or gaining knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning or acquiring knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygft7djqxl610ex0cnxc6xl",
                        "tokens": [
                            " when",
                            " a",
                            " reporter",
                            " of",
                            " interest",
                            " updates",
                            " their",
                            " Qu",
                            "ora",
                            " profile",
                            ".",
                            "\n",
                            "\n",
                            "Learn",
                            " More",
                            " About",
                            " Your",
                            " Own",
                            " Website",
                            ",",
                            " Customers",
                            ",",
                            " or",
                            " Industry",
                            "\n",
                            "\n",
                            "Keep",
                            " Track",
                            " of",
                            " Open",
                            " Site",
                            " Explorer",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Just",
                            " Disc",
                            "overed",
                            " Links",
                            "\n",
                            "\n",
                            "WHAT",
                            " IT",
                            " ME",
                            "ANS",
                            ":",
                            " Get",
                            " an",
                            " alert",
                            " when",
                            " a",
                            " new",
                            " website",
                            " links",
                            " to",
                            " yours",
                            " without",
                            " having",
                            " to",
                            " manually",
                            " check",
                            " on",
                            " a",
                            " regular",
                            " basis",
                            ".",
                            "\n",
                            "\n",
                            "HOW",
                            " TO",
                            " DO",
                            " IT",
                            ":",
                            "\n",
                            "\n",
                            "Search",
                            " for",
                            " your",
                            " website",
                            " or",
                            " page",
                            " on",
                            " Moz",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Open",
                            " Site",
                            " Explorer",
                            ".",
                            " When",
                            " the",
                            " results",
                            " come",
                            " up",
                            ",",
                            " click",
                            " on",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "Just",
                            " Disc",
                            "overed",
                            "\u00e2\u0122",
                            "\u013f",
                            " tab",
                            " Copy",
                            " the",
                            " URL",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "Just",
                            " Disc",
                            "overed",
                            "\u00e2\u0122",
                            "\u013f",
                            " tab",
                            " Go",
                            " to",
                            " Page",
                            "2",
                            "R",
                            "SS",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.196,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.196,
                            1.384,
                            0.617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.195,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft7djqxl710exwcoai8r7",
                        "tokens": [
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " Scientific",
                            " Revolution",
                            " began",
                            " to",
                            " dispro",
                            "ve",
                            " past",
                            " ideals",
                            " and",
                            " new",
                            " ideas",
                            " were",
                            " shown",
                            " to",
                            " the",
                            " masses",
                            ",",
                            " many",
                            " Europeans",
                            " experienced",
                            " tre",
                            "p",
                            "idation",
                            ".",
                            " Despite",
                            " the",
                            " advances",
                            " in",
                            " science",
                            " and",
                            " the",
                            " efforts",
                            " of",
                            " the",
                            " scientists",
                            " of",
                            " the",
                            " six",
                            "teenth",
                            " and",
                            " sevent",
                            "eenth",
                            " century",
                            " to",
                            " demonstrate",
                            " that",
                            " the",
                            " world",
                            " and",
                            " universe",
                            " were",
                            " governed",
                            " by",
                            " discern",
                            "ible",
                            " laws",
                            ",",
                            " the",
                            " Scientific",
                            " Revolution",
                            " had",
                            " little",
                            " impact",
                            " on",
                            " the",
                            " everyday",
                            " lives",
                            " and",
                            " thoughts",
                            " of",
                            " the",
                            " mass",
                            " of",
                            " European",
                            " citizens",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " breakthrough",
                            "s",
                            " made",
                            " in",
                            " astronomy",
                            " and",
                            " physics",
                            ",",
                            " most",
                            " Europeans",
                            " retained",
                            " a",
                            " belief",
                            " in",
                            " ast",
                            "rology",
                            ",",
                            " mystical",
                            " processes",
                            ",",
                            " ghosts",
                            ",",
                            " and",
                            " magic",
                            ".",
                            " German",
                            " princes",
                            " often",
                            " relied",
                            " on",
                            " court",
                            " ast"
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.458,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.458,
                            2.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.195,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft7dlqxlr10ex6w9wqygx",
                        "tokens": [
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " Scientific",
                            " Revolution",
                            " began",
                            " to",
                            " dispro",
                            "ve",
                            " past",
                            " ideals",
                            " and",
                            " new",
                            " ideas",
                            " were",
                            " shown",
                            " to",
                            " the",
                            " masses",
                            ",",
                            " many",
                            " Europeans",
                            " experienced",
                            " tre",
                            "p",
                            "idation",
                            ".",
                            " Despite",
                            " the",
                            " advances",
                            " in",
                            " science",
                            " and",
                            " the",
                            " efforts",
                            " of",
                            " the",
                            " scientists",
                            " of",
                            " the",
                            " six",
                            "teenth",
                            " and",
                            " sevent",
                            "eenth",
                            " century",
                            " to",
                            " demonstrate",
                            " that",
                            " the",
                            " world",
                            " and",
                            " universe",
                            " were",
                            " governed",
                            " by",
                            " discern",
                            "ible",
                            " laws",
                            ",",
                            " the",
                            " Scientific",
                            " Revolution",
                            " had",
                            " little",
                            " impact",
                            " on",
                            " the",
                            " everyday",
                            " lives",
                            " and",
                            " thoughts",
                            " of",
                            " the",
                            " mass",
                            " of",
                            " European",
                            " citizens",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " breakthrough",
                            "s",
                            " made",
                            " in",
                            " astronomy",
                            " and",
                            " physics",
                            ",",
                            " most",
                            " Europeans",
                            " retained",
                            " a",
                            " belief",
                            " in",
                            " ast",
                            "rology",
                            ",",
                            " mystical",
                            " processes",
                            ",",
                            " ghosts",
                            ",",
                            " and",
                            " magic",
                            ".",
                            " German",
                            " princes",
                            " often",
                            " relied",
                            " on",
                            " court",
                            " ast"
                        ],
                        "dataIndex": null,
                        "index": "20609",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.458,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.458,
                            2.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:21.059Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 28.156,
                        "binMax": 35.195,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "43239",
            "description": " expressions related to discovery and learning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5301162004470825,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "43239",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:26:49.080Z",
                "maxActApprox": 28.086,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43239,
                    49906,
                    78255,
                    9332,
                    40642,
                    15406,
                    49437,
                    51672,
                    21510,
                    96054,
                    27376,
                    11780,
                    14700,
                    21719,
                    76035,
                    27464,
                    95621,
                    45539,
                    80299,
                    52023,
                    21334,
                    16705,
                    50503,
                    41857,
                    14876
                ],
                "topkCosSimValues": [
                    1,
                    0.605,
                    0.4965,
                    0.4765,
                    0.4597,
                    0.4322,
                    0.4179,
                    0.4074,
                    0.4028,
                    0.3998,
                    0.3954,
                    0.3941,
                    0.3921,
                    0.3859,
                    0.381,
                    0.38,
                    0.3763,
                    0.3756,
                    0.3745,
                    0.374,
                    0.3728,
                    0.371,
                    0.3677,
                    0.3658,
                    0.3655
                ],
                "neuron_alignment_indices": [
                    510,
                    722,
                    483
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.095,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    70,
                    510,
                    417
                ],
                "correlated_neurons_pearson": [
                    0.016,
                    0.015,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.015,
                    0.014
                ],
                "correlated_features_indices": [
                    43163,
                    43198,
                    43151
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.008,
                    0.001,
                    0
                ],
                "neg_str": [
                    "onding",
                    "uay",
                    " watershed",
                    "alach",
                    "\u012a\u0134",
                    "taboola",
                    " ****",
                    "idation",
                    " backbone",
                    " bu"
                ],
                "neg_values": [
                    -0.764,
                    -0.722,
                    -0.625,
                    -0.622,
                    -0.621,
                    -0.603,
                    -0.601,
                    -0.587,
                    -0.58,
                    -0.57
                ],
                "pos_str": [
                    "enance",
                    "stadt",
                    "biz",
                    "ername",
                    "clude",
                    "adays",
                    "that",
                    " oneself",
                    "dylib",
                    " that"
                ],
                "pos_values": [
                    1.06,
                    0.674,
                    0.662,
                    0.642,
                    0.64,
                    0.638,
                    0.631,
                    0.626,
                    0.622,
                    0.621
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    132,
                    118,
                    75,
                    49,
                    46,
                    36,
                    34,
                    22,
                    19,
                    13,
                    19,
                    12,
                    12,
                    6,
                    4,
                    7,
                    4,
                    7,
                    6,
                    2,
                    5,
                    2,
                    1,
                    0,
                    2,
                    0,
                    1,
                    3,
                    1,
                    3,
                    2,
                    3,
                    1,
                    1,
                    4,
                    4,
                    2,
                    1,
                    3,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.282,
                    0.844,
                    1.405,
                    1.967,
                    2.529,
                    3.09,
                    3.652,
                    4.214,
                    4.775,
                    5.337,
                    5.899,
                    6.461,
                    7.022,
                    7.584,
                    8.146,
                    8.707,
                    9.269,
                    9.831,
                    10.392,
                    10.954,
                    11.516,
                    12.078,
                    12.639,
                    13.201,
                    13.763,
                    14.324,
                    14.886,
                    15.448,
                    16.009,
                    16.571,
                    17.133,
                    17.695,
                    18.256,
                    18.818,
                    19.38,
                    19.941,
                    20.503,
                    21.065,
                    21.626,
                    22.188,
                    22.75,
                    23.312,
                    23.873,
                    24.435,
                    24.997,
                    25.558,
                    26.12,
                    26.682,
                    27.243,
                    27.805
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    3,
                    3,
                    6,
                    24,
                    33,
                    88,
                    132,
                    275,
                    434,
                    631,
                    1031,
                    1510,
                    2091,
                    2836,
                    3380,
                    3951,
                    4443,
                    4622,
                    4566,
                    4352,
                    3925,
                    3274,
                    2628,
                    1974,
                    1410,
                    1055,
                    605,
                    390,
                    230,
                    142,
                    98,
                    45,
                    31,
                    17,
                    12,
                    5,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.746,
                    -0.71,
                    -0.673,
                    -0.637,
                    -0.6,
                    -0.564,
                    -0.527,
                    -0.491,
                    -0.454,
                    -0.418,
                    -0.381,
                    -0.345,
                    -0.308,
                    -0.272,
                    -0.235,
                    -0.199,
                    -0.162,
                    -0.126,
                    -0.089,
                    -0.053,
                    -0.016,
                    0.02,
                    0.057,
                    0.093,
                    0.13,
                    0.166,
                    0.203,
                    0.239,
                    0.276,
                    0.312,
                    0.349,
                    0.385,
                    0.422,
                    0.458,
                    0.495,
                    0.531,
                    0.568,
                    0.604,
                    0.641,
                    0.677,
                    0.714,
                    0.75,
                    0.787,
                    0.823,
                    0.86,
                    0.896,
                    0.933,
                    0.969,
                    1.006,
                    1.042
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases related to learning and discovery of information",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " expressions related to discovery and learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and discovery",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggz1qs81xu10ex5rddcvoo",
                        "tokens": [
                            ".",
                            " Cream",
                            " or",
                            " jam",
                            " is",
                            " fine",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " So",
                            " says",
                            " 34",
                            "-",
                            "year",
                            "-",
                            "old",
                            " T",
                            "ing",
                            "ting",
                            " He",
                            ",",
                            " in",
                            " answer",
                            " to",
                            " the",
                            " question",
                            " of",
                            " which",
                            " to",
                            " spread",
                            " on",
                            " the",
                            " sc",
                            "one",
                            " first",
                            " in",
                            " a",
                            " British",
                            " cream",
                            " tea",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " relief",
                            " to",
                            " learn",
                            " that",
                            " I",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " doing",
                            " the",
                            " wrong",
                            " thing",
                            " all",
                            " my",
                            " life",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " in",
                            " the",
                            " Essex",
                            " tea",
                            " room",
                            " of",
                            " an",
                            " up",
                            "market",
                            " British",
                            " jam",
                            " maker",
                            " and",
                            " on",
                            " the",
                            " table",
                            " before",
                            " us",
                            " is",
                            " a",
                            " plate",
                            " of",
                            " fluffy",
                            " sc",
                            "ones",
                            ",",
                            " a",
                            " bowl",
                            " of",
                            " cl",
                            "otted",
                            " cream",
                            " and",
                            " miniature",
                            " jars",
                            " of",
                            " strawberry",
                            " jam",
                            ".",
                            " T",
                            "ing",
                            "ting",
                            " may",
                            " be",
                            " Shan",
                            "gh",
                            "ain",
                            "ese",
                            " but",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " giving",
                            " me",
                            " a",
                            " lesson",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.086,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.086,
                            3.429,
                            0.91,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.086,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggz1qs81xv10exl65nn2jv",
                        "tokens": [
                            " you",
                            " wouldn",
                            "'t",
                            " have",
                            " really",
                            " been",
                            " able",
                            " to",
                            " guess",
                            " which",
                            " team",
                            " won",
                            " or",
                            " lost",
                            ";",
                            " both",
                            " guys",
                            " on",
                            " the",
                            " winning",
                            " team",
                            " sounded",
                            " like",
                            " they",
                            " really",
                            " felt",
                            " sorry",
                            " for",
                            " their",
                            " brothers",
                            ".",
                            "\n",
                            "\n",
                            "Philadelphia",
                            " Flyers",
                            ":",
                            " I",
                            "'m",
                            " surprised",
                            " to",
                            " learn",
                            " that",
                            " Michael",
                            " Del",
                            " Z",
                            "otto",
                            "'s",
                            " career",
                            "-",
                            "best",
                            " point",
                            " streak",
                            " isn",
                            "'t",
                            " \u00e2\u0122",
                            "\u013e",
                            "two",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Pitt",
                            "sburgh",
                            " Penguins",
                            ":",
                            " If",
                            " the",
                            " Penguins",
                            " trade",
                            " for",
                            " Jar",
                            "om",
                            "ir",
                            " Jag",
                            "r",
                            ",",
                            " Pittsburgh",
                            " dissolve",
                            " into",
                            " two",
                            " war",
                            "ring",
                            " factions",
                            " of",
                            " fans",
                            ".",
                            " I",
                            " hope",
                            " so",
                            " badly",
                            " that",
                            " this",
                            " happens",
                            ".",
                            "\n",
                            "\n",
                            "San",
                            " Jose",
                            " Sharks",
                            ":",
                            " The",
                            " d",
                            "ang",
                            " Sharks",
                            " are",
                            " looking",
                            " pretty",
                            " good",
                            " these",
                            " days",
                            ".",
                            " Ant",
                            "ti",
                            " Ni",
                            "emi",
                            " with",
                            " a",
                            " 31",
                            "-",
                            "save",
                            " shut",
                            "out",
                            ",",
                            " the",
                            " 31",
                            "st"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.825,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.825,
                            1.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.086,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggz1qv81yi10exr4t834ny",
                        "tokens": [
                            " you",
                            " wouldn",
                            "'t",
                            " have",
                            " really",
                            " been",
                            " able",
                            " to",
                            " guess",
                            " which",
                            " team",
                            " won",
                            " or",
                            " lost",
                            ";",
                            " both",
                            " guys",
                            " on",
                            " the",
                            " winning",
                            " team",
                            " sounded",
                            " like",
                            " they",
                            " really",
                            " felt",
                            " sorry",
                            " for",
                            " their",
                            " brothers",
                            ".",
                            "\n",
                            "\n",
                            "Philadelphia",
                            " Flyers",
                            ":",
                            " I",
                            "'m",
                            " surprised",
                            " to",
                            " learn",
                            " that",
                            " Michael",
                            " Del",
                            " Z",
                            "otto",
                            "'s",
                            " career",
                            "-",
                            "best",
                            " point",
                            " streak",
                            " isn",
                            "'t",
                            " \u00e2\u0122",
                            "\u013e",
                            "two",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Pitt",
                            "sburgh",
                            " Penguins",
                            ":",
                            " If",
                            " the",
                            " Penguins",
                            " trade",
                            " for",
                            " Jar",
                            "om",
                            "ir",
                            " Jag",
                            "r",
                            ",",
                            " Pittsburgh",
                            " dissolve",
                            " into",
                            " two",
                            " war",
                            "ring",
                            " factions",
                            " of",
                            " fans",
                            ".",
                            " I",
                            " hope",
                            " so",
                            " badly",
                            " that",
                            " this",
                            " happens",
                            ".",
                            "\n",
                            "\n",
                            "San",
                            " Jose",
                            " Sharks",
                            ":",
                            " The",
                            " d",
                            "ang",
                            " Sharks",
                            " are",
                            " looking",
                            " pretty",
                            " good",
                            " these",
                            " days",
                            ".",
                            " Ant",
                            "ti",
                            " Ni",
                            "emi",
                            " with",
                            " a",
                            " 31",
                            "-",
                            "save",
                            " shut",
                            "out",
                            ",",
                            " the",
                            " 31",
                            "st"
                        ],
                        "dataIndex": null,
                        "index": "43239",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.825,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.825,
                            1.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:53.304Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 22.469,
                        "binMax": 28.086,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84173",
            "description": " verbs that indicate knowledge acquisition and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.524330735206604,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84173",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:10.804Z",
                "maxActApprox": 15.044,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84173,
                    48354,
                    33115,
                    36323,
                    71167,
                    77782,
                    71194,
                    64425,
                    30531,
                    23047,
                    79179,
                    41003,
                    57287,
                    52248,
                    22083,
                    3405,
                    10135,
                    31772,
                    29525,
                    86712,
                    80530,
                    96770,
                    21376,
                    98056,
                    56517
                ],
                "topkCosSimValues": [
                    1,
                    0.3333,
                    0.323,
                    0.2965,
                    0.2842,
                    0.2676,
                    0.2663,
                    0.2607,
                    0.2591,
                    0.2544,
                    0.2525,
                    0.2511,
                    0.2464,
                    0.242,
                    0.235,
                    0.2319,
                    0.2264,
                    0.2261,
                    0.2259,
                    0.223,
                    0.2173,
                    0.2145,
                    0.2127,
                    0.2103,
                    0.2073
                ],
                "neuron_alignment_indices": [
                    548,
                    615,
                    23
                ],
                "neuron_alignment_values": [
                    0.089,
                    0.086,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    665,
                    570,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.007,
                    0.01
                ],
                "correlated_features_indices": [
                    84160,
                    84183,
                    84152
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "assad",
                    "iosyn",
                    "married",
                    " authorised",
                    "amar",
                    "older",
                    "lis",
                    "uploads",
                    "alde",
                    "imposed"
                ],
                "neg_values": [
                    -0.672,
                    -0.67,
                    -0.656,
                    -0.649,
                    -0.647,
                    -0.628,
                    -0.622,
                    -0.62,
                    -0.605,
                    -0.591
                ],
                "pos_str": [
                    " anything",
                    " something",
                    " Anything",
                    "nothing",
                    " nothing",
                    "THING",
                    "something",
                    "anything",
                    " whatever",
                    " Nothing"
                ],
                "pos_values": [
                    1.073,
                    0.982,
                    0.937,
                    0.934,
                    0.933,
                    0.876,
                    0.874,
                    0.865,
                    0.828,
                    0.788
                ],
                "frac_nonzero": 0.00027,
                "freq_hist_data_bar_heights": [
                    375,
                    193,
                    100,
                    60,
                    35,
                    21,
                    21,
                    19,
                    7,
                    5,
                    2,
                    4,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.152,
                    0.453,
                    0.753,
                    1.054,
                    1.355,
                    1.656,
                    1.957,
                    2.258,
                    2.559,
                    2.86,
                    3.16,
                    3.461,
                    3.762,
                    4.063,
                    4.364,
                    4.665,
                    4.966,
                    5.266,
                    5.567,
                    5.868,
                    6.169,
                    6.47,
                    6.771,
                    7.072,
                    7.372,
                    7.673,
                    7.974,
                    8.275,
                    8.576,
                    8.877,
                    9.178,
                    9.478,
                    9.779,
                    10.08,
                    10.381,
                    10.682,
                    10.983,
                    11.284,
                    11.585,
                    11.885,
                    12.186,
                    12.487,
                    12.788,
                    13.089,
                    13.39,
                    13.691,
                    13.991,
                    14.292,
                    14.593,
                    14.894
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    4,
                    9,
                    27,
                    42,
                    71,
                    141,
                    221,
                    364,
                    558,
                    789,
                    1207,
                    1563,
                    2123,
                    2627,
                    3056,
                    3555,
                    3912,
                    4079,
                    4152,
                    3904,
                    3747,
                    3161,
                    2625,
                    2214,
                    1737,
                    1323,
                    969,
                    734,
                    470,
                    292,
                    230,
                    122,
                    82,
                    44,
                    36,
                    20,
                    9,
                    11,
                    6,
                    5,
                    2,
                    1,
                    0,
                    3,
                    1,
                    2,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.654,
                    -0.619,
                    -0.584,
                    -0.55,
                    -0.515,
                    -0.48,
                    -0.445,
                    -0.41,
                    -0.375,
                    -0.34,
                    -0.305,
                    -0.27,
                    -0.236,
                    -0.201,
                    -0.166,
                    -0.131,
                    -0.096,
                    -0.061,
                    -0.026,
                    0.009,
                    0.044,
                    0.078,
                    0.113,
                    0.148,
                    0.183,
                    0.218,
                    0.253,
                    0.288,
                    0.323,
                    0.358,
                    0.392,
                    0.427,
                    0.462,
                    0.497,
                    0.532,
                    0.567,
                    0.602,
                    0.637,
                    0.672,
                    0.706,
                    0.741,
                    0.776,
                    0.811,
                    0.846,
                    0.881,
                    0.916,
                    0.951,
                    0.986,
                    1.021,
                    1.055
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " words and phrases related to knowledge and understanding",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " verbs that indicate knowledge acquisition and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyginxig34mo10exrot654gh",
                        "tokens": [
                            "-",
                            "received",
                            " speeches",
                            ",",
                            " Paul",
                            " on",
                            " Thursday",
                            " told",
                            " conservative",
                            " activists",
                            " the",
                            " Republican",
                            " Party",
                            " had",
                            " grown",
                            " \"",
                            "st",
                            "ale",
                            " and",
                            " moss",
                            " covered",
                            "\"",
                            " and",
                            " said",
                            " the",
                            " GOP",
                            " needs",
                            " a",
                            " more",
                            " libertarian",
                            " approach",
                            " that",
                            " makes",
                            " freedom",
                            " the",
                            " movement",
                            "'s",
                            " defining",
                            " principle",
                            ".",
                            " take",
                            " our",
                            " poll",
                            " -",
                            " story",
                            " continues",
                            " below",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            "\n",
                            "\n",
                            "Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " *",
                            " Yes",
                            ",",
                            " they",
                            "'ve",
                            " gotten",
                            " so",
                            " much",
                            " wrong",
                            " recently",
                            " that",
                            " they",
                            "'re",
                            " bound",
                            " to",
                            " be",
                            " on",
                            " their",
                            " best",
                            " behavior",
                            ".",
                            " No",
                            ",",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "84173",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.044,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.821,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:13.811Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.044,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyginxig34mr10exd56q1qgf",
                        "tokens": [
                            "-",
                            "received",
                            " speeches",
                            ",",
                            " Paul",
                            " on",
                            " Thursday",
                            " told",
                            " conservative",
                            " activists",
                            " the",
                            " Republican",
                            " Party",
                            " had",
                            " grown",
                            " \"",
                            "st",
                            "ale",
                            " and",
                            " moss",
                            " covered",
                            "\"",
                            " and",
                            " said",
                            " the",
                            " GOP",
                            " needs",
                            " a",
                            " more",
                            " libertarian",
                            " approach",
                            " that",
                            " makes",
                            " freedom",
                            " the",
                            " movement",
                            "'s",
                            " defining",
                            " principle",
                            ".",
                            " take",
                            " our",
                            " poll",
                            " -",
                            " story",
                            " continues",
                            " below",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            "\n",
                            "\n",
                            "Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " *",
                            " Yes",
                            ",",
                            " they",
                            "'ve",
                            " gotten",
                            " so",
                            " much",
                            " wrong",
                            " recently",
                            " that",
                            " they",
                            "'re",
                            " bound",
                            " to",
                            " be",
                            " on",
                            " their",
                            " best",
                            " behavior",
                            ".",
                            " No",
                            ",",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "84173",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.044,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.821,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:13.811Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.044,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyginxih34n010exds7kgd78",
                        "tokens": [
                            "-",
                            "received",
                            " speeches",
                            ",",
                            " Paul",
                            " on",
                            " Thursday",
                            " told",
                            " conservative",
                            " activists",
                            " the",
                            " Republican",
                            " Party",
                            " had",
                            " grown",
                            " \"",
                            "st",
                            "ale",
                            " and",
                            " moss",
                            " covered",
                            "\"",
                            " and",
                            " said",
                            " the",
                            " GOP",
                            " needs",
                            " a",
                            " more",
                            " libertarian",
                            " approach",
                            " that",
                            " makes",
                            " freedom",
                            " the",
                            " movement",
                            "'s",
                            " defining",
                            " principle",
                            ".",
                            " take",
                            " our",
                            " poll",
                            " -",
                            " story",
                            " continues",
                            " below",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            "\n",
                            "\n",
                            "Will",
                            " the",
                            " media",
                            " learn",
                            " anything",
                            " from",
                            " their",
                            " biased",
                            " reporting",
                            " of",
                            " the",
                            " J",
                            "ussie",
                            " Sm",
                            "ol",
                            "lett",
                            " story",
                            "?",
                            " *",
                            " Yes",
                            ",",
                            " they",
                            "'ve",
                            " gotten",
                            " so",
                            " much",
                            " wrong",
                            " recently",
                            " that",
                            " they",
                            "'re",
                            " bound",
                            " to",
                            " be",
                            " on",
                            " their",
                            " best",
                            " behavior",
                            ".",
                            " No",
                            ",",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "84173",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.044,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.821,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:13.811Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.044,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "30335",
            "description": " phrases related to learning and gaining information",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5236974358558655,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "30335",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:53:26.693Z",
                "maxActApprox": 41.688,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30335,
                    37022,
                    35811,
                    18802,
                    22094,
                    34957,
                    20747,
                    30287,
                    13352,
                    33551,
                    47878,
                    23357,
                    10763,
                    47823,
                    46722,
                    29434,
                    27013,
                    37323,
                    46953,
                    4144,
                    39880,
                    47288,
                    16700,
                    34528,
                    46109
                ],
                "topkCosSimValues": [
                    1,
                    0.5354,
                    0.5011,
                    0.4889,
                    0.485,
                    0.4661,
                    0.4548,
                    0.4477,
                    0.4133,
                    0.4102,
                    0.393,
                    0.3911,
                    0.3878,
                    0.387,
                    0.3799,
                    0.3779,
                    0.3722,
                    0.3611,
                    0.3607,
                    0.3586,
                    0.3582,
                    0.358,
                    0.352,
                    0.3503,
                    0.3502
                ],
                "neuron_alignment_indices": [
                    285,
                    755,
                    97
                ],
                "neuron_alignment_values": [
                    0.136,
                    0.1,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    285,
                    62,
                    97
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.019,
                    0.017
                ],
                "correlated_features_indices": [
                    30326,
                    30345,
                    30389
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    "cffffcc",
                    "*/(",
                    " Yugoslavia",
                    "bour",
                    "adra",
                    "opped",
                    "gered",
                    "ItemTracker",
                    "peror",
                    "Dialogue"
                ],
                "neg_values": [
                    -0.725,
                    -0.685,
                    -0.678,
                    -0.661,
                    -0.627,
                    -0.624,
                    -0.623,
                    -0.623,
                    -0.612,
                    -0.61
                ],
                "pos_str": [
                    " why",
                    " WHY",
                    "why",
                    " how",
                    " details",
                    " explains",
                    " More",
                    " specifics",
                    " HOW",
                    "ings"
                ],
                "pos_values": [
                    0.953,
                    0.9,
                    0.891,
                    0.86,
                    0.82,
                    0.797,
                    0.786,
                    0.776,
                    0.767,
                    0.766
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    94,
                    69,
                    45,
                    53,
                    32,
                    29,
                    15,
                    20,
                    13,
                    11,
                    7,
                    4,
                    7,
                    4,
                    1,
                    4,
                    10,
                    9,
                    4,
                    3,
                    5,
                    3,
                    1,
                    2,
                    4,
                    3,
                    1,
                    3,
                    4,
                    8,
                    4,
                    4,
                    2,
                    7,
                    5,
                    2,
                    5,
                    1,
                    3,
                    0,
                    3,
                    2,
                    0,
                    1,
                    1,
                    1,
                    0,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.419,
                    1.253,
                    2.087,
                    2.92,
                    3.754,
                    4.588,
                    5.421,
                    6.255,
                    7.089,
                    7.923,
                    8.756,
                    9.59,
                    10.424,
                    11.257,
                    12.091,
                    12.925,
                    13.759,
                    14.592,
                    15.426,
                    16.26,
                    17.093,
                    17.927,
                    18.761,
                    19.594,
                    20.428,
                    21.262,
                    22.096,
                    22.929,
                    23.763,
                    24.597,
                    25.43,
                    26.264,
                    27.098,
                    27.932,
                    28.765,
                    29.599,
                    30.433,
                    31.266,
                    32.1,
                    32.934,
                    33.768,
                    34.601,
                    35.435,
                    36.269,
                    37.102,
                    37.936,
                    38.77,
                    39.603,
                    40.437,
                    41.271
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    2,
                    11,
                    9,
                    12,
                    26,
                    33,
                    74,
                    132,
                    216,
                    387,
                    623,
                    873,
                    1241,
                    1743,
                    2420,
                    3046,
                    3521,
                    4105,
                    4337,
                    4573,
                    4384,
                    3921,
                    3414,
                    2900,
                    2319,
                    1721,
                    1357,
                    877,
                    664,
                    437,
                    276,
                    197,
                    142,
                    80,
                    63,
                    37,
                    30,
                    10,
                    8,
                    9,
                    6,
                    6,
                    4,
                    2,
                    1,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.708,
                    -0.674,
                    -0.641,
                    -0.607,
                    -0.574,
                    -0.54,
                    -0.506,
                    -0.473,
                    -0.439,
                    -0.406,
                    -0.372,
                    -0.339,
                    -0.305,
                    -0.272,
                    -0.238,
                    -0.205,
                    -0.171,
                    -0.137,
                    -0.104,
                    -0.07,
                    -0.037,
                    -0.003,
                    0.03,
                    0.064,
                    0.097,
                    0.131,
                    0.165,
                    0.198,
                    0.232,
                    0.265,
                    0.299,
                    0.332,
                    0.366,
                    0.399,
                    0.433,
                    0.467,
                    0.5,
                    0.534,
                    0.567,
                    0.601,
                    0.634,
                    0.668,
                    0.701,
                    0.735,
                    0.768,
                    0.802,
                    0.836,
                    0.869,
                    0.903,
                    0.936
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases related to learning and gaining information",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk634l13leli666c72g5vfg",
                        "tokens": [
                            "K",
                            "no",
                            "ji",
                            " reviews",
                            " products",
                            " and",
                            " up",
                            "-",
                            "and",
                            "-",
                            "coming",
                            " brands",
                            " we",
                            " think",
                            " you",
                            "'ll",
                            " love",
                            ".",
                            " In",
                            " certain",
                            " cases",
                            ",",
                            " we",
                            " may",
                            " receive",
                            " a",
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " Scientific",
                            " Revolution",
                            " began",
                            " to",
                            " dispro",
                            "ve",
                            " past",
                            " ideals",
                            " and",
                            " new",
                            " ideas",
                            " were",
                            " shown",
                            " to",
                            " the",
                            " masses",
                            ",",
                            " many",
                            " Europeans",
                            " experienced",
                            " tre",
                            "p",
                            "idation",
                            ".",
                            " Despite",
                            " the",
                            " advances",
                            " in",
                            " science",
                            " and",
                            " the",
                            " efforts",
                            " of",
                            " the",
                            " scientists",
                            " of",
                            " the",
                            " six",
                            "teenth",
                            " and",
                            " sevent",
                            "eenth",
                            " century",
                            " to",
                            " demonstrate",
                            " that",
                            " the",
                            " world",
                            " and",
                            " universe",
                            " were",
                            " governed",
                            " by",
                            " discern",
                            "ible",
                            " laws",
                            ",",
                            " the",
                            " Scientific",
                            " Revolution",
                            " had",
                            " little",
                            " impact",
                            " on",
                            " the",
                            " everyday",
                            " lives",
                            " and",
                            " thoughts",
                            " of",
                            " the",
                            " mass",
                            " of",
                            " European",
                            " citizens",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " breakthrough",
                            "s",
                            " made",
                            " in",
                            " astronomy",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "30335",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.688,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.688,
                            6.59,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:30.211Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 41.688,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk634l13lemi666ipmkj1mf",
                        "tokens": [
                            "K",
                            "no",
                            "ji",
                            " reviews",
                            " products",
                            " and",
                            " up",
                            "-",
                            "and",
                            "-",
                            "coming",
                            " brands",
                            " we",
                            " think",
                            " you",
                            "'ll",
                            " love",
                            ".",
                            " In",
                            " certain",
                            " cases",
                            ",",
                            " we",
                            " may",
                            " receive",
                            " a",
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "King",
                            " Henry",
                            " VIII",
                            " is",
                            " the",
                            " best",
                            "-",
                            "known",
                            " of",
                            " the",
                            " English",
                            " Kings",
                            ",",
                            " a",
                            " man",
                            " who",
                            " turned",
                            " from",
                            " a",
                            " talented",
                            " and",
                            " admired",
                            " renaissance",
                            " prince",
                            " to",
                            " an",
                            " aut",
                            "ocratic",
                            ",",
                            " fat",
                            ",",
                            " tyrant",
                            ".",
                            " He",
                            " is",
                            " also",
                            " well",
                            "-",
                            "known",
                            " for",
                            " being",
                            " the",
                            " only",
                            " King",
                            " with",
                            " more",
                            " wives",
                            " than",
                            " mist",
                            "resses",
                            ",",
                            " marrying",
                            " an",
                            " astonishing",
                            " 6",
                            " times",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " who",
                            " were",
                            " the",
                            " women",
                            " King",
                            " Henry",
                            " VIII",
                            " married",
                            "?",
                            " Read",
                            " on",
                            " to",
                            " find",
                            " out",
                            " the",
                            " crucial",
                            " facts",
                            " about",
                            " Henry",
                            " VIII",
                            "'s",
                            " third",
                            " wife",
                            ",",
                            " Jane",
                            " Seymour",
                            ",",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "30335",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.688,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.688,
                            6.59,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.736,
                            13.938,
                            1.568,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:30.211Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 41.688,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk634l33lf8i666gvcki9sp",
                        "tokens": [
                            "K",
                            "no",
                            "ji",
                            " reviews",
                            " products",
                            " and",
                            " up",
                            "-",
                            "and",
                            "-",
                            "coming",
                            " brands",
                            " we",
                            " think",
                            " you",
                            "'ll",
                            " love",
                            ".",
                            " In",
                            " certain",
                            " cases",
                            ",",
                            " we",
                            " may",
                            " receive",
                            " a",
                            " commission",
                            " from",
                            " brands",
                            " mentioned",
                            " in",
                            " our",
                            " guides",
                            ".",
                            " Learn",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "King",
                            " Henry",
                            " VIII",
                            " is",
                            " the",
                            " best",
                            "-",
                            "known",
                            " of",
                            " the",
                            " English",
                            " Kings",
                            ",",
                            " a",
                            " man",
                            " who",
                            " turned",
                            " from",
                            " a",
                            " talented",
                            " and",
                            " admired",
                            " renaissance",
                            " prince",
                            " to",
                            " an",
                            " aut",
                            "ocratic",
                            ",",
                            " fat",
                            ",",
                            " tyrant",
                            ".",
                            " He",
                            " is",
                            " also",
                            " well",
                            "-",
                            "known",
                            " for",
                            " being",
                            " the",
                            " only",
                            " King",
                            " with",
                            " more",
                            " wives",
                            " than",
                            " mist",
                            "resses",
                            ",",
                            " marrying",
                            " an",
                            " astonishing",
                            " 6",
                            " times",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " who",
                            " were",
                            " the",
                            " women",
                            " King",
                            " Henry",
                            " VIII",
                            " married",
                            "?",
                            " Read",
                            " on",
                            " to",
                            " find",
                            " out",
                            " the",
                            " crucial",
                            " facts",
                            " about",
                            " Henry",
                            " VIII",
                            "'s",
                            " third",
                            " wife",
                            ",",
                            " Jane",
                            " Seymour",
                            ",",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "30335",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.688,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.688,
                            6.59,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.736,
                            13.938,
                            1.568,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:30.211Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 33.35,
                        "binMax": 41.688,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36759",
            "description": " actions related to learning and practicing skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5230404138565063,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 13.291,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36759,
                    80530,
                    6057,
                    64733,
                    34954,
                    14052,
                    96770,
                    33115,
                    29063,
                    11105,
                    55382,
                    59850,
                    97527,
                    84712,
                    15165,
                    57852,
                    52248,
                    22083,
                    50986,
                    6850,
                    76062,
                    26071,
                    49673,
                    7364,
                    10485
                ],
                "topkCosSimValues": [
                    1,
                    0.5951,
                    0.5934,
                    0.5701,
                    0.5328,
                    0.4929,
                    0.4908,
                    0.4778,
                    0.4684,
                    0.4549,
                    0.4378,
                    0.4362,
                    0.4357,
                    0.4286,
                    0.428,
                    0.4258,
                    0.4207,
                    0.4182,
                    0.4174,
                    0.417,
                    0.4154,
                    0.4034,
                    0.4003,
                    0.3977,
                    0.396
                ],
                "neuron_alignment_indices": [
                    756,
                    393,
                    447
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.137,
                    0.131
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.061,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.07,
                    0.034
                ],
                "correlated_features_indices": [
                    36790,
                    36840,
                    36787
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.021,
                    0.006,
                    0.003
                ],
                "neg_str": [
                    "ortment",
                    "aran",
                    "emonic",
                    "advertising",
                    "oris",
                    "rin",
                    "hon",
                    "odon",
                    "grad",
                    "arty"
                ],
                "neg_values": [
                    -0.622,
                    -0.585,
                    -0.584,
                    -0.573,
                    -0.57,
                    -0.555,
                    -0.553,
                    -0.553,
                    -0.55,
                    -0.545
                ],
                "pos_str": [
                    " differently",
                    " freely",
                    " separately",
                    " excessively",
                    " directly",
                    " continuously",
                    " blindly",
                    " extensively",
                    " elsewhere",
                    " anyway"
                ],
                "pos_values": [
                    0.846,
                    0.829,
                    0.822,
                    0.779,
                    0.767,
                    0.766,
                    0.765,
                    0.764,
                    0.763,
                    0.759
                ],
                "frac_nonzero": 0.00365,
                "freq_hist_data_bar_heights": [
                    1695,
                    1427,
                    1185,
                    1012,
                    832,
                    711,
                    617,
                    515,
                    484,
                    401,
                    352,
                    293,
                    274,
                    220,
                    195,
                    180,
                    157,
                    135,
                    112,
                    104,
                    75,
                    73,
                    67,
                    54,
                    53,
                    48,
                    34,
                    21,
                    26,
                    21,
                    18,
                    18,
                    15,
                    9,
                    10,
                    4,
                    6,
                    8,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.93,
                    1.196,
                    1.462,
                    1.728,
                    1.994,
                    2.26,
                    2.525,
                    2.791,
                    3.057,
                    3.323,
                    3.589,
                    3.854,
                    4.12,
                    4.386,
                    4.652,
                    4.918,
                    5.184,
                    5.449,
                    5.715,
                    5.981,
                    6.247,
                    6.513,
                    6.779,
                    7.044,
                    7.31,
                    7.576,
                    7.842,
                    8.108,
                    8.373,
                    8.639,
                    8.905,
                    9.171,
                    9.437,
                    9.703,
                    9.968,
                    10.234,
                    10.5,
                    10.766,
                    11.032,
                    11.297,
                    11.563,
                    11.829,
                    12.095,
                    12.361,
                    12.627,
                    12.892,
                    13.158
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    14,
                    18,
                    19,
                    42,
                    76,
                    97,
                    180,
                    250,
                    398,
                    595,
                    849,
                    1222,
                    1681,
                    2166,
                    2679,
                    3186,
                    3622,
                    4005,
                    4027,
                    4002,
                    3965,
                    3469,
                    3043,
                    2447,
                    1988,
                    1546,
                    1160,
                    930,
                    685,
                    499,
                    360,
                    264,
                    190,
                    138,
                    101,
                    80,
                    54,
                    64,
                    28,
                    36,
                    24,
                    17,
                    12,
                    6,
                    8,
                    7,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.608,
                    -0.578,
                    -0.549,
                    -0.519,
                    -0.49,
                    -0.461,
                    -0.431,
                    -0.402,
                    -0.373,
                    -0.343,
                    -0.314,
                    -0.284,
                    -0.255,
                    -0.226,
                    -0.196,
                    -0.167,
                    -0.138,
                    -0.108,
                    -0.079,
                    -0.049,
                    -0.02,
                    0.009,
                    0.039,
                    0.068,
                    0.097,
                    0.127,
                    0.156,
                    0.186,
                    0.215,
                    0.244,
                    0.274,
                    0.303,
                    0.332,
                    0.362,
                    0.391,
                    0.42,
                    0.45,
                    0.479,
                    0.509,
                    0.538,
                    0.567,
                    0.597,
                    0.626,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.773,
                    0.802,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions related to learning and practicing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and typing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmwa335lx10exco67ax55",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa335m610exgnqozkf4",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa535mk10exsw1a50vs",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.633,
                        "binMax": 13.291,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "5909",
            "description": "phrases about teaching and learning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5181505967288863,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "5909",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:36:07.210Z",
                "maxActApprox": 28.887,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5909,
                    71639,
                    44064,
                    18323,
                    68287,
                    27303,
                    90785,
                    96831,
                    5968,
                    32386,
                    19017,
                    33056,
                    20644,
                    77660,
                    31896,
                    77000,
                    67212,
                    26576,
                    57450,
                    13254,
                    14559,
                    64057,
                    8294,
                    68625,
                    1105
                ],
                "topkCosSimValues": [
                    1,
                    0.5204,
                    0.5038,
                    0.4824,
                    0.4772,
                    0.4715,
                    0.444,
                    0.4255,
                    0.4243,
                    0.3881,
                    0.3849,
                    0.3556,
                    0.352,
                    0.3491,
                    0.3485,
                    0.3482,
                    0.3437,
                    0.3429,
                    0.3425,
                    0.3362,
                    0.334,
                    0.3336,
                    0.3314,
                    0.3306,
                    0.3294
                ],
                "neuron_alignment_indices": [
                    126,
                    602,
                    45
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.096,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    279,
                    567,
                    126
                ],
                "correlated_neurons_pearson": [
                    0.017,
                    0.016,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.013,
                    0.015
                ],
                "correlated_features_indices": [
                    5812,
                    5888,
                    5762
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.003,
                    0.001
                ],
                "neg_str": [
                    "iture",
                    "beck",
                    "obin",
                    "etheus",
                    "ioxide",
                    "pload",
                    "endez",
                    " Corker",
                    " insured",
                    "levard"
                ],
                "neg_values": [
                    -0.804,
                    -0.721,
                    -0.72,
                    -0.72,
                    -0.679,
                    -0.629,
                    -0.628,
                    -0.618,
                    -0.616,
                    -0.615
                ],
                "pos_str": [
                    " lesson",
                    " lessons",
                    " curriculum",
                    " skills",
                    " kindergarten",
                    " Teach",
                    " curric",
                    " basics",
                    " fundamentals",
                    " teach"
                ],
                "pos_values": [
                    1.172,
                    1.081,
                    0.986,
                    0.921,
                    0.903,
                    0.892,
                    0.885,
                    0.88,
                    0.876,
                    0.851
                ],
                "frac_nonzero": 0.00049,
                "freq_hist_data_bar_heights": [
                    337,
                    276,
                    175,
                    125,
                    96,
                    71,
                    64,
                    44,
                    34,
                    41,
                    38,
                    26,
                    20,
                    21,
                    22,
                    9,
                    11,
                    9,
                    11,
                    8,
                    13,
                    8,
                    8,
                    4,
                    4,
                    7,
                    3,
                    7,
                    9,
                    2,
                    8,
                    3,
                    7,
                    0,
                    4,
                    5,
                    3,
                    5,
                    0,
                    2,
                    2,
                    0,
                    2,
                    3,
                    0,
                    2,
                    1,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.291,
                    0.869,
                    1.446,
                    2.024,
                    2.602,
                    3.179,
                    3.757,
                    4.335,
                    4.913,
                    5.49,
                    6.068,
                    6.646,
                    7.223,
                    7.801,
                    8.379,
                    8.957,
                    9.534,
                    10.112,
                    10.69,
                    11.267,
                    11.845,
                    12.423,
                    13,
                    13.578,
                    14.156,
                    14.734,
                    15.311,
                    15.889,
                    16.467,
                    17.044,
                    17.622,
                    18.2,
                    18.778,
                    19.355,
                    19.933,
                    20.511,
                    21.088,
                    21.666,
                    22.244,
                    22.821,
                    23.399,
                    23.977,
                    24.555,
                    25.132,
                    25.71,
                    26.288,
                    26.865,
                    27.443,
                    28.021,
                    28.599
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    3,
                    1,
                    8,
                    11,
                    28,
                    46,
                    119,
                    200,
                    312,
                    525,
                    810,
                    1295,
                    1787,
                    2485,
                    3246,
                    3771,
                    4524,
                    4817,
                    4785,
                    4534,
                    4023,
                    3455,
                    2735,
                    2007,
                    1450,
                    1043,
                    802,
                    482,
                    321,
                    194,
                    142,
                    86,
                    65,
                    39,
                    38,
                    19,
                    16,
                    11,
                    6,
                    6,
                    4,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.785,
                    -0.745,
                    -0.706,
                    -0.666,
                    -0.627,
                    -0.587,
                    -0.548,
                    -0.508,
                    -0.468,
                    -0.429,
                    -0.389,
                    -0.35,
                    -0.31,
                    -0.271,
                    -0.231,
                    -0.192,
                    -0.152,
                    -0.113,
                    -0.073,
                    -0.034,
                    0.006,
                    0.045,
                    0.085,
                    0.124,
                    0.164,
                    0.204,
                    0.243,
                    0.283,
                    0.322,
                    0.362,
                    0.401,
                    0.441,
                    0.48,
                    0.52,
                    0.559,
                    0.599,
                    0.638,
                    0.678,
                    0.717,
                    0.757,
                    0.796,
                    0.836,
                    0.875,
                    0.915,
                    0.955,
                    0.994,
                    1.034,
                    1.073,
                    1.113,
                    1.152
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases about teaching and learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf5xdgfs3110exo1ctjumz",
                        "tokens": [
                            " movie",
                            " Welcome",
                            " To",
                            " The",
                            " R",
                            "ile",
                            "ys",
                            "\n",
                            "\n",
                            "'",
                            "I",
                            " am",
                            " heart",
                            "broken",
                            ".",
                            " My",
                            " bud",
                            " James",
                            " Gand",
                            "olf",
                            "ini",
                            " just",
                            " died",
                            ".",
                            " Last",
                            " Saturday",
                            " he",
                            " told",
                            " me",
                            " at",
                            " our",
                            " kids",
                            " graduation",
                            " [",
                            "that",
                            "]",
                            " he",
                            " was",
                            " so",
                            " happy",
                            " to",
                            " go",
                            " with",
                            " his",
                            " son",
                            " to",
                            " Italy",
                            ".",
                            " A",
                            " boy",
                            " trip",
                            "!'",
                            " Mar",
                            "ini",
                            " wrote",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " '",
                            "It",
                            " was",
                            " an",
                            " honor",
                            " to",
                            " have",
                            " met",
                            " this",
                            " man",
                            ",",
                            " such",
                            " a",
                            " great",
                            " Dad",
                            "!",
                            " I",
                            " spent",
                            " so",
                            " much",
                            " time",
                            " with",
                            " James",
                            " son",
                            " teaching",
                            " him",
                            " soccer",
                            ".",
                            " I",
                            " feel",
                            " for",
                            " that",
                            " kid",
                            " it",
                            " must",
                            " be",
                            " so",
                            " hard",
                            " right",
                            " now",
                            " for",
                            " little",
                            " [",
                            "Michael",
                            "]",
                            ".'",
                            "\n",
                            "\n",
                            "'",
                            "RIP",
                            " James",
                            " Gand",
                            "olf",
                            "ini",
                            ".",
                            " A",
                            " great",
                            " friend",
                            ",'",
                            " wrote",
                            " Jeff",
                            " Daniels",
                            ",",
                            " his",
                            " co",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.887,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.887,
                            7.359,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf5xdgfs3210exchrp1dz1",
                        "tokens": [
                            " hard",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "dep",
                            "rogram",
                            "\u00e2\u0122",
                            "\u013f",
                            " his",
                            " kids",
                            " from",
                            " the",
                            " traditional",
                            " way",
                            " of",
                            " learning",
                            " by",
                            " teaching",
                            " them",
                            " about",
                            " how",
                            " their",
                            " brains",
                            " work",
                            " and",
                            " why",
                            " the",
                            " dominant",
                            " teaching",
                            " style",
                            " is",
                            " incompatible",
                            ".",
                            " When",
                            " Hol",
                            "man",
                            " treated",
                            " his",
                            " students",
                            " like",
                            " adults",
                            " who",
                            " could",
                            " understand",
                            " the",
                            " system",
                            " in",
                            " which",
                            " they",
                            " played",
                            ",",
                            " he",
                            " earned",
                            " their",
                            " trust",
                            " and",
                            " their",
                            " hard",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "Sometimes",
                            " the",
                            " teaching",
                            " and",
                            " studying",
                            " strategies",
                            " thought",
                            " to",
                            " work",
                            " best",
                            " actively",
                            " contradict",
                            " brain",
                            "-",
                            "based",
                            " learning",
                            ".",
                            " New",
                            " York",
                            " Times",
                            " writer",
                            " Benedict",
                            " Carey",
                            " devoted",
                            " an",
                            " entire",
                            " book",
                            " to",
                            " describing",
                            " counter",
                            "-",
                            "intuitive",
                            " study",
                            " strategies",
                            " based",
                            " in",
                            " cognitive",
                            " science",
                            " about",
                            " memory",
                            " and",
                            " learning",
                            ".",
                            " For",
                            " example",
                            ",",
                            " students",
                            " tend",
                            " to",
                            " spend",
                            " hours",
                            " cram",
                            "ming",
                            " for",
                            " a",
                            " test",
                            " the",
                            " next",
                            " day",
                            ",",
                            " only",
                            " to",
                            " promptly",
                            " forget",
                            " everything"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.985,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.768,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.985,
                            5.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf5xdgfs3310ex10c14yz8",
                        "tokens": [
                            " for",
                            " O",
                            "atmeal",
                            " Ra",
                            "isin",
                            " S",
                            "con",
                            "es",
                            ".",
                            " I",
                            " hope",
                            " you",
                            " enjoy",
                            " Ell",
                            "a",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " selection",
                            " and",
                            " please",
                            " spend",
                            " time",
                            " with",
                            " your",
                            " kids",
                            " teaching",
                            " them",
                            " how",
                            " to",
                            " cook",
                            ".",
                            " Be",
                            " sure",
                            " to",
                            " sign",
                            " up",
                            " for",
                            " my",
                            " weekly",
                            " emails",
                            " so",
                            " you",
                            " can",
                            " share",
                            " with",
                            " your",
                            " kids",
                            " what",
                            " Ell",
                            "a",
                            " makes",
                            " next",
                            ".",
                            "\n",
                            "\n",
                            "Follow",
                            " me",
                            " on",
                            " Facebook",
                            " \u2013",
                            " Pinterest",
                            " \u2013",
                            " Twitter",
                            " \u2013",
                            " Google",
                            " +",
                            " \u2013",
                            " Instagram",
                            "\n",
                            "\n",
                            "Pin",
                            " It",
                            " Last",
                            " weekends",
                            " office",
                            " remod",
                            "el",
                            ".",
                            " P",
                            "ainted",
                            " the",
                            " walls",
                            " a",
                            " light",
                            " grey",
                            "-",
                            "blue",
                            ".",
                            " P",
                            "ainted",
                            " the",
                            " desk",
                            " with",
                            " black",
                            " chalk",
                            " paint",
                            ".",
                            " The",
                            " plan",
                            " is",
                            " also",
                            " to",
                            " use",
                            " the",
                            " office",
                            " as",
                            " my",
                            " studio",
                            " for",
                            " food",
                            " photography",
                            ".",
                            " Plenty",
                            " of",
                            " natural",
                            " light",
                            " and",
                            " I",
                            " added",
                            " 5000",
                            " K",
                            " natural",
                            " daylight",
                            " bulbs",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.592,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.592,
                            6.04,
                            1.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "21306",
            "description": "questions about understanding or learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5144398212432861,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "21306",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:55:08.250Z",
                "maxActApprox": 46.771,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21306,
                    11,
                    59028,
                    24863,
                    97707,
                    62741,
                    63520,
                    60147,
                    38758,
                    90284,
                    2430,
                    23492,
                    5418,
                    42965,
                    29326,
                    29674,
                    5228,
                    58522,
                    2086,
                    15009,
                    78040,
                    23145,
                    69877,
                    2372,
                    81898
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7336,
                    0.6773,
                    0.6355,
                    0.6096,
                    0.608,
                    0.606,
                    0.5991,
                    0.5956,
                    0.5951,
                    0.5894,
                    0.5793,
                    0.5581,
                    0.5506,
                    0.5474,
                    0.5369,
                    0.5271,
                    0.5197,
                    0.4772,
                    0.4568,
                    0.4391,
                    0.4388,
                    0.3822,
                    0.3546
                ],
                "neuron_alignment_indices": [
                    243,
                    373,
                    350
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.095,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    243,
                    60,
                    350
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.019,
                    0.019
                ],
                "correlated_features_indices": [
                    21352,
                    21266,
                    21244
                ],
                "correlated_features_pearson": [
                    0.011,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.012,
                    0,
                    0
                ],
                "neg_str": [
                    "phant",
                    "UA",
                    "iture",
                    "hammad",
                    "anship",
                    "aber",
                    " Issue",
                    "reporting",
                    "aredevil",
                    "idered"
                ],
                "neg_values": [
                    -0.701,
                    -0.654,
                    -0.627,
                    -0.615,
                    -0.612,
                    -0.591,
                    -0.585,
                    -0.584,
                    -0.583,
                    -0.582
                ],
                "pos_str": [
                    " lucky",
                    "ls",
                    " much",
                    " messed",
                    "beit",
                    " hard",
                    "itzer",
                    " thankful",
                    " frustrating",
                    " grateful"
                ],
                "pos_values": [
                    0.765,
                    0.753,
                    0.752,
                    0.747,
                    0.736,
                    0.715,
                    0.71,
                    0.709,
                    0.694,
                    0.694
                ],
                "frac_nonzero": 0.0002,
                "freq_hist_data_bar_heights": [
                    104,
                    77,
                    59,
                    45,
                    42,
                    38,
                    30,
                    28,
                    19,
                    23,
                    13,
                    8,
                    17,
                    13,
                    12,
                    7,
                    7,
                    9,
                    4,
                    2,
                    2,
                    3,
                    6,
                    3,
                    3,
                    1,
                    2,
                    0,
                    2,
                    2,
                    2,
                    0,
                    3,
                    3,
                    3,
                    5,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.48,
                    1.415,
                    2.351,
                    3.286,
                    4.221,
                    5.156,
                    6.091,
                    7.026,
                    7.962,
                    8.897,
                    9.832,
                    10.767,
                    11.702,
                    12.637,
                    13.573,
                    14.508,
                    15.443,
                    16.378,
                    17.313,
                    18.248,
                    19.184,
                    20.119,
                    21.054,
                    21.989,
                    22.924,
                    23.859,
                    24.795,
                    25.73,
                    26.665,
                    27.6,
                    28.535,
                    29.47,
                    30.406,
                    31.341,
                    32.276,
                    33.211,
                    34.146,
                    35.081,
                    36.017,
                    36.952,
                    37.887,
                    38.822,
                    39.757,
                    40.692,
                    41.628,
                    42.563,
                    43.498,
                    44.433,
                    45.368,
                    46.303
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    4,
                    7,
                    19,
                    21,
                    28,
                    70,
                    109,
                    155,
                    248,
                    378,
                    484,
                    743,
                    1087,
                    1356,
                    1818,
                    2190,
                    2719,
                    3255,
                    3665,
                    3743,
                    3945,
                    3934,
                    3657,
                    3266,
                    2861,
                    2350,
                    1925,
                    1529,
                    1195,
                    882,
                    680,
                    493,
                    380,
                    291,
                    222,
                    148,
                    132,
                    99,
                    67,
                    32,
                    23,
                    16,
                    13,
                    4,
                    2,
                    3,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.686,
                    -0.657,
                    -0.628,
                    -0.598,
                    -0.569,
                    -0.54,
                    -0.51,
                    -0.481,
                    -0.452,
                    -0.422,
                    -0.393,
                    -0.364,
                    -0.334,
                    -0.305,
                    -0.276,
                    -0.247,
                    -0.217,
                    -0.188,
                    -0.159,
                    -0.129,
                    -0.1,
                    -0.071,
                    -0.041,
                    -0.012,
                    0.017,
                    0.047,
                    0.076,
                    0.105,
                    0.135,
                    0.164,
                    0.193,
                    0.223,
                    0.252,
                    0.281,
                    0.311,
                    0.34,
                    0.369,
                    0.399,
                    0.428,
                    0.457,
                    0.486,
                    0.516,
                    0.545,
                    0.574,
                    0.604,
                    0.633,
                    0.662,
                    0.692,
                    0.721,
                    0.75
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions about understanding or learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfubx4rgf010exsjeyoxom",
                        "tokens": [
                            " President",
                            " Enrique",
                            " Pe",
                            "\u00c3\u00b1a",
                            " Nieto",
                            " on",
                            " Jan",
                            ".",
                            " 27",
                            ",",
                            " according",
                            " to",
                            " a",
                            " transcript",
                            " published",
                            " Thursday",
                            " by",
                            " The",
                            " Washington",
                            " Post",
                            ".",
                            "\n",
                            "\n",
                            "[",
                            "Trump",
                            " urged",
                            " Mexican",
                            " president",
                            " to",
                            " end",
                            " his",
                            " public",
                            " defiance",
                            " on",
                            " border",
                            " wall",
                            ",",
                            " transcript",
                            " reveals",
                            "]",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Listen",
                            ",",
                            " I",
                            " know",
                            " how",
                            " tough",
                            " these",
                            " guys",
                            " are",
                            " \u2014",
                            " our",
                            " military",
                            " will",
                            " knock",
                            " them",
                            " out",
                            " like",
                            " you",
                            " never",
                            " thought",
                            " of",
                            ",",
                            " we",
                            " will",
                            " work",
                            " to",
                            " help",
                            " you",
                            " knock",
                            " them",
                            " out",
                            " because",
                            " your",
                            " country",
                            " does",
                            " not",
                            " want",
                            " that",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Trump",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " can",
                            " Trump",
                            " actually",
                            " do",
                            " that",
                            "?",
                            "\n",
                            "\n",
                            "Republican",
                            " presidential",
                            " nominee",
                            " Donald",
                            " Trump",
                            " discussed",
                            " border",
                            " security",
                            " at",
                            " the",
                            " third",
                            " and",
                            " final",
                            " presidential",
                            " debate",
                            ",",
                            " Oct",
                            ".",
                            " 19",
                            ",",
                            " in",
                            " Las",
                            " Vegas",
                            ".",
                            " (",
                            "The",
                            " Washington",
                            " Post"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.771,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.771,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx5rgf110ex2b7evkpk",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx7rgfm10exporrr5nf",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.417,
                        "binMax": 46.771,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}