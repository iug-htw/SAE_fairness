{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "constructivist learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.575496648281614,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5335305055100037,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "93327",
            "description": "discussions about social constructs and their implications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5109000205993652,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "93327",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:24:01.481Z",
                "maxActApprox": 8.016,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    93327,
                    21512,
                    36105,
                    19886,
                    65190,
                    29083,
                    18474,
                    26594,
                    2645,
                    68643,
                    51733,
                    39304,
                    26774,
                    36827,
                    74887,
                    24024,
                    96080,
                    70815,
                    61564,
                    8454,
                    71560,
                    57391,
                    44148,
                    87590,
                    13974
                ],
                "topkCosSimValues": [
                    1,
                    0.4781,
                    0.4725,
                    0.454,
                    0.4367,
                    0.426,
                    0.4258,
                    0.424,
                    0.3928,
                    0.3928,
                    0.3877,
                    0.3842,
                    0.3838,
                    0.3766,
                    0.3726,
                    0.3688,
                    0.3609,
                    0.3592,
                    0.3591,
                    0.352,
                    0.349,
                    0.3463,
                    0.3442,
                    0.3433,
                    0.3389
                ],
                "neuron_alignment_indices": [
                    317,
                    503,
                    355
                ],
                "neuron_alignment_values": [
                    0.107,
                    0.1,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    718,
                    55,
                    739
                ],
                "correlated_neurons_pearson": [
                    0.051,
                    0.047,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.062,
                    0.062,
                    0.028
                ],
                "correlated_features_indices": [
                    93279,
                    93268,
                    93295
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.004
                ],
                "neg_str": [
                    " GoPro",
                    " VIP",
                    " Bounty",
                    "\u00f0\u0141\u013a",
                    " Kardash",
                    "kids",
                    "CEO",
                    "UFC",
                    "gy",
                    " Snapchat"
                ],
                "neg_values": [
                    -0.814,
                    -0.788,
                    -0.775,
                    -0.768,
                    -0.76,
                    -0.758,
                    -0.747,
                    -0.735,
                    -0.731,
                    -0.73
                ],
                "pos_str": [
                    " moreover",
                    " eluc",
                    " philosophers",
                    " presupp",
                    " furthermore",
                    " epist",
                    " conject",
                    " philosoph",
                    " scarcely",
                    " nevertheless"
                ],
                "pos_values": [
                    1.197,
                    1.178,
                    1.147,
                    1.098,
                    1.091,
                    1.085,
                    1.077,
                    1.032,
                    1.03,
                    1.023
                ],
                "frac_nonzero": 0.006710000000000001,
                "freq_hist_data_bar_heights": [
                    2514,
                    2200,
                    2066,
                    1772,
                    1557,
                    1437,
                    1124,
                    1094,
                    945,
                    812,
                    734,
                    624,
                    554,
                    496,
                    434,
                    352,
                    330,
                    289,
                    251,
                    226,
                    190,
                    162,
                    148,
                    112,
                    104,
                    108,
                    83,
                    54,
                    58,
                    43,
                    48,
                    30,
                    20,
                    23,
                    18,
                    17,
                    14,
                    11,
                    7,
                    6,
                    6,
                    4,
                    4,
                    1,
                    6,
                    0,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.08,
                    0.241,
                    0.401,
                    0.561,
                    0.722,
                    0.882,
                    1.042,
                    1.203,
                    1.363,
                    1.523,
                    1.684,
                    1.844,
                    2.004,
                    2.165,
                    2.325,
                    2.485,
                    2.646,
                    2.806,
                    2.966,
                    3.127,
                    3.287,
                    3.447,
                    3.608,
                    3.768,
                    3.928,
                    4.088,
                    4.249,
                    4.409,
                    4.569,
                    4.73,
                    4.89,
                    5.05,
                    5.211,
                    5.371,
                    5.531,
                    5.692,
                    5.852,
                    6.012,
                    6.173,
                    6.333,
                    6.493,
                    6.654,
                    6.814,
                    6.974,
                    7.135,
                    7.295,
                    7.455,
                    7.615,
                    7.776,
                    7.936
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    12,
                    20,
                    35,
                    49,
                    110,
                    198,
                    328,
                    450,
                    699,
                    1062,
                    1476,
                    1815,
                    2330,
                    2760,
                    3159,
                    3590,
                    3756,
                    3783,
                    3565,
                    3493,
                    2965,
                    2694,
                    2381,
                    2012,
                    1687,
                    1308,
                    1102,
                    817,
                    644,
                    515,
                    354,
                    276,
                    251,
                    161,
                    101,
                    88,
                    62,
                    52,
                    28,
                    23,
                    9,
                    6,
                    10,
                    6,
                    0,
                    4,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.794,
                    -0.754,
                    -0.713,
                    -0.673,
                    -0.633,
                    -0.593,
                    -0.553,
                    -0.512,
                    -0.472,
                    -0.432,
                    -0.392,
                    -0.351,
                    -0.311,
                    -0.271,
                    -0.231,
                    -0.191,
                    -0.15,
                    -0.11,
                    -0.07,
                    -0.03,
                    0.01,
                    0.051,
                    0.091,
                    0.131,
                    0.171,
                    0.212,
                    0.252,
                    0.292,
                    0.332,
                    0.372,
                    0.413,
                    0.453,
                    0.493,
                    0.533,
                    0.574,
                    0.614,
                    0.654,
                    0.694,
                    0.734,
                    0.775,
                    0.815,
                    0.855,
                    0.895,
                    0.936,
                    0.976,
                    1.016,
                    1.056,
                    1.096,
                    1.137,
                    1.177
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions about social constructs and their implications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " constructs related to social and political theories of race",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj0meoa19110exp50y27j2",
                        "tokens": [
                            " white",
                            ";",
                            " it",
                            " does",
                            " not",
                            " make",
                            " a",
                            " person",
                            " white",
                            ".",
                            "\n",
                            "\n",
                            "Whit",
                            "eness",
                            " is",
                            ",",
                            " it",
                            " seems",
                            " pretty",
                            " obvious",
                            ",",
                            " a",
                            " social",
                            " or",
                            " political",
                            " construct",
                            " of",
                            " some",
                            " sort",
                            ",",
                            " something",
                            " elaborated",
                            " upon",
                            " conceptions",
                            " of",
                            " kins",
                            "hip",
                            " or",
                            " common",
                            " ancestry",
                            " and",
                            " upon",
                            " ancient",
                            " ethn",
                            "oc",
                            "entric",
                            " associations",
                            " of",
                            " good",
                            " and",
                            " evil",
                            " with",
                            " light",
                            " and",
                            " dark",
                            ".",
                            " Those",
                            " who",
                            " fashion",
                            " this",
                            " construct",
                            " of",
                            " whit",
                            "eness",
                            ",",
                            " who",
                            " elaborate",
                            " on",
                            " these",
                            " conceptions",
                            ",",
                            " are",
                            " primarily",
                            " a",
                            " certain",
                            " group",
                            " of",
                            " males",
                            ".",
                            " It",
                            " is",
                            " their",
                            " construct",
                            ".",
                            " They",
                            " construct",
                            " a",
                            " conception",
                            " of",
                            " their",
                            " \u00e2\u0122",
                            "\u013e",
                            "us",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " their",
                            " kindred",
                            ",",
                            " their",
                            " nation",
                            ",",
                            " their",
                            " tribe",
                            ".",
                            " Ear",
                            "liest",
                            " uses",
                            " of",
                            " the",
                            " word",
                            " \u00e2\u0122",
                            "\u013a",
                            "race",
                            "\u00e2\u0122",
                            "\u013b",
                            " in",
                            " English",
                            ",",
                            " according",
                            " to",
                            " The",
                            " Oxford",
                            " English",
                            " Dictionary",
                            ",",
                            " make"
                        ],
                        "dataIndex": null,
                        "index": "93327",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.016,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.307,
                            4.074,
                            4.884,
                            0.588,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.44,
                            2.597,
                            1.982,
                            2.722,
                            0,
                            0,
                            3.811,
                            8.016,
                            5.873,
                            4.896,
                            1.004,
                            1.813,
                            0.838,
                            0,
                            0,
                            3.609,
                            5.536,
                            1.872,
                            0,
                            0,
                            3.726,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0.193,
                            0.379,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.725,
                            0.801,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.486
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:05.953Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.016,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj0meoa19210exqism5y2u",
                        "tokens": [
                            " The",
                            " Tant",
                            "ra",
                            " Sh",
                            "ast",
                            "ra",
                            " is",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " and",
                            " whatever",
                            " be",
                            " its",
                            " historical",
                            " origin",
                            ",",
                            " a",
                            " development",
                            " of",
                            " the",
                            " V",
                            "aid",
                            "ika",
                            " K",
                            "arm",
                            "ak",
                            "anda",
                            ",",
                            " promulg",
                            "ated",
                            " to",
                            " meet",
                            " the",
                            " needs",
                            " of",
                            " that",
                            " age",
                            ".",
                            " Shiva",
                            " says",
                            ":",
                            " \"",
                            "For",
                            " the",
                            " benefit",
                            " of",
                            " men",
                            " of",
                            " the",
                            " Kali",
                            " age",
                            ",",
                            " men",
                            " bere",
                            "ft",
                            " of",
                            " energy",
                            " and",
                            " dependent",
                            " for",
                            " existence",
                            " on",
                            " the",
                            " food",
                            " they",
                            " eat",
                            ",",
                            " the",
                            " K",
                            "aul",
                            "a",
                            " doctrine",
                            ",",
                            " O",
                            " ausp",
                            "icious",
                            " one",
                            "!",
                            " is",
                            " given",
                            "\"",
                            " (",
                            "Ch",
                            "ap",
                            ".",
                            " IX",
                            ".,",
                            " verse",
                            " 12",
                            ").",
                            " To",
                            " the",
                            " Tant",
                            "ra",
                            " we",
                            " must",
                            " therefore",
                            " look",
                            " if",
                            " we",
                            " would",
                            " understand",
                            " ar",
                            "ight",
                            " both",
                            " ritual",
                            ",",
                            " yoga",
                            ",",
                            " and",
                            " sad",
                            "h",
                            "ana",
                            " of",
                            " all",
                            " kinds",
                            ",",
                            " as",
                            " also",
                            " the",
                            " general",
                            " principles",
                            " of",
                            " which",
                            " these"
                        ],
                        "dataIndex": null,
                        "index": "93327",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.713,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.497,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.999,
                            0.106,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.154,
                            0,
                            0,
                            0,
                            3.589,
                            7.713,
                            4.598,
                            6.775,
                            5.902,
                            4.835,
                            3.168,
                            3.531,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:05.953Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.016,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj0meqa19h10ex56pmmx5a",
                        "tokens": [
                            " The",
                            " Tant",
                            "ra",
                            " Sh",
                            "ast",
                            "ra",
                            " is",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " and",
                            " whatever",
                            " be",
                            " its",
                            " historical",
                            " origin",
                            ",",
                            " a",
                            " development",
                            " of",
                            " the",
                            " V",
                            "aid",
                            "ika",
                            " K",
                            "arm",
                            "ak",
                            "anda",
                            ",",
                            " promulg",
                            "ated",
                            " to",
                            " meet",
                            " the",
                            " needs",
                            " of",
                            " that",
                            " age",
                            ".",
                            " Shiva",
                            " says",
                            ":",
                            " \"",
                            "For",
                            " the",
                            " benefit",
                            " of",
                            " men",
                            " of",
                            " the",
                            " Kali",
                            " age",
                            ",",
                            " men",
                            " bere",
                            "ft",
                            " of",
                            " energy",
                            " and",
                            " dependent",
                            " for",
                            " existence",
                            " on",
                            " the",
                            " food",
                            " they",
                            " eat",
                            ",",
                            " the",
                            " K",
                            "aul",
                            "a",
                            " doctrine",
                            ",",
                            " O",
                            " ausp",
                            "icious",
                            " one",
                            "!",
                            " is",
                            " given",
                            "\"",
                            " (",
                            "Ch",
                            "ap",
                            ".",
                            " IX",
                            ".,",
                            " verse",
                            " 12",
                            ").",
                            " To",
                            " the",
                            " Tant",
                            "ra",
                            " we",
                            " must",
                            " therefore",
                            " look",
                            " if",
                            " we",
                            " would",
                            " understand",
                            " ar",
                            "ight",
                            " both",
                            " ritual",
                            ",",
                            " yoga",
                            ",",
                            " and",
                            " sad",
                            "h",
                            "ana",
                            " of",
                            " all",
                            " kinds",
                            ",",
                            " as",
                            " also",
                            " the",
                            " general",
                            " principles",
                            " of",
                            " which",
                            " these"
                        ],
                        "dataIndex": null,
                        "index": "93327",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.713,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.497,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.999,
                            0.106,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.154,
                            0,
                            0,
                            0,
                            3.589,
                            7.713,
                            4.598,
                            6.775,
                            5.902,
                            4.835,
                            3.168,
                            3.531,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:05.953Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.016,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21740",
            "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5039531288174919,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21740",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:12:34.087Z",
                "maxActApprox": 36.416,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21740,
                    3088,
                    21487,
                    12947,
                    16697,
                    2946,
                    20433,
                    251,
                    4001,
                    17235,
                    4407,
                    4717,
                    23503,
                    14215,
                    6124,
                    13657,
                    2197,
                    12026,
                    13434,
                    12886,
                    7963,
                    17224,
                    6857,
                    13339,
                    10095
                ],
                "topkCosSimValues": [
                    1,
                    0.5718,
                    0.5358,
                    0.419,
                    0.4171,
                    0.4083,
                    0.3814,
                    0.3811,
                    0.37,
                    0.3452,
                    0.3149,
                    0.3122,
                    0.3097,
                    0.3061,
                    0.3036,
                    0.2992,
                    0.298,
                    0.295,
                    0.2895,
                    0.2846,
                    0.2834,
                    0.283,
                    0.2741,
                    0.2639,
                    0.2629
                ],
                "neuron_alignment_indices": [
                    502,
                    363,
                    741
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.109,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    502,
                    566,
                    718
                ],
                "correlated_neurons_pearson": [
                    0.06,
                    0.05,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.058,
                    0.051,
                    0.041
                ],
                "correlated_features_indices": [
                    21711,
                    21727,
                    21757
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.009,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "umption",
                    " completion",
                    " Proced",
                    " Squid",
                    " sorcery",
                    " summary",
                    "allo",
                    " Volcano",
                    " Spur",
                    " Biology"
                ],
                "neg_values": [
                    -0.638,
                    -0.622,
                    -0.612,
                    -0.611,
                    -0.607,
                    -0.6,
                    -0.596,
                    -0.584,
                    -0.584,
                    -0.582
                ],
                "pos_str": [
                    " adore",
                    " admire",
                    " trusts",
                    " trusted",
                    " sidx",
                    " affection",
                    " befriend",
                    "igl",
                    "assadors",
                    " interviewed"
                ],
                "pos_values": [
                    0.954,
                    0.9,
                    0.865,
                    0.854,
                    0.8,
                    0.797,
                    0.796,
                    0.789,
                    0.779,
                    0.778
                ],
                "frac_nonzero": 0.00222,
                "freq_hist_data_bar_heights": [
                    1873,
                    1215,
                    804,
                    548,
                    393,
                    305,
                    251,
                    190,
                    178,
                    120,
                    116,
                    96,
                    84,
                    68,
                    67,
                    58,
                    59,
                    45,
                    49,
                    47,
                    27,
                    30,
                    25,
                    25,
                    21,
                    26,
                    20,
                    20,
                    19,
                    23,
                    12,
                    21,
                    13,
                    21,
                    16,
                    14,
                    15,
                    7,
                    9,
                    9,
                    12,
                    9,
                    9,
                    1,
                    3,
                    3,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.364,
                    1.093,
                    1.821,
                    2.549,
                    3.278,
                    4.006,
                    4.734,
                    5.463,
                    6.191,
                    6.919,
                    7.648,
                    8.376,
                    9.104,
                    9.833,
                    10.561,
                    11.289,
                    12.018,
                    12.746,
                    13.474,
                    14.203,
                    14.931,
                    15.659,
                    16.388,
                    17.116,
                    17.844,
                    18.572,
                    19.301,
                    20.029,
                    20.757,
                    21.486,
                    22.214,
                    22.942,
                    23.671,
                    24.399,
                    25.127,
                    25.856,
                    26.584,
                    27.312,
                    28.041,
                    28.769,
                    29.497,
                    30.226,
                    30.954,
                    31.682,
                    32.411,
                    33.139,
                    33.867,
                    34.596,
                    35.324,
                    36.052
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    13,
                    15,
                    32,
                    79,
                    124,
                    226,
                    344,
                    526,
                    743,
                    1006,
                    1395,
                    1826,
                    2448,
                    2769,
                    3259,
                    3635,
                    3664,
                    3840,
                    3742,
                    3509,
                    3114,
                    2826,
                    2268,
                    1971,
                    1604,
                    1381,
                    1003,
                    819,
                    556,
                    424,
                    284,
                    218,
                    176,
                    129,
                    84,
                    61,
                    50,
                    26,
                    13,
                    14,
                    9,
                    7,
                    6,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.622,
                    -0.59,
                    -0.558,
                    -0.526,
                    -0.494,
                    -0.463,
                    -0.431,
                    -0.399,
                    -0.367,
                    -0.335,
                    -0.303,
                    -0.272,
                    -0.24,
                    -0.208,
                    -0.176,
                    -0.144,
                    -0.112,
                    -0.081,
                    -0.049,
                    -0.017,
                    0.015,
                    0.047,
                    0.078,
                    0.11,
                    0.142,
                    0.174,
                    0.206,
                    0.238,
                    0.269,
                    0.301,
                    0.333,
                    0.365,
                    0.397,
                    0.429,
                    0.46,
                    0.492,
                    0.524,
                    0.556,
                    0.588,
                    0.62,
                    0.651,
                    0.683,
                    0.715,
                    0.747,
                    0.779,
                    0.811,
                    0.842,
                    0.874,
                    0.906,
                    0.938
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn050nknwui666bug7k88o",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050pknxhi6668it3dmdq",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 29.133,
                        "binMax": 36.416,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050nknwvi666w5dxgs5u",
                        "tokens": [
                            "'s",
                            " just",
                            " b",
                            "oll",
                            "ocks",
                            ".",
                            " Its",
                            " not",
                            " a",
                            " lot",
                            " of",
                            " sugar",
                            " in",
                            " the",
                            " scheme",
                            " of",
                            " things",
                            " at",
                            " all",
                            ",",
                            " and",
                            " the",
                            " stuff",
                            " about",
                            " processed",
                            " meat",
                            " is",
                            " badly",
                            " reported",
                            " and",
                            " misunderstood",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " and",
                            " everyone",
                            " I",
                            " know",
                            " was",
                            " raised",
                            " on",
                            " beans",
                            " on",
                            " toast",
                            " and",
                            " the",
                            " kind",
                            " of",
                            " food",
                            " people",
                            " sne",
                            "er",
                            " about",
                            " on",
                            " here",
                            ".",
                            " Never",
                            " did",
                            " any",
                            " of",
                            " us",
                            " any",
                            " harm",
                            ".",
                            " In",
                            " fact",
                            " its",
                            " now",
                            " that",
                            " everything",
                            " is",
                            " reduced",
                            " sugar",
                            " this",
                            " and",
                            " reduced",
                            " fat",
                            " that",
                            " that",
                            " the",
                            " kids",
                            " are",
                            " all",
                            " getting",
                            " obese",
                            " and",
                            " diabetes",
                            ".",
                            " Everyone",
                            " talks",
                            " about",
                            " kale",
                            " and",
                            " qu",
                            "inoa",
                            " but",
                            " they",
                            " are",
                            " less",
                            " healthy",
                            " than",
                            " those",
                            " of",
                            " us",
                            " raised",
                            " on",
                            " beans",
                            " and",
                            " turkey",
                            " drum",
                            "mers",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " fine",
                            " OP",
                            ",",
                            " its",
                            " food",
                            ".",
                            " Nothing",
                            " even",
                            " slightly",
                            " wrong"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.455,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.455,
                            0.145,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12849",
            "description": "content related to educational psychology and learning experiences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49328070878982544,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12849",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:01:13.921Z",
                "maxActApprox": 49.117,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12849,
                    20008,
                    13240,
                    8581,
                    7804,
                    3969,
                    9365,
                    7187,
                    9709,
                    7511,
                    8895,
                    2951,
                    4849,
                    1353,
                    4375,
                    2878,
                    15591,
                    19680,
                    10990,
                    8921,
                    15005,
                    1833,
                    12980,
                    19318,
                    14797
                ],
                "topkCosSimValues": [
                    1,
                    0.7413,
                    0.5438,
                    0.4984,
                    0.4831,
                    0.4655,
                    0.4593,
                    0.4568,
                    0.4064,
                    0.3952,
                    0.3851,
                    0.3757,
                    0.3671,
                    0.3625,
                    0.3492,
                    0.3279,
                    0.3268,
                    0.322,
                    0.322,
                    0.3211,
                    0.319,
                    0.3172,
                    0.3168,
                    0.3154,
                    0.311
                ],
                "neuron_alignment_indices": [
                    271,
                    62,
                    575
                ],
                "neuron_alignment_values": [
                    0.16,
                    0.119,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.019,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.018,
                    0.015
                ],
                "correlated_features_indices": [
                    12860,
                    12818,
                    12899
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "zzi",
                    "pard",
                    "\u0124\u00aa",
                    "vati",
                    " Shipping",
                    "swick",
                    "senal",
                    "een",
                    " spraying",
                    "tar"
                ],
                "neg_values": [
                    -0.754,
                    -0.694,
                    -0.691,
                    -0.688,
                    -0.684,
                    -0.641,
                    -0.64,
                    -0.636,
                    -0.628,
                    -0.619
                ],
                "pos_str": [
                    " disabilities",
                    " Curve",
                    " curve",
                    " disability",
                    "icult",
                    " aids",
                    "learn",
                    " lessons",
                    " Clicker",
                    " disabled"
                ],
                "pos_values": [
                    1.068,
                    0.925,
                    0.915,
                    0.866,
                    0.768,
                    0.762,
                    0.754,
                    0.738,
                    0.737,
                    0.731
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    115,
                    76,
                    57,
                    36,
                    28,
                    20,
                    12,
                    15,
                    12,
                    11,
                    11,
                    9,
                    12,
                    8,
                    3,
                    5,
                    3,
                    4,
                    6,
                    4,
                    6,
                    13,
                    3,
                    2,
                    3,
                    3,
                    0,
                    4,
                    2,
                    3,
                    1,
                    3,
                    3,
                    3,
                    3,
                    1,
                    3,
                    6,
                    4,
                    1,
                    3,
                    5,
                    5,
                    0,
                    5,
                    1,
                    2,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.5,
                    1.483,
                    2.465,
                    3.447,
                    4.429,
                    5.411,
                    6.393,
                    7.376,
                    8.358,
                    9.34,
                    10.322,
                    11.304,
                    12.286,
                    13.268,
                    14.251,
                    15.233,
                    16.215,
                    17.197,
                    18.179,
                    19.161,
                    20.144,
                    21.126,
                    22.108,
                    23.09,
                    24.072,
                    25.054,
                    26.036,
                    27.019,
                    28.001,
                    28.983,
                    29.965,
                    30.947,
                    31.929,
                    32.912,
                    33.894,
                    34.876,
                    35.858,
                    36.84,
                    37.822,
                    38.804,
                    39.787,
                    40.769,
                    41.751,
                    42.733,
                    43.715,
                    44.697,
                    45.68,
                    46.662,
                    47.644,
                    48.626
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    0,
                    11,
                    21,
                    13,
                    37,
                    71,
                    116,
                    209,
                    346,
                    499,
                    780,
                    1207,
                    1642,
                    2322,
                    2971,
                    3658,
                    4074,
                    4494,
                    4561,
                    4454,
                    4010,
                    3528,
                    2942,
                    2309,
                    1782,
                    1323,
                    892,
                    664,
                    474,
                    313,
                    184,
                    107,
                    88,
                    50,
                    28,
                    24,
                    16,
                    15,
                    10,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.699,
                    -0.662,
                    -0.626,
                    -0.59,
                    -0.553,
                    -0.517,
                    -0.48,
                    -0.444,
                    -0.408,
                    -0.371,
                    -0.335,
                    -0.298,
                    -0.262,
                    -0.225,
                    -0.189,
                    -0.153,
                    -0.116,
                    -0.08,
                    -0.043,
                    -0.007,
                    0.03,
                    0.066,
                    0.102,
                    0.139,
                    0.175,
                    0.212,
                    0.248,
                    0.285,
                    0.321,
                    0.357,
                    0.394,
                    0.43,
                    0.467,
                    0.503,
                    0.539,
                    0.576,
                    0.612,
                    0.649,
                    0.685,
                    0.722,
                    0.758,
                    0.794,
                    0.831,
                    0.867,
                    0.904,
                    0.94,
                    0.977,
                    1.013,
                    1.049
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "content related to educational psychology and learning experiences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmlhmzc7l2i666fxbcpcsw",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhn0c7l6i666zbaenjoe",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhmzc7l3i66681yibbcr",
                        "tokens": [
                            " on",
                            " comparative",
                            " psychology",
                            " and",
                            " the",
                            " learning",
                            " process",
                            " led",
                            " to",
                            " the",
                            " theory",
                            " of",
                            " connection",
                            "ism",
                            " and",
                            " helped",
                            " lay",
                            " the",
                            " scientific",
                            " foundation",
                            " for",
                            " educational",
                            " psychology",
                            ".",
                            " He",
                            " also",
                            " worked",
                            " on",
                            " solving",
                            " industrial",
                            " problems",
                            ",",
                            " such",
                            " as",
                            " employee",
                            " exams",
                            " and",
                            " testing",
                            ".",
                            " He",
                            " was",
                            " a",
                            " member",
                            " of",
                            " the",
                            " board",
                            " of",
                            " the",
                            " Psychological",
                            " Corporation",
                            " and",
                            " served",
                            " as",
                            " president",
                            " of",
                            " the",
                            " American",
                            " Psychological",
                            " Association",
                            " in",
                            " 1912",
                            ".[",
                            "1",
                            "][",
                            "2",
                            "]",
                            " A",
                            " Review",
                            " of",
                            " General",
                            " Psychology",
                            " survey",
                            ",",
                            " published",
                            " in",
                            " 2002",
                            ",",
                            " ranked",
                            " Thor",
                            "nd",
                            "ike",
                            " as",
                            " the",
                            " ninth",
                            "-",
                            "most",
                            " cited",
                            " psychologist",
                            " of",
                            " the",
                            " 20",
                            "th",
                            " century",
                            ".[",
                            "3",
                            "]",
                            " Edward",
                            " Thor",
                            "nd",
                            "ike",
                            " had",
                            " a",
                            " powerful",
                            " impact",
                            " on",
                            " reinforcement",
                            " theory",
                            " and",
                            " behavior",
                            " analysis",
                            ",",
                            " providing",
                            " the",
                            " basic",
                            " framework",
                            " for",
                            " empirical",
                            " laws",
                            " in",
                            " behavior",
                            " psychology",
                            " with",
                            " his",
                            " law",
                            " of",
                            " effect",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.626,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.626,
                            2.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3427",
            "description": "concepts related to teaching and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48560523986816406,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3427",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:27.928Z",
                "maxActApprox": 15.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3427,
                    77561,
                    60325,
                    73728,
                    50077,
                    33640,
                    55572,
                    46187,
                    52346,
                    44237,
                    71908,
                    41600,
                    11,
                    70412,
                    53181,
                    83314,
                    42965,
                    79098,
                    21161,
                    23492,
                    28490,
                    42202,
                    93440,
                    42300,
                    59028
                ],
                "topkCosSimValues": [
                    1,
                    0.5752,
                    0.5313,
                    0.518,
                    0.4759,
                    0.4686,
                    0.4422,
                    0.3923,
                    0.391,
                    0.3864,
                    0.3785,
                    0.3768,
                    0.3757,
                    0.3679,
                    0.367,
                    0.367,
                    0.3629,
                    0.3589,
                    0.3481,
                    0.3475,
                    0.3419,
                    0.3416,
                    0.3379,
                    0.3346,
                    0.3338
                ],
                "neuron_alignment_indices": [
                    635,
                    603,
                    263
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.094,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    263,
                    236,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    3457,
                    3415,
                    3391
                ],
                "correlated_features_pearson": [
                    0.054,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.054,
                    0.009,
                    0.001
                ],
                "neg_str": [
                    "Rum",
                    "storm",
                    "inqu",
                    " Inqu",
                    "estate",
                    "luster",
                    " inquiries",
                    " Noel",
                    " Bellev",
                    " Graves"
                ],
                "neg_values": [
                    -0.653,
                    -0.639,
                    -0.636,
                    -0.612,
                    -0.604,
                    -0.598,
                    -0.595,
                    -0.589,
                    -0.588,
                    -0.586
                ],
                "pos_str": [
                    " versatility",
                    " ropes",
                    " prowess",
                    "agy",
                    " horizont",
                    " ingenuity",
                    "alore",
                    "emade",
                    " vectors",
                    " flexibility"
                ],
                "pos_values": [
                    0.9,
                    0.817,
                    0.79,
                    0.753,
                    0.746,
                    0.734,
                    0.699,
                    0.698,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00055,
                "freq_hist_data_bar_heights": [
                    266,
                    194,
                    153,
                    123,
                    145,
                    105,
                    91,
                    85,
                    57,
                    50,
                    46,
                    43,
                    51,
                    29,
                    23,
                    30,
                    31,
                    15,
                    26,
                    22,
                    20,
                    8,
                    9,
                    10,
                    12,
                    7,
                    6,
                    6,
                    6,
                    6,
                    7,
                    8,
                    4,
                    6,
                    0,
                    3,
                    2,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.164,
                    0.483,
                    0.802,
                    1.121,
                    1.439,
                    1.758,
                    2.077,
                    2.396,
                    2.715,
                    3.033,
                    3.352,
                    3.671,
                    3.99,
                    4.308,
                    4.627,
                    4.946,
                    5.265,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.858,
                    7.177,
                    7.496,
                    7.815,
                    8.133,
                    8.452,
                    8.771,
                    9.09,
                    9.408,
                    9.727,
                    10.046,
                    10.365,
                    10.683,
                    11.002,
                    11.321,
                    11.64,
                    11.958,
                    12.277,
                    12.596,
                    12.915,
                    13.233,
                    13.552,
                    13.871,
                    14.19,
                    14.508,
                    14.827,
                    15.146,
                    15.465,
                    15.784
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    6,
                    21,
                    29,
                    57,
                    67,
                    144,
                    219,
                    332,
                    505,
                    720,
                    983,
                    1366,
                    1739,
                    2245,
                    2684,
                    3097,
                    3501,
                    3914,
                    3820,
                    3809,
                    3646,
                    3331,
                    2951,
                    2520,
                    2074,
                    1696,
                    1302,
                    1023,
                    739,
                    528,
                    402,
                    246,
                    194,
                    117,
                    80,
                    50,
                    29,
                    18,
                    14,
                    10,
                    10,
                    6,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.638,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.203,
                    -0.172,
                    -0.141,
                    -0.11,
                    -0.079,
                    -0.048,
                    -0.016,
                    0.015,
                    0.046,
                    0.077,
                    0.108,
                    0.139,
                    0.17,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.418,
                    0.449,
                    0.48,
                    0.511,
                    0.542,
                    0.574,
                    0.605,
                    0.636,
                    0.667,
                    0.698,
                    0.729,
                    0.76,
                    0.791,
                    0.822,
                    0.853,
                    0.884
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and instructions related to methods and processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to teaching and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf154kdwgm10ex7gzz8956",
                        "tokens": [
                            " Al",
                            "inea",
                            " outside",
                            " Chicago",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " chance",
                            " to",
                            " present",
                            " their",
                            " cooking",
                            " in",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " disc",
                            "erning",
                            " food",
                            " city",
                            " without",
                            " the",
                            " full",
                            "-",
                            "time",
                            " commitment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " can",
                            "'t",
                            " tell",
                            " you",
                            " how",
                            " many",
                            " chefs",
                            " have",
                            " said",
                            " to",
                            " me",
                            ",",
                            " '",
                            "Yeah",
                            ",",
                            " you",
                            "'re",
                            " a",
                            " big",
                            " fish",
                            " in",
                            " a",
                            " small",
                            " pond",
                            ".",
                            " The",
                            " only",
                            " reason",
                            " you",
                            "'re",
                            " so",
                            " popular",
                            " is",
                            " because",
                            " you",
                            "'re",
                            " in",
                            " the",
                            " Midwest",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " In",
                            " a",
                            " way",
                            ",",
                            " we",
                            "'re",
                            " am",
                            "ped",
                            " up",
                            ",\"",
                            " A",
                            "chat",
                            "z",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " want",
                            " to",
                            " introduce",
                            " Al",
                            "inea",
                            " food",
                            " to",
                            " the",
                            " j",
                            "aded",
                            " New",
                            " Yorker",
                            ".",
                            " We",
                            "'re",
                            " going",
                            " to",
                            " show",
                            " New",
                            " Yorkers",
                            " what",
                            " Chicago",
                            " food",
                            " is",
                            " all",
                            " about",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " collaboration"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.943,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            1.683,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.943,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgn10exy3t5v2tt",
                        "tokens": [
                            " has",
                            " come",
                            " to",
                            " this",
                            " particular",
                            " point",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Load",
                            " third",
                            " party",
                            " embed",
                            "\n",
                            "\n",
                            "As",
                            " an",
                            " avid",
                            " bike",
                            ",",
                            " parks",
                            " and",
                            " neighborhood",
                            " advocate",
                            ",",
                            " Ford",
                            " has",
                            " been",
                            " fighting",
                            " the",
                            " decline",
                            " of",
                            " Detroit",
                            " for",
                            " years",
                            ".",
                            " To",
                            " see",
                            " his",
                            " hometown",
                            " become",
                            " trendy",
                            " with",
                            " everyone",
                            " from",
                            " tech",
                            " developers",
                            " to",
                            " hip",
                            "ster",
                            " craft",
                            "-",
                            "l",
                            "iqu",
                            "or",
                            " dist",
                            "ill",
                            "ers",
                            " makes",
                            " him",
                            " laugh",
                            " with",
                            " joy",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Being",
                            " a",
                            " unique",
                            " individual",
                            " showcasing",
                            " your",
                            " talent",
                            " is",
                            " like",
                            " the",
                            " new",
                            " hot",
                            " thing",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Everybody",
                            " wants",
                            " to",
                            " show",
                            " us",
                            " what",
                            " they",
                            " can",
                            " do",
                            ".",
                            " People",
                            " are",
                            " coming",
                            " here",
                            " from",
                            " all",
                            " over",
                            " the",
                            " country",
                            ",",
                            " because",
                            " of",
                            " the",
                            " access",
                            " to",
                            " material",
                            ",",
                            " talent",
                            " and",
                            " overall",
                            " attitude",
                            " to",
                            " get"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.881,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.746,
                            1.82,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.881,
                            4.034,
                            4.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgo10exkj0oeyt1",
                        "tokens": [
                            " I",
                            " would",
                            " love",
                            " to",
                            " show",
                            " how",
                            " the",
                            " card",
                            " handle",
                            " but",
                            " I",
                            "'m",
                            " not",
                            " really",
                            " good",
                            " a",
                            " that",
                            ",",
                            " this",
                            " video",
                            " is",
                            " the",
                            " best",
                            " i",
                            " could",
                            " do",
                            "...",
                            " Sorry",
                            " :(",
                            " https",
                            "://",
                            "www",
                            ".",
                            "youtube",
                            ".",
                            "com",
                            "/",
                            "watch",
                            "?",
                            "v",
                            "=",
                            "U",
                            "An",
                            "8",
                            "g",
                            "U",
                            "5",
                            "r",
                            "61",
                            "s",
                            " ***",
                            " #",
                            "Le",
                            " Website",
                            " To",
                            " make",
                            " all",
                            " this",
                            " a",
                            " little",
                            " less",
                            " complicated",
                            " i",
                            " set",
                            " up",
                            " a",
                            " website",
                            " with",
                            " the",
                            " very",
                            " original",
                            " and",
                            " thought",
                            "-",
                            "through",
                            " name",
                            " [",
                            "L",
                            "OL",
                            "Playing",
                            "C",
                            "ards",
                            ".",
                            "com",
                            "](",
                            "http",
                            "://",
                            "www",
                            ".",
                            "lol",
                            "playing",
                            "cards",
                            ".",
                            "com",
                            "/",
                            ").",
                            " here",
                            " are",
                            " some",
                            " screenshots",
                            ":",
                            " Front",
                            " page",
                            " with",
                            " the",
                            " story",
                            " and",
                            " stuff",
                            "s",
                            ":",
                            " http",
                            "://",
                            "i",
                            ".",
                            "imgur",
                            ".",
                            "com",
                            "/",
                            "q",
                            "fy",
                            "B",
                            "10",
                            "Z",
                            ".",
                            "png",
                            " A",
                            " page"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.408,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.408,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "52826",
            "description": " concepts related to advanced cognitive stages and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48153096437454224,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "52826",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:40:09.008Z",
                "maxActApprox": 15.789,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    52826,
                    96686,
                    40863,
                    97899,
                    71247,
                    24561,
                    48130,
                    55567,
                    8808,
                    71698,
                    35618,
                    28127,
                    92040,
                    57404,
                    84959,
                    81141,
                    50650,
                    6393,
                    35398,
                    60541,
                    43498,
                    33284,
                    6516,
                    4039,
                    90574
                ],
                "topkCosSimValues": [
                    1,
                    0.5445,
                    0.5429,
                    0.4984,
                    0.4932,
                    0.4931,
                    0.4881,
                    0.4847,
                    0.4611,
                    0.4355,
                    0.435,
                    0.4342,
                    0.4316,
                    0.4176,
                    0.4173,
                    0.4145,
                    0.4073,
                    0.4068,
                    0.3996,
                    0.396,
                    0.3915,
                    0.3866,
                    0.3857,
                    0.3852,
                    0.3835
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    621
                ],
                "neuron_alignment_values": [
                    0.163,
                    0.109,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    594,
                    288,
                    459
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.046,
                    0.044
                ],
                "correlated_neurons_l1": [
                    0.046,
                    0.07,
                    0.047
                ],
                "correlated_features_indices": [
                    52914,
                    52866,
                    52812
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.009,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " contagious",
                    " Antar",
                    " embassies",
                    " Stard",
                    " Kazakh",
                    " hay",
                    " Canter",
                    " pseudonym",
                    " Kush",
                    " NEO"
                ],
                "neg_values": [
                    -0.581,
                    -0.564,
                    -0.547,
                    -0.541,
                    -0.541,
                    -0.534,
                    -0.531,
                    -0.524,
                    -0.519,
                    -0.516
                ],
                "pos_str": [
                    " thereof",
                    " counterpart",
                    " meanwhile",
                    " versa",
                    "SPONSORED",
                    "ogy",
                    " likewise",
                    "JV",
                    "OPE",
                    " ones"
                ],
                "pos_values": [
                    0.797,
                    0.767,
                    0.76,
                    0.735,
                    0.693,
                    0.691,
                    0.679,
                    0.677,
                    0.664,
                    0.661
                ],
                "frac_nonzero": 0.006059999999999999,
                "freq_hist_data_bar_heights": [
                    4184,
                    3244,
                    2529,
                    1903,
                    1535,
                    1102,
                    911,
                    727,
                    590,
                    455,
                    339,
                    307,
                    239,
                    190,
                    151,
                    95,
                    84,
                    98,
                    64,
                    62,
                    50,
                    38,
                    36,
                    34,
                    19,
                    14,
                    14,
                    10,
                    8,
                    12,
                    4,
                    7,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    3,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.158,
                    0.474,
                    0.79,
                    1.105,
                    1.421,
                    1.737,
                    2.053,
                    2.368,
                    2.684,
                    3,
                    3.316,
                    3.632,
                    3.947,
                    4.263,
                    4.579,
                    4.895,
                    5.21,
                    5.526,
                    5.842,
                    6.158,
                    6.474,
                    6.789,
                    7.105,
                    7.421,
                    7.737,
                    8.052,
                    8.368,
                    8.684,
                    9,
                    9.315,
                    9.631,
                    9.947,
                    10.263,
                    10.579,
                    10.894,
                    11.21,
                    11.526,
                    11.842,
                    12.157,
                    12.473,
                    12.789,
                    13.105,
                    13.421,
                    13.736,
                    14.052,
                    14.368,
                    14.684,
                    14.999,
                    15.315,
                    15.631
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    8,
                    12,
                    32,
                    71,
                    99,
                    159,
                    283,
                    418,
                    608,
                    824,
                    1265,
                    1646,
                    2052,
                    2465,
                    2834,
                    3124,
                    3399,
                    3510,
                    3403,
                    3327,
                    3074,
                    2771,
                    2408,
                    2225,
                    1945,
                    1750,
                    1422,
                    1192,
                    993,
                    793,
                    622,
                    482,
                    339,
                    249,
                    173,
                    104,
                    63,
                    50,
                    16,
                    11,
                    8,
                    5,
                    5,
                    5,
                    2,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.567,
                    -0.539,
                    -0.512,
                    -0.484,
                    -0.457,
                    -0.429,
                    -0.402,
                    -0.374,
                    -0.347,
                    -0.319,
                    -0.291,
                    -0.264,
                    -0.236,
                    -0.209,
                    -0.181,
                    -0.154,
                    -0.126,
                    -0.099,
                    -0.071,
                    -0.043,
                    -0.016,
                    0.012,
                    0.039,
                    0.067,
                    0.094,
                    0.122,
                    0.149,
                    0.177,
                    0.205,
                    0.232,
                    0.26,
                    0.287,
                    0.315,
                    0.342,
                    0.37,
                    0.397,
                    0.425,
                    0.453,
                    0.48,
                    0.508,
                    0.535,
                    0.563,
                    0.59,
                    0.618,
                    0.645,
                    0.673,
                    0.701,
                    0.728,
                    0.756,
                    0.783
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to advanced cognitive stages and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements related to knowledge and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghg5xgfbje10exspp02x14",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xgfbjl10expd7x9tbo",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xifbk010exgakbmy4t",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.631,
                        "binMax": 15.789,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "87346",
            "description": " concepts related to social constructs and their implications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4756049230334217,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "87346",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:17:33.954Z",
                "maxActApprox": 17.63,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    87346,
                    51884,
                    6523,
                    32062,
                    24997,
                    23497,
                    74702,
                    68682,
                    67130,
                    8202,
                    50632,
                    60235,
                    15588,
                    82094,
                    21277,
                    18813,
                    84284,
                    46129,
                    61680,
                    55965,
                    30968,
                    48735,
                    36592,
                    47035,
                    9752
                ],
                "topkCosSimValues": [
                    1,
                    0.6194,
                    0.6151,
                    0.6076,
                    0.5552,
                    0.5457,
                    0.5354,
                    0.5245,
                    0.4998,
                    0.4994,
                    0.4839,
                    0.4771,
                    0.4642,
                    0.4591,
                    0.4581,
                    0.4489,
                    0.438,
                    0.4358,
                    0.4358,
                    0.4314,
                    0.4314,
                    0.4312,
                    0.4298,
                    0.4276,
                    0.4268
                ],
                "neuron_alignment_indices": [
                    691,
                    469,
                    729
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.109,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    490,
                    691,
                    427
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.033,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.032,
                    0.025
                ],
                "correlated_features_indices": [
                    87352,
                    87339,
                    87377
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " respectively",
                    " awoken",
                    "ufact",
                    "\u00e3\u0124\u00a8",
                    "00007",
                    " Amen",
                    "ilts",
                    "ats",
                    "iblings",
                    "weeney"
                ],
                "neg_values": [
                    -0.689,
                    -0.622,
                    -0.613,
                    -0.585,
                    -0.581,
                    -0.573,
                    -0.571,
                    -0.568,
                    -0.563,
                    -0.562
                ],
                "pos_str": [
                    " nor",
                    " anymore",
                    " necessarily",
                    " slightest",
                    "olithic",
                    "isable",
                    "iable",
                    " coincidence",
                    " fortun",
                    "iev"
                ],
                "pos_values": [
                    1.154,
                    1.133,
                    0.73,
                    0.674,
                    0.67,
                    0.662,
                    0.656,
                    0.633,
                    0.632,
                    0.63
                ],
                "frac_nonzero": 0.00108,
                "freq_hist_data_bar_heights": [
                    532,
                    474,
                    364,
                    276,
                    244,
                    217,
                    165,
                    153,
                    130,
                    108,
                    115,
                    86,
                    75,
                    50,
                    50,
                    56,
                    34,
                    23,
                    27,
                    29,
                    25,
                    20,
                    21,
                    22,
                    15,
                    15,
                    5,
                    6,
                    9,
                    8,
                    6,
                    1,
                    1,
                    5,
                    0,
                    6,
                    3,
                    4,
                    1,
                    2,
                    2,
                    2,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.177,
                    0.529,
                    0.882,
                    1.234,
                    1.587,
                    1.94,
                    2.292,
                    2.645,
                    2.997,
                    3.35,
                    3.702,
                    4.055,
                    4.408,
                    4.76,
                    5.113,
                    5.465,
                    5.818,
                    6.171,
                    6.523,
                    6.876,
                    7.228,
                    7.581,
                    7.934,
                    8.286,
                    8.639,
                    8.991,
                    9.344,
                    9.696,
                    10.049,
                    10.402,
                    10.754,
                    11.107,
                    11.459,
                    11.812,
                    12.165,
                    12.517,
                    12.87,
                    13.222,
                    13.575,
                    13.928,
                    14.28,
                    14.633,
                    14.985,
                    15.338,
                    15.691,
                    16.043,
                    16.396,
                    16.748,
                    17.101,
                    17.454
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    11,
                    18,
                    40,
                    64,
                    129,
                    221,
                    357,
                    674,
                    1076,
                    1534,
                    2177,
                    2912,
                    3721,
                    4397,
                    4787,
                    4971,
                    4620,
                    4315,
                    3595,
                    3148,
                    2321,
                    1785,
                    1243,
                    799,
                    577,
                    338,
                    172,
                    119,
                    59,
                    31,
                    17,
                    9,
                    8,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.671,
                    -0.634,
                    -0.597,
                    -0.56,
                    -0.523,
                    -0.487,
                    -0.45,
                    -0.413,
                    -0.376,
                    -0.339,
                    -0.302,
                    -0.265,
                    -0.228,
                    -0.192,
                    -0.155,
                    -0.118,
                    -0.081,
                    -0.044,
                    -0.007,
                    0.03,
                    0.067,
                    0.103,
                    0.14,
                    0.177,
                    0.214,
                    0.251,
                    0.288,
                    0.325,
                    0.362,
                    0.398,
                    0.435,
                    0.472,
                    0.509,
                    0.546,
                    0.583,
                    0.62,
                    0.657,
                    0.693,
                    0.73,
                    0.767,
                    0.804,
                    0.841,
                    0.878,
                    0.915,
                    0.952,
                    0.988,
                    1.025,
                    1.062,
                    1.099,
                    1.136
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to social constructs and their implications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to abstractness and exclusivity in discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygisbxc5jah10exrf9yh6b4",
                        "tokens": [
                            " are",
                            " some",
                            " of",
                            " those",
                            " suggested",
                            " as",
                            " explaining",
                            " a",
                            " portion",
                            " of",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " IQ",
                            " between",
                            " races",
                            ".",
                            " These",
                            " factors",
                            " are",
                            " not",
                            " mutually",
                            " exclusive",
                            " with",
                            " one",
                            " another",
                            ",",
                            " and",
                            " some",
                            " may",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " contribute",
                            " directly",
                            " to",
                            " others",
                            ".",
                            " Furthermore",
                            ",",
                            " the",
                            " relationship",
                            " between",
                            " genetics",
                            " and",
                            " environmental",
                            " factors",
                            " may",
                            " be",
                            " complicated",
                            ".",
                            " For",
                            " example",
                            ",",
                            " the",
                            " differences",
                            " in",
                            " socioeconomic",
                            " environment",
                            " for",
                            " a",
                            " child",
                            " may",
                            " be",
                            " due",
                            " to",
                            " differences",
                            " in",
                            " genetic",
                            " IQ",
                            " for",
                            " the",
                            " parents",
                            ",",
                            " and",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " brain",
                            " size",
                            " between",
                            " races",
                            " could",
                            " be",
                            " the",
                            " result",
                            " of",
                            " nutritional",
                            " factors",
                            ".",
                            " All",
                            " recent",
                            " reviews",
                            " agree",
                            " that",
                            " some",
                            " environmental",
                            " factors",
                            " that",
                            " are",
                            " unequ",
                            "ally",
                            " distributed",
                            " between",
                            " racial",
                            " groups",
                            " have",
                            " been",
                            " shown",
                            " to",
                            " affect",
                            " intelligence",
                            " in",
                            " ways",
                            " that",
                            " could",
                            " contribute",
                            " to",
                            " the",
                            " test",
                            " score",
                            " gap",
                            ".",
                            " However"
                        ],
                        "dataIndex": null,
                        "index": "87346",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.63,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.626,
                            17.63,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.131Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.104,
                        "binMax": 17.63,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygisbxa5j9x10exp5xxkzav",
                        "tokens": [
                            " are",
                            " some",
                            " of",
                            " those",
                            " suggested",
                            " as",
                            " explaining",
                            " a",
                            " portion",
                            " of",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " IQ",
                            " between",
                            " races",
                            ".",
                            " These",
                            " factors",
                            " are",
                            " not",
                            " mutually",
                            " exclusive",
                            " with",
                            " one",
                            " another",
                            ",",
                            " and",
                            " some",
                            " may",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " contribute",
                            " directly",
                            " to",
                            " others",
                            ".",
                            " Furthermore",
                            ",",
                            " the",
                            " relationship",
                            " between",
                            " genetics",
                            " and",
                            " environmental",
                            " factors",
                            " may",
                            " be",
                            " complicated",
                            ".",
                            " For",
                            " example",
                            ",",
                            " the",
                            " differences",
                            " in",
                            " socioeconomic",
                            " environment",
                            " for",
                            " a",
                            " child",
                            " may",
                            " be",
                            " due",
                            " to",
                            " differences",
                            " in",
                            " genetic",
                            " IQ",
                            " for",
                            " the",
                            " parents",
                            ",",
                            " and",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " brain",
                            " size",
                            " between",
                            " races",
                            " could",
                            " be",
                            " the",
                            " result",
                            " of",
                            " nutritional",
                            " factors",
                            ".",
                            " All",
                            " recent",
                            " reviews",
                            " agree",
                            " that",
                            " some",
                            " environmental",
                            " factors",
                            " that",
                            " are",
                            " unequ",
                            "ally",
                            " distributed",
                            " between",
                            " racial",
                            " groups",
                            " have",
                            " been",
                            " shown",
                            " to",
                            " affect",
                            " intelligence",
                            " in",
                            " ways",
                            " that",
                            " could",
                            " contribute",
                            " to",
                            " the",
                            " test",
                            " score",
                            " gap",
                            ".",
                            " However"
                        ],
                        "dataIndex": null,
                        "index": "87346",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.63,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.626,
                            17.63,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.131Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.63,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygisbxa5j9y10ex71zr1eks",
                        "tokens": [
                            " is",
                            " leading",
                            " the",
                            " excavation",
                            " at",
                            " G\u00c3\u00b6",
                            "bek",
                            "lite",
                            "pe",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            " depicts",
                            " a",
                            " human",
                            " head",
                            " in",
                            " the",
                            " wing",
                            " of",
                            " a",
                            " v",
                            "ulture",
                            " and",
                            " a",
                            " head",
                            "less",
                            " human",
                            " body",
                            " under",
                            " the",
                            " st",
                            "ela",
                            ".",
                            " There",
                            " are",
                            " various",
                            " figures",
                            " like",
                            " cr",
                            "anes",
                            " and",
                            " scorp",
                            "ions",
                            " around",
                            " this",
                            " figure",
                            ".",
                            " This",
                            " is",
                            " the",
                            " portrayal",
                            " of",
                            " a",
                            " moment",
                            ";",
                            " it",
                            " could",
                            " be",
                            " the",
                            " first",
                            " example",
                            " of",
                            " pict",
                            "ograph",
                            ".",
                            " They",
                            " are",
                            " not",
                            " random",
                            " figures",
                            ".",
                            " We",
                            " see",
                            " this",
                            " type",
                            " of",
                            " thing",
                            " portrayal",
                            " on",
                            " the",
                            " walls",
                            " in",
                            " 6",
                            ",",
                            "000",
                            "-",
                            "5",
                            ",",
                            "000",
                            " B",
                            ".",
                            "C",
                            ".",
                            " in",
                            " \u00c3",
                            "\u0129",
                            "atal",
                            "h",
                            "\u00c3\u00b6",
                            "y",
                            "\u00c3\u00bc",
                            "k",
                            " [",
                            "in",
                            " modern",
                            "-",
                            "day",
                            " western",
                            " Turkey",
                            "].",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " \u00e2\u0122",
                            "\u013a",
                            "V",
                            "ulture",
                            "-",
                            "Stone",
                            "\u00e2\u0122",
                            "\u013b",
                            ".",
                            " Credit"
                        ],
                        "dataIndex": null,
                        "index": "87346",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.474,
                        "maxValueTokenIndex": 70,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.474,
                            2.701,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.131Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.63,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "34472",
            "description": "concepts related to understanding and knowledge acquisition",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4749690890312195,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "34472",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:00:49.061Z",
                "maxActApprox": 8.652,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    34472,
                    40351,
                    19229,
                    26183,
                    12737,
                    36064,
                    34171,
                    26658,
                    23624,
                    41598,
                    27830,
                    27472,
                    38013,
                    15624,
                    46100,
                    36221,
                    26314,
                    4131,
                    46711,
                    20780,
                    47822,
                    14572,
                    44650,
                    48515,
                    47098
                ],
                "topkCosSimValues": [
                    1,
                    0.3966,
                    0.388,
                    0.3679,
                    0.3668,
                    0.3552,
                    0.3503,
                    0.3493,
                    0.3418,
                    0.3404,
                    0.3306,
                    0.3274,
                    0.3259,
                    0.3161,
                    0.3135,
                    0.312,
                    0.312,
                    0.3072,
                    0.3071,
                    0.3064,
                    0.3064,
                    0.304,
                    0.3024,
                    0.3023,
                    0.3002
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    568
                ],
                "neuron_alignment_values": [
                    0.189,
                    0.114,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    568,
                    39,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.038,
                    0.035,
                    0.035
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.039,
                    0.022
                ],
                "correlated_features_indices": [
                    34494,
                    34511,
                    34429
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.007,
                    0.004
                ],
                "correlated_features_l1": [
                    0.014,
                    0.008,
                    0.006
                ],
                "neg_str": [
                    " vetoed",
                    " Supporters",
                    " ransom",
                    " veto",
                    " Corker",
                    " billboard",
                    "dor",
                    " Shelter",
                    " billboards",
                    "onement"
                ],
                "neg_values": [
                    -0.742,
                    -0.717,
                    -0.704,
                    -0.698,
                    -0.694,
                    -0.694,
                    -0.694,
                    -0.693,
                    -0.692,
                    -0.691
                ],
                "pos_str": [
                    " learning",
                    "learning",
                    "Learning",
                    " comprehension",
                    " understanding",
                    " knowledge",
                    " beginner",
                    " lear",
                    " learners",
                    " tutorials"
                ],
                "pos_values": [
                    1.364,
                    1.301,
                    1.221,
                    1.201,
                    1.157,
                    1.13,
                    1.127,
                    1.121,
                    1.119,
                    1.109
                ],
                "frac_nonzero": 0.00534,
                "freq_hist_data_bar_heights": [
                    2388,
                    2143,
                    1780,
                    1557,
                    1352,
                    1134,
                    1001,
                    811,
                    720,
                    617,
                    532,
                    427,
                    374,
                    295,
                    278,
                    231,
                    186,
                    136,
                    144,
                    100,
                    95,
                    83,
                    65,
                    55,
                    46,
                    40,
                    37,
                    32,
                    24,
                    14,
                    14,
                    14,
                    8,
                    9,
                    10,
                    7,
                    3,
                    8,
                    6,
                    4,
                    1,
                    2,
                    1,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.26,
                    0.433,
                    0.606,
                    0.779,
                    0.952,
                    1.125,
                    1.298,
                    1.471,
                    1.644,
                    1.817,
                    1.99,
                    2.163,
                    2.336,
                    2.509,
                    2.682,
                    2.855,
                    3.028,
                    3.201,
                    3.374,
                    3.547,
                    3.72,
                    3.893,
                    4.066,
                    4.239,
                    4.412,
                    4.585,
                    4.758,
                    4.931,
                    5.104,
                    5.278,
                    5.451,
                    5.624,
                    5.797,
                    5.97,
                    6.143,
                    6.316,
                    6.489,
                    6.662,
                    6.835,
                    7.008,
                    7.181,
                    7.354,
                    7.527,
                    7.7,
                    7.873,
                    8.046,
                    8.219,
                    8.392,
                    8.565
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    22,
                    46,
                    79,
                    149,
                    319,
                    493,
                    781,
                    1055,
                    1569,
                    2054,
                    2627,
                    3087,
                    3557,
                    3951,
                    4165,
                    4099,
                    3820,
                    3504,
                    3093,
                    2620,
                    2123,
                    1640,
                    1280,
                    999,
                    764,
                    621,
                    435,
                    346,
                    225,
                    194,
                    142,
                    99,
                    80,
                    52,
                    39,
                    39,
                    16,
                    20,
                    12,
                    9,
                    2,
                    5,
                    4,
                    1,
                    2,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.679,
                    -0.636,
                    -0.594,
                    -0.552,
                    -0.51,
                    -0.468,
                    -0.426,
                    -0.384,
                    -0.342,
                    -0.299,
                    -0.257,
                    -0.215,
                    -0.173,
                    -0.131,
                    -0.089,
                    -0.047,
                    -0.005,
                    0.038,
                    0.08,
                    0.122,
                    0.164,
                    0.206,
                    0.248,
                    0.29,
                    0.332,
                    0.375,
                    0.417,
                    0.459,
                    0.501,
                    0.543,
                    0.585,
                    0.627,
                    0.669,
                    0.712,
                    0.754,
                    0.796,
                    0.838,
                    0.88,
                    0.922,
                    0.964,
                    1.006,
                    1.048,
                    1.091,
                    1.133,
                    1.175,
                    1.217,
                    1.259,
                    1.301,
                    1.343
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "concepts related to understanding and knowledge acquisition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6cn2k7f0yi6663jp2hsi8",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 8.652,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6cn2k7f0zi666dlgoplz8",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 8.652,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6cn2m7f1ii666sp15qxku",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 6.921,
                        "binMax": 8.652,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "4641",
            "description": " concepts related to education and training experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47242268919944763,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "4641",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:06:20.802Z",
                "maxActApprox": 12.149,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4641,
                    6207,
                    42773,
                    25823,
                    42009,
                    41405,
                    39702,
                    2403,
                    16393,
                    15383,
                    35402,
                    40345,
                    17573,
                    34861,
                    1518,
                    24990,
                    3037,
                    31918,
                    13437,
                    29019,
                    18190,
                    46920,
                    16843,
                    37772,
                    45240
                ],
                "topkCosSimValues": [
                    1,
                    0.5654,
                    0.514,
                    0.4914,
                    0.4856,
                    0.4809,
                    0.4778,
                    0.4718,
                    0.4642,
                    0.4629,
                    0.462,
                    0.4582,
                    0.4374,
                    0.4337,
                    0.4269,
                    0.4262,
                    0.4213,
                    0.4069,
                    0.4057,
                    0.4015,
                    0.4013,
                    0.3993,
                    0.3952,
                    0.3929,
                    0.3927
                ],
                "neuron_alignment_indices": [
                    158,
                    572,
                    733
                ],
                "neuron_alignment_values": [
                    0.105,
                    0.103,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    572,
                    115
                ],
                "correlated_neurons_pearson": [
                    0.054,
                    0.035,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.067,
                    0.04,
                    0.038
                ],
                "correlated_features_indices": [
                    4696,
                    4631,
                    4624
                ],
                "correlated_features_pearson": [
                    0.01,
                    0.009,
                    0.004
                ],
                "correlated_features_l1": [
                    0.012,
                    0.009,
                    0.005
                ],
                "neg_str": [
                    " embassies",
                    "appropriately",
                    " iPads",
                    " Authors",
                    " assorted",
                    "liest",
                    " Commissioners",
                    "theless",
                    " helicopters",
                    " DVDs"
                ],
                "neg_values": [
                    -0.725,
                    -0.709,
                    -0.707,
                    -0.66,
                    -0.648,
                    -0.646,
                    -0.636,
                    -0.636,
                    -0.631,
                    -0.628
                ],
                "pos_str": [
                    " regimen",
                    " presence",
                    " foothold",
                    " stance",
                    " environment",
                    " trajectory",
                    "ixture",
                    " standpoint",
                    "ibliography",
                    " vibe"
                ],
                "pos_values": [
                    0.903,
                    0.866,
                    0.839,
                    0.839,
                    0.815,
                    0.81,
                    0.799,
                    0.797,
                    0.792,
                    0.787
                ],
                "frac_nonzero": 0.00312,
                "freq_hist_data_bar_heights": [
                    1154,
                    962,
                    885,
                    768,
                    671,
                    594,
                    526,
                    466,
                    432,
                    385,
                    327,
                    292,
                    276,
                    243,
                    232,
                    196,
                    177,
                    162,
                    147,
                    120,
                    108,
                    92,
                    88,
                    85,
                    63,
                    59,
                    62,
                    39,
                    36,
                    28,
                    23,
                    28,
                    12,
                    11,
                    17,
                    9,
                    9,
                    7,
                    6,
                    3,
                    5,
                    2,
                    4,
                    2,
                    2,
                    0,
                    1,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.122,
                    0.365,
                    0.608,
                    0.851,
                    1.094,
                    1.337,
                    1.58,
                    1.823,
                    2.066,
                    2.309,
                    2.552,
                    2.795,
                    3.037,
                    3.28,
                    3.523,
                    3.766,
                    4.009,
                    4.252,
                    4.495,
                    4.738,
                    4.981,
                    5.224,
                    5.467,
                    5.71,
                    5.953,
                    6.196,
                    6.439,
                    6.682,
                    6.925,
                    7.168,
                    7.411,
                    7.654,
                    7.897,
                    8.14,
                    8.383,
                    8.626,
                    8.869,
                    9.112,
                    9.355,
                    9.598,
                    9.841,
                    10.084,
                    10.327,
                    10.57,
                    10.813,
                    11.056,
                    11.299,
                    11.542,
                    11.785,
                    12.028
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    8,
                    24,
                    25,
                    57,
                    96,
                    125,
                    238,
                    359,
                    498,
                    659,
                    860,
                    1211,
                    1501,
                    1893,
                    2199,
                    2631,
                    2961,
                    3195,
                    3312,
                    3402,
                    3304,
                    3121,
                    2859,
                    2589,
                    2313,
                    1970,
                    1785,
                    1491,
                    1245,
                    1033,
                    805,
                    653,
                    543,
                    378,
                    258,
                    232,
                    142,
                    94,
                    61,
                    35,
                    29,
                    22,
                    19,
                    5,
                    7,
                    2,
                    3,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.708,
                    -0.676,
                    -0.643,
                    -0.611,
                    -0.578,
                    -0.546,
                    -0.513,
                    -0.481,
                    -0.448,
                    -0.415,
                    -0.383,
                    -0.35,
                    -0.318,
                    -0.285,
                    -0.253,
                    -0.22,
                    -0.188,
                    -0.155,
                    -0.123,
                    -0.09,
                    -0.057,
                    -0.025,
                    0.008,
                    0.04,
                    0.073,
                    0.105,
                    0.138,
                    0.17,
                    0.203,
                    0.235,
                    0.268,
                    0.301,
                    0.333,
                    0.366,
                    0.398,
                    0.431,
                    0.463,
                    0.496,
                    0.528,
                    0.561,
                    0.593,
                    0.626,
                    0.659,
                    0.691,
                    0.724,
                    0.756,
                    0.789,
                    0.821,
                    0.854,
                    0.886
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to education and training experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4eim8fx5zi666hi8agzcp",
                        "tokens": [
                            " to",
                            " UW",
                            " without",
                            " much",
                            " fan",
                            "fare",
                            " and",
                            " became",
                            " a",
                            " Madison",
                            " star",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " Lad",
                            "ys",
                            "mith",
                            ",",
                            " Wisconsin",
                            " native",
                            ",",
                            " Leon",
                            "hard",
                            " walked",
                            " on",
                            " at",
                            " UW",
                            " in",
                            " 2001",
                            " following",
                            " a",
                            " strong",
                            " high",
                            " school",
                            " career",
                            " at",
                            " Flam",
                            "be",
                            "au",
                            " High",
                            " School",
                            " in",
                            " Tony",
                            ",",
                            " Wisconsin",
                            ".",
                            " His",
                            " humble",
                            " beginnings",
                            " turned",
                            " into",
                            " years",
                            " of",
                            " success",
                            ",",
                            " as",
                            " after",
                            " a",
                            " true",
                            " freshman",
                            " 2001",
                            " season",
                            " spent",
                            " mostly",
                            " playing",
                            " special",
                            " teams",
                            ",",
                            " he",
                            " became",
                            " the",
                            " full",
                            "-",
                            "time",
                            " starter",
                            " at",
                            " strong",
                            " safety",
                            " as",
                            " a",
                            " sophomore",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " went",
                            " on",
                            " to",
                            " start",
                            " 39",
                            " straight",
                            " games",
                            " to",
                            " finish",
                            " out",
                            " his",
                            " career",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " total",
                            ",",
                            " Leon",
                            "hard",
                            " played",
                            " 51",
                            " games",
                            " as",
                            " a",
                            " Bad",
                            "ger",
                            ",",
                            " starting",
                            " 14",
                            " games",
                            " at",
                            " strong",
                            " safety",
                            " and",
                            " 25",
                            " at",
                            " free",
                            " safety",
                            ".",
                            " He"
                        ],
                        "dataIndex": null,
                        "index": "4641",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.149,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.149,
                            7.636,
                            0.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.233,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:22.346Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4eim8fx60i666kmsilzvb",
                        "tokens": [
                            " operatives",
                            " who",
                            " hoped",
                            " he",
                            " would",
                            " be",
                            " tougher",
                            " on",
                            " the",
                            " first",
                            "-",
                            "term",
                            " incumbent",
                            ".",
                            " The",
                            " event",
                            " appeared",
                            " to",
                            " benefit",
                            " He",
                            "it",
                            "kamp",
                            ",",
                            " who",
                            " faces",
                            " a",
                            " tough",
                            " re",
                            "-",
                            "election",
                            " next",
                            " year",
                            ".",
                            "\n",
                            "\n",
                            "Trump",
                            " also",
                            " traveled",
                            " to",
                            " Indiana",
                            " with",
                            " Sen",
                            ".",
                            " Joe",
                            " Donn",
                            "elly",
                            ",",
                            " another",
                            " Democrat",
                            " facing",
                            " a",
                            " difficult",
                            " re",
                            "-",
                            "election",
                            " in",
                            " 2018",
                            ".",
                            " Donn",
                            "elly",
                            " also",
                            " joined",
                            " Vice",
                            " President",
                            " Mike",
                            " Pence",
                            " for",
                            " a",
                            " tax",
                            " reform",
                            " event",
                            " in",
                            " their",
                            " home",
                            " state",
                            ",",
                            " which",
                            " Trump",
                            " carried",
                            " by",
                            " 19",
                            " points",
                            ".",
                            " During",
                            " Tuesday",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " press",
                            " conference",
                            ",",
                            " Donn",
                            "elly",
                            " recalled",
                            " those",
                            " visits",
                            ",",
                            " attempting",
                            " to",
                            " show",
                            " constituents",
                            " he",
                            " was",
                            " willing",
                            " to",
                            " work",
                            " with",
                            " the",
                            " White",
                            " House",
                            ".",
                            " But",
                            " the",
                            " eventual",
                            " legislation",
                            ",",
                            " he",
                            " said",
                            ",",
                            " did",
                            " not",
                            " do",
                            " enough",
                            " for",
                            " middle",
                            "-",
                            "class"
                        ],
                        "dataIndex": null,
                        "index": "4641",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.977,
                        "maxValueTokenIndex": 52,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.293,
                            2.599,
                            6.593,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.977,
                            5.118,
                            6.239,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:22.346Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4eim8fx63i6664u5wdp8e",
                        "tokens": [
                            " operatives",
                            " who",
                            " hoped",
                            " he",
                            " would",
                            " be",
                            " tougher",
                            " on",
                            " the",
                            " first",
                            "-",
                            "term",
                            " incumbent",
                            ".",
                            " The",
                            " event",
                            " appeared",
                            " to",
                            " benefit",
                            " He",
                            "it",
                            "kamp",
                            ",",
                            " who",
                            " faces",
                            " a",
                            " tough",
                            " re",
                            "-",
                            "election",
                            " next",
                            " year",
                            ".",
                            "\n",
                            "\n",
                            "Trump",
                            " also",
                            " traveled",
                            " to",
                            " Indiana",
                            " with",
                            " Sen",
                            ".",
                            " Joe",
                            " Donn",
                            "elly",
                            ",",
                            " another",
                            " Democrat",
                            " facing",
                            " a",
                            " difficult",
                            " re",
                            "-",
                            "election",
                            " in",
                            " 2018",
                            ".",
                            " Donn",
                            "elly",
                            " also",
                            " joined",
                            " Vice",
                            " President",
                            " Mike",
                            " Pence",
                            " for",
                            " a",
                            " tax",
                            " reform",
                            " event",
                            " in",
                            " their",
                            " home",
                            " state",
                            ",",
                            " which",
                            " Trump",
                            " carried",
                            " by",
                            " 19",
                            " points",
                            ".",
                            " During",
                            " Tuesday",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " press",
                            " conference",
                            ",",
                            " Donn",
                            "elly",
                            " recalled",
                            " those",
                            " visits",
                            ",",
                            " attempting",
                            " to",
                            " show",
                            " constituents",
                            " he",
                            " was",
                            " willing",
                            " to",
                            " work",
                            " with",
                            " the",
                            " White",
                            " House",
                            ".",
                            " But",
                            " the",
                            " eventual",
                            " legislation",
                            ",",
                            " he",
                            " said",
                            ",",
                            " did",
                            " not",
                            " do",
                            " enough",
                            " for",
                            " middle",
                            "-",
                            "class"
                        ],
                        "dataIndex": null,
                        "index": "4641",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.977,
                        "maxValueTokenIndex": 52,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.293,
                            2.599,
                            6.593,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.977,
                            5.118,
                            6.239,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:22.346Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47086262702941895,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3544",
            "description": "the presence of recurrent actions or experiences related to personal reflection and learning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46630537309082665,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3544",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:38.051Z",
                "maxActApprox": 16.606,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3544,
                    54715,
                    72128,
                    58583,
                    2037,
                    65425,
                    39991,
                    82171,
                    49577,
                    96323,
                    25399,
                    82101,
                    38137,
                    35752,
                    46740,
                    54792,
                    52435,
                    14475,
                    26788,
                    53443,
                    79595,
                    58656,
                    85400,
                    30264,
                    34526
                ],
                "topkCosSimValues": [
                    1,
                    0.5234,
                    0.4761,
                    0.4418,
                    0.4384,
                    0.4375,
                    0.4342,
                    0.4282,
                    0.4134,
                    0.4091,
                    0.4026,
                    0.4023,
                    0.3879,
                    0.3879,
                    0.3783,
                    0.3675,
                    0.3654,
                    0.3585,
                    0.3581,
                    0.3555,
                    0.3528,
                    0.3513,
                    0.3426,
                    0.3414,
                    0.3381
                ],
                "neuron_alignment_indices": [
                    763,
                    126,
                    579
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.099,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    566,
                    282,
                    579
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.023,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.032,
                    0.025,
                    0.024
                ],
                "correlated_features_indices": [
                    3511,
                    3541,
                    3581
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Nim",
                    " Julius",
                    "States",
                    " Proceedings",
                    "Britain",
                    " Allied",
                    "osion",
                    " Contemporary",
                    "vice",
                    "Picture"
                ],
                "neg_values": [
                    -0.653,
                    -0.646,
                    -0.624,
                    -0.612,
                    -0.6,
                    -0.591,
                    -0.577,
                    -0.568,
                    -0.553,
                    -0.552
                ],
                "pos_str": [
                    "rontal",
                    " enough",
                    "\u00e3\u0124\u00a6\u00e3\u0124\u00b9",
                    "%:",
                    "\u00e3\u0125\u00bc\u00e3\u0124\u00af",
                    "tested",
                    "\u00e3\u0124\u00a2\u00e3\u0125\u00ab",
                    " ourselves",
                    "cedented",
                    "\u00e3\u0125\u0128"
                ],
                "pos_values": [
                    0.758,
                    0.757,
                    0.725,
                    0.715,
                    0.687,
                    0.677,
                    0.665,
                    0.663,
                    0.658,
                    0.655
                ],
                "frac_nonzero": 0.00063,
                "freq_hist_data_bar_heights": [
                    230,
                    186,
                    150,
                    113,
                    93,
                    84,
                    60,
                    45,
                    44,
                    49,
                    38,
                    37,
                    37,
                    34,
                    25,
                    35,
                    28,
                    40,
                    49,
                    49,
                    38,
                    40,
                    48,
                    30,
                    30,
                    27,
                    37,
                    23,
                    30,
                    31,
                    35,
                    31,
                    34,
                    21,
                    15,
                    15,
                    11,
                    9,
                    11,
                    7,
                    9,
                    4,
                    4,
                    4,
                    0,
                    6,
                    4,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.167,
                    0.5,
                    0.832,
                    1.164,
                    1.496,
                    1.828,
                    2.16,
                    2.492,
                    2.824,
                    3.156,
                    3.488,
                    3.82,
                    4.152,
                    4.485,
                    4.817,
                    5.149,
                    5.481,
                    5.813,
                    6.145,
                    6.477,
                    6.809,
                    7.141,
                    7.473,
                    7.805,
                    8.137,
                    8.47,
                    8.802,
                    9.134,
                    9.466,
                    9.798,
                    10.13,
                    10.462,
                    10.794,
                    11.126,
                    11.458,
                    11.79,
                    12.122,
                    12.455,
                    12.787,
                    13.119,
                    13.451,
                    13.783,
                    14.115,
                    14.447,
                    14.779,
                    15.111,
                    15.443,
                    15.775,
                    16.107,
                    16.439
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    3,
                    3,
                    16,
                    33,
                    53,
                    95,
                    142,
                    210,
                    297,
                    430,
                    603,
                    843,
                    1166,
                    1408,
                    1735,
                    2240,
                    2535,
                    2832,
                    3163,
                    3446,
                    3577,
                    3556,
                    3524,
                    3220,
                    2892,
                    2480,
                    2183,
                    1838,
                    1483,
                    1125,
                    894,
                    678,
                    440,
                    356,
                    230,
                    146,
                    119,
                    92,
                    68,
                    34,
                    19,
                    14,
                    9,
                    11,
                    5,
                    2,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.639,
                    -0.61,
                    -0.582,
                    -0.554,
                    -0.526,
                    -0.497,
                    -0.469,
                    -0.441,
                    -0.413,
                    -0.385,
                    -0.356,
                    -0.328,
                    -0.3,
                    -0.272,
                    -0.243,
                    -0.215,
                    -0.187,
                    -0.159,
                    -0.131,
                    -0.102,
                    -0.074,
                    -0.046,
                    -0.018,
                    0.011,
                    0.039,
                    0.067,
                    0.095,
                    0.123,
                    0.152,
                    0.18,
                    0.208,
                    0.236,
                    0.265,
                    0.293,
                    0.321,
                    0.349,
                    0.377,
                    0.406,
                    0.434,
                    0.462,
                    0.49,
                    0.519,
                    0.547,
                    0.575,
                    0.603,
                    0.631,
                    0.66,
                    0.688,
                    0.716,
                    0.744
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "the presence of recurrent actions or experiences related to personal reflection and learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf1ckedzlj10exlg2ll8gn",
                        "tokens": [
                            ".",
                            " Matthew",
                            " 24",
                            ":",
                            "14",
                            " (",
                            "MP",
                            "3",
                            ")",
                            "<|endoftext|>",
                            "I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " always",
                            " managed",
                            " to",
                            " dodge",
                            " the",
                            " bullet",
                            " and",
                            " avoid",
                            " the",
                            " addictive",
                            " pull",
                            " of",
                            " Pok\u00c3\u00a9mon",
                            ".",
                            " Leave",
                            " it",
                            " to",
                            " a",
                            " button",
                            "-",
                            "m",
                            "ashing",
                            " b",
                            "rawler",
                            " with",
                            " plastic",
                            " figur",
                            "ine",
                            " accessories",
                            " to",
                            " finally",
                            " get",
                            " me",
                            " hooked",
                            ".",
                            " At",
                            " first",
                            " glance",
                            ",",
                            " Pok\u00c3\u00a9mon",
                            " Rumble",
                            " U",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " much",
                            " to",
                            " look",
                            " at",
                            ".",
                            " With",
                            " its",
                            " simplistic",
                            " controls",
                            " and",
                            " repetitive",
                            " gameplay",
                            ",",
                            " you",
                            " might",
                            " feel",
                            " inclined",
                            " to",
                            " dismiss",
                            " it",
                            " as",
                            " yet",
                            " another",
                            " cash",
                            "-",
                            "in",
                            " of",
                            " the",
                            " popular",
                            " Nintendo",
                            " franchise",
                            ".",
                            " But",
                            " despite",
                            " its",
                            " faults",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " actually",
                            " much",
                            " more",
                            " to",
                            " Rumble",
                            " U",
                            " than",
                            " meets",
                            " the",
                            " eye",
                            ",",
                            " making",
                            " this",
                            " a",
                            " satisfying",
                            " and",
                            " fun",
                            " little",
                            " title",
                            " for",
                            " fans",
                            " of",
                            " the",
                            " series",
                            " and",
                            " newcomers"
                        ],
                        "dataIndex": null,
                        "index": "3544",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.606,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.606,
                            10.09,
                            3.946,
                            0.348,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:41.326Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.606,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf1ckedzlk10extuy3bnyl",
                        "tokens": [
                            "\n",
                            "I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " always",
                            " been",
                            " one",
                            " to",
                            " pass",
                            " to",
                            " race",
                            ".\"",
                            "\n",
                            "\n",
                            "Did",
                            " you",
                            " set",
                            " out",
                            " to",
                            " train",
                            " a",
                            " champion",
                            " race",
                            " driver",
                            "?",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "No",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "So",
                            " why",
                            " do",
                            " that",
                            " to",
                            " him",
                            "?",
                            "\n",
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " I",
                            " used",
                            " to",
                            " do",
                            " to",
                            " myself",
                            ".",
                            " Initially",
                            " I",
                            " wanted",
                            " him",
                            " to",
                            " be",
                            " a",
                            " rally",
                            " car",
                            " driver",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " passion",
                            ",",
                            " but",
                            " it",
                            " was",
                            " actually",
                            " Karen",
                            " who",
                            " got",
                            " Shane",
                            " to",
                            " do",
                            " the",
                            " Formula",
                            " V",
                            "ee",
                            " Scholarship",
                            " [",
                            "and",
                            " start",
                            " road",
                            " racing",
                            " in",
                            " 2004",
                            "].",
                            " So",
                            " that",
                            " was",
                            " Karen",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " doing",
                            " not",
                            " mine",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " did",
                            " he",
                            " blue",
                            " about",
                            " having",
                            " to",
                            " start",
                            " off",
                            " the",
                            " back",
                            " facing",
                            " backwards",
                            "?",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "3544",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.452,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.452,
                            4.397,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:41.326Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.606,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf1ckedzll10exyq9n4vuy",
                        "tokens": [
                            "les",
                            " from",
                            " side",
                            " to",
                            " side",
                            ",",
                            " moves",
                            " the",
                            " ball",
                            " quickly",
                            " and",
                            " backs",
                            " up",
                            " the",
                            " play",
                            ".",
                            " Take",
                            " the",
                            " Chelsea",
                            " goal",
                            " for",
                            " example",
                            ",",
                            " he",
                            " was",
                            " far",
                            " higher",
                            " up",
                            " the",
                            " pitch",
                            " than",
                            " you",
                            " would",
                            " expect",
                            " a",
                            " player",
                            " of",
                            " that",
                            " position",
                            " to",
                            " be",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " spent",
                            " the",
                            " last",
                            " year",
                            " or",
                            " so",
                            " wondering",
                            " if",
                            " Henderson",
                            " would",
                            " find",
                            " his",
                            " role",
                            " in",
                            " this",
                            " side",
                            " and",
                            " been",
                            " trying",
                            " to",
                            " figure",
                            " out",
                            " what",
                            " it",
                            " would",
                            " be",
                            " if",
                            " so",
                            ".",
                            " Obviously",
                            ",",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " much",
                            " evidence",
                            " to",
                            " go",
                            " on",
                            " but",
                            " the",
                            " last",
                            " few",
                            " games",
                            " have",
                            " shown",
                            " great",
                            " promise",
                            ".",
                            " Top",
                            " teams",
                            " with",
                            " attacking",
                            " intent",
                            " have",
                            " been",
                            " in",
                            " opposition",
                            ",",
                            " as",
                            " have",
                            " Championship",
                            " sides",
                            ",",
                            " sides",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " in",
                            " and",
                            " around",
                            " the",
                            " top",
                            " half"
                        ],
                        "dataIndex": null,
                        "index": "3544",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.975,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.975,
                            0.248,
                            1.162,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:41.326Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.606,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "37298",
            "description": " statements related to teaching and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46477097482854357,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "37298",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:18:08.931Z",
                "maxActApprox": 9.544,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37298,
                    90447,
                    44148,
                    93599,
                    2714,
                    82087,
                    36307,
                    18136,
                    17278,
                    70016,
                    71300,
                    59012,
                    23643,
                    97518,
                    40768,
                    70808,
                    98181,
                    78615,
                    85101,
                    21925,
                    40309,
                    53445,
                    26319,
                    42245,
                    49591
                ],
                "topkCosSimValues": [
                    1,
                    0.5543,
                    0.5408,
                    0.5356,
                    0.517,
                    0.516,
                    0.5119,
                    0.5118,
                    0.4883,
                    0.4736,
                    0.4733,
                    0.4704,
                    0.4662,
                    0.4625,
                    0.4608,
                    0.4595,
                    0.4592,
                    0.4577,
                    0.4546,
                    0.4544,
                    0.4533,
                    0.4516,
                    0.4492,
                    0.448,
                    0.4464
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    218
                ],
                "neuron_alignment_values": [
                    0.264,
                    0.118,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    8,
                    566,
                    87
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.037,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.056,
                    0.039,
                    -0.014
                ],
                "correlated_features_indices": [
                    37301,
                    37309,
                    37397
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "rete",
                    "aucas",
                    "atile",
                    " Unique",
                    "ciating",
                    " oval",
                    " exceeds",
                    " ambul",
                    "nexus",
                    "yth"
                ],
                "neg_values": [
                    -0.555,
                    -0.545,
                    -0.534,
                    -0.529,
                    -0.502,
                    -0.495,
                    -0.492,
                    -0.474,
                    -0.474,
                    -0.474
                ],
                "pos_str": [
                    " nonetheless",
                    " nevertheless",
                    " apologies",
                    " caveats",
                    " caution",
                    "endix",
                    " doubtless",
                    " gladly",
                    "warning",
                    " caveat"
                ],
                "pos_values": [
                    0.872,
                    0.768,
                    0.758,
                    0.707,
                    0.683,
                    0.641,
                    0.638,
                    0.63,
                    0.624,
                    0.624
                ],
                "frac_nonzero": 0.00287,
                "freq_hist_data_bar_heights": [
                    1368,
                    1126,
                    971,
                    817,
                    720,
                    624,
                    563,
                    441,
                    389,
                    346,
                    262,
                    219,
                    176,
                    182,
                    137,
                    119,
                    96,
                    87,
                    54,
                    60,
                    58,
                    36,
                    34,
                    32,
                    21,
                    19,
                    13,
                    11,
                    12,
                    9,
                    6,
                    3,
                    7,
                    2,
                    6,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.286,
                    0.477,
                    0.668,
                    0.859,
                    1.05,
                    1.241,
                    1.432,
                    1.623,
                    1.813,
                    2.004,
                    2.195,
                    2.386,
                    2.577,
                    2.768,
                    2.959,
                    3.149,
                    3.34,
                    3.531,
                    3.722,
                    3.913,
                    4.104,
                    4.295,
                    4.486,
                    4.676,
                    4.867,
                    5.058,
                    5.249,
                    5.44,
                    5.631,
                    5.822,
                    6.012,
                    6.203,
                    6.394,
                    6.585,
                    6.776,
                    6.967,
                    7.158,
                    7.349,
                    7.539,
                    7.73,
                    7.921,
                    8.112,
                    8.303,
                    8.494,
                    8.685,
                    8.875,
                    9.066,
                    9.257,
                    9.448
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    7,
                    14,
                    28,
                    58,
                    117,
                    184,
                    319,
                    492,
                    788,
                    1177,
                    1627,
                    2113,
                    2641,
                    3121,
                    3628,
                    3919,
                    3956,
                    3942,
                    3876,
                    3556,
                    3014,
                    2683,
                    2153,
                    1739,
                    1406,
                    1057,
                    774,
                    568,
                    356,
                    295,
                    209,
                    159,
                    95,
                    63,
                    47,
                    20,
                    20,
                    13,
                    5,
                    8,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.541,
                    -0.512,
                    -0.484,
                    -0.455,
                    -0.426,
                    -0.398,
                    -0.369,
                    -0.341,
                    -0.312,
                    -0.284,
                    -0.255,
                    -0.227,
                    -0.198,
                    -0.17,
                    -0.141,
                    -0.113,
                    -0.084,
                    -0.055,
                    -0.027,
                    0.002,
                    0.03,
                    0.059,
                    0.087,
                    0.116,
                    0.144,
                    0.173,
                    0.201,
                    0.23,
                    0.259,
                    0.287,
                    0.316,
                    0.344,
                    0.373,
                    0.401,
                    0.43,
                    0.458,
                    0.487,
                    0.515,
                    0.544,
                    0.573,
                    0.601,
                    0.63,
                    0.658,
                    0.687,
                    0.715,
                    0.744,
                    0.772,
                    0.801,
                    0.829,
                    0.858
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements related to teaching and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases expressing advice or suggestions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggntmh3k9e10ex8zq32xmy",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmj3k9y10exc6tmgsm1",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.635,
                        "binMax": 9.543,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmh3k9f10exukem1fpm",
                        "tokens": [
                            " this",
                            " console",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "Now",
                            " N",
                            "aughty",
                            " Dog",
                            " returns",
                            " to",
                            " the",
                            " spotlight",
                            " with",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            ".",
                            " Both",
                            " expected",
                            "ly",
                            " and",
                            " amazingly",
                            ",",
                            " N",
                            "aughty",
                            " Dog",
                            " has",
                            " indeed",
                            " best",
                            "ed",
                            " Nate",
                            "'s",
                            " first",
                            " adventure",
                            " and",
                            " has",
                            " created",
                            " a",
                            " sequel",
                            " that",
                            " is",
                            " not",
                            " only",
                            " bigger",
                            " and",
                            " better",
                            " in",
                            " practically",
                            " every",
                            " way",
                            ",",
                            " but",
                            " also",
                            " packs",
                            " a",
                            " multiplayer",
                            " component",
                            " that",
                            " could",
                            " be",
                            " released",
                            " as",
                            " its",
                            " own",
                            " separate",
                            ",",
                            " full",
                            "-",
                            "priced",
                            " game",
                            " and",
                            " people",
                            " would",
                            " stand",
                            " in",
                            " line",
                            " to",
                            " hand",
                            " over",
                            " their",
                            " cash",
                            ".",
                            "\n",
                            "\n",
                            "Yes",
                            ",",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            " is",
                            " fantastic",
                            ".",
                            "\n",
                            "\n",
                            "Click",
                            " the",
                            " image",
                            " to",
                            " watch",
                            " our",
                            " in",
                            "-",
                            "depth",
                            " video",
                            " review",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "rying",
                            " to",
                            " remain",
                            " as",
                            " spoiler",
                            "-",
                            "free",
                            " as",
                            " possible",
                            ",",
                            " I",
                            "'ll"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.545,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.14,
                            7.545
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "8181",
            "description": "references to lessons and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.45780205726623535,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "8181",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:12:28.743Z",
                "maxActApprox": 53.204,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8181,
                    46953,
                    11474,
                    33871,
                    37022,
                    46722,
                    46531,
                    44019,
                    32839,
                    5768,
                    44382,
                    14838,
                    27830,
                    35811,
                    10248,
                    34244,
                    47808,
                    12664,
                    22854,
                    24835,
                    46048,
                    46696,
                    47724,
                    48202,
                    11447
                ],
                "topkCosSimValues": [
                    1,
                    0.5135,
                    0.4978,
                    0.4883,
                    0.4749,
                    0.458,
                    0.4562,
                    0.4173,
                    0.4081,
                    0.4074,
                    0.407,
                    0.4065,
                    0.4019,
                    0.3995,
                    0.388,
                    0.3831,
                    0.381,
                    0.3798,
                    0.3789,
                    0.3775,
                    0.37,
                    0.3698,
                    0.3689,
                    0.3677,
                    0.3659
                ],
                "neuron_alignment_indices": [
                    35,
                    615,
                    438
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    438,
                    324,
                    98
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.013,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.013,
                    0.014
                ],
                "correlated_features_indices": [
                    8126,
                    8201,
                    8185
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.004,
                    0.001
                ],
                "correlated_features_l1": [
                    0.007,
                    0.004,
                    0.001
                ],
                "neg_str": [
                    "BLIC",
                    "rencies",
                    "idays",
                    "ords",
                    " contiguous",
                    " occupancy",
                    "endars",
                    "roid",
                    "oreal",
                    "ovo"
                ],
                "neg_values": [
                    -0.66,
                    -0.657,
                    -0.645,
                    -0.636,
                    -0.623,
                    -0.622,
                    -0.621,
                    -0.615,
                    -0.603,
                    -0.598
                ],
                "pos_str": [
                    " Learned",
                    " learned",
                    " learnt",
                    " lessons",
                    " taught",
                    "Lear",
                    " lesson",
                    " Teach",
                    "learn",
                    "ister"
                ],
                "pos_values": [
                    1.353,
                    1.16,
                    1.091,
                    1.054,
                    1.038,
                    1.023,
                    1.006,
                    0.909,
                    0.907,
                    0.807
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    87,
                    40,
                    40,
                    14,
                    13,
                    12,
                    7,
                    4,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    3,
                    0,
                    1,
                    2,
                    4,
                    4,
                    1,
                    4,
                    6,
                    10,
                    4,
                    7,
                    1,
                    7,
                    8,
                    5,
                    5,
                    5,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.533,
                    1.597,
                    2.661,
                    3.725,
                    4.789,
                    5.853,
                    6.917,
                    7.981,
                    9.045,
                    10.109,
                    11.174,
                    12.238,
                    13.302,
                    14.366,
                    15.43,
                    16.494,
                    17.558,
                    18.622,
                    19.686,
                    20.75,
                    21.814,
                    22.878,
                    23.942,
                    25.006,
                    26.07,
                    27.134,
                    28.198,
                    29.263,
                    30.327,
                    31.391,
                    32.455,
                    33.519,
                    34.583,
                    35.647,
                    36.711,
                    37.775,
                    38.839,
                    39.903,
                    40.967,
                    42.031,
                    43.095,
                    44.159,
                    45.223,
                    46.287,
                    47.352,
                    48.416,
                    49.48,
                    50.544,
                    51.608,
                    52.672
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    7,
                    18,
                    34,
                    77,
                    131,
                    243,
                    426,
                    676,
                    1089,
                    1621,
                    2306,
                    3088,
                    3793,
                    4551,
                    5011,
                    5265,
                    4817,
                    4478,
                    3770,
                    2848,
                    2102,
                    1418,
                    900,
                    647,
                    390,
                    227,
                    119,
                    81,
                    49,
                    20,
                    15,
                    12,
                    2,
                    7,
                    2,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.64,
                    -0.6,
                    -0.56,
                    -0.52,
                    -0.479,
                    -0.439,
                    -0.399,
                    -0.358,
                    -0.318,
                    -0.278,
                    -0.238,
                    -0.197,
                    -0.157,
                    -0.117,
                    -0.077,
                    -0.036,
                    0.004,
                    0.044,
                    0.084,
                    0.125,
                    0.165,
                    0.205,
                    0.245,
                    0.286,
                    0.326,
                    0.366,
                    0.406,
                    0.447,
                    0.487,
                    0.527,
                    0.568,
                    0.608,
                    0.648,
                    0.688,
                    0.729,
                    0.769,
                    0.809,
                    0.849,
                    0.89,
                    0.93,
                    0.97,
                    1.01,
                    1.051,
                    1.091,
                    1.131,
                    1.171,
                    1.212,
                    1.252,
                    1.292,
                    1.333
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to lessons and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4mjp1j6xhi666yxp4bygr",
                        "tokens": [
                            "\"",
                            " know",
                            " and",
                            " newcomers",
                            " do",
                            " not",
                            ".",
                            " Instead",
                            ",",
                            " it",
                            " is",
                            " about",
                            " lessons",
                            " that",
                            " we",
                            " all",
                            " need",
                            " to",
                            " learn",
                            " more",
                            " than",
                            " once",
                            ",",
                            " and",
                            " remind",
                            " ourselves",
                            " of",
                            ".",
                            " It",
                            " is",
                            " about",
                            " tendencies",
                            " that",
                            " are",
                            " common",
                            ",",
                            " and",
                            " understandable",
                            ",",
                            " and",
                            " come",
                            " with",
                            " the",
                            " flush",
                            " of",
                            " excitement",
                            " of",
                            " learning",
                            " any",
                            " new",
                            " thing",
                            " that",
                            " we",
                            " understand",
                            " is",
                            " important",
                            ",",
                            " and",
                            " about",
                            " the",
                            " difficulty",
                            ",",
                            " always",
                            ",",
                            " in",
                            " trying",
                            " to",
                            " decide",
                            " how",
                            " best",
                            " to",
                            " convey",
                            " that",
                            " excitement",
                            " and",
                            " sense",
                            " of",
                            " importance",
                            " to",
                            " others",
                            ",",
                            " in",
                            " a",
                            " way",
                            " that",
                            " they",
                            " will",
                            " listen",
                            ".",
                            " It",
                            " is",
                            " written",
                            " more",
                            " specifically",
                            ",",
                            " but",
                            " only",
                            " because",
                            " I",
                            " have",
                            " found",
                            " that",
                            " if",
                            " we",
                            " don",
                            "'t",
                            " talk",
                            " specifics",
                            " as",
                            " well",
                            " as",
                            " general",
                            "ities",
                            ",",
                            " the",
                            " general",
                            "ities",
                            " make",
                            " no",
                            " sense",
                            ".",
                            " This",
                            " holds",
                            " for",
                            " algebra",
                            "ic",
                            " structures"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.204,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.204,
                            2.58,
                            0,
                            0,
                            0,
                            0.684,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4mjp1j6xii666zfxspbvm",
                        "tokens": [
                            " race",
                            " report",
                            " immediately",
                            " after",
                            ",",
                            " trying",
                            " to",
                            " remember",
                            " as",
                            " much",
                            " detail",
                            " as",
                            " I",
                            " possibly",
                            " can",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " post",
                            "-",
                            "mortem",
                            ",",
                            " to",
                            " assess",
                            " what",
                            ",",
                            " if",
                            " any",
                            ",",
                            " went",
                            " wrong",
                            ",",
                            " lessons",
                            " learned",
                            " and",
                            " things",
                            " to",
                            " improve",
                            " for",
                            " a",
                            " subsequent",
                            " race",
                            ".",
                            "\n",
                            "\n",
                            "Maybe",
                            " elite",
                            " runners",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " PR",
                            "S",
                            ",",
                            " but",
                            " for",
                            " a",
                            " late",
                            "-",
                            "bl",
                            "oom",
                            "er",
                            ",",
                            " mere",
                            "-",
                            "m",
                            "ortal",
                            ",",
                            " mid",
                            "-",
                            "pack",
                            " runner",
                            " like",
                            " me",
                            "?",
                            " I",
                            " find",
                            " this",
                            " preparation",
                            " insanely",
                            " helpful",
                            " to",
                            " get",
                            " to",
                            " the",
                            " finish",
                            " line",
                            " in",
                            " one",
                            " piece",
                            " while",
                            " still",
                            " smiling",
                            ".",
                            " Not",
                            " to",
                            " mention",
                            " how",
                            " grat",
                            "ifying",
                            " it",
                            " is",
                            " to",
                            " see",
                            " the",
                            " week",
                            " long",
                            " strategy",
                            " play",
                            " out",
                            " during",
                            " the",
                            " race",
                            ".",
                            " Most",
                            " of",
                            " the",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "Related"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.077,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.077,
                            8.3,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4mjp1j6xji666f21i7qgq",
                        "tokens": [
                            " EU",
                            " when",
                            " other",
                            " players",
                            " \u2013",
                            " the",
                            " US",
                            ",",
                            " China",
                            ",",
                            " India",
                            " \u2013",
                            " are",
                            " the",
                            " size",
                            " of",
                            " continents",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "ameron",
                            " touches",
                            " on",
                            " this",
                            " when",
                            " he",
                            " talks",
                            " about",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "global",
                            " race",
                            "\u00e2\u0122",
                            "\u013f",
                            " but",
                            " he",
                            " has",
                            " in",
                            " mind",
                            " a",
                            " commercial",
                            " rivalry",
                            " played",
                            " out",
                            " within",
                            " globally",
                            " recognised",
                            " boundaries",
                            " of",
                            " free",
                            "-",
                            "market",
                            " capitalism",
                            ".",
                            " A",
                            " lesson",
                            " from",
                            " Crimea",
                            " is",
                            " that",
                            " some",
                            " states",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " play",
                            " by",
                            " those",
                            " rules",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " much",
                            " point",
                            " expecting",
                            " a",
                            " more",
                            " sophisticated",
                            " account",
                            " of",
                            " Britain",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " role",
                            " in",
                            " the",
                            " world",
                            " from",
                            " the",
                            " Prime",
                            " Minister",
                            ".",
                            " It",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " in",
                            " his",
                            " nature",
                            " to",
                            " dwell",
                            " on",
                            " perplex",
                            "ing",
                            " things",
                            ".",
                            " His",
                            " friends",
                            " present",
                            " his",
                            " short",
                            " attention",
                            " span",
                            " as",
                            " a",
                            " healthy",
                            " aversion"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.317,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.317,
                            0.365,
                            0,
                            0.291,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "1105",
            "description": " concepts related to understanding and knowledge acquisition",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4516497254371643,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "1105",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:29:52.011Z",
                "maxActApprox": 17.973,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1105,
                    8294,
                    59619,
                    60810,
                    91605,
                    44064,
                    17480,
                    23047,
                    73120,
                    20644,
                    90785,
                    42673,
                    90312,
                    63175,
                    71910,
                    50957,
                    67784,
                    14769,
                    73782,
                    13254,
                    62879,
                    40739,
                    47132,
                    26937,
                    85894
                ],
                "topkCosSimValues": [
                    1,
                    0.5255,
                    0.521,
                    0.5,
                    0.4949,
                    0.4879,
                    0.4756,
                    0.4691,
                    0.4663,
                    0.4545,
                    0.4272,
                    0.4045,
                    0.4028,
                    0.4001,
                    0.3979,
                    0.3967,
                    0.3931,
                    0.3898,
                    0.388,
                    0.3871,
                    0.3865,
                    0.3791,
                    0.3761,
                    0.3718,
                    0.3686
                ],
                "neuron_alignment_indices": [
                    481,
                    755,
                    97
                ],
                "neuron_alignment_values": [
                    0.179,
                    0.111,
                    0.088
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    755,
                    285,
                    271
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.027,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.026,
                    0.024,
                    0.024
                ],
                "correlated_features_indices": [
                    1099,
                    1102,
                    1112
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "aughters",
                    "uries",
                    " comeback",
                    "ager",
                    "edition",
                    "democracy",
                    "onement",
                    "aturdays",
                    " suicides",
                    " outp"
                ],
                "neg_values": [
                    -0.812,
                    -0.794,
                    -0.693,
                    -0.672,
                    -0.663,
                    -0.628,
                    -0.621,
                    -0.615,
                    -0.614,
                    -0.609
                ],
                "pos_str": [
                    " basics",
                    " HOW",
                    " how",
                    " fundamentals",
                    " WHY",
                    "ledge",
                    " Concepts",
                    " beforehand",
                    " trig",
                    " anatomy"
                ],
                "pos_values": [
                    1.12,
                    1.074,
                    1.041,
                    1.032,
                    1.017,
                    0.894,
                    0.869,
                    0.867,
                    0.856,
                    0.85
                ],
                "frac_nonzero": 0.00077,
                "freq_hist_data_bar_heights": [
                    437,
                    317,
                    250,
                    233,
                    186,
                    180,
                    94,
                    94,
                    78,
                    66,
                    70,
                    45,
                    56,
                    44,
                    43,
                    27,
                    18,
                    13,
                    26,
                    18,
                    15,
                    12,
                    13,
                    10,
                    9,
                    4,
                    9,
                    10,
                    6,
                    3,
                    6,
                    1,
                    3,
                    3,
                    2,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.181,
                    0.541,
                    0.9,
                    1.26,
                    1.619,
                    1.978,
                    2.338,
                    2.697,
                    3.057,
                    3.416,
                    3.776,
                    4.135,
                    4.494,
                    4.854,
                    5.213,
                    5.573,
                    5.932,
                    6.292,
                    6.651,
                    7.01,
                    7.37,
                    7.729,
                    8.089,
                    8.448,
                    8.808,
                    9.167,
                    9.526,
                    9.886,
                    10.245,
                    10.605,
                    10.964,
                    11.323,
                    11.683,
                    12.042,
                    12.402,
                    12.761,
                    13.121,
                    13.48,
                    13.839,
                    14.199,
                    14.558,
                    14.918,
                    15.277,
                    15.637,
                    15.996,
                    16.355,
                    16.715,
                    17.074,
                    17.434,
                    17.793
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    0,
                    3,
                    2,
                    12,
                    19,
                    43,
                    97,
                    178,
                    278,
                    504,
                    784,
                    1134,
                    1648,
                    2209,
                    2811,
                    3520,
                    4008,
                    4413,
                    4333,
                    4297,
                    3859,
                    3525,
                    2929,
                    2500,
                    1953,
                    1500,
                    1081,
                    806,
                    576,
                    424,
                    276,
                    172,
                    121,
                    84,
                    55,
                    34,
                    23,
                    16,
                    9,
                    4,
                    6,
                    3,
                    1,
                    0,
                    0,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.793,
                    -0.754,
                    -0.715,
                    -0.677,
                    -0.638,
                    -0.6,
                    -0.561,
                    -0.522,
                    -0.484,
                    -0.445,
                    -0.406,
                    -0.368,
                    -0.329,
                    -0.29,
                    -0.252,
                    -0.213,
                    -0.174,
                    -0.136,
                    -0.097,
                    -0.058,
                    -0.02,
                    0.019,
                    0.058,
                    0.096,
                    0.135,
                    0.174,
                    0.212,
                    0.251,
                    0.289,
                    0.328,
                    0.367,
                    0.405,
                    0.444,
                    0.483,
                    0.521,
                    0.56,
                    0.599,
                    0.637,
                    0.676,
                    0.715,
                    0.753,
                    0.792,
                    0.831,
                    0.869,
                    0.908,
                    0.947,
                    0.985,
                    1.024,
                    1.062,
                    1.101
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to understanding and knowledge acquisition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts related to comprehension and understanding",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygexrt5c5x510exfbscfey6",
                        "tokens": [
                            " to",
                            " create",
                            " tension",
                            ",",
                            " which",
                            " means",
                            " you",
                            " just",
                            " learned",
                            " something",
                            " really",
                            " important",
                            " about",
                            " game",
                            " design",
                            "!",
                            "\n",
                            "\n",
                            "Once",
                            " you",
                            " understand",
                            " how",
                            " games",
                            " affect",
                            " you",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " able",
                            " to",
                            " start",
                            " to",
                            " see",
                            " how",
                            " they",
                            " affect",
                            " others",
                            ".",
                            " Some",
                            " experiences",
                            " found",
                            " in",
                            " games",
                            " are",
                            " for",
                            " a",
                            " very",
                            " narrow",
                            " audience",
                            ",",
                            " but",
                            " many",
                            " experiences",
                            " are",
                            " experienced",
                            " similarly",
                            " by",
                            " players",
                            " everywhere",
                            ",",
                            " and",
                            " so",
                            " understanding",
                            " yourself",
                            " will",
                            " do",
                            " a",
                            " huge",
                            " service",
                            " to",
                            " you",
                            " understanding",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "PASS",
                            "ION",
                            "\n",
                            "\n",
                            "Well",
                            ",",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " summary",
                            " info",
                            " about",
                            " what",
                            " I",
                            " think",
                            " it",
                            " takes",
                            " to",
                            " do",
                            " game",
                            " design",
                            ",",
                            " but",
                            " how",
                            " does",
                            " one",
                            " know",
                            " if",
                            " game",
                            " design",
                            " is",
                            " really",
                            " something",
                            " they",
                            " should",
                            " pursue",
                            "?",
                            "\n",
                            "\n",
                            "I",
                            " think",
                            " that",
                            " sometimes",
                            " our"
                        ],
                        "dataIndex": null,
                        "index": "1105",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.973,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.59,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.973,
                            8.307,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.968,
                            4.24,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.221,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.373,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:54.524Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.973,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygexrt6c5x610exn2tncac3",
                        "tokens": [
                            " that",
                            " the",
                            " design",
                            " is",
                            " made",
                            " of",
                            " many",
                            " different",
                            " shapes",
                            ".",
                            " This",
                            " can",
                            " get",
                            " messy",
                            " when",
                            " trying",
                            " to",
                            " print",
                            " the",
                            " artwork",
                            " in",
                            " layers",
                            ",",
                            " as",
                            " you",
                            " need",
                            " to",
                            " with",
                            " screen",
                            "-",
                            "print",
                            "ing",
                            ".",
                            " So",
                            " I",
                            " need",
                            " to",
                            " separate",
                            " the",
                            " colors",
                            " into",
                            " two",
                            " layers",
                            " (",
                            "the",
                            " brown",
                            " and",
                            " the",
                            " te",
                            "al",
                            " layers",
                            ")",
                            " so",
                            " that",
                            " when",
                            " the",
                            " layers",
                            " overlap",
                            " they",
                            " do",
                            " not",
                            " interfere",
                            " with",
                            " each",
                            " other",
                            ".",
                            "\n",
                            "\n",
                            "Step",
                            " 4",
                            "a",
                            "\n",
                            "\n",
                            "This",
                            " next",
                            " step",
                            " is",
                            " the",
                            " basic",
                            " process",
                            " that",
                            " will",
                            " be",
                            " repeated",
                            " throughout",
                            " this",
                            " tut",
                            ",",
                            " so",
                            " its",
                            " important",
                            " to",
                            " understand",
                            ".",
                            " It",
                            " will",
                            " involve",
                            " adding",
                            " or",
                            " subtract",
                            "ing",
                            " combinations",
                            " of",
                            " shapes",
                            " using",
                            " the",
                            " path",
                            "finder",
                            " palette",
                            ".",
                            " Suggest",
                            "ion",
                            ":",
                            " experiment",
                            " with",
                            " every",
                            " option",
                            " of",
                            " this",
                            " palette",
                            ".",
                            " It",
                            "'s",
                            " the",
                            " easiest",
                            " way",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "1105",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.676,
                        "maxValueTokenIndex": 92,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.676,
                            1.838,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:54.524Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.973,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygexrt8c5xs10exg55pp9l7",
                        "tokens": [
                            " that",
                            " the",
                            " design",
                            " is",
                            " made",
                            " of",
                            " many",
                            " different",
                            " shapes",
                            ".",
                            " This",
                            " can",
                            " get",
                            " messy",
                            " when",
                            " trying",
                            " to",
                            " print",
                            " the",
                            " artwork",
                            " in",
                            " layers",
                            ",",
                            " as",
                            " you",
                            " need",
                            " to",
                            " with",
                            " screen",
                            "-",
                            "print",
                            "ing",
                            ".",
                            " So",
                            " I",
                            " need",
                            " to",
                            " separate",
                            " the",
                            " colors",
                            " into",
                            " two",
                            " layers",
                            " (",
                            "the",
                            " brown",
                            " and",
                            " the",
                            " te",
                            "al",
                            " layers",
                            ")",
                            " so",
                            " that",
                            " when",
                            " the",
                            " layers",
                            " overlap",
                            " they",
                            " do",
                            " not",
                            " interfere",
                            " with",
                            " each",
                            " other",
                            ".",
                            "\n",
                            "\n",
                            "Step",
                            " 4",
                            "a",
                            "\n",
                            "\n",
                            "This",
                            " next",
                            " step",
                            " is",
                            " the",
                            " basic",
                            " process",
                            " that",
                            " will",
                            " be",
                            " repeated",
                            " throughout",
                            " this",
                            " tut",
                            ",",
                            " so",
                            " its",
                            " important",
                            " to",
                            " understand",
                            ".",
                            " It",
                            " will",
                            " involve",
                            " adding",
                            " or",
                            " subtract",
                            "ing",
                            " combinations",
                            " of",
                            " shapes",
                            " using",
                            " the",
                            " path",
                            "finder",
                            " palette",
                            ".",
                            " Suggest",
                            "ion",
                            ":",
                            " experiment",
                            " with",
                            " every",
                            " option",
                            " of",
                            " this",
                            " palette",
                            ".",
                            " It",
                            "'s",
                            " the",
                            " easiest",
                            " way",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "1105",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.676,
                        "maxValueTokenIndex": 92,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.676,
                            1.838,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:54.524Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.378,
                        "binMax": 17.973,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5368",
            "description": "statements related to education and teaching methods",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44991092234584484,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5368",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:26.905Z",
                "maxActApprox": 40.572,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5368,
                    5681,
                    4191,
                    3878,
                    4574,
                    723,
                    407,
                    3647,
                    2419,
                    1460,
                    2278,
                    2769,
                    3848,
                    3311,
                    1370,
                    1154,
                    2255,
                    4728,
                    4634,
                    2208,
                    3651,
                    24,
                    4188,
                    5488,
                    1073
                ],
                "topkCosSimValues": [
                    1,
                    0.4779,
                    0.4544,
                    0.4237,
                    0.4202,
                    0.3907,
                    0.3893,
                    0.375,
                    0.3556,
                    0.3397,
                    0.3274,
                    0.3194,
                    0.3128,
                    0.3117,
                    0.3048,
                    0.293,
                    0.2913,
                    0.2848,
                    0.2829,
                    0.2712,
                    0.2708,
                    0.2705,
                    0.2698,
                    0.2661,
                    0.2601
                ],
                "neuron_alignment_indices": [
                    546,
                    698,
                    765
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.112,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    546,
                    765,
                    43
                ],
                "correlated_neurons_pearson": [
                    0.147,
                    0.117,
                    0.116
                ],
                "correlated_neurons_l1": [
                    0.146,
                    0.121,
                    0.105
                ],
                "correlated_features_indices": [
                    5286,
                    5324,
                    5358
                ],
                "correlated_features_pearson": [
                    0.115,
                    0.035,
                    0.016
                ],
                "correlated_features_l1": [
                    0.119,
                    0.04,
                    0.02
                ],
                "neg_str": [
                    "uta",
                    "itol",
                    " Zeal",
                    "\u00e3\u0123\u0142",
                    "cast",
                    "thora",
                    "venth",
                    "chnology",
                    "uther",
                    " GG"
                ],
                "neg_values": [
                    -0.677,
                    -0.584,
                    -0.577,
                    -0.576,
                    -0.566,
                    -0.559,
                    -0.556,
                    -0.551,
                    -0.544,
                    -0.541
                ],
                "pos_str": [
                    " according",
                    " says",
                    "according",
                    " said",
                    " writes",
                    " experts",
                    "said",
                    " analysts",
                    " observes",
                    " explained"
                ],
                "pos_values": [
                    1.418,
                    1.113,
                    1.1,
                    1.079,
                    0.911,
                    0.904,
                    0.886,
                    0.884,
                    0.829,
                    0.828
                ],
                "frac_nonzero": 0.01185,
                "freq_hist_data_bar_heights": [
                    7376,
                    5300,
                    3830,
                    3039,
                    2342,
                    1933,
                    1697,
                    1450,
                    1190,
                    1033,
                    868,
                    833,
                    636,
                    653,
                    534,
                    506,
                    423,
                    416,
                    302,
                    330,
                    286,
                    271,
                    251,
                    202,
                    189,
                    182,
                    141,
                    156,
                    119,
                    118,
                    102,
                    85,
                    91,
                    63,
                    57,
                    45,
                    36,
                    35,
                    36,
                    17,
                    27,
                    22,
                    19,
                    13,
                    11,
                    8,
                    3,
                    4,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.406,
                    1.217,
                    2.029,
                    2.84,
                    3.651,
                    4.463,
                    5.274,
                    6.086,
                    6.897,
                    7.709,
                    8.52,
                    9.331,
                    10.143,
                    10.954,
                    11.766,
                    12.577,
                    13.389,
                    14.2,
                    15.011,
                    15.823,
                    16.634,
                    17.446,
                    18.257,
                    19.069,
                    19.88,
                    20.691,
                    21.503,
                    22.314,
                    23.126,
                    23.937,
                    24.749,
                    25.56,
                    26.371,
                    27.183,
                    27.994,
                    28.806,
                    29.617,
                    30.429,
                    31.24,
                    32.051,
                    32.863,
                    33.674,
                    34.486,
                    35.297,
                    36.109,
                    36.92,
                    37.731,
                    38.543,
                    39.354,
                    40.166
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    7,
                    24,
                    31,
                    65,
                    154,
                    313,
                    558,
                    990,
                    1568,
                    2592,
                    3493,
                    4521,
                    5249,
                    5643,
                    5445,
                    4876,
                    4117,
                    3263,
                    2374,
                    1716,
                    1189,
                    772,
                    516,
                    296,
                    178,
                    105,
                    69,
                    45,
                    25,
                    23,
                    9,
                    10,
                    4,
                    8,
                    0,
                    4,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.656,
                    -0.614,
                    -0.572,
                    -0.53,
                    -0.488,
                    -0.446,
                    -0.404,
                    -0.363,
                    -0.321,
                    -0.279,
                    -0.237,
                    -0.195,
                    -0.153,
                    -0.111,
                    -0.069,
                    -0.027,
                    0.014,
                    0.056,
                    0.098,
                    0.14,
                    0.182,
                    0.224,
                    0.266,
                    0.308,
                    0.35,
                    0.391,
                    0.433,
                    0.475,
                    0.517,
                    0.559,
                    0.601,
                    0.643,
                    0.685,
                    0.727,
                    0.768,
                    0.81,
                    0.852,
                    0.894,
                    0.936,
                    0.978,
                    1.02,
                    1.062,
                    1.104,
                    1.145,
                    1.187,
                    1.229,
                    1.271,
                    1.313,
                    1.355,
                    1.397
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "statements related to education and teaching methods",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtgs65xpjwi6667wv6k8da",
                        "tokens": [
                            " It",
                            " also",
                            " could",
                            " mean",
                            " that",
                            " schools",
                            " are",
                            " missing",
                            " the",
                            " right",
                            " time",
                            " to",
                            " teach",
                            " those",
                            " subjects",
                            ".",
                            "\n",
                            "\n",
                            "School",
                            "s",
                            " ought",
                            " to",
                            " consider",
                            " some",
                            " gender",
                            "-",
                            "based",
                            " curric",
                            "ula",
                            ",",
                            " Jensen",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " beyond",
                            " gender",
                            " differences",
                            ",",
                            " if",
                            " every",
                            " student",
                            " were",
                            " given",
                            " a",
                            " neurological",
                            " evaluation",
                            ",",
                            " educators",
                            " would",
                            " have",
                            " powerful",
                            " clues",
                            " as",
                            " to",
                            " the",
                            " best",
                            " way",
                            " to",
                            " personal",
                            "ize",
                            " learning",
                            ",",
                            " she",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Br",
                            "ains",
                            " are",
                            " in",
                            " such",
                            " a",
                            " different",
                            " state",
                            " from",
                            " person",
                            " to",
                            " person",
                            ",",
                            " they",
                            " should",
                            " be",
                            " taught",
                            " differently",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "<|endoftext|>",
                            "Why",
                            " has",
                            " the",
                            " BBC",
                            " become",
                            " the",
                            " official",
                            " propaganda",
                            " arm",
                            " of",
                            " the",
                            " Vatican",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " Vatican",
                            " is",
                            " desperate",
                            " to",
                            " rehabilit",
                            "ate",
                            " its",
                            " reputation",
                            ".",
                            " And",
                            " well",
                            " it",
                            " might",
                            " be",
                            ".",
                            " The",
                            " past"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.572,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.621,
                            0,
                            5.03,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.4,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.66,
                            0.712,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.572,
                            2.983,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.879,
                            11.477,
                            5.085,
                            0,
                            0,
                            6.51,
                            33.86,
                            3.338,
                            10.238,
                            1.222,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjxi666fvxm0wp4",
                        "tokens": [
                            " and",
                            " run",
                            " east",
                            "bound",
                            " on",
                            " Roosevelt",
                            " Street",
                            ",",
                            " said",
                            " Deputy",
                            " Jo",
                            "aquin",
                            " En",
                            "ri",
                            "quez",
                            ",",
                            " a",
                            " sheriff",
                            "'s",
                            " spokesman",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " detention",
                            " officers",
                            " secured",
                            " the",
                            " other",
                            " two",
                            " inmates",
                            ",",
                            " and",
                            " the",
                            " second",
                            " detention",
                            " officer",
                            " hopped",
                            " back",
                            " in",
                            " the",
                            " van",
                            " and",
                            " took",
                            " off",
                            " after",
                            " Fres",
                            "cas",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            " Another",
                            " deputy",
                            " was",
                            " called",
                            " for",
                            " backup",
                            ",",
                            " and",
                            " the",
                            " hospital",
                            " was",
                            " placed",
                            " on",
                            " a",
                            " brief",
                            " lockdown",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " officer",
                            " caught",
                            " up",
                            " with",
                            " Fres",
                            "cas",
                            " about",
                            " 500",
                            " yards",
                            " away",
                            " from",
                            " the",
                            " hospital",
                            ",",
                            " exited",
                            " the",
                            " van",
                            " and",
                            " a",
                            " struggle",
                            " ensued",
                            " over",
                            " the",
                            " officer",
                            "'s",
                            " weapon",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Investigators",
                            " say",
                            " Fres",
                            "cas",
                            " held",
                            " the",
                            " gun",
                            " at",
                            " one",
                            " point",
                            ",",
                            " but",
                            " it",
                            " was",
                            " unclear",
                            " whether",
                            " Fres"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.617,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.701,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.935,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.219,
                            0,
                            0,
                            3.136,
                            0,
                            0,
                            15.275,
                            0,
                            0,
                            5.967,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.623,
                            0,
                            0,
                            0,
                            0.513,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.758,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.191,
                            0,
                            0.513,
                            39.617,
                            1.141,
                            0,
                            5.073,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjyi666ft8m5a48",
                        "tokens": [
                            "than",
                            "-",
                            "usual",
                            " target",
                            " number",
                            " may",
                            " be",
                            " partially",
                            " driven",
                            " by",
                            " an",
                            " effort",
                            " to",
                            " reach",
                            " a",
                            " deportation",
                            " goal",
                            " at",
                            " the",
                            " end",
                            " of",
                            " the",
                            " fiscal",
                            " year",
                            ",",
                            " which",
                            " ends",
                            " Sept",
                            ".",
                            " 30",
                            ",",
                            " one",
                            " of",
                            " the",
                            " officials",
                            " said",
                            ".",
                            " Operation",
                            " Mega",
                            " is",
                            " still",
                            " in",
                            " the",
                            " planning",
                            " stage",
                            " and",
                            " its",
                            " details",
                            " may",
                            " change",
                            " or",
                            " it",
                            " may",
                            " even",
                            " be",
                            " cancelled",
                            ",",
                            " the",
                            " officials",
                            " said",
                            ",",
                            " especially",
                            " as",
                            " the",
                            " agency",
                            " re",
                            "alloc",
                            "ates",
                            " resources",
                            " toward",
                            " rescue",
                            " operations",
                            " in",
                            " Florida",
                            " ahead",
                            " of",
                            " the",
                            " looming",
                            " Hurricane",
                            " Irma",
                            ".",
                            " If",
                            " carried",
                            " out",
                            ",",
                            " it",
                            " would",
                            " come",
                            " on",
                            " the",
                            " heels",
                            " of",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " controversial",
                            " decision",
                            " to",
                            " end",
                            " the",
                            " Def",
                            "erred",
                            " Action",
                            " for",
                            " Childhood",
                            " Arri",
                            "vals",
                            " program",
                            ",",
                            " known",
                            " as",
                            " DACA",
                            ",",
                            " that",
                            " allows",
                            " some",
                            " immigrants",
                            " who",
                            " were",
                            " brought",
                            " into",
                            " the",
                            " United",
                            " States",
                            " as",
                            " children"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.38,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.587,
                            0.206,
                            0,
                            0,
                            0,
                            0,
                            29.692,
                            9.692,
                            0.4,
                            3.468,
                            0.9,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.005,
                            1.471,
                            0,
                            2.862,
                            0,
                            0,
                            0,
                            0.226,
                            39.38,
                            4.746,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36819",
            "description": "references to various types of educational or institutional frameworks",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4476508560596908,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36819",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 9.08,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36819,
                    27504,
                    29349,
                    73305,
                    90627,
                    5153,
                    94870,
                    20575,
                    81240,
                    92629,
                    30939,
                    20532,
                    94271,
                    54877,
                    87745,
                    74536,
                    64760,
                    95329,
                    3582,
                    10769,
                    87992,
                    65711,
                    7099,
                    8563,
                    57646
                ],
                "topkCosSimValues": [
                    1,
                    0.4184,
                    0.3677,
                    0.3662,
                    0.3658,
                    0.3554,
                    0.3549,
                    0.3522,
                    0.3516,
                    0.3503,
                    0.3487,
                    0.3459,
                    0.3441,
                    0.3425,
                    0.338,
                    0.3341,
                    0.3293,
                    0.3287,
                    0.328,
                    0.3227,
                    0.3218,
                    0.3181,
                    0.3178,
                    0.3158,
                    0.3147
                ],
                "neuron_alignment_indices": [
                    294,
                    71,
                    679
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.103,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    575,
                    146
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.027,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.039,
                    0.033,
                    0.023
                ],
                "correlated_features_indices": [
                    36828,
                    36783,
                    36835
                ],
                "correlated_features_pearson": [
                    0.015,
                    0.006,
                    0.006
                ],
                "correlated_features_l1": [
                    0.015,
                    0.007,
                    0.007
                ],
                "neg_str": [
                    "erb",
                    "bound",
                    " earthqu",
                    "locked",
                    "bread",
                    "mel",
                    "cigarettes",
                    "col",
                    "cpu",
                    "biology"
                ],
                "neg_values": [
                    -0.594,
                    -0.594,
                    -0.574,
                    -0.571,
                    -0.568,
                    -0.56,
                    -0.559,
                    -0.548,
                    -0.517,
                    -0.514
                ],
                "pos_str": [
                    "ary",
                    " alike",
                    "ulhu",
                    "\u00e8\u0122\u0127",
                    "ierre",
                    "jriwal",
                    "aries",
                    "alam",
                    "unia",
                    " Preview"
                ],
                "pos_values": [
                    0.717,
                    0.705,
                    0.612,
                    0.592,
                    0.571,
                    0.564,
                    0.546,
                    0.546,
                    0.545,
                    0.544
                ],
                "frac_nonzero": 0.00111,
                "freq_hist_data_bar_heights": [
                    424,
                    402,
                    354,
                    319,
                    247,
                    224,
                    254,
                    182,
                    148,
                    133,
                    123,
                    109,
                    85,
                    85,
                    63,
                    54,
                    55,
                    31,
                    34,
                    29,
                    16,
                    22,
                    19,
                    18,
                    18,
                    10,
                    8,
                    4,
                    5,
                    1,
                    2,
                    5,
                    2,
                    2,
                    1,
                    1,
                    2,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.092,
                    0.273,
                    0.455,
                    0.636,
                    0.818,
                    1,
                    1.181,
                    1.363,
                    1.544,
                    1.726,
                    1.908,
                    2.089,
                    2.271,
                    2.452,
                    2.634,
                    2.816,
                    2.997,
                    3.179,
                    3.36,
                    3.542,
                    3.724,
                    3.905,
                    4.087,
                    4.268,
                    4.45,
                    4.631,
                    4.813,
                    4.995,
                    5.176,
                    5.358,
                    5.539,
                    5.721,
                    5.903,
                    6.084,
                    6.266,
                    6.447,
                    6.629,
                    6.811,
                    6.992,
                    7.174,
                    7.355,
                    7.537,
                    7.719,
                    7.9,
                    8.082,
                    8.263,
                    8.445,
                    8.626,
                    8.808,
                    8.99
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    3,
                    1,
                    9,
                    17,
                    35,
                    46,
                    78,
                    131,
                    209,
                    338,
                    482,
                    606,
                    878,
                    1124,
                    1542,
                    1986,
                    2247,
                    2744,
                    3075,
                    3356,
                    3624,
                    3809,
                    3752,
                    3609,
                    3174,
                    2919,
                    2526,
                    1959,
                    1664,
                    1237,
                    934,
                    657,
                    495,
                    329,
                    225,
                    154,
                    111,
                    67,
                    50,
                    19,
                    12,
                    5,
                    8,
                    2,
                    2,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.581,
                    -0.555,
                    -0.528,
                    -0.502,
                    -0.476,
                    -0.45,
                    -0.424,
                    -0.397,
                    -0.371,
                    -0.345,
                    -0.319,
                    -0.292,
                    -0.266,
                    -0.24,
                    -0.214,
                    -0.188,
                    -0.161,
                    -0.135,
                    -0.109,
                    -0.083,
                    -0.056,
                    -0.03,
                    -0.004,
                    0.022,
                    0.048,
                    0.075,
                    0.101,
                    0.127,
                    0.153,
                    0.18,
                    0.206,
                    0.232,
                    0.258,
                    0.285,
                    0.311,
                    0.337,
                    0.363,
                    0.389,
                    0.416,
                    0.442,
                    0.468,
                    0.494,
                    0.521,
                    0.547,
                    0.573,
                    0.599,
                    0.625,
                    0.652,
                    0.678,
                    0.704
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " terms related to academic and scientific contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to various types of educational or institutional frameworks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to academic disciplines and research proposals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmz6s374110ex62pnweml",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " leave",
                            " loose",
                            " ends",
                            ".",
                            "\n",
                            "\n",
                            "Cut",
                            ",",
                            " cut",
                            ",",
                            " cut",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            ",",
                            " I",
                            " think",
                            ",",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " important",
                            " to",
                            " begin",
                            " with",
                            " the",
                            " NS",
                            "FD",
                            "DR",
                            "IG",
                            " is",
                            " that",
                            " it",
                            " is",
                            " easier",
                            " (",
                            "for",
                            " me",
                            ")",
                            " to",
                            " trim",
                            " and",
                            " cut",
                            " material",
                            " than",
                            " it",
                            " is",
                            " to",
                            " add",
                            ".",
                            " It",
                            " is",
                            " true",
                            " that",
                            " some",
                            " agencies",
                            " are",
                            " asking",
                            " different",
                            " kinds",
                            " of",
                            " questions",
                            ".",
                            " The",
                            " Social",
                            " Science",
                            " Research",
                            " Council",
                            ",",
                            " for",
                            " example",
                            ",",
                            " wants",
                            " Mellon",
                            " International",
                            " Diss",
                            "ertation",
                            " Research",
                            " Fellowship",
                            " proposals",
                            " to",
                            " draw",
                            " heavily",
                            " on",
                            " inter",
                            "dis",
                            "cipl",
                            "in",
                            "arity",
                            ",",
                            " so",
                            " I",
                            " wrote",
                            " about",
                            " feminist",
                            " geography",
                            ",",
                            " urban",
                            " studies",
                            ",",
                            " global",
                            " health",
                            ",",
                            " and",
                            " the",
                            " sociology",
                            " of",
                            " space",
                            ".",
                            " The",
                            " Wen",
                            "ner",
                            "-",
                            "G",
                            "ren",
                            " Diss",
                            "ertation",
                            " Field",
                            "work",
                            " Grant"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.08,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.08,
                            0,
                            0.262,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.08,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmz6u374n10ex9zbu39mf",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " leave",
                            " loose",
                            " ends",
                            ".",
                            "\n",
                            "\n",
                            "Cut",
                            ",",
                            " cut",
                            ",",
                            " cut",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            ",",
                            " I",
                            " think",
                            ",",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " important",
                            " to",
                            " begin",
                            " with",
                            " the",
                            " NS",
                            "FD",
                            "DR",
                            "IG",
                            " is",
                            " that",
                            " it",
                            " is",
                            " easier",
                            " (",
                            "for",
                            " me",
                            ")",
                            " to",
                            " trim",
                            " and",
                            " cut",
                            " material",
                            " than",
                            " it",
                            " is",
                            " to",
                            " add",
                            ".",
                            " It",
                            " is",
                            " true",
                            " that",
                            " some",
                            " agencies",
                            " are",
                            " asking",
                            " different",
                            " kinds",
                            " of",
                            " questions",
                            ".",
                            " The",
                            " Social",
                            " Science",
                            " Research",
                            " Council",
                            ",",
                            " for",
                            " example",
                            ",",
                            " wants",
                            " Mellon",
                            " International",
                            " Diss",
                            "ertation",
                            " Research",
                            " Fellowship",
                            " proposals",
                            " to",
                            " draw",
                            " heavily",
                            " on",
                            " inter",
                            "dis",
                            "cipl",
                            "in",
                            "arity",
                            ",",
                            " so",
                            " I",
                            " wrote",
                            " about",
                            " feminist",
                            " geography",
                            ",",
                            " urban",
                            " studies",
                            ",",
                            " global",
                            " health",
                            ",",
                            " and",
                            " the",
                            " sociology",
                            " of",
                            " space",
                            ".",
                            " The",
                            " Wen",
                            "ner",
                            "-",
                            "G",
                            "ren",
                            " Diss",
                            "ertation",
                            " Field",
                            "work",
                            " Grant"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.08,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.08,
                            0,
                            0.262,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.264,
                        "binMax": 9.08,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmz6s374210excv7avn35",
                        "tokens": [
                            " differ",
                            " in",
                            " a",
                            " default",
                            " value",
                            " are",
                            " a",
                            " redef",
                            "inition",
                            ",",
                            " not",
                            " an",
                            " overload",
                            ".)",
                            " But",
                            " because",
                            " a",
                            " parameter",
                            " pack",
                            " can",
                            " be",
                            " empty",
                            " (",
                            "and",
                            " will",
                            " be",
                            " in",
                            " this",
                            " use",
                            " case",
                            "),",
                            " the",
                            " two",
                            " definitions",
                            " are",
                            " really",
                            " the",
                            " same",
                            " in",
                            " practice",
                            ".",
                            " It",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " matter",
                            " which",
                            " definition",
                            " gets",
                            " the",
                            " parameter",
                            " pack",
                            " because",
                            ",",
                            " as",
                            " we",
                            " just",
                            " discussed",
                            ",",
                            " it",
                            " will",
                            " be",
                            " empty",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            " that",
                            " the",
                            " compiler",
                            " rejects",
                            " a",
                            " redef",
                            "inition",
                            " is",
                            " because",
                            " it",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " which",
                            " function",
                            " to",
                            " call",
                            ",",
                            " the",
                            " original",
                            " or",
                            " the",
                            " redef",
                            "inition",
                            ".",
                            " By",
                            " using",
                            " the",
                            " empty",
                            " parameter",
                            " pack",
                            " trick",
                            " to",
                            " fool",
                            " the",
                            " compiler",
                            " into",
                            " thinking",
                            " that",
                            " these",
                            " are",
                            " two",
                            " different",
                            " definitions",
                            " when",
                            " in",
                            " practice",
                            " they",
                            " really",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            ",",
                            " aren",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.443,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.212,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.443,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.08,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "45527",
            "description": " key insights or lessons derived from various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44372910261154175,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "45527",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:30:59.401Z",
                "maxActApprox": 18.521,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    45527,
                    49603,
                    65736,
                    97883,
                    31877,
                    62861,
                    76867,
                    69954,
                    89628,
                    72320,
                    96613,
                    28189,
                    69761,
                    52905,
                    87712,
                    88187,
                    40231,
                    15583,
                    62125,
                    7998,
                    37956,
                    54048,
                    82540,
                    60424,
                    47339
                ],
                "topkCosSimValues": [
                    1,
                    0.578,
                    0.5137,
                    0.5133,
                    0.5122,
                    0.4465,
                    0.4398,
                    0.4378,
                    0.4356,
                    0.4334,
                    0.4246,
                    0.4216,
                    0.417,
                    0.4095,
                    0.404,
                    0.3999,
                    0.394,
                    0.3936,
                    0.3923,
                    0.391,
                    0.3871,
                    0.3862,
                    0.3839,
                    0.3825,
                    0.3819
                ],
                "neuron_alignment_indices": [
                    447,
                    542,
                    200
                ],
                "neuron_alignment_values": [
                    0.174,
                    0.113,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    679,
                    540,
                    386
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.025,
                    0.025
                ],
                "correlated_neurons_l1": [
                    0.033,
                    0.029,
                    0.027
                ],
                "correlated_features_indices": [
                    45468,
                    45438,
                    45547
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "NetMessage",
                    "endars",
                    "dule",
                    "him",
                    "liv",
                    "nec",
                    "odes",
                    "ugu",
                    "rir",
                    " masse"
                ],
                "neg_values": [
                    -0.967,
                    -0.921,
                    -0.757,
                    -0.735,
                    -0.687,
                    -0.683,
                    -0.657,
                    -0.656,
                    -0.651,
                    -0.65
                ],
                "pos_str": [
                    " underpin",
                    " uttered",
                    "argument",
                    " glean",
                    " emerges",
                    " refrain",
                    " articulated",
                    " argument",
                    " economists",
                    "SourceFile"
                ],
                "pos_values": [
                    0.882,
                    0.784,
                    0.737,
                    0.723,
                    0.703,
                    0.688,
                    0.67,
                    0.665,
                    0.664,
                    0.66
                ],
                "frac_nonzero": 0.0005899999999999999,
                "freq_hist_data_bar_heights": [
                    280,
                    251,
                    208,
                    170,
                    131,
                    106,
                    94,
                    99,
                    62,
                    51,
                    39,
                    53,
                    35,
                    42,
                    23,
                    29,
                    33,
                    14,
                    24,
                    14,
                    13,
                    15,
                    6,
                    8,
                    7,
                    4,
                    3,
                    5,
                    7,
                    2,
                    5,
                    7,
                    1,
                    1,
                    2,
                    3,
                    0,
                    1,
                    1,
                    3,
                    4,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.186,
                    0.556,
                    0.927,
                    1.297,
                    1.667,
                    2.038,
                    2.408,
                    2.779,
                    3.149,
                    3.519,
                    3.89,
                    4.26,
                    4.631,
                    5.001,
                    5.371,
                    5.742,
                    6.112,
                    6.483,
                    6.853,
                    7.223,
                    7.594,
                    7.964,
                    8.335,
                    8.705,
                    9.075,
                    9.446,
                    9.816,
                    10.187,
                    10.557,
                    10.927,
                    11.298,
                    11.668,
                    12.039,
                    12.409,
                    12.779,
                    13.15,
                    13.52,
                    13.891,
                    14.261,
                    14.631,
                    15.002,
                    15.372,
                    15.743,
                    16.113,
                    16.483,
                    16.854,
                    17.224,
                    17.595,
                    17.965,
                    18.336
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    4,
                    8,
                    17,
                    42,
                    70,
                    113,
                    198,
                    328,
                    503,
                    730,
                    1111,
                    1519,
                    1989,
                    2578,
                    3089,
                    3697,
                    4175,
                    4306,
                    4367,
                    4202,
                    3840,
                    3313,
                    2760,
                    2187,
                    1632,
                    1163,
                    786,
                    555,
                    360,
                    247,
                    157,
                    80,
                    51,
                    28,
                    27,
                    9,
                    5,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.948,
                    -0.911,
                    -0.875,
                    -0.838,
                    -0.801,
                    -0.764,
                    -0.727,
                    -0.69,
                    -0.653,
                    -0.616,
                    -0.579,
                    -0.542,
                    -0.505,
                    -0.468,
                    -0.431,
                    -0.394,
                    -0.357,
                    -0.32,
                    -0.283,
                    -0.246,
                    -0.209,
                    -0.172,
                    -0.135,
                    -0.098,
                    -0.061,
                    -0.024,
                    0.013,
                    0.05,
                    0.087,
                    0.124,
                    0.161,
                    0.198,
                    0.235,
                    0.272,
                    0.309,
                    0.346,
                    0.383,
                    0.42,
                    0.457,
                    0.494,
                    0.531,
                    0.568,
                    0.605,
                    0.642,
                    0.678,
                    0.715,
                    0.752,
                    0.789,
                    0.826,
                    0.863
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " key insights or lessons derived from various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " key insights, lessons, and themes related to socio-economic or political discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh4fo19ru510exv78x1msa",
                        "tokens": [
                            ",",
                            " every",
                            " Treasury",
                            " official",
                            ".",
                            " It",
                            "'s",
                            " equivalent",
                            " to",
                            " being",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " being",
                            " able",
                            " to",
                            " see",
                            " and",
                            " know",
                            " everything",
                            " that",
                            " goes",
                            " on",
                            " in",
                            " the",
                            " economy",
                            ".",
                            " And",
                            " that",
                            "'s",
                            " amazing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            "'ve",
                            " said",
                            " that",
                            " you",
                            " were",
                            " not",
                            " really",
                            " a",
                            " gamer",
                            " before",
                            " working",
                            " with",
                            " Valve",
                            ".",
                            " What",
                            " did",
                            " you",
                            " learn",
                            " about",
                            " video",
                            " game",
                            " worlds",
                            "?",
                            " What",
                            " surprised",
                            " you",
                            "?",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " The",
                            " most",
                            " poignant",
                            " observation",
                            " was",
                            " the",
                            " speed",
                            " with",
                            " which",
                            " these",
                            " economies",
                            " evolve",
                            ".",
                            " Within",
                            " a",
                            " year",
                            ",",
                            " you",
                            " have",
                            " an",
                            " evolutionary",
                            " process",
                            " that",
                            " can",
                            " replicate",
                            " what",
                            " happened",
                            " out",
                            " there",
                            " in",
                            " the",
                            " out",
                            "lying",
                            " economies",
                            ",",
                            " in",
                            " terms",
                            " of",
                            " creating",
                            " a",
                            " complex",
                            " web",
                            " of",
                            " exchanges",
                            " and",
                            " sound",
                            " economic",
                            " systems",
                            ".",
                            " And",
                            " the",
                            " out",
                            "lying",
                            " economy",
                            " took",
                            " centuries"
                        ],
                        "dataIndex": null,
                        "index": "45527",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.521,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.521,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:31:04.595Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.521,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh4fo39ruq10ex522zvc8w",
                        "tokens": [
                            ",",
                            " every",
                            " Treasury",
                            " official",
                            ".",
                            " It",
                            "'s",
                            " equivalent",
                            " to",
                            " being",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " being",
                            " able",
                            " to",
                            " see",
                            " and",
                            " know",
                            " everything",
                            " that",
                            " goes",
                            " on",
                            " in",
                            " the",
                            " economy",
                            ".",
                            " And",
                            " that",
                            "'s",
                            " amazing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            "'ve",
                            " said",
                            " that",
                            " you",
                            " were",
                            " not",
                            " really",
                            " a",
                            " gamer",
                            " before",
                            " working",
                            " with",
                            " Valve",
                            ".",
                            " What",
                            " did",
                            " you",
                            " learn",
                            " about",
                            " video",
                            " game",
                            " worlds",
                            "?",
                            " What",
                            " surprised",
                            " you",
                            "?",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " The",
                            " most",
                            " poignant",
                            " observation",
                            " was",
                            " the",
                            " speed",
                            " with",
                            " which",
                            " these",
                            " economies",
                            " evolve",
                            ".",
                            " Within",
                            " a",
                            " year",
                            ",",
                            " you",
                            " have",
                            " an",
                            " evolutionary",
                            " process",
                            " that",
                            " can",
                            " replicate",
                            " what",
                            " happened",
                            " out",
                            " there",
                            " in",
                            " the",
                            " out",
                            "lying",
                            " economies",
                            ",",
                            " in",
                            " terms",
                            " of",
                            " creating",
                            " a",
                            " complex",
                            " web",
                            " of",
                            " exchanges",
                            " and",
                            " sound",
                            " economic",
                            " systems",
                            ".",
                            " And",
                            " the",
                            " out",
                            "lying",
                            " economy",
                            " took",
                            " centuries"
                        ],
                        "dataIndex": null,
                        "index": "45527",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.521,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.521,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:31:04.595Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.817,
                        "binMax": 18.521,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh4fo19ru610ex9pb18qoe",
                        "tokens": [
                            "ology",
                            " X",
                            " Domain",
                            " Inter",
                            "actions",
                            " on",
                            " Complex",
                            " Thinking",
                            " A",
                            " primary",
                            " assumption",
                            " of",
                            " the",
                            " present",
                            " article",
                            " is",
                            " that",
                            " this",
                            " same",
                            " culture",
                            " \u00c3\u0139",
                            " domain",
                            " interaction",
                            " applies",
                            " to",
                            " political",
                            " culture",
                            " (",
                            "defined",
                            " operation",
                            "ally",
                            " by",
                            " political",
                            " ideology",
                            ").",
                            " This",
                            " idea",
                            " is",
                            " not",
                            " new",
                            ".",
                            " Over",
                            " 25",
                            " years",
                            " ago",
                            ",",
                            " Tet",
                            "lock",
                            " (",
                            "1986",
                            ")",
                            " pointed",
                            " out",
                            " that",
                            ",",
                            " because",
                            " conservatives",
                            " and",
                            " liberals",
                            " differ",
                            " in",
                            " which",
                            " values",
                            " are",
                            " in",
                            " conflict",
                            ",",
                            " his",
                            " Value",
                            " Pl",
                            "ural",
                            "ism",
                            " Model",
                            " predicts",
                            " ideology",
                            " \u00c3\u0139",
                            " domain",
                            " interactions",
                            ".",
                            " Of",
                            " course",
                            ",",
                            " his",
                            " model",
                            " also",
                            " predicts",
                            " that",
                            " integ",
                            "rative",
                            " complexity",
                            " most",
                            " typically",
                            " breaks",
                            " left",
                            " of",
                            " center",
                            ";",
                            " thus",
                            ",",
                            " it",
                            " expects",
                            " both",
                            " a",
                            " main",
                            " effect",
                            " (",
                            "liber",
                            "als",
                            " more",
                            " complex",
                            ")",
                            " and",
                            " interactions",
                            " with",
                            " issue",
                            " domain",
                            ".",
                            " Yet",
                            " it",
                            " is",
                            " worth",
                            " noting",
                            " that",
                            ",",
                            " while",
                            " the",
                            " main"
                        ],
                        "dataIndex": null,
                        "index": "45527",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.032,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.032,
                            4.54,
                            0.701,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:31:04.595Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.521,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "46953",
            "description": " references to the concept of learning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4396210050808792,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "46953",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:22:38.755Z",
                "maxActApprox": 50.478,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    46953,
                    37022,
                    46722,
                    35811,
                    44019,
                    24835,
                    8181,
                    4782,
                    14407,
                    22854,
                    11474,
                    33871,
                    24173,
                    47724,
                    37774,
                    24144,
                    5198,
                    44382,
                    11731,
                    30335,
                    33946,
                    46531,
                    18847,
                    2491,
                    11447
                ],
                "topkCosSimValues": [
                    1,
                    0.7516,
                    0.589,
                    0.569,
                    0.5474,
                    0.5151,
                    0.5135,
                    0.4765,
                    0.4708,
                    0.4584,
                    0.4529,
                    0.4143,
                    0.3993,
                    0.3906,
                    0.3844,
                    0.3699,
                    0.3689,
                    0.3667,
                    0.3611,
                    0.3607,
                    0.3582,
                    0.3575,
                    0.3546,
                    0.3469,
                    0.3419
                ],
                "neuron_alignment_indices": [
                    271,
                    62,
                    119
                ],
                "neuron_alignment_values": [
                    0.146,
                    0.125,
                    0.114
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.018,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.018,
                    0.016
                ],
                "correlated_features_indices": [
                    46920,
                    46980,
                    46940
                ],
                "correlated_features_pearson": [
                    0.018,
                    0.008,
                    0.002
                ],
                "correlated_features_l1": [
                    0.018,
                    0.008,
                    0.002
                ],
                "neg_str": [
                    "zzi",
                    "vati",
                    "\u0124\u00aa",
                    "lished",
                    "pard",
                    "oute",
                    "senal",
                    "swick",
                    "cci",
                    " Shipping"
                ],
                "neg_values": [
                    -0.751,
                    -0.749,
                    -0.743,
                    -0.666,
                    -0.66,
                    -0.658,
                    -0.652,
                    -0.652,
                    -0.652,
                    -0.651
                ],
                "pos_str": [
                    " disabilities",
                    " Curve",
                    " curve",
                    " disability",
                    " lessons",
                    " aids",
                    " comprehension",
                    " disabled",
                    " Disability",
                    " experiences"
                ],
                "pos_values": [
                    1.073,
                    0.922,
                    0.908,
                    0.886,
                    0.771,
                    0.751,
                    0.745,
                    0.732,
                    0.726,
                    0.723
                ],
                "frac_nonzero": 0.00013,
                "freq_hist_data_bar_heights": [
                    64,
                    39,
                    35,
                    17,
                    25,
                    14,
                    13,
                    12,
                    17,
                    8,
                    11,
                    11,
                    6,
                    13,
                    7,
                    10,
                    7,
                    6,
                    5,
                    7,
                    4,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    1,
                    1,
                    2,
                    2,
                    0,
                    3,
                    6,
                    4,
                    0,
                    6,
                    5,
                    4,
                    5,
                    2,
                    1,
                    1,
                    5,
                    2,
                    4,
                    2,
                    3,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.512,
                    1.521,
                    2.531,
                    3.54,
                    4.549,
                    5.559,
                    6.568,
                    7.578,
                    8.587,
                    9.597,
                    10.606,
                    11.615,
                    12.625,
                    13.634,
                    14.644,
                    15.653,
                    16.662,
                    17.672,
                    18.681,
                    19.691,
                    20.7,
                    21.709,
                    22.719,
                    23.728,
                    24.738,
                    25.747,
                    26.757,
                    27.766,
                    28.775,
                    29.785,
                    30.794,
                    31.804,
                    32.813,
                    33.822,
                    34.832,
                    35.841,
                    36.851,
                    37.86,
                    38.869,
                    39.879,
                    40.888,
                    41.898,
                    42.907,
                    43.917,
                    44.926,
                    45.935,
                    46.945,
                    47.954,
                    48.964,
                    49.973
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    10,
                    11,
                    19,
                    24,
                    45,
                    86,
                    152,
                    221,
                    361,
                    554,
                    838,
                    1250,
                    1675,
                    2276,
                    3048,
                    3655,
                    4120,
                    4439,
                    4597,
                    4436,
                    3987,
                    3511,
                    2902,
                    2270,
                    1744,
                    1242,
                    940,
                    651,
                    404,
                    280,
                    175,
                    107,
                    86,
                    40,
                    32,
                    20,
                    20,
                    15,
                    5,
                    2,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.733,
                    -0.696,
                    -0.66,
                    -0.623,
                    -0.587,
                    -0.55,
                    -0.514,
                    -0.477,
                    -0.441,
                    -0.404,
                    -0.368,
                    -0.331,
                    -0.295,
                    -0.258,
                    -0.222,
                    -0.186,
                    -0.149,
                    -0.113,
                    -0.076,
                    -0.04,
                    -0.003,
                    0.033,
                    0.07,
                    0.106,
                    0.143,
                    0.179,
                    0.216,
                    0.252,
                    0.289,
                    0.325,
                    0.362,
                    0.398,
                    0.435,
                    0.471,
                    0.508,
                    0.544,
                    0.58,
                    0.617,
                    0.653,
                    0.69,
                    0.726,
                    0.763,
                    0.799,
                    0.836,
                    0.872,
                    0.909,
                    0.945,
                    0.982,
                    1.018,
                    1.055
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to the concept of learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk74sobixahi666rdiaznst",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46953",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.478,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.741,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:47.650Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.478,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk74sobixali666k8dy1hcm",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46953",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.478,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.741,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:47.650Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.478,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk74sodixb5i66647dcxrku",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "46953",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.478,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.741,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:22:47.650Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 40.382,
                        "binMax": 50.478,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "57419",
            "description": " collective experiences and conclusions drawn from shared understanding or discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4387941062450409,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "57419",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:45:01.994Z",
                "maxActApprox": 24.131,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    57419,
                    84710,
                    3779,
                    85876,
                    60237,
                    18748,
                    80394,
                    32420,
                    54834,
                    6481,
                    61018,
                    14536,
                    77548,
                    27708,
                    82620,
                    93187,
                    87324,
                    95,
                    81946,
                    42591,
                    19317,
                    38954,
                    21929,
                    69724,
                    37833
                ],
                "topkCosSimValues": [
                    1,
                    0.4664,
                    0.4118,
                    0.4036,
                    0.3684,
                    0.3619,
                    0.3422,
                    0.3412,
                    0.3403,
                    0.3334,
                    0.3289,
                    0.3275,
                    0.3271,
                    0.3262,
                    0.3185,
                    0.3107,
                    0.3098,
                    0.3073,
                    0.3058,
                    0.2916,
                    0.2901,
                    0.2898,
                    0.2859,
                    0.285,
                    0.2845
                ],
                "neuron_alignment_indices": [
                    40,
                    39,
                    378
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.101,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    39,
                    732,
                    685
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.01,
                    0.009
                ],
                "correlated_features_indices": [
                    57421,
                    57381,
                    57444
                ],
                "correlated_features_pearson": [
                    0.01,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.011,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "iqueness",
                    "advertisement",
                    " anniversary",
                    "Nob",
                    " Anniversary",
                    "ror",
                    "urg",
                    "itant",
                    "osponsors",
                    "cellence"
                ],
                "neg_values": [
                    -0.672,
                    -0.639,
                    -0.628,
                    -0.608,
                    -0.606,
                    -0.599,
                    -0.592,
                    -0.589,
                    -0.579,
                    -0.572
                ],
                "pos_str": [
                    " onwards",
                    " onward",
                    " derived",
                    " glean",
                    " standpoint",
                    " derive",
                    " sprang",
                    " derives",
                    " emerges",
                    "idth"
                ],
                "pos_values": [
                    1.23,
                    0.97,
                    0.812,
                    0.772,
                    0.767,
                    0.762,
                    0.76,
                    0.749,
                    0.736,
                    0.731
                ],
                "frac_nonzero": 0.00045,
                "freq_hist_data_bar_heights": [
                    342,
                    246,
                    169,
                    118,
                    86,
                    64,
                    45,
                    42,
                    35,
                    33,
                    23,
                    26,
                    17,
                    19,
                    14,
                    10,
                    13,
                    6,
                    4,
                    12,
                    14,
                    2,
                    1,
                    5,
                    7,
                    8,
                    7,
                    1,
                    10,
                    5,
                    4,
                    2,
                    7,
                    0,
                    2,
                    1,
                    2,
                    2,
                    3,
                    3,
                    2,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.242,
                    0.725,
                    1.208,
                    1.69,
                    2.173,
                    2.655,
                    3.138,
                    3.621,
                    4.103,
                    4.586,
                    5.068,
                    5.551,
                    6.033,
                    6.516,
                    6.999,
                    7.481,
                    7.964,
                    8.446,
                    8.929,
                    9.412,
                    9.894,
                    10.377,
                    10.859,
                    11.342,
                    11.825,
                    12.307,
                    12.79,
                    13.272,
                    13.755,
                    14.238,
                    14.72,
                    15.203,
                    15.685,
                    16.168,
                    16.651,
                    17.133,
                    17.616,
                    18.098,
                    18.581,
                    19.064,
                    19.546,
                    20.029,
                    20.511,
                    20.994,
                    21.477,
                    21.959,
                    22.442,
                    22.924,
                    23.407,
                    23.89
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    4,
                    7,
                    14,
                    30,
                    78,
                    139,
                    242,
                    430,
                    690,
                    1050,
                    1549,
                    2183,
                    2883,
                    3766,
                    4296,
                    4714,
                    4868,
                    4755,
                    4411,
                    3704,
                    3087,
                    2390,
                    1696,
                    1205,
                    778,
                    514,
                    337,
                    181,
                    105,
                    59,
                    34,
                    17,
                    12,
                    11,
                    4,
                    3,
                    6,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.653,
                    -0.615,
                    -0.577,
                    -0.539,
                    -0.501,
                    -0.463,
                    -0.425,
                    -0.387,
                    -0.349,
                    -0.311,
                    -0.273,
                    -0.235,
                    -0.197,
                    -0.159,
                    -0.121,
                    -0.083,
                    -0.045,
                    -0.006,
                    0.032,
                    0.07,
                    0.108,
                    0.146,
                    0.184,
                    0.222,
                    0.26,
                    0.298,
                    0.336,
                    0.374,
                    0.412,
                    0.45,
                    0.488,
                    0.526,
                    0.564,
                    0.602,
                    0.64,
                    0.678,
                    0.716,
                    0.754,
                    0.792,
                    0.83,
                    0.868,
                    0.906,
                    0.945,
                    0.983,
                    1.021,
                    1.059,
                    1.097,
                    1.135,
                    1.173,
                    1.211
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " collective experiences and conclusions drawn from shared understanding or discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to community involvement and moral values",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghmiz8isvz10extlot73ry",
                        "tokens": [
                            ",",
                            " which",
                            " occurs",
                            " when",
                            " we",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " As",
                            " long",
                            " as",
                            " we",
                            " have",
                            " a",
                            " bodily",
                            " concept",
                            " of",
                            " life",
                            ",",
                            " our",
                            " understanding",
                            " is",
                            " sense",
                            " gratification",
                            " because",
                            " the",
                            " body",
                            " is",
                            " made",
                            " of",
                            " senses",
                            ".",
                            " When",
                            " we",
                            " progress",
                            " from",
                            " the",
                            " bodily",
                            " platform",
                            " and",
                            " we",
                            " see",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " center",
                            " of",
                            " sense",
                            " activity",
                            ",",
                            " we",
                            " take",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " final",
                            " stage",
                            " of",
                            " realization",
                            ".",
                            " That",
                            " is",
                            " the",
                            " mental",
                            " platform",
                            ".",
                            " From",
                            " the",
                            " mental",
                            " platform",
                            " we",
                            " may",
                            " come",
                            " to",
                            " the",
                            " intellectual",
                            " platform",
                            ",",
                            " and",
                            " from",
                            " the",
                            " intellectual",
                            " platform",
                            " we",
                            " can",
                            " rise",
                            " to",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            ".",
                            " Finally",
                            " we",
                            " can",
                            " rise",
                            " above",
                            " even",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            " and",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " These",
                            " are",
                            " the",
                            " stages",
                            " of",
                            " God",
                            " realization",
                            ".",
                            " However",
                            ",",
                            " in",
                            " this",
                            " age"
                        ],
                        "dataIndex": null,
                        "index": "57419",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.131,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.154,
                            2.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.402,
                            18.95,
                            24.131,
                            12.93,
                            8.535,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.105,
                            9.631,
                            3.723,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:45:08.726Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 24.131,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghmiz9isw810ex5h2c9ow3",
                        "tokens": [
                            ",",
                            " which",
                            " occurs",
                            " when",
                            " we",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " As",
                            " long",
                            " as",
                            " we",
                            " have",
                            " a",
                            " bodily",
                            " concept",
                            " of",
                            " life",
                            ",",
                            " our",
                            " understanding",
                            " is",
                            " sense",
                            " gratification",
                            " because",
                            " the",
                            " body",
                            " is",
                            " made",
                            " of",
                            " senses",
                            ".",
                            " When",
                            " we",
                            " progress",
                            " from",
                            " the",
                            " bodily",
                            " platform",
                            " and",
                            " we",
                            " see",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " center",
                            " of",
                            " sense",
                            " activity",
                            ",",
                            " we",
                            " take",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " final",
                            " stage",
                            " of",
                            " realization",
                            ".",
                            " That",
                            " is",
                            " the",
                            " mental",
                            " platform",
                            ".",
                            " From",
                            " the",
                            " mental",
                            " platform",
                            " we",
                            " may",
                            " come",
                            " to",
                            " the",
                            " intellectual",
                            " platform",
                            ",",
                            " and",
                            " from",
                            " the",
                            " intellectual",
                            " platform",
                            " we",
                            " can",
                            " rise",
                            " to",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            ".",
                            " Finally",
                            " we",
                            " can",
                            " rise",
                            " above",
                            " even",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            " and",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " These",
                            " are",
                            " the",
                            " stages",
                            " of",
                            " God",
                            " realization",
                            ".",
                            " However",
                            ",",
                            " in",
                            " this",
                            " age"
                        ],
                        "dataIndex": null,
                        "index": "57419",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.131,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.154,
                            2.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.402,
                            18.95,
                            24.131,
                            12.93,
                            8.535,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.105,
                            9.631,
                            3.723,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:45:08.726Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 24.131,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghmizbiswu10exapprd8is",
                        "tokens": [
                            ",",
                            " which",
                            " occurs",
                            " when",
                            " we",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " As",
                            " long",
                            " as",
                            " we",
                            " have",
                            " a",
                            " bodily",
                            " concept",
                            " of",
                            " life",
                            ",",
                            " our",
                            " understanding",
                            " is",
                            " sense",
                            " gratification",
                            " because",
                            " the",
                            " body",
                            " is",
                            " made",
                            " of",
                            " senses",
                            ".",
                            " When",
                            " we",
                            " progress",
                            " from",
                            " the",
                            " bodily",
                            " platform",
                            " and",
                            " we",
                            " see",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " center",
                            " of",
                            " sense",
                            " activity",
                            ",",
                            " we",
                            " take",
                            " the",
                            " mind",
                            " as",
                            " the",
                            " final",
                            " stage",
                            " of",
                            " realization",
                            ".",
                            " That",
                            " is",
                            " the",
                            " mental",
                            " platform",
                            ".",
                            " From",
                            " the",
                            " mental",
                            " platform",
                            " we",
                            " may",
                            " come",
                            " to",
                            " the",
                            " intellectual",
                            " platform",
                            ",",
                            " and",
                            " from",
                            " the",
                            " intellectual",
                            " platform",
                            " we",
                            " can",
                            " rise",
                            " to",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            ".",
                            " Finally",
                            " we",
                            " can",
                            " rise",
                            " above",
                            " even",
                            " the",
                            " transcend",
                            "ental",
                            " platform",
                            " and",
                            " come",
                            " to",
                            " the",
                            " spiritual",
                            " platform",
                            ".",
                            " These",
                            " are",
                            " the",
                            " stages",
                            " of",
                            " God",
                            " realization",
                            ".",
                            " However",
                            ",",
                            " in",
                            " this",
                            " age"
                        ],
                        "dataIndex": null,
                        "index": "57419",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.131,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.154,
                            2.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.402,
                            18.95,
                            24.131,
                            12.93,
                            8.535,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.105,
                            9.631,
                            3.723,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:45:08.726Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 9.652,
                        "binMax": 14.478,
                        "binContains": 2e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}