{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "reward based learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "11596",
            "description": "concepts related to rewards and reinforcement learning",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7036466598510742,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "11596",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:31:52.102Z",
                "maxActApprox": 39.026,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11596,
                    8692,
                    8197,
                    2891,
                    5899,
                    11750,
                    2702,
                    7554,
                    1876,
                    6329,
                    2745,
                    2525,
                    1031,
                    717,
                    11033,
                    4654,
                    2812,
                    1439,
                    8055,
                    961,
                    3160,
                    6169,
                    1479,
                    7589,
                    7634
                ],
                "topkCosSimValues": [
                    1,
                    0.4687,
                    0.4158,
                    0.366,
                    0.3559,
                    0.3487,
                    0.3482,
                    0.348,
                    0.3422,
                    0.3389,
                    0.3341,
                    0.3283,
                    0.3127,
                    0.3078,
                    0.3065,
                    0.3037,
                    0.3015,
                    0.2972,
                    0.2969,
                    0.2951,
                    0.2936,
                    0.2917,
                    0.2914,
                    0.2879,
                    0.2779
                ],
                "neuron_alignment_indices": [
                    620,
                    96,
                    381
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.107,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    724,
                    288,
                    717
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.025,
                    0.025
                ],
                "correlated_neurons_l1": [
                    0.033,
                    0.031,
                    0.022
                ],
                "correlated_features_indices": [
                    11639,
                    11532,
                    11615
                ],
                "correlated_features_pearson": [
                    0.01,
                    0.005,
                    0.005
                ],
                "correlated_features_l1": [
                    0.011,
                    0.006,
                    0.005
                ],
                "neg_str": [
                    "abad",
                    "abases",
                    " Sloven",
                    "uania",
                    "torn",
                    " Alic",
                    "head",
                    "enium",
                    "inx",
                    "opic"
                ],
                "neg_values": [
                    -0.814,
                    -0.805,
                    -0.763,
                    -0.726,
                    -0.71,
                    -0.696,
                    -0.682,
                    -0.681,
                    -0.678,
                    -0.673
                ],
                "pos_str": [
                    " rewarded",
                    " reward",
                    " rewards",
                    " incentiv",
                    " incentive",
                    " reap",
                    " tiers",
                    " reinforcement",
                    " incentives",
                    " recipients"
                ],
                "pos_values": [
                    1.092,
                    0.981,
                    0.95,
                    0.921,
                    0.92,
                    0.887,
                    0.847,
                    0.833,
                    0.826,
                    0.818
                ],
                "frac_nonzero": 0.00127,
                "freq_hist_data_bar_heights": [
                    1187,
                    705,
                    477,
                    348,
                    213,
                    168,
                    133,
                    81,
                    81,
                    61,
                    73,
                    52,
                    26,
                    33,
                    27,
                    26,
                    22,
                    30,
                    26,
                    16,
                    12,
                    7,
                    10,
                    8,
                    9,
                    14,
                    6,
                    10,
                    7,
                    7,
                    6,
                    5,
                    3,
                    8,
                    4,
                    7,
                    6,
                    8,
                    8,
                    9,
                    10,
                    11,
                    8,
                    5,
                    2,
                    3,
                    4,
                    1,
                    1,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.39,
                    1.171,
                    1.951,
                    2.732,
                    3.512,
                    4.293,
                    5.073,
                    5.854,
                    6.634,
                    7.415,
                    8.196,
                    8.976,
                    9.757,
                    10.537,
                    11.318,
                    12.098,
                    12.879,
                    13.659,
                    14.44,
                    15.22,
                    16.001,
                    16.781,
                    17.562,
                    18.342,
                    19.123,
                    19.903,
                    20.684,
                    21.464,
                    22.245,
                    23.025,
                    23.806,
                    24.586,
                    25.367,
                    26.148,
                    26.928,
                    27.709,
                    28.489,
                    29.27,
                    30.05,
                    30.831,
                    31.611,
                    32.392,
                    33.172,
                    33.953,
                    34.733,
                    35.514,
                    36.294,
                    37.075,
                    37.855,
                    38.636
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    2,
                    6,
                    7,
                    13,
                    42,
                    52,
                    87,
                    161,
                    265,
                    432,
                    635,
                    959,
                    1324,
                    1955,
                    2428,
                    2949,
                    3668,
                    4177,
                    4514,
                    4577,
                    4265,
                    3946,
                    3425,
                    2740,
                    2308,
                    1657,
                    1237,
                    849,
                    549,
                    374,
                    217,
                    157,
                    101,
                    69,
                    38,
                    28,
                    18,
                    5,
                    4,
                    3,
                    2,
                    3,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.795,
                    -0.757,
                    -0.719,
                    -0.681,
                    -0.643,
                    -0.605,
                    -0.566,
                    -0.528,
                    -0.49,
                    -0.452,
                    -0.414,
                    -0.376,
                    -0.338,
                    -0.3,
                    -0.262,
                    -0.223,
                    -0.185,
                    -0.147,
                    -0.109,
                    -0.071,
                    -0.033,
                    0.005,
                    0.043,
                    0.082,
                    0.12,
                    0.158,
                    0.196,
                    0.234,
                    0.272,
                    0.31,
                    0.348,
                    0.386,
                    0.425,
                    0.463,
                    0.501,
                    0.539,
                    0.577,
                    0.615,
                    0.653,
                    0.691,
                    0.73,
                    0.768,
                    0.806,
                    0.844,
                    0.882,
                    0.92,
                    0.958,
                    0.996,
                    1.034,
                    1.073
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "concepts related to rewards and reinforcement learning",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu4e569l64i666gsdaqeu6",
                        "tokens": [
                            " by",
                            " observing",
                            " the",
                            " reward",
                            " we",
                            " get",
                            " as",
                            " a",
                            " consequence",
                            " of",
                            " our",
                            " actions",
                            ".",
                            " This",
                            " is",
                            " the",
                            " essence",
                            " of",
                            " reinforcement",
                            " learning",
                            ".",
                            " An",
                            " agent",
                            " (",
                            "the",
                            " player",
                            ")",
                            " performs",
                            " some",
                            " actions",
                            " which",
                            " change",
                            " the",
                            " state",
                            " of",
                            " the",
                            " environment",
                            " (",
                            "the",
                            " pixels",
                            " on",
                            " the",
                            " screen",
                            ")",
                            " and",
                            " gets",
                            " a",
                            " reward",
                            " for",
                            " his",
                            " actions",
                            " (",
                            "incre",
                            "ase",
                            " of",
                            " score",
                            ").",
                            "\n",
                            "\n",
                            "Re",
                            "in",
                            "forcement",
                            " learning",
                            " lies",
                            " somewhere",
                            " between",
                            " supervised",
                            " and",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            ".",
                            " In",
                            " supervised",
                            " learning",
                            " we",
                            " have",
                            " a",
                            " label",
                            " for",
                            " every",
                            " training",
                            " example",
                            " and",
                            " in",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            " there",
                            " is",
                            " no",
                            " label",
                            " at",
                            " all",
                            ".",
                            " In",
                            " reinforcement",
                            " learning",
                            " we",
                            " have",
                            " rewards",
                            " which",
                            " are",
                            " sparse",
                            " and",
                            " time",
                            "-",
                            "del",
                            "ayed",
                            " labels",
                            ".",
                            " Using",
                            " only",
                            " on",
                            " those",
                            " rewards",
                            " the",
                            " agent",
                            " has",
                            " to",
                            " learn",
                            " to",
                            " behave",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "11596",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.026,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            38.873,
                            0,
                            8.004,
                            0.731,
                            0.1,
                            2.723,
                            1.671,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.94,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.456,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.026,
                            9.547,
                            0.832,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.223,
                            0,
                            0,
                            0,
                            0,
                            1.025,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.744,
                            0,
                            0,
                            0,
                            31.923,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.193,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.079,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:31:56.789Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.026,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu4e569l66i666g9o1hkvi",
                        "tokens": [
                            " by",
                            " observing",
                            " the",
                            " reward",
                            " we",
                            " get",
                            " as",
                            " a",
                            " consequence",
                            " of",
                            " our",
                            " actions",
                            ".",
                            " This",
                            " is",
                            " the",
                            " essence",
                            " of",
                            " reinforcement",
                            " learning",
                            ".",
                            " An",
                            " agent",
                            " (",
                            "the",
                            " player",
                            ")",
                            " performs",
                            " some",
                            " actions",
                            " which",
                            " change",
                            " the",
                            " state",
                            " of",
                            " the",
                            " environment",
                            " (",
                            "the",
                            " pixels",
                            " on",
                            " the",
                            " screen",
                            ")",
                            " and",
                            " gets",
                            " a",
                            " reward",
                            " for",
                            " his",
                            " actions",
                            " (",
                            "incre",
                            "ase",
                            " of",
                            " score",
                            ").",
                            "\n",
                            "\n",
                            "Re",
                            "in",
                            "forcement",
                            " learning",
                            " lies",
                            " somewhere",
                            " between",
                            " supervised",
                            " and",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            ".",
                            " In",
                            " supervised",
                            " learning",
                            " we",
                            " have",
                            " a",
                            " label",
                            " for",
                            " every",
                            " training",
                            " example",
                            " and",
                            " in",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            " there",
                            " is",
                            " no",
                            " label",
                            " at",
                            " all",
                            ".",
                            " In",
                            " reinforcement",
                            " learning",
                            " we",
                            " have",
                            " rewards",
                            " which",
                            " are",
                            " sparse",
                            " and",
                            " time",
                            "-",
                            "del",
                            "ayed",
                            " labels",
                            ".",
                            " Using",
                            " only",
                            " on",
                            " those",
                            " rewards",
                            " the",
                            " agent",
                            " has",
                            " to",
                            " learn",
                            " to",
                            " behave",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "11596",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.026,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            38.873,
                            0,
                            8.004,
                            0.731,
                            0.1,
                            2.723,
                            1.671,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.94,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.456,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.026,
                            9.547,
                            0.832,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.223,
                            0,
                            0,
                            0,
                            0,
                            1.025,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.744,
                            0,
                            0,
                            0,
                            31.923,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.193,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.079,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:31:56.789Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.026,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu4e589l6ri666bhwefr2w",
                        "tokens": [
                            " by",
                            " observing",
                            " the",
                            " reward",
                            " we",
                            " get",
                            " as",
                            " a",
                            " consequence",
                            " of",
                            " our",
                            " actions",
                            ".",
                            " This",
                            " is",
                            " the",
                            " essence",
                            " of",
                            " reinforcement",
                            " learning",
                            ".",
                            " An",
                            " agent",
                            " (",
                            "the",
                            " player",
                            ")",
                            " performs",
                            " some",
                            " actions",
                            " which",
                            " change",
                            " the",
                            " state",
                            " of",
                            " the",
                            " environment",
                            " (",
                            "the",
                            " pixels",
                            " on",
                            " the",
                            " screen",
                            ")",
                            " and",
                            " gets",
                            " a",
                            " reward",
                            " for",
                            " his",
                            " actions",
                            " (",
                            "incre",
                            "ase",
                            " of",
                            " score",
                            ").",
                            "\n",
                            "\n",
                            "Re",
                            "in",
                            "forcement",
                            " learning",
                            " lies",
                            " somewhere",
                            " between",
                            " supervised",
                            " and",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            ".",
                            " In",
                            " supervised",
                            " learning",
                            " we",
                            " have",
                            " a",
                            " label",
                            " for",
                            " every",
                            " training",
                            " example",
                            " and",
                            " in",
                            " un",
                            "super",
                            "vised",
                            " learning",
                            " there",
                            " is",
                            " no",
                            " label",
                            " at",
                            " all",
                            ".",
                            " In",
                            " reinforcement",
                            " learning",
                            " we",
                            " have",
                            " rewards",
                            " which",
                            " are",
                            " sparse",
                            " and",
                            " time",
                            "-",
                            "del",
                            "ayed",
                            " labels",
                            ".",
                            " Using",
                            " only",
                            " on",
                            " those",
                            " rewards",
                            " the",
                            " agent",
                            " has",
                            " to",
                            " learn",
                            " to",
                            " behave",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "11596",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.026,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            38.873,
                            0,
                            8.004,
                            0.731,
                            0.1,
                            2.723,
                            1.671,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.94,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.456,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.026,
                            9.547,
                            0.832,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.223,
                            0,
                            0,
                            0,
                            0,
                            1.025,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.744,
                            0,
                            0,
                            0,
                            31.923,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.193,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.079,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:31:56.789Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 31.221,
                        "binMax": 39.026,
                        "binContains": 2e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64410",
            "description": "terms related to rewards and recognition for actions or behaviors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6070840358734131,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64410",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:39.058Z",
                "maxActApprox": 37.588,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64410,
                    39196,
                    22365,
                    39308,
                    18838,
                    17356,
                    18919,
                    67655,
                    37831,
                    52672,
                    71609,
                    94002,
                    20698,
                    39633,
                    40246,
                    61418,
                    24528,
                    97672,
                    93953,
                    32074,
                    21496,
                    69692,
                    93665,
                    22837,
                    8089
                ],
                "topkCosSimValues": [
                    1,
                    0.7135,
                    0.5013,
                    0.4852,
                    0.4812,
                    0.4776,
                    0.4522,
                    0.449,
                    0.4287,
                    0.4113,
                    0.4112,
                    0.4079,
                    0.4013,
                    0.3924,
                    0.3912,
                    0.3905,
                    0.3857,
                    0.3851,
                    0.3843,
                    0.384,
                    0.383,
                    0.3735,
                    0.3719,
                    0.3714,
                    0.3677
                ],
                "neuron_alignment_indices": [
                    620,
                    329,
                    665
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.106,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    262,
                    665,
                    381
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    64398,
                    64427,
                    64388
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "abases",
                    "soDeliveryDate",
                    "abad",
                    "bsite",
                    "blog",
                    "inx",
                    "torn",
                    "head",
                    "uter",
                    "stones"
                ],
                "neg_values": [
                    -0.83,
                    -0.784,
                    -0.776,
                    -0.732,
                    -0.732,
                    -0.727,
                    -0.682,
                    -0.68,
                    -0.676,
                    -0.667
                ],
                "pos_str": [
                    " rewarded",
                    " reap",
                    " rewards",
                    " reward",
                    " rewarding",
                    " handsome",
                    "giving",
                    " recipients",
                    "rious",
                    "edience"
                ],
                "pos_values": [
                    0.953,
                    0.933,
                    0.908,
                    0.878,
                    0.822,
                    0.821,
                    0.797,
                    0.795,
                    0.793,
                    0.782
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    36,
                    16,
                    18,
                    15,
                    12,
                    5,
                    8,
                    5,
                    8,
                    3,
                    2,
                    4,
                    2,
                    3,
                    5,
                    7,
                    3,
                    2,
                    2,
                    5,
                    4,
                    3,
                    3,
                    3,
                    6,
                    3,
                    4,
                    1,
                    2,
                    2,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    2,
                    4,
                    0,
                    3,
                    2,
                    2,
                    3,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.381,
                    1.132,
                    1.884,
                    2.636,
                    3.387,
                    4.139,
                    4.891,
                    5.642,
                    6.394,
                    7.146,
                    7.897,
                    8.649,
                    9.401,
                    10.152,
                    10.904,
                    11.656,
                    12.407,
                    13.159,
                    13.911,
                    14.662,
                    15.414,
                    16.166,
                    16.917,
                    17.669,
                    18.421,
                    19.172,
                    19.924,
                    20.676,
                    21.427,
                    22.179,
                    22.931,
                    23.682,
                    24.434,
                    25.186,
                    25.937,
                    26.689,
                    27.441,
                    28.192,
                    28.944,
                    29.696,
                    30.447,
                    31.199,
                    31.951,
                    32.702,
                    33.454,
                    34.206,
                    34.957,
                    35.709,
                    36.461,
                    37.212
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    3,
                    0,
                    5,
                    11,
                    15,
                    29,
                    52,
                    83,
                    127,
                    220,
                    344,
                    471,
                    742,
                    1096,
                    1522,
                    2083,
                    2548,
                    3096,
                    3510,
                    4070,
                    4289,
                    4130,
                    4133,
                    3731,
                    3134,
                    2692,
                    2173,
                    1735,
                    1274,
                    892,
                    648,
                    507,
                    343,
                    207,
                    107,
                    94,
                    61,
                    29,
                    14,
                    12,
                    4,
                    5,
                    3,
                    4,
                    2,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.812,
                    -0.776,
                    -0.741,
                    -0.705,
                    -0.669,
                    -0.634,
                    -0.598,
                    -0.562,
                    -0.527,
                    -0.491,
                    -0.455,
                    -0.42,
                    -0.384,
                    -0.348,
                    -0.313,
                    -0.277,
                    -0.242,
                    -0.206,
                    -0.17,
                    -0.135,
                    -0.099,
                    -0.063,
                    -0.028,
                    0.008,
                    0.044,
                    0.079,
                    0.115,
                    0.151,
                    0.186,
                    0.222,
                    0.258,
                    0.293,
                    0.329,
                    0.364,
                    0.4,
                    0.436,
                    0.471,
                    0.507,
                    0.543,
                    0.578,
                    0.614,
                    0.65,
                    0.685,
                    0.721,
                    0.757,
                    0.792,
                    0.828,
                    0.864,
                    0.899,
                    0.935
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instances of the word \"reward\" and its variations, indicating a focus on positive reinforcement or compensation",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to rewards and recognition for actions or behaviors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwb1to5bk10exwca7tdzv",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.588,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwb1uo5c110exumz18trj",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.588,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwb1vo5c810ex7ozkwsgs",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 30.071,
                        "binMax": 37.588,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "2370",
            "description": "reward-related terms and information about levels or tiers",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6054574431615308,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "2370",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:18:18.802Z",
                "maxActApprox": 25.8,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2370,
                    8851,
                    4461,
                    3031,
                    10042,
                    6125,
                    4618,
                    8262,
                    10804,
                    1371,
                    9392,
                    11176,
                    7458,
                    7035,
                    9097,
                    2330,
                    9060,
                    9677,
                    3772,
                    9412,
                    9984,
                    8384,
                    4310,
                    12072,
                    2349
                ],
                "topkCosSimValues": [
                    1,
                    0.3045,
                    0.2998,
                    0.2874,
                    0.2759,
                    0.2596,
                    0.2466,
                    0.2332,
                    0.2267,
                    0.2202,
                    0.2195,
                    0.2188,
                    0.2167,
                    0.215,
                    0.2104,
                    0.1992,
                    0.1979,
                    0.1977,
                    0.1953,
                    0.1947,
                    0.1887,
                    0.1853,
                    0.1838,
                    0.1835,
                    0.1829
                ],
                "neuron_alignment_indices": [
                    495,
                    671,
                    278
                ],
                "neuron_alignment_values": [
                    0.121,
                    0.101,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    409,
                    111,
                    495
                ],
                "correlated_neurons_pearson": [
                    0.049,
                    0.045,
                    0.043
                ],
                "correlated_neurons_l1": [
                    0.043,
                    0.039,
                    0.042
                ],
                "correlated_features_indices": [
                    2334,
                    2411,
                    2330
                ],
                "correlated_features_pearson": [
                    0.035,
                    0.022,
                    0.014
                ],
                "correlated_features_l1": [
                    0.037,
                    0.024,
                    0.016
                ],
                "neg_str": [
                    "anamo",
                    "warm",
                    "gob",
                    "Haw",
                    "alos",
                    "Lyn",
                    "burg",
                    "awed",
                    "\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a",
                    "opol"
                ],
                "neg_values": [
                    -0.884,
                    -0.812,
                    -0.803,
                    -0.794,
                    -0.789,
                    -0.785,
                    -0.784,
                    -0.783,
                    -0.763,
                    -0.761
                ],
                "pos_str": [
                    " ratio",
                    " category",
                    " method",
                    " suggestion",
                    " message",
                    " coefficient",
                    " technique",
                    " formula",
                    " requirement",
                    " trait"
                ],
                "pos_values": [
                    1.074,
                    1.01,
                    1.01,
                    0.979,
                    0.976,
                    0.963,
                    0.958,
                    0.958,
                    0.957,
                    0.956
                ],
                "frac_nonzero": 0.00522,
                "freq_hist_data_bar_heights": [
                    4740,
                    2840,
                    1960,
                    1375,
                    1007,
                    756,
                    649,
                    483,
                    389,
                    326,
                    277,
                    251,
                    183,
                    154,
                    158,
                    121,
                    104,
                    88,
                    92,
                    69,
                    52,
                    54,
                    56,
                    34,
                    31,
                    28,
                    17,
                    18,
                    9,
                    16,
                    10,
                    9,
                    8,
                    13,
                    9,
                    4,
                    7,
                    3,
                    5,
                    6,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.258,
                    0.774,
                    1.29,
                    1.806,
                    2.322,
                    2.838,
                    3.354,
                    3.87,
                    4.386,
                    4.902,
                    5.418,
                    5.934,
                    6.45,
                    6.966,
                    7.482,
                    7.998,
                    8.514,
                    9.03,
                    9.546,
                    10.062,
                    10.578,
                    11.094,
                    11.61,
                    12.126,
                    12.642,
                    13.158,
                    13.674,
                    14.19,
                    14.706,
                    15.222,
                    15.738,
                    16.254,
                    16.77,
                    17.286,
                    17.802,
                    18.318,
                    18.834,
                    19.35,
                    19.866,
                    20.382,
                    20.898,
                    21.414,
                    21.93,
                    22.446,
                    22.962,
                    23.478,
                    23.994,
                    24.51,
                    25.026,
                    25.542
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    6,
                    14,
                    12,
                    34,
                    68,
                    129,
                    212,
                    303,
                    428,
                    660,
                    915,
                    1261,
                    1593,
                    1986,
                    2295,
                    2532,
                    2909,
                    2967,
                    3088,
                    3283,
                    3122,
                    3151,
                    2818,
                    2551,
                    2210,
                    1928,
                    1732,
                    1439,
                    1303,
                    1038,
                    888,
                    731,
                    617,
                    499,
                    387,
                    306,
                    227,
                    180,
                    136,
                    96,
                    81,
                    45,
                    28,
                    17,
                    21,
                    6,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.865,
                    -0.826,
                    -0.786,
                    -0.747,
                    -0.708,
                    -0.669,
                    -0.63,
                    -0.591,
                    -0.552,
                    -0.512,
                    -0.473,
                    -0.434,
                    -0.395,
                    -0.356,
                    -0.317,
                    -0.277,
                    -0.238,
                    -0.199,
                    -0.16,
                    -0.121,
                    -0.082,
                    -0.042,
                    -0.003,
                    0.036,
                    0.075,
                    0.114,
                    0.153,
                    0.193,
                    0.232,
                    0.271,
                    0.31,
                    0.349,
                    0.388,
                    0.428,
                    0.467,
                    0.506,
                    0.545,
                    0.584,
                    0.623,
                    0.663,
                    0.702,
                    0.741,
                    0.78,
                    0.819,
                    0.858,
                    0.898,
                    0.937,
                    0.976,
                    1.015,
                    1.054
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "reward-related terms and information about levels or tiers",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtmz0a0qcyi6669x4yt0ez",
                        "tokens": [
                            " points",
                            " for",
                            " each",
                            " battle",
                            " they",
                            " take",
                            " part",
                            " in",
                            ".",
                            " Those",
                            " with",
                            " the",
                            " highest",
                            " scores",
                            " will",
                            " win",
                            " event",
                            " prizes",
                            ":",
                            "\n",
                            "\n",
                            "Main",
                            " Pri",
                            "zes",
                            " in",
                            " Operation",
                            " Safari",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ",",
                            "000",
                            " x",
                            " FC",
                            "M",
                            " 50",
                            " t",
                            ",",
                            " French",
                            " Tier",
                            " VIII",
                            " Premium",
                            " heavy",
                            " tank",
                            "\n",
                            "\n",
                            "9",
                            ",",
                            "000",
                            " x",
                            " T",
                            "23",
                            "E",
                            "3",
                            ",",
                            " American",
                            " Tier",
                            " VII",
                            " Premium",
                            " medium",
                            " tank",
                            "\n",
                            "\n",
                            "Important",
                            ":",
                            " Please",
                            " note",
                            " that",
                            " parallel",
                            " to",
                            " this",
                            " event",
                            ",",
                            " the",
                            " T",
                            "23",
                            "E",
                            "3",
                            " will",
                            " undergo",
                            " some",
                            " balancing",
                            " in",
                            " terms",
                            " of",
                            " penetration",
                            ":",
                            " standard",
                            " AP",
                            " shell",
                            " will",
                            " now",
                            " have",
                            " 149",
                            "mm",
                            " of",
                            " penetration",
                            " at",
                            " 100",
                            "m",
                            " (",
                            "old",
                            " value",
                            ":",
                            " 128",
                            "mm",
                            "),",
                            " and",
                            " the",
                            " AP",
                            "CR",
                            " shell",
                            " will",
                            " have",
                            " 190",
                            "mm",
                            " of",
                            " penetration",
                            " at",
                            " 100",
                            "m",
                            " (",
                            "old",
                            " value",
                            ":",
                            " 177"
                        ],
                        "dataIndex": null,
                        "index": "2370",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.8,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.841,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.579,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.8,
                            0.393,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:24.013Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 25.8,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtmz0d0qdii666gedhqz18",
                        "tokens": [
                            " points",
                            " for",
                            " each",
                            " battle",
                            " they",
                            " take",
                            " part",
                            " in",
                            ".",
                            " Those",
                            " with",
                            " the",
                            " highest",
                            " scores",
                            " will",
                            " win",
                            " event",
                            " prizes",
                            ":",
                            "\n",
                            "\n",
                            "Main",
                            " Pri",
                            "zes",
                            " in",
                            " Operation",
                            " Safari",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ",",
                            "000",
                            " x",
                            " FC",
                            "M",
                            " 50",
                            " t",
                            ",",
                            " French",
                            " Tier",
                            " VIII",
                            " Premium",
                            " heavy",
                            " tank",
                            "\n",
                            "\n",
                            "9",
                            ",",
                            "000",
                            " x",
                            " T",
                            "23",
                            "E",
                            "3",
                            ",",
                            " American",
                            " Tier",
                            " VII",
                            " Premium",
                            " medium",
                            " tank",
                            "\n",
                            "\n",
                            "Important",
                            ":",
                            " Please",
                            " note",
                            " that",
                            " parallel",
                            " to",
                            " this",
                            " event",
                            ",",
                            " the",
                            " T",
                            "23",
                            "E",
                            "3",
                            " will",
                            " undergo",
                            " some",
                            " balancing",
                            " in",
                            " terms",
                            " of",
                            " penetration",
                            ":",
                            " standard",
                            " AP",
                            " shell",
                            " will",
                            " now",
                            " have",
                            " 149",
                            "mm",
                            " of",
                            " penetration",
                            " at",
                            " 100",
                            "m",
                            " (",
                            "old",
                            " value",
                            ":",
                            " 128",
                            "mm",
                            "),",
                            " and",
                            " the",
                            " AP",
                            "CR",
                            " shell",
                            " will",
                            " have",
                            " 190",
                            "mm",
                            " of",
                            " penetration",
                            " at",
                            " 100",
                            "m",
                            " (",
                            "old",
                            " value",
                            ":",
                            " 177"
                        ],
                        "dataIndex": null,
                        "index": "2370",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.8,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.841,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.579,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.8,
                            0.393,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:24.013Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 20.64,
                        "binMax": 25.8,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtmz0a0qczi6661ffhq836",
                        "tokens": [
                            "%",
                            " of",
                            " players",
                            " have",
                            " completed",
                            " 36",
                            " challenges",
                            " and",
                            " have",
                            " earned",
                            " the",
                            " Per",
                            "and",
                            "us",
                            " Portal",
                            " Effect",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " are",
                            " just",
                            " less",
                            " than",
                            " six",
                            " weeks",
                            " left",
                            " in",
                            " the",
                            " Per",
                            "and",
                            "us",
                            " leagues",
                            ",",
                            " which",
                            " is",
                            " plenty",
                            " of",
                            " time",
                            " for",
                            " you",
                            " to",
                            " push",
                            " for",
                            " the",
                            " next",
                            " reward",
                            " tier",
                            "!",
                            "\n",
                            "\n",
                            "This",
                            " graph",
                            " shows",
                            " the",
                            " relative",
                            " number",
                            " of",
                            " people",
                            " who",
                            " have",
                            " completed",
                            " each",
                            " exact",
                            " number",
                            " of",
                            " challenges",
                            ".",
                            "There",
                            " are",
                            " just",
                            " less",
                            " than",
                            " six",
                            " weeks",
                            " left",
                            " in",
                            " the",
                            " Per",
                            "and",
                            "us",
                            " leagues",
                            ",",
                            " which",
                            " is",
                            " plenty",
                            " of",
                            " time",
                            " for",
                            " you",
                            " to",
                            " push",
                            " for",
                            " the",
                            " next",
                            " reward",
                            " tier",
                            "!",
                            " Last",
                            " bumped",
                            " on",
                            " Apr",
                            " 27",
                            ",",
                            " 2016",
                            ",",
                            " 5",
                            ":",
                            "47",
                            ":",
                            "31",
                            " PM",
                            "\n",
                            "\n",
                            "Posted",
                            " by",
                            " B",
                            "ex",
                            "_",
                            "GG",
                            "G",
                            "\n",
                            "\n",
                            "on",
                            " Gr",
                            "inding",
                            " Gear"
                        ],
                        "dataIndex": null,
                        "index": "2370",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 21.412,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.554,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.648,
                            0,
                            0,
                            0,
                            0,
                            0.827,
                            6.51,
                            1.099,
                            21.412,
                            19.161,
                            2.611,
                            0.731,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:24.013Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 25.8,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "88767",
            "description": " key terms related to rewards and decision-making in dynamic environments",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5852124094963074,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "88767",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:19:01.448Z",
                "maxActApprox": 7.654,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    88767,
                    18247,
                    34726,
                    19853,
                    13887,
                    5166,
                    9263,
                    37936,
                    48324,
                    1369,
                    26858,
                    12666,
                    85672,
                    51932,
                    65311,
                    55349,
                    91631,
                    29906,
                    81818,
                    59766,
                    26776,
                    42420,
                    38029,
                    48414,
                    30219
                ],
                "topkCosSimValues": [
                    1,
                    0.6686,
                    0.6273,
                    0.609,
                    0.588,
                    0.5836,
                    0.5809,
                    0.5726,
                    0.5702,
                    0.5693,
                    0.5684,
                    0.5673,
                    0.5612,
                    0.5611,
                    0.5601,
                    0.56,
                    0.5599,
                    0.5496,
                    0.5449,
                    0.5429,
                    0.5413,
                    0.5345,
                    0.5342,
                    0.5328,
                    0.5312
                ],
                "neuron_alignment_indices": [
                    480,
                    447,
                    481
                ],
                "neuron_alignment_values": [
                    0.37,
                    0.283,
                    0.263
                ],
                "neuron_alignment_l1": [
                    0.02,
                    0.015,
                    0.014
                ],
                "correlated_neurons_indices": [
                    288,
                    480,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.075,
                    0.074,
                    0.068
                ],
                "correlated_neurons_l1": [
                    0.093,
                    0.019,
                    0.072
                ],
                "correlated_features_indices": [
                    88708,
                    88770,
                    88666
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.011,
                    0.006
                ],
                "correlated_features_l1": [
                    0.02,
                    0.012,
                    0.006
                ],
                "neg_str": [
                    " condol",
                    " millenn",
                    "advert",
                    "\u00e7\u012b\u012a",
                    "audi",
                    " advoc",
                    " renamed",
                    " campaigned",
                    "mobi",
                    " condem"
                ],
                "neg_values": [
                    -0.559,
                    -0.557,
                    -0.549,
                    -0.533,
                    -0.526,
                    -0.526,
                    -0.523,
                    -0.511,
                    -0.501,
                    -0.496
                ],
                "pos_str": [
                    ".",
                    ".</",
                    " ().",
                    ".[",
                    ".<",
                    " or",
                    "'.",
                    "\u00e3\u0122\u0124",
                    ".\u2014",
                    "()."
                ],
                "pos_values": [
                    0.713,
                    0.706,
                    0.666,
                    0.641,
                    0.631,
                    0.631,
                    0.622,
                    0.618,
                    0.618,
                    0.615
                ],
                "frac_nonzero": 0.00579,
                "freq_hist_data_bar_heights": [
                    2162,
                    1952,
                    1712,
                    1562,
                    1427,
                    1240,
                    1084,
                    912,
                    893,
                    744,
                    677,
                    543,
                    429,
                    422,
                    371,
                    315,
                    266,
                    254,
                    231,
                    154,
                    158,
                    116,
                    102,
                    91,
                    79,
                    52,
                    45,
                    47,
                    30,
                    37,
                    23,
                    21,
                    17,
                    14,
                    7,
                    5,
                    6,
                    1,
                    2,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.077,
                    0.23,
                    0.383,
                    0.536,
                    0.689,
                    0.842,
                    0.995,
                    1.148,
                    1.301,
                    1.454,
                    1.607,
                    1.761,
                    1.914,
                    2.067,
                    2.22,
                    2.373,
                    2.526,
                    2.679,
                    2.832,
                    2.985,
                    3.138,
                    3.291,
                    3.444,
                    3.598,
                    3.751,
                    3.904,
                    4.057,
                    4.21,
                    4.363,
                    4.516,
                    4.669,
                    4.822,
                    4.975,
                    5.128,
                    5.282,
                    5.435,
                    5.588,
                    5.741,
                    5.894,
                    6.047,
                    6.2,
                    6.353,
                    6.506,
                    6.659,
                    6.812,
                    6.966,
                    7.119,
                    7.272,
                    7.425,
                    7.578
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    5,
                    9,
                    20,
                    31,
                    51,
                    87,
                    154,
                    224,
                    329,
                    598,
                    777,
                    1076,
                    1541,
                    1894,
                    2371,
                    2630,
                    3054,
                    3372,
                    3539,
                    3772,
                    3667,
                    3502,
                    3264,
                    2952,
                    2578,
                    2120,
                    1717,
                    1381,
                    995,
                    764,
                    533,
                    402,
                    285,
                    166,
                    116,
                    84,
                    70,
                    31,
                    19,
                    20,
                    14,
                    9,
                    4,
                    11,
                    7,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.546,
                    -0.521,
                    -0.495,
                    -0.47,
                    -0.444,
                    -0.419,
                    -0.394,
                    -0.368,
                    -0.343,
                    -0.317,
                    -0.292,
                    -0.266,
                    -0.241,
                    -0.216,
                    -0.19,
                    -0.165,
                    -0.139,
                    -0.114,
                    -0.088,
                    -0.063,
                    -0.038,
                    -0.012,
                    0.013,
                    0.039,
                    0.064,
                    0.09,
                    0.115,
                    0.141,
                    0.166,
                    0.191,
                    0.217,
                    0.242,
                    0.268,
                    0.293,
                    0.319,
                    0.344,
                    0.369,
                    0.395,
                    0.42,
                    0.446,
                    0.471,
                    0.497,
                    0.522,
                    0.547,
                    0.573,
                    0.598,
                    0.624,
                    0.649,
                    0.675,
                    0.7
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to processes and their efficiency in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " key terms related to rewards and decision-making in dynamic environments",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiu99i6l3a10exonfp66iz",
                        "tokens": [
                            "+",
                            "r",
                            "_",
                            "n",
                            "\\)",
                            "\n",
                            "\n",
                            "As",
                            " our",
                            " process",
                            " is",
                            " sto",
                            "ch",
                            "astic",
                            " there",
                            " is",
                            " no",
                            " guarantee",
                            " that",
                            " the",
                            " same",
                            " action",
                            " will",
                            " give",
                            " the",
                            " same",
                            " reward",
                            " (",
                            "e",
                            ".",
                            "g",
                            ".",
                            " when",
                            " we",
                            " start",
                            " the",
                            " game",
                            " the",
                            " ball",
                            " starts",
                            " in",
                            " a",
                            " random",
                            " direction",
                            ").",
                            " It",
                            " means",
                            " that",
                            " the",
                            " most",
                            " distant",
                            " rewards",
                            " are",
                            " also",
                            " the",
                            " most",
                            " uncertain",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " this",
                            " reason",
                            " we",
                            " want",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "disc",
                            "ard",
                            "\u00e2\u0122",
                            "\u013f",
                            " rewards",
                            " far",
                            " away",
                            " in",
                            " the",
                            " future",
                            " using",
                            " a",
                            " discount",
                            " factor",
                            " \\(\\",
                            "gam",
                            "ma",
                            "\\",
                            "):",
                            "\n",
                            "\n",
                            "\\",
                            "(\\",
                            "begin",
                            "{",
                            "align",
                            "}",
                            "R",
                            "_",
                            "t",
                            " &",
                            " =",
                            " r",
                            "_",
                            "t",
                            " +",
                            " \\",
                            "gam",
                            "ma",
                            " r",
                            "_{",
                            "t",
                            "+",
                            "1",
                            "}",
                            " +",
                            " \\",
                            "gam",
                            "ma",
                            "^",
                            "2",
                            " r",
                            "_{",
                            "t",
                            "+",
                            "2",
                            "}",
                            " +",
                            " \u00e2\u0122\u00a6"
                        ],
                        "dataIndex": null,
                        "index": "88767",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.654,
                        "maxValueTokenIndex": 26,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.116,
                            1.878,
                            2.042,
                            0,
                            1.51,
                            7.654,
                            0.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:08.979Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.654,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiu99k6l3v10excraxjipx",
                        "tokens": [
                            "+",
                            "r",
                            "_",
                            "n",
                            "\\)",
                            "\n",
                            "\n",
                            "As",
                            " our",
                            " process",
                            " is",
                            " sto",
                            "ch",
                            "astic",
                            " there",
                            " is",
                            " no",
                            " guarantee",
                            " that",
                            " the",
                            " same",
                            " action",
                            " will",
                            " give",
                            " the",
                            " same",
                            " reward",
                            " (",
                            "e",
                            ".",
                            "g",
                            ".",
                            " when",
                            " we",
                            " start",
                            " the",
                            " game",
                            " the",
                            " ball",
                            " starts",
                            " in",
                            " a",
                            " random",
                            " direction",
                            ").",
                            " It",
                            " means",
                            " that",
                            " the",
                            " most",
                            " distant",
                            " rewards",
                            " are",
                            " also",
                            " the",
                            " most",
                            " uncertain",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " this",
                            " reason",
                            " we",
                            " want",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "disc",
                            "ard",
                            "\u00e2\u0122",
                            "\u013f",
                            " rewards",
                            " far",
                            " away",
                            " in",
                            " the",
                            " future",
                            " using",
                            " a",
                            " discount",
                            " factor",
                            " \\(\\",
                            "gam",
                            "ma",
                            "\\",
                            "):",
                            "\n",
                            "\n",
                            "\\",
                            "(\\",
                            "begin",
                            "{",
                            "align",
                            "}",
                            "R",
                            "_",
                            "t",
                            " &",
                            " =",
                            " r",
                            "_",
                            "t",
                            " +",
                            " \\",
                            "gam",
                            "ma",
                            " r",
                            "_{",
                            "t",
                            "+",
                            "1",
                            "}",
                            " +",
                            " \\",
                            "gam",
                            "ma",
                            "^",
                            "2",
                            " r",
                            "_{",
                            "t",
                            "+",
                            "2",
                            "}",
                            " +",
                            " \u00e2\u0122\u00a6"
                        ],
                        "dataIndex": null,
                        "index": "88767",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.654,
                        "maxValueTokenIndex": 26,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.116,
                            1.878,
                            2.042,
                            0,
                            1.51,
                            7.654,
                            0.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:08.979Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.124,
                        "binMax": 7.654,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiu99i6l3b10extuk5jov7",
                        "tokens": [
                            " use",
                            " when",
                            " you",
                            " don",
                            "'t",
                            " know",
                            " everything",
                            ",",
                            " you",
                            "'re",
                            " not",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " and",
                            " you",
                            " need",
                            " to",
                            " use",
                            " something",
                            " in",
                            " order",
                            " to",
                            " gain",
                            " feeling",
                            " as",
                            " to",
                            " what",
                            " is",
                            " happening",
                            " to",
                            " prices",
                            ",",
                            " what",
                            " is",
                            " happening",
                            " to",
                            " quantities",
                            ",",
                            " what",
                            "'s",
                            " happening",
                            " to",
                            " investments",
                            ",",
                            " and",
                            " so",
                            " on",
                            " and",
                            " so",
                            " forth",
                            ".",
                            " But",
                            " in",
                            " a",
                            " video",
                            " game",
                            " world",
                            ",",
                            " all",
                            " the",
                            " data",
                            " are",
                            " there",
                            ".",
                            " It",
                            "'s",
                            " like",
                            " being",
                            " God",
                            ",",
                            " who",
                            " has",
                            " access",
                            " to",
                            " everything",
                            " and",
                            " to",
                            " what",
                            " every",
                            " member",
                            " of",
                            " the",
                            " social",
                            " economy",
                            " is",
                            " doing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            " have",
                            " the",
                            " perfect",
                            " knowledge",
                            " that",
                            " every",
                            " central",
                            " banker",
                            " wishes",
                            " he",
                            " or",
                            " she",
                            " had",
                            ".",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " Indeed",
                            ".",
                            " Every",
                            " congressman",
                            ",",
                            " every",
                            " senator",
                            ",",
                            " every",
                            " regulator",
                            ",",
                            " every",
                            " banker"
                        ],
                        "dataIndex": null,
                        "index": "88767",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.375,
                        "maxValueTokenIndex": 30,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.301,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.084,
                            2.191,
                            0,
                            0,
                            0,
                            0.029,
                            7.375,
                            0.77,
                            5.845,
                            0.225,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:08.979Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.654,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84596",
            "description": " terms related to rewards and their implications within a context",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5815169811248779,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84596",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:39.970Z",
                "maxActApprox": 67.778,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84596,
                    91419,
                    16702,
                    15555,
                    61276,
                    14567,
                    16345,
                    88971,
                    55483,
                    18191,
                    43292,
                    48102,
                    1181,
                    95681,
                    70783,
                    33937,
                    7996,
                    25952,
                    20883,
                    64153,
                    95856,
                    79762,
                    2764,
                    18207,
                    54718
                ],
                "topkCosSimValues": [
                    1,
                    0.5203,
                    0.445,
                    0.4418,
                    0.4403,
                    0.4291,
                    0.4285,
                    0.4208,
                    0.4167,
                    0.416,
                    0.415,
                    0.4119,
                    0.4087,
                    0.4019,
                    0.3909,
                    0.3893,
                    0.3825,
                    0.379,
                    0.3784,
                    0.3776,
                    0.376,
                    0.3747,
                    0.3735,
                    0.3714,
                    0.3713
                ],
                "neuron_alignment_indices": [
                    566,
                    365,
                    157
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.1,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    251,
                    262,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.005
                ],
                "correlated_features_indices": [
                    84620,
                    84673,
                    84682
                ],
                "correlated_features_pearson": [
                    0.006,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.006,
                    0,
                    0
                ],
                "neg_str": [
                    " suspic",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u0128",
                    " otherwise",
                    " CPC",
                    "uously",
                    " JPM",
                    " Gemini",
                    "\u00da",
                    " \u00d8\u00a7\u00d9\u0126",
                    " \u00e8\u00a3\u0131\u00e8"
                ],
                "neg_values": [
                    -0.733,
                    -0.706,
                    -0.676,
                    -0.676,
                    -0.648,
                    -0.62,
                    -0.611,
                    -0.6,
                    -0.597,
                    -0.595
                ],
                "pos_str": [
                    "ritten",
                    "ards",
                    "atche",
                    "arded",
                    "inding",
                    "riter",
                    "rite",
                    "arding",
                    "rites",
                    "rote"
                ],
                "pos_values": [
                    1.261,
                    1.209,
                    1.173,
                    1.066,
                    1.028,
                    0.997,
                    0.984,
                    0.97,
                    0.963,
                    0.951
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    12,
                    10,
                    2,
                    1,
                    3,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.699,
                    2.054,
                    3.41,
                    4.765,
                    6.12,
                    7.475,
                    8.83,
                    10.185,
                    11.54,
                    12.895,
                    14.25,
                    15.606,
                    16.961,
                    18.316,
                    19.671,
                    21.026,
                    22.381,
                    23.736,
                    25.091,
                    26.447,
                    27.802,
                    29.157,
                    30.512,
                    31.867,
                    33.222,
                    34.577,
                    35.932,
                    37.288,
                    38.643,
                    39.998,
                    41.353,
                    42.708,
                    44.063,
                    45.418,
                    46.773,
                    48.129,
                    49.484,
                    50.839,
                    52.194,
                    53.549,
                    54.904,
                    56.259,
                    57.614,
                    58.97,
                    60.325,
                    61.68,
                    63.035,
                    64.39,
                    65.745,
                    67.1
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    2,
                    9,
                    22,
                    39,
                    75,
                    177,
                    262,
                    487,
                    847,
                    1341,
                    1936,
                    2692,
                    3487,
                    4128,
                    4646,
                    4804,
                    4652,
                    4335,
                    3606,
                    3001,
                    2389,
                    1829,
                    1426,
                    1032,
                    794,
                    602,
                    455,
                    343,
                    245,
                    172,
                    140,
                    90,
                    69,
                    43,
                    27,
                    13,
                    10,
                    10,
                    4,
                    2,
                    3,
                    2,
                    1,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.714,
                    -0.674,
                    -0.634,
                    -0.594,
                    -0.554,
                    -0.514,
                    -0.474,
                    -0.434,
                    -0.394,
                    -0.355,
                    -0.315,
                    -0.275,
                    -0.235,
                    -0.195,
                    -0.155,
                    -0.115,
                    -0.075,
                    -0.035,
                    0.004,
                    0.044,
                    0.084,
                    0.124,
                    0.164,
                    0.204,
                    0.244,
                    0.284,
                    0.323,
                    0.363,
                    0.403,
                    0.443,
                    0.483,
                    0.523,
                    0.563,
                    0.603,
                    0.643,
                    0.682,
                    0.722,
                    0.762,
                    0.802,
                    0.842,
                    0.882,
                    0.922,
                    0.962,
                    1.002,
                    1.041,
                    1.081,
                    1.121,
                    1.161,
                    1.201,
                    1.241
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " words associated with rewards and their variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " terms related to rewards and their implications within a context",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiojyq3glx10extcd7vhi9",
                        "tokens": [
                            "\"",
                            "As",
                            " you",
                            " move",
                            " further",
                            " and",
                            " further",
                            " away",
                            " from",
                            " standardized",
                            " reporting",
                            ",",
                            " investors",
                            " can",
                            " understand",
                            " it",
                            " less",
                            " and",
                            " less",
                            ".\"",
                            "\n",
                            "\n",
                            "J",
                            "ensen",
                            " said",
                            " the",
                            " O",
                            "SC",
                            " already",
                            " has",
                            " all",
                            " of",
                            " the",
                            " tools",
                            " it",
                            " needs",
                            " to",
                            " enforce",
                            " such",
                            " cases",
                            " --",
                            " it",
                            "'s",
                            " just",
                            " a",
                            " matter",
                            " of",
                            " identifying",
                            " misleading",
                            " disclosures",
                            ",",
                            " something",
                            " that",
                            " the",
                            " whistleblower",
                            " program",
                            " can",
                            " help",
                            " with",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            " of",
                            " up",
                            " to",
                            " $",
                            "5",
                            " million",
                            "\n",
                            "\n",
                            "Since",
                            " its",
                            " launch",
                            " in",
                            " July",
                            ",",
                            " the",
                            " Ontario",
                            " Securities",
                            " Commission",
                            "'s",
                            " whistleblower",
                            " program",
                            " has",
                            " already",
                            " garnered",
                            " more",
                            " than",
                            " 30",
                            " tips",
                            " detailing",
                            " the",
                            " kinds",
                            " of",
                            " securities",
                            " law",
                            " violations",
                            " that",
                            " the",
                            " regulator",
                            " is",
                            " targeting",
                            " in",
                            " its",
                            " enforcement",
                            " actions",
                            ",",
                            " Jensen",
                            " said",
                            " Tuesday",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Some",
                            " of",
                            " them",
                            " are",
                            " the",
                            " kinds",
                            " of",
                            " tips",
                            " that",
                            " we",
                            " really"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.778,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.778,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 67.778,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiojys3gmh10ex7fm7pnyg",
                        "tokens": [
                            "\"",
                            "As",
                            " you",
                            " move",
                            " further",
                            " and",
                            " further",
                            " away",
                            " from",
                            " standardized",
                            " reporting",
                            ",",
                            " investors",
                            " can",
                            " understand",
                            " it",
                            " less",
                            " and",
                            " less",
                            ".\"",
                            "\n",
                            "\n",
                            "J",
                            "ensen",
                            " said",
                            " the",
                            " O",
                            "SC",
                            " already",
                            " has",
                            " all",
                            " of",
                            " the",
                            " tools",
                            " it",
                            " needs",
                            " to",
                            " enforce",
                            " such",
                            " cases",
                            " --",
                            " it",
                            "'s",
                            " just",
                            " a",
                            " matter",
                            " of",
                            " identifying",
                            " misleading",
                            " disclosures",
                            ",",
                            " something",
                            " that",
                            " the",
                            " whistleblower",
                            " program",
                            " can",
                            " help",
                            " with",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            " of",
                            " up",
                            " to",
                            " $",
                            "5",
                            " million",
                            "\n",
                            "\n",
                            "Since",
                            " its",
                            " launch",
                            " in",
                            " July",
                            ",",
                            " the",
                            " Ontario",
                            " Securities",
                            " Commission",
                            "'s",
                            " whistleblower",
                            " program",
                            " has",
                            " already",
                            " garnered",
                            " more",
                            " than",
                            " 30",
                            " tips",
                            " detailing",
                            " the",
                            " kinds",
                            " of",
                            " securities",
                            " law",
                            " violations",
                            " that",
                            " the",
                            " regulator",
                            " is",
                            " targeting",
                            " in",
                            " its",
                            " enforcement",
                            " actions",
                            ",",
                            " Jensen",
                            " said",
                            " Tuesday",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Some",
                            " of",
                            " them",
                            " are",
                            " the",
                            " kinds",
                            " of",
                            " tips",
                            " that",
                            " we",
                            " really"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.778,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.778,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 54.222,
                        "binMax": 67.778,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiojyq3gly10ex0keyhr9r",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "ear",
                            "n",
                            " some",
                            " sweet",
                            " rewards",
                            ",",
                            " starting",
                            " at",
                            " the",
                            " $",
                            "10",
                            " level",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " will",
                            " ABC",
                            " will",
                            " use",
                            " the",
                            " money",
                            " for",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " money",
                            " we",
                            " raise",
                            " from",
                            " this",
                            " campaign",
                            " will",
                            " be",
                            " used",
                            " to",
                            " get",
                            " this",
                            " project",
                            " off",
                            " the",
                            " ground",
                            ".",
                            " We",
                            " will",
                            " be",
                            " able",
                            " to",
                            " secure",
                            " the",
                            " desired",
                            " location",
                            " in",
                            " the",
                            " heart",
                            " of",
                            " Alexandria",
                            ".",
                            "\n",
                            "\n",
                            "Tap",
                            "room",
                            ".",
                            " We",
                            " plan",
                            " to",
                            " renov",
                            "ate",
                            " an",
                            " existing",
                            " building",
                            " on",
                            " the",
                            " property",
                            " into",
                            " a",
                            " community",
                            " tap",
                            "room",
                            ",",
                            " with",
                            " a",
                            " home",
                            "-",
                            "like",
                            " feel",
                            ",",
                            " where",
                            " people",
                            " can",
                            " find",
                            " good",
                            " company",
                            " and",
                            " great",
                            " beer",
                            ".",
                            " Your",
                            " support",
                            " will",
                            " be",
                            " able",
                            " to",
                            " help",
                            " outfit",
                            " our",
                            " tap",
                            "room",
                            " and",
                            " create",
                            " a",
                            " space",
                            " for",
                            " all",
                            " to",
                            " enjoy",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 63.806,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            63.806,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 67.778,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64410",
            "description": "instances of the word \"reward\" and its variations, indicating a focus on positive reinforcement or compensation",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5813964605331421,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64410",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:39.058Z",
                "maxActApprox": 37.588,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64410,
                    39196,
                    22365,
                    39308,
                    18838,
                    17356,
                    18919,
                    67655,
                    37831,
                    52672,
                    71609,
                    94002,
                    20698,
                    39633,
                    40246,
                    61418,
                    24528,
                    97672,
                    93953,
                    32074,
                    21496,
                    69692,
                    93665,
                    22837,
                    8089
                ],
                "topkCosSimValues": [
                    1,
                    0.7135,
                    0.5013,
                    0.4852,
                    0.4812,
                    0.4776,
                    0.4522,
                    0.449,
                    0.4287,
                    0.4113,
                    0.4112,
                    0.4079,
                    0.4013,
                    0.3924,
                    0.3912,
                    0.3905,
                    0.3857,
                    0.3851,
                    0.3843,
                    0.384,
                    0.383,
                    0.3735,
                    0.3719,
                    0.3714,
                    0.3677
                ],
                "neuron_alignment_indices": [
                    620,
                    329,
                    665
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.106,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    262,
                    665,
                    381
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    64398,
                    64427,
                    64388
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "abases",
                    "soDeliveryDate",
                    "abad",
                    "bsite",
                    "blog",
                    "inx",
                    "torn",
                    "head",
                    "uter",
                    "stones"
                ],
                "neg_values": [
                    -0.83,
                    -0.784,
                    -0.776,
                    -0.732,
                    -0.732,
                    -0.727,
                    -0.682,
                    -0.68,
                    -0.676,
                    -0.667
                ],
                "pos_str": [
                    " rewarded",
                    " reap",
                    " rewards",
                    " reward",
                    " rewarding",
                    " handsome",
                    "giving",
                    " recipients",
                    "rious",
                    "edience"
                ],
                "pos_values": [
                    0.953,
                    0.933,
                    0.908,
                    0.878,
                    0.822,
                    0.821,
                    0.797,
                    0.795,
                    0.793,
                    0.782
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    36,
                    16,
                    18,
                    15,
                    12,
                    5,
                    8,
                    5,
                    8,
                    3,
                    2,
                    4,
                    2,
                    3,
                    5,
                    7,
                    3,
                    2,
                    2,
                    5,
                    4,
                    3,
                    3,
                    3,
                    6,
                    3,
                    4,
                    1,
                    2,
                    2,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    2,
                    4,
                    0,
                    3,
                    2,
                    2,
                    3,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.381,
                    1.132,
                    1.884,
                    2.636,
                    3.387,
                    4.139,
                    4.891,
                    5.642,
                    6.394,
                    7.146,
                    7.897,
                    8.649,
                    9.401,
                    10.152,
                    10.904,
                    11.656,
                    12.407,
                    13.159,
                    13.911,
                    14.662,
                    15.414,
                    16.166,
                    16.917,
                    17.669,
                    18.421,
                    19.172,
                    19.924,
                    20.676,
                    21.427,
                    22.179,
                    22.931,
                    23.682,
                    24.434,
                    25.186,
                    25.937,
                    26.689,
                    27.441,
                    28.192,
                    28.944,
                    29.696,
                    30.447,
                    31.199,
                    31.951,
                    32.702,
                    33.454,
                    34.206,
                    34.957,
                    35.709,
                    36.461,
                    37.212
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    3,
                    0,
                    5,
                    11,
                    15,
                    29,
                    52,
                    83,
                    127,
                    220,
                    344,
                    471,
                    742,
                    1096,
                    1522,
                    2083,
                    2548,
                    3096,
                    3510,
                    4070,
                    4289,
                    4130,
                    4133,
                    3731,
                    3134,
                    2692,
                    2173,
                    1735,
                    1274,
                    892,
                    648,
                    507,
                    343,
                    207,
                    107,
                    94,
                    61,
                    29,
                    14,
                    12,
                    4,
                    5,
                    3,
                    4,
                    2,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.812,
                    -0.776,
                    -0.741,
                    -0.705,
                    -0.669,
                    -0.634,
                    -0.598,
                    -0.562,
                    -0.527,
                    -0.491,
                    -0.455,
                    -0.42,
                    -0.384,
                    -0.348,
                    -0.313,
                    -0.277,
                    -0.242,
                    -0.206,
                    -0.17,
                    -0.135,
                    -0.099,
                    -0.063,
                    -0.028,
                    0.008,
                    0.044,
                    0.079,
                    0.115,
                    0.151,
                    0.186,
                    0.222,
                    0.258,
                    0.293,
                    0.329,
                    0.364,
                    0.4,
                    0.436,
                    0.471,
                    0.507,
                    0.543,
                    0.578,
                    0.614,
                    0.65,
                    0.685,
                    0.721,
                    0.757,
                    0.792,
                    0.828,
                    0.864,
                    0.899,
                    0.935
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instances of the word \"reward\" and its variations, indicating a focus on positive reinforcement or compensation",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to rewards and recognition for actions or behaviors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwb1to5bk10exwca7tdzv",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.588,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwb1uo5c110exumz18trj",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.588,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwb1vo5c810ex7ozkwsgs",
                        "tokens": [
                            "en",
                            ",",
                            " a",
                            " physicist",
                            " who",
                            " works",
                            " on",
                            " electromagnetic",
                            " lev",
                            "itation",
                            " at",
                            " Rad",
                            "b",
                            "oud",
                            " University",
                            " in",
                            " N",
                            "ij",
                            "me",
                            "gen",
                            ",",
                            " the",
                            " Netherlands",
                            ",",
                            " says",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " impressed",
                            " with",
                            " the",
                            " invention",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " really",
                            " like",
                            " it",
                            ";",
                            " this",
                            " is",
                            " a",
                            " very",
                            " versatile",
                            " platform",
                            " \u2014",
                            " almost",
                            " anything",
                            " you",
                            " want",
                            " to",
                            " manipulate",
                            ",",
                            " you",
                            " can",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "This",
                            " article",
                            " is",
                            " reproduced",
                            " with",
                            " permission",
                            " from",
                            " the",
                            " magazine",
                            " Nature",
                            ".",
                            " The",
                            " article",
                            " was",
                            " first",
                            " published",
                            " on",
                            " July",
                            " 15",
                            ",",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Once",
                            " upon",
                            " a",
                            " time",
                            " there",
                            " were",
                            " two",
                            " girls",
                            ".",
                            " One",
                            " was",
                            " kind",
                            " and",
                            " helpful",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " gold",
                            ".",
                            " The",
                            " other",
                            " was",
                            " mean",
                            " and",
                            " lazy",
                            " and",
                            " was",
                            " rewarded",
                            " with",
                            " a",
                            " box",
                            " of",
                            " snakes",
                            ".",
                            " You",
                            " may",
                            " know"
                        ],
                        "dataIndex": null,
                        "index": "64410",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.588,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.588,
                            2.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:52:45.009Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 30.071,
                        "binMax": 37.588,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "39196",
            "description": "terms related to rewards and incentives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5758111133688035,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "39196",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:20:47.473Z",
                "maxActApprox": 45.188,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39196,
                    64410,
                    39308,
                    22365,
                    17356,
                    32074,
                    39633,
                    87467,
                    71609,
                    94002,
                    18919,
                    71576,
                    61418,
                    49749,
                    91705,
                    36943,
                    78848,
                    22012,
                    55814,
                    11427,
                    12438,
                    44011,
                    25821,
                    27290,
                    62534
                ],
                "topkCosSimValues": [
                    1,
                    0.7135,
                    0.6364,
                    0.5378,
                    0.5102,
                    0.5059,
                    0.4799,
                    0.476,
                    0.4758,
                    0.4736,
                    0.4702,
                    0.4441,
                    0.439,
                    0.4389,
                    0.4371,
                    0.4347,
                    0.4286,
                    0.4226,
                    0.4161,
                    0.4073,
                    0.4062,
                    0.4058,
                    0.4017,
                    0.3957,
                    0.3936
                ],
                "neuron_alignment_indices": [
                    288,
                    620,
                    35
                ],
                "neuron_alignment_values": [
                    0.136,
                    0.116,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    189,
                    313,
                    620
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.013,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.015,
                    0.013,
                    0.009
                ],
                "correlated_features_indices": [
                    39218,
                    39169,
                    39111
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Sloven",
                    "abases",
                    "ovie",
                    "sei",
                    " Osw",
                    " Ange",
                    "abad",
                    "icago",
                    "cling",
                    "obiles"
                ],
                "neg_values": [
                    -0.785,
                    -0.768,
                    -0.727,
                    -0.716,
                    -0.716,
                    -0.7,
                    -0.694,
                    -0.685,
                    -0.68,
                    -0.678
                ],
                "pos_str": [
                    " tiers",
                    " reward",
                    " rewards",
                    " fulfillment",
                    " recipients",
                    " tier",
                    " payout",
                    " recipient",
                    " payable",
                    " rewarded"
                ],
                "pos_values": [
                    1.014,
                    0.966,
                    0.929,
                    0.846,
                    0.811,
                    0.81,
                    0.797,
                    0.764,
                    0.759,
                    0.751
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    74,
                    54,
                    28,
                    20,
                    13,
                    16,
                    6,
                    6,
                    1,
                    1,
                    0,
                    2,
                    2,
                    1,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    4,
                    3,
                    3,
                    4,
                    1,
                    2,
                    4,
                    4,
                    6,
                    3,
                    2,
                    5,
                    7,
                    5,
                    8,
                    2,
                    6,
                    4,
                    4,
                    7,
                    6,
                    4,
                    8,
                    2,
                    5,
                    5,
                    3,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.454,
                    1.358,
                    2.261,
                    3.165,
                    4.069,
                    4.973,
                    5.876,
                    6.78,
                    7.684,
                    8.588,
                    9.491,
                    10.395,
                    11.299,
                    12.202,
                    13.106,
                    14.01,
                    14.914,
                    15.817,
                    16.721,
                    17.625,
                    18.528,
                    19.432,
                    20.336,
                    21.24,
                    22.143,
                    23.047,
                    23.951,
                    24.854,
                    25.758,
                    26.662,
                    27.566,
                    28.469,
                    29.373,
                    30.277,
                    31.181,
                    32.084,
                    32.988,
                    33.892,
                    34.795,
                    35.699,
                    36.603,
                    37.507,
                    38.41,
                    39.314,
                    40.218,
                    41.121,
                    42.025,
                    42.929,
                    43.833,
                    44.736
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    5,
                    7,
                    12,
                    21,
                    39,
                    64,
                    110,
                    186,
                    321,
                    416,
                    636,
                    916,
                    1312,
                    1689,
                    2176,
                    2764,
                    3311,
                    3709,
                    4078,
                    4269,
                    4215,
                    3905,
                    3521,
                    2997,
                    2509,
                    2027,
                    1534,
                    1078,
                    759,
                    539,
                    390,
                    257,
                    153,
                    110,
                    73,
                    46,
                    41,
                    24,
                    8,
                    11,
                    6,
                    2,
                    2,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.767,
                    -0.731,
                    -0.695,
                    -0.659,
                    -0.623,
                    -0.587,
                    -0.551,
                    -0.515,
                    -0.479,
                    -0.443,
                    -0.407,
                    -0.371,
                    -0.335,
                    -0.299,
                    -0.263,
                    -0.227,
                    -0.191,
                    -0.155,
                    -0.119,
                    -0.083,
                    -0.048,
                    -0.012,
                    0.024,
                    0.06,
                    0.096,
                    0.132,
                    0.168,
                    0.204,
                    0.24,
                    0.276,
                    0.312,
                    0.348,
                    0.384,
                    0.42,
                    0.456,
                    0.492,
                    0.528,
                    0.564,
                    0.6,
                    0.636,
                    0.672,
                    0.708,
                    0.744,
                    0.78,
                    0.816,
                    0.852,
                    0.888,
                    0.924,
                    0.96,
                    0.996
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to rewards and incentives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to rewards and incentives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggrg494zv810exr5x7tqbh",
                        "tokens": [
                            " into",
                            " book",
                            "stores",
                            " and",
                            " comic",
                            " stands",
                            " everywhere",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " greatly",
                            " value",
                            " our",
                            " contributors",
                            " and",
                            " have",
                            " a",
                            " large",
                            " range",
                            " of",
                            " rewards",
                            " for",
                            " those",
                            " who",
                            " choose",
                            " to",
                            " support",
                            " our",
                            " project",
                            ".",
                            " We",
                            " are",
                            " offering",
                            " everything",
                            " from",
                            " a",
                            " free",
                            " pre",
                            "quel",
                            " short",
                            " story",
                            " to",
                            " a",
                            " thank",
                            " you",
                            " phone",
                            " call",
                            " and",
                            " a",
                            " fictional",
                            " title",
                            " of",
                            " nobility",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "5",
                            " or",
                            " more",
                            " and",
                            " we",
                            " will",
                            " give",
                            " you",
                            " a",
                            " big",
                            " thanks",
                            " on",
                            " our",
                            " website",
                            ",",
                            " lasting",
                            " as",
                            " long",
                            " as",
                            " we",
                            " exist",
                            ".",
                            " Given",
                            " advancing",
                            " technology",
                            " and",
                            " a",
                            " successful",
                            " series",
                            " of",
                            " projects",
                            " we",
                            " plan",
                            " on",
                            " this",
                            " being",
                            " F",
                            "ORE",
                            "VER",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "7",
                            " or",
                            " more",
                            " and",
                            " you",
                            " will",
                            " get",
                            " the",
                            " previous",
                            " reward",
                            " and",
                            " a",
                            " digital",
                            " download",
                            " of",
                            " Lost",
                            " D",
                            "aim",
                            "yo",
                            ",",
                            " the",
                            " short"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.188,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.54,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrg4b4zvj10ex17gr289a",
                        "tokens": [
                            " into",
                            " book",
                            "stores",
                            " and",
                            " comic",
                            " stands",
                            " everywhere",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " greatly",
                            " value",
                            " our",
                            " contributors",
                            " and",
                            " have",
                            " a",
                            " large",
                            " range",
                            " of",
                            " rewards",
                            " for",
                            " those",
                            " who",
                            " choose",
                            " to",
                            " support",
                            " our",
                            " project",
                            ".",
                            " We",
                            " are",
                            " offering",
                            " everything",
                            " from",
                            " a",
                            " free",
                            " pre",
                            "quel",
                            " short",
                            " story",
                            " to",
                            " a",
                            " thank",
                            " you",
                            " phone",
                            " call",
                            " and",
                            " a",
                            " fictional",
                            " title",
                            " of",
                            " nobility",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "5",
                            " or",
                            " more",
                            " and",
                            " we",
                            " will",
                            " give",
                            " you",
                            " a",
                            " big",
                            " thanks",
                            " on",
                            " our",
                            " website",
                            ",",
                            " lasting",
                            " as",
                            " long",
                            " as",
                            " we",
                            " exist",
                            ".",
                            " Given",
                            " advancing",
                            " technology",
                            " and",
                            " a",
                            " successful",
                            " series",
                            " of",
                            " projects",
                            " we",
                            " plan",
                            " on",
                            " this",
                            " being",
                            " F",
                            "ORE",
                            "VER",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "7",
                            " or",
                            " more",
                            " and",
                            " you",
                            " will",
                            " get",
                            " the",
                            " previous",
                            " reward",
                            " and",
                            " a",
                            " digital",
                            " download",
                            " of",
                            " Lost",
                            " D",
                            "aim",
                            "yo",
                            ",",
                            " the",
                            " short"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.188,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.54,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrg494zv910exoptsu1fp",
                        "tokens": [
                            ",",
                            " and",
                            " allowing",
                            " the",
                            " fans",
                            " (",
                            "YOU",
                            "!)",
                            " to",
                            " be",
                            " much",
                            " more",
                            " involved",
                            " in",
                            " the",
                            " incentives",
                            " for",
                            " the",
                            " next",
                            " go",
                            " around",
                            ".",
                            "\n",
                            "\n",
                            "WH",
                            "Y",
                            " $",
                            "12",
                            ",",
                            "000",
                            "?:",
                            "\n",
                            "\n",
                            "After",
                            " crunch",
                            "ing",
                            " the",
                            " numbers",
                            ",",
                            " this",
                            " is",
                            " the",
                            " necessary",
                            " amount",
                            " in",
                            " order",
                            " for",
                            " me",
                            " to",
                            " accomplish",
                            " all",
                            " that",
                            " I",
                            " am",
                            " offering",
                            ".",
                            " The",
                            " money",
                            " would",
                            " fund",
                            " the",
                            " printing",
                            " of",
                            " 500",
                            " full",
                            "-",
                            "color",
                            " 100",
                            "+",
                            " page",
                            " soft",
                            " cover",
                            " copies",
                            " of",
                            " the",
                            " first",
                            " book",
                            ".",
                            " It",
                            " would",
                            " also",
                            " go",
                            " towards",
                            " creating",
                            " and",
                            " distributing",
                            " the",
                            " rewards",
                            " to",
                            " all",
                            " of",
                            " those",
                            " who",
                            " pledge",
                            ".",
                            " Last",
                            " but",
                            " not",
                            " least",
                            ",",
                            " and",
                            " I",
                            "'m",
                            " not",
                            " going",
                            " to",
                            " lie",
                            ",",
                            " a",
                            " good",
                            " portion",
                            " of",
                            " the",
                            " funding",
                            " will",
                            " enable",
                            " me",
                            " to",
                            " take",
                            " time",
                            " away",
                            " from",
                            " my",
                            " full",
                            " time",
                            " job",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.541,
                        "maxValueTokenIndex": 87,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.293,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "47776",
            "description": "references to rewards and incentives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.565875496514113,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "47776",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:24:21.339Z",
                "maxActApprox": 46.676,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    47776,
                    10651,
                    25967,
                    8598,
                    44199,
                    44315,
                    11246,
                    7998,
                    43298,
                    41017,
                    29774,
                    37320,
                    27279,
                    33606,
                    25728,
                    36281,
                    47244,
                    1198,
                    32006,
                    17129,
                    48067,
                    25787,
                    19242,
                    6719,
                    4296
                ],
                "topkCosSimValues": [
                    1,
                    0.6213,
                    0.5588,
                    0.5356,
                    0.5228,
                    0.4903,
                    0.49,
                    0.4839,
                    0.4492,
                    0.4468,
                    0.428,
                    0.4038,
                    0.4032,
                    0.4031,
                    0.3954,
                    0.393,
                    0.38,
                    0.3792,
                    0.3785,
                    0.3765,
                    0.3759,
                    0.3721,
                    0.3699,
                    0.3682,
                    0.3677
                ],
                "neuron_alignment_indices": [
                    288,
                    620,
                    348
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.115,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    620,
                    424,
                    262
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.013,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.012,
                    0.011
                ],
                "correlated_features_indices": [
                    47782,
                    47844,
                    47820
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.011,
                    0.004
                ],
                "correlated_features_l1": [
                    0.016,
                    0.011,
                    0.004
                ],
                "neg_str": [
                    "abases",
                    " Sloven",
                    "abad",
                    "ovie",
                    " Osw",
                    "inx",
                    "ahime",
                    "uania",
                    "icago",
                    "obiles"
                ],
                "neg_values": [
                    -0.818,
                    -0.795,
                    -0.754,
                    -0.743,
                    -0.724,
                    -0.722,
                    -0.706,
                    -0.695,
                    -0.692,
                    -0.675
                ],
                "pos_str": [
                    " reward",
                    " rewards",
                    " rewarded",
                    " tiers",
                    "giving",
                    " fulfillment",
                    " recipients",
                    " rewarding",
                    " reap",
                    " incentive"
                ],
                "pos_values": [
                    1.021,
                    0.978,
                    0.936,
                    0.809,
                    0.805,
                    0.798,
                    0.793,
                    0.788,
                    0.778,
                    0.776
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    163,
                    91,
                    49,
                    22,
                    19,
                    10,
                    4,
                    4,
                    5,
                    5,
                    2,
                    3,
                    0,
                    4,
                    0,
                    1,
                    0,
                    3,
                    2,
                    2,
                    2,
                    1,
                    2,
                    2,
                    1,
                    5,
                    2,
                    5,
                    2,
                    4,
                    4,
                    4,
                    4,
                    5,
                    4,
                    5,
                    4,
                    5,
                    10,
                    8,
                    7,
                    4,
                    5,
                    3,
                    9,
                    2,
                    2,
                    2,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.47,
                    1.403,
                    2.337,
                    3.27,
                    4.203,
                    5.137,
                    6.07,
                    7.004,
                    7.937,
                    8.871,
                    9.804,
                    10.738,
                    11.671,
                    12.605,
                    13.538,
                    14.472,
                    15.405,
                    16.338,
                    17.272,
                    18.205,
                    19.139,
                    20.072,
                    21.006,
                    21.939,
                    22.873,
                    23.806,
                    24.74,
                    25.673,
                    26.607,
                    27.54,
                    28.474,
                    29.407,
                    30.34,
                    31.274,
                    32.207,
                    33.141,
                    34.074,
                    35.008,
                    35.941,
                    36.875,
                    37.808,
                    38.742,
                    39.675,
                    40.609,
                    41.542,
                    42.475,
                    43.409,
                    44.342,
                    45.276,
                    46.209
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    3,
                    4,
                    6,
                    15,
                    28,
                    25,
                    82,
                    134,
                    184,
                    301,
                    500,
                    766,
                    1052,
                    1492,
                    1969,
                    2480,
                    3051,
                    3730,
                    4027,
                    4373,
                    4382,
                    4191,
                    3769,
                    3327,
                    2786,
                    2165,
                    1577,
                    1209,
                    921,
                    620,
                    381,
                    242,
                    165,
                    105,
                    73,
                    45,
                    24,
                    19,
                    9,
                    8,
                    3,
                    6,
                    2,
                    0,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.799,
                    -0.762,
                    -0.726,
                    -0.689,
                    -0.652,
                    -0.615,
                    -0.579,
                    -0.542,
                    -0.505,
                    -0.468,
                    -0.432,
                    -0.395,
                    -0.358,
                    -0.321,
                    -0.284,
                    -0.248,
                    -0.211,
                    -0.174,
                    -0.137,
                    -0.101,
                    -0.064,
                    -0.027,
                    0.01,
                    0.046,
                    0.083,
                    0.12,
                    0.157,
                    0.193,
                    0.23,
                    0.267,
                    0.304,
                    0.341,
                    0.377,
                    0.414,
                    0.451,
                    0.488,
                    0.524,
                    0.561,
                    0.598,
                    0.635,
                    0.671,
                    0.708,
                    0.745,
                    0.782,
                    0.818,
                    0.855,
                    0.892,
                    0.929,
                    0.965,
                    1.002
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to rewards and incentives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk76w59jomii6660ha5md40",
                        "tokens": [
                            " outweigh",
                            "s",
                            " the",
                            " possible",
                            " reward",
                            ".",
                            " The",
                            " company",
                            ",",
                            " he",
                            " said",
                            ",",
                            " can",
                            " only",
                            " expect",
                            " to",
                            " start",
                            " making",
                            " profits",
                            " around",
                            " the",
                            " middle",
                            " of",
                            " the",
                            " next",
                            " decade",
                            " at",
                            " the",
                            " earliest",
                            ",",
                            " and",
                            " then",
                            " only",
                            " if",
                            " the",
                            " oil",
                            " price",
                            " is",
                            " at",
                            " least",
                            " $",
                            "80",
                            " per",
                            " barrel",
                            ".",
                            " Much",
                            " better",
                            ",",
                            " said",
                            " Wal",
                            "ia",
                            ",",
                            " would",
                            " be",
                            " for",
                            " Shell",
                            " to",
                            " invest",
                            " in",
                            " other",
                            " projects",
                            ",",
                            " for",
                            " instance",
                            " in",
                            " Brazil",
                            " and",
                            " Australia",
                            " and",
                            " in",
                            " its",
                            " new",
                            " acquisition",
                            ",",
                            " BG",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Chu",
                            "ks",
                            "hi",
                            " Sea",
                            " can",
                            " supply",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " oil",
                            " needs",
                            " for",
                            " just",
                            " two",
                            " months",
                            "\n",
                            "\n",
                            "But",
                            " Shell",
                            " remained",
                            " deaf",
                            " to",
                            " all",
                            " these",
                            " pleas",
                            ".",
                            " CEO",
                            " Ben",
                            " van",
                            " Be",
                            "urden",
                            " said",
                            " Shell",
                            " was",
                            " managing",
                            " the",
                            " risks",
                            " of",
                            " Arctic",
                            " drilling",
                            " \u00e2\u0122",
                            "\u013e",
                            "down",
                            " to",
                            " the",
                            " levels"
                        ],
                        "dataIndex": null,
                        "index": "47776",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.676,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            46.676,
                            1.762,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:24:25.058Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.676,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk76w5bjon3i666cwb6oiz7",
                        "tokens": [
                            " outweigh",
                            "s",
                            " the",
                            " possible",
                            " reward",
                            ".",
                            " The",
                            " company",
                            ",",
                            " he",
                            " said",
                            ",",
                            " can",
                            " only",
                            " expect",
                            " to",
                            " start",
                            " making",
                            " profits",
                            " around",
                            " the",
                            " middle",
                            " of",
                            " the",
                            " next",
                            " decade",
                            " at",
                            " the",
                            " earliest",
                            ",",
                            " and",
                            " then",
                            " only",
                            " if",
                            " the",
                            " oil",
                            " price",
                            " is",
                            " at",
                            " least",
                            " $",
                            "80",
                            " per",
                            " barrel",
                            ".",
                            " Much",
                            " better",
                            ",",
                            " said",
                            " Wal",
                            "ia",
                            ",",
                            " would",
                            " be",
                            " for",
                            " Shell",
                            " to",
                            " invest",
                            " in",
                            " other",
                            " projects",
                            ",",
                            " for",
                            " instance",
                            " in",
                            " Brazil",
                            " and",
                            " Australia",
                            " and",
                            " in",
                            " its",
                            " new",
                            " acquisition",
                            ",",
                            " BG",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Chu",
                            "ks",
                            "hi",
                            " Sea",
                            " can",
                            " supply",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " oil",
                            " needs",
                            " for",
                            " just",
                            " two",
                            " months",
                            "\n",
                            "\n",
                            "But",
                            " Shell",
                            " remained",
                            " deaf",
                            " to",
                            " all",
                            " these",
                            " pleas",
                            ".",
                            " CEO",
                            " Ben",
                            " van",
                            " Be",
                            "urden",
                            " said",
                            " Shell",
                            " was",
                            " managing",
                            " the",
                            " risks",
                            " of",
                            " Arctic",
                            " drilling",
                            " \u00e2\u0122",
                            "\u013e",
                            "down",
                            " to",
                            " the",
                            " levels"
                        ],
                        "dataIndex": null,
                        "index": "47776",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.676,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            46.676,
                            1.762,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:24:25.058Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 37.341,
                        "binMax": 46.676,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk76w59jomji66673zovq0f",
                        "tokens": [
                            "\n",
                            "\n",
                            "We",
                            " have",
                            " several",
                            " reward",
                            " tiers",
                            " to",
                            " thank",
                            " you",
                            " for",
                            " your",
                            " support",
                            ".",
                            " Depending",
                            " on",
                            " the",
                            " reward",
                            " tier",
                            " you",
                            " select",
                            ",",
                            " you",
                            " will",
                            " receive",
                            " wall",
                            "papers",
                            ",",
                            " digital",
                            " copies",
                            " of",
                            " Buck",
                            ",",
                            " the",
                            " soundtrack",
                            " and",
                            " the",
                            " art",
                            " book",
                            ",",
                            " a",
                            " limited",
                            " edition",
                            " physical",
                            " copy",
                            " of",
                            " Buck",
                            " on",
                            " disc",
                            ",",
                            " signed",
                            " items",
                            ",",
                            " access",
                            " to",
                            " the",
                            " Alpha",
                            " and",
                            " Beta",
                            " versions",
                            " of",
                            " Buck",
                            " and",
                            " more",
                            "!",
                            " Check",
                            " the",
                            " reward",
                            " tiers",
                            " on",
                            " the",
                            " right",
                            " or",
                            " the",
                            " images",
                            " below",
                            " to",
                            " see",
                            " what",
                            " you",
                            " can",
                            " get",
                            " for",
                            " backing",
                            " Buck",
                            "!",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            " above",
                            ",",
                            " we",
                            "'ve",
                            " budget",
                            "ed",
                            " for",
                            " the",
                            " funds",
                            " that",
                            ",",
                            " with",
                            " your",
                            " support",
                            ",",
                            " will",
                            " help",
                            " us",
                            " finish",
                            " the",
                            " development",
                            " of",
                            " Buck",
                            ".",
                            " There",
                            " are",
                            " Kickstarter",
                            " fees",
                            " to",
                            " cover",
                            ",",
                            " taxes",
                            ",",
                            " marketing",
                            " costs"
                        ],
                        "dataIndex": null,
                        "index": "47776",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.672,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.672,
                            0.362,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.901,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.165,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.826,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:24:25.058Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.676,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "22194",
            "description": " specific terms related to reward or incentive structures",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5601901412010193,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "22194",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:56:32.159Z",
                "maxActApprox": 35.582,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    22194,
                    26145,
                    77442,
                    16429,
                    90503,
                    57564,
                    48297,
                    83516,
                    82028,
                    76268,
                    43233,
                    47658,
                    27725,
                    18801,
                    34034,
                    21639,
                    76166,
                    74342,
                    15395,
                    29818,
                    67825,
                    17862,
                    79058,
                    58683,
                    85863
                ],
                "topkCosSimValues": [
                    1,
                    0.6038,
                    0.578,
                    0.5132,
                    0.3736,
                    0.3547,
                    0.3455,
                    0.3301,
                    0.3268,
                    0.3267,
                    0.3236,
                    0.3222,
                    0.3208,
                    0.3203,
                    0.3129,
                    0.3125,
                    0.3121,
                    0.3104,
                    0.309,
                    0.3046,
                    0.3017,
                    0.2999,
                    0.2962,
                    0.2943,
                    0.2929
                ],
                "neuron_alignment_indices": [
                    373,
                    323,
                    343
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.119,
                    0.113
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    343,
                    120,
                    546
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_features_indices": [
                    22148,
                    22194,
                    22142
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0,
                    0
                ],
                "neg_str": [
                    "AY",
                    "natureconservancy",
                    "dfx",
                    "RO",
                    "isSpecialOrderable",
                    "ELD",
                    "ECT",
                    "WN",
                    "ERG",
                    "TY"
                ],
                "neg_values": [
                    -0.742,
                    -0.719,
                    -0.667,
                    -0.663,
                    -0.653,
                    -0.626,
                    -0.616,
                    -0.616,
                    -0.614,
                    -0.605
                ],
                "pos_str": [
                    "neau",
                    "anza",
                    "iton",
                    "bon",
                    "uses",
                    "amic",
                    "fman",
                    "isson",
                    " fide",
                    "nets"
                ],
                "pos_values": [
                    1.38,
                    0.939,
                    0.935,
                    0.899,
                    0.834,
                    0.807,
                    0.805,
                    0.801,
                    0.798,
                    0.795
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    31,
                    6,
                    6,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.357,
                    1.069,
                    1.78,
                    2.492,
                    3.204,
                    3.915,
                    4.627,
                    5.338,
                    6.05,
                    6.762,
                    7.473,
                    8.185,
                    8.896,
                    9.608,
                    10.32,
                    11.031,
                    11.743,
                    12.454,
                    13.166,
                    13.878,
                    14.589,
                    15.301,
                    16.012,
                    16.724,
                    17.436,
                    18.147,
                    18.859,
                    19.57,
                    20.282,
                    20.994,
                    21.705,
                    22.417,
                    23.128,
                    23.84,
                    24.552,
                    25.263,
                    25.975,
                    26.687,
                    27.398,
                    28.11,
                    28.821,
                    29.533,
                    30.245,
                    30.956,
                    31.668,
                    32.379,
                    33.091,
                    33.803,
                    34.514,
                    35.226
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    4,
                    10,
                    15,
                    31,
                    66,
                    151,
                    264,
                    492,
                    852,
                    1455,
                    2295,
                    3131,
                    4176,
                    5079,
                    5327,
                    5382,
                    5086,
                    4516,
                    3521,
                    2732,
                    1851,
                    1228,
                    844,
                    589,
                    371,
                    275,
                    202,
                    116,
                    69,
                    40,
                    43,
                    8,
                    12,
                    9,
                    6,
                    1,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.679,
                    -0.636,
                    -0.594,
                    -0.551,
                    -0.509,
                    -0.466,
                    -0.424,
                    -0.381,
                    -0.339,
                    -0.297,
                    -0.254,
                    -0.212,
                    -0.169,
                    -0.127,
                    -0.084,
                    -0.042,
                    0.001,
                    0.043,
                    0.085,
                    0.128,
                    0.17,
                    0.213,
                    0.255,
                    0.298,
                    0.34,
                    0.383,
                    0.425,
                    0.467,
                    0.51,
                    0.552,
                    0.595,
                    0.637,
                    0.68,
                    0.722,
                    0.765,
                    0.807,
                    0.849,
                    0.892,
                    0.934,
                    0.977,
                    1.019,
                    1.062,
                    1.104,
                    1.146,
                    1.189,
                    1.231,
                    1.274,
                    1.316,
                    1.359
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " specific terms related to reward or incentive structures",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "words related to the term \"bon\"",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfw4q9s4o410ex02mi7ib1",
                        "tokens": [
                            ".\"",
                            "\n",
                            "\n",
                            "'",
                            "We",
                            " Should",
                            " Have",
                            " Noticed",
                            " Something",
                            "'",
                            "\n",
                            "\n",
                            "Sah",
                            "ra",
                            "'s",
                            " father",
                            " is",
                            " a",
                            " tall",
                            ",",
                            " gentle",
                            " man",
                            " with",
                            " powerful",
                            " hands",
                            ".",
                            " In",
                            " a",
                            " region",
                            " with",
                            " high",
                            " unemployment",
                            ",",
                            " he",
                            " has",
                            " been",
                            " supporting",
                            " his",
                            " family",
                            " with",
                            " odd",
                            " jobs",
                            " for",
                            " the",
                            " last",
                            " few",
                            " years",
                            ".",
                            " \"",
                            "We",
                            " should",
                            " have",
                            " noticed",
                            " something",
                            ",\"",
                            " says",
                            " Me",
                            "hen",
                            "ni",
                            ".",
                            " His",
                            " wife",
                            " repeatedly",
                            " says",
                            " the",
                            " same",
                            " thing",
                            ".",
                            "\n",
                            "\n",
                            "Me",
                            "h",
                            "ault",
                            " and",
                            " Me",
                            "hen",
                            "ni",
                            " live",
                            " with",
                            " their",
                            " children",
                            " in",
                            " a",
                            " yellow",
                            ",",
                            " two",
                            "-",
                            "story",
                            " house",
                            ",",
                            " in",
                            " a",
                            " town",
                            " of",
                            " 8",
                            ",",
                            "000",
                            " inhabitants",
                            " near",
                            " Nar",
                            "bon",
                            "ne",
                            ",",
                            " which",
                            " we",
                            " will",
                            " not",
                            " name",
                            ",",
                            " surrounded",
                            " by",
                            " the",
                            " vine",
                            "yards",
                            " of",
                            " the",
                            " Lang",
                            "ued",
                            "oc",
                            " region",
                            ".",
                            " Wild",
                            " grape",
                            "v",
                            "ines",
                            " are",
                            " ent"
                        ],
                        "dataIndex": null,
                        "index": "22194",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.582,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:56:37.577Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.582,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfw4qbs4oo10ex5j1debse",
                        "tokens": [
                            ".\"",
                            "\n",
                            "\n",
                            "'",
                            "We",
                            " Should",
                            " Have",
                            " Noticed",
                            " Something",
                            "'",
                            "\n",
                            "\n",
                            "Sah",
                            "ra",
                            "'s",
                            " father",
                            " is",
                            " a",
                            " tall",
                            ",",
                            " gentle",
                            " man",
                            " with",
                            " powerful",
                            " hands",
                            ".",
                            " In",
                            " a",
                            " region",
                            " with",
                            " high",
                            " unemployment",
                            ",",
                            " he",
                            " has",
                            " been",
                            " supporting",
                            " his",
                            " family",
                            " with",
                            " odd",
                            " jobs",
                            " for",
                            " the",
                            " last",
                            " few",
                            " years",
                            ".",
                            " \"",
                            "We",
                            " should",
                            " have",
                            " noticed",
                            " something",
                            ",\"",
                            " says",
                            " Me",
                            "hen",
                            "ni",
                            ".",
                            " His",
                            " wife",
                            " repeatedly",
                            " says",
                            " the",
                            " same",
                            " thing",
                            ".",
                            "\n",
                            "\n",
                            "Me",
                            "h",
                            "ault",
                            " and",
                            " Me",
                            "hen",
                            "ni",
                            " live",
                            " with",
                            " their",
                            " children",
                            " in",
                            " a",
                            " yellow",
                            ",",
                            " two",
                            "-",
                            "story",
                            " house",
                            ",",
                            " in",
                            " a",
                            " town",
                            " of",
                            " 8",
                            ",",
                            "000",
                            " inhabitants",
                            " near",
                            " Nar",
                            "bon",
                            "ne",
                            ",",
                            " which",
                            " we",
                            " will",
                            " not",
                            " name",
                            ",",
                            " surrounded",
                            " by",
                            " the",
                            " vine",
                            "yards",
                            " of",
                            " the",
                            " Lang",
                            "ued",
                            "oc",
                            " region",
                            ".",
                            " Wild",
                            " grape",
                            "v",
                            "ines",
                            " are",
                            " ent"
                        ],
                        "dataIndex": null,
                        "index": "22194",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.582,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:56:37.577Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 28.465,
                        "binMax": 35.582,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfw4q9s4o510exeyzsq5kr",
                        "tokens": [
                            "k",
                            ".",
                            "a",
                            " Micro",
                            " (",
                            "E",
                            "bon",
                            " Moss",
                            "-",
                            "B",
                            "ach",
                            "r",
                            "ach",
                            "),",
                            " Frank",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " longtime",
                            " hacker",
                            " ally",
                            " in",
                            " the",
                            " comics",
                            ",",
                            " and",
                            " his",
                            " wife",
                            ",",
                            " Sarah",
                            " (",
                            "Ja",
                            "ime",
                            " Ray",
                            " Newman",
                            "):",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "Big",
                            " bad",
                            " Billy",
                            " Russo",
                            ",",
                            " a",
                            ".",
                            "k",
                            ".",
                            "a",
                            ".",
                            " J",
                            "igsaw",
                            " (",
                            "Ben",
                            " Barnes",
                            "),",
                            " the",
                            " gunman",
                            " in",
                            " the",
                            " comics",
                            " hired",
                            " to",
                            " cover",
                            " up",
                            " the",
                            " botched",
                            " assassination",
                            " attempt",
                            " that",
                            " got",
                            " Frank",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " family",
                            " killed",
                            " in",
                            " the",
                            " cross",
                            "fire",
                            "\u2014",
                            "but",
                            " included",
                            " in",
                            " the",
                            " show",
                            " as",
                            " a",
                            " former",
                            " combat",
                            " vet",
                            " friend",
                            " of",
                            " Frank",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " who",
                            " now",
                            " runs",
                            " a",
                            " private",
                            " military",
                            " company",
                            ":",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "A",
                            " few",
                            " more",
                            " military",
                            " figures",
                            ",",
                            " including",
                            " another",
                            " member",
                            " of",
                            " Frank",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "22194",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.93,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.93,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:56:37.577Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.582,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "2072",
            "description": "phrases related to rewards or consequences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5595269203186035,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "2072",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:47:14.770Z",
                "maxActApprox": 24.808,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2072,
                    9057,
                    16719,
                    7976,
                    23867,
                    20386,
                    4871,
                    9968,
                    22101,
                    16219,
                    9639,
                    2164,
                    10438,
                    5739,
                    4606,
                    12629,
                    1768,
                    13107,
                    3983,
                    14222,
                    21235,
                    6918,
                    16549,
                    7468,
                    21913
                ],
                "topkCosSimValues": [
                    1,
                    0.4482,
                    0.4252,
                    0.4103,
                    0.4032,
                    0.3927,
                    0.3924,
                    0.3793,
                    0.3694,
                    0.3607,
                    0.3591,
                    0.3576,
                    0.3547,
                    0.3533,
                    0.3518,
                    0.3502,
                    0.3416,
                    0.3356,
                    0.3314,
                    0.326,
                    0.3188,
                    0.3171,
                    0.314,
                    0.3128,
                    0.311
                ],
                "neuron_alignment_indices": [
                    456,
                    671,
                    617
                ],
                "neuron_alignment_values": [
                    0.088,
                    0.081,
                    0.081
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    507,
                    665,
                    468
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.026,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.03,
                    0.031,
                    0.024
                ],
                "correlated_features_indices": [
                    2164,
                    2116,
                    2134
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.017,
                    0.008
                ],
                "correlated_features_l1": [
                    0.019,
                    0.018,
                    0.008
                ],
                "neg_str": [
                    "soDeliveryDate",
                    "fo",
                    "bsite",
                    "auntlet",
                    "fax",
                    "fried",
                    "behind",
                    "chart",
                    "ija",
                    "psons"
                ],
                "neg_values": [
                    -0.678,
                    -0.674,
                    -0.669,
                    -0.654,
                    -0.653,
                    -0.648,
                    -0.643,
                    -0.635,
                    -0.632,
                    -0.616
                ],
                "pos_str": [
                    " individuals",
                    " broadcasters",
                    " recipients",
                    " applicants",
                    " wasteful",
                    " individual",
                    " incumb",
                    " sellers",
                    "erous",
                    " them"
                ],
                "pos_values": [
                    0.865,
                    0.857,
                    0.839,
                    0.788,
                    0.774,
                    0.756,
                    0.75,
                    0.747,
                    0.745,
                    0.743
                ],
                "frac_nonzero": 0.00139,
                "freq_hist_data_bar_heights": [
                    961,
                    776,
                    541,
                    405,
                    329,
                    269,
                    196,
                    173,
                    103,
                    107,
                    79,
                    71,
                    49,
                    44,
                    38,
                    30,
                    21,
                    17,
                    12,
                    17,
                    15,
                    17,
                    12,
                    7,
                    13,
                    5,
                    8,
                    7,
                    5,
                    5,
                    6,
                    5,
                    7,
                    3,
                    4,
                    2,
                    0,
                    1,
                    1,
                    0,
                    3,
                    0,
                    2,
                    3,
                    2,
                    1,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.249,
                    0.745,
                    1.241,
                    1.737,
                    2.233,
                    2.729,
                    3.226,
                    3.722,
                    4.218,
                    4.714,
                    5.21,
                    5.706,
                    6.202,
                    6.699,
                    7.195,
                    7.691,
                    8.187,
                    8.683,
                    9.179,
                    9.675,
                    10.172,
                    10.668,
                    11.164,
                    11.66,
                    12.156,
                    12.652,
                    13.148,
                    13.645,
                    14.141,
                    14.637,
                    15.133,
                    15.629,
                    16.125,
                    16.621,
                    17.118,
                    17.614,
                    18.11,
                    18.606,
                    19.102,
                    19.598,
                    20.094,
                    20.591,
                    21.087,
                    21.583,
                    22.079,
                    22.575,
                    23.071,
                    23.567,
                    24.064,
                    24.56
                ],
                "logits_hist_data_bar_heights": [
                    6,
                    3,
                    9,
                    23,
                    24,
                    35,
                    79,
                    125,
                    186,
                    260,
                    401,
                    576,
                    790,
                    1106,
                    1410,
                    1804,
                    2264,
                    2683,
                    2986,
                    3335,
                    3636,
                    3670,
                    3765,
                    3693,
                    3284,
                    2823,
                    2640,
                    2088,
                    1590,
                    1274,
                    976,
                    744,
                    572,
                    400,
                    270,
                    200,
                    128,
                    114,
                    83,
                    65,
                    45,
                    35,
                    18,
                    17,
                    8,
                    4,
                    5,
                    2,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.662,
                    -0.632,
                    -0.601,
                    -0.57,
                    -0.539,
                    -0.508,
                    -0.477,
                    -0.447,
                    -0.416,
                    -0.385,
                    -0.354,
                    -0.323,
                    -0.292,
                    -0.261,
                    -0.231,
                    -0.2,
                    -0.169,
                    -0.138,
                    -0.107,
                    -0.076,
                    -0.045,
                    -0.015,
                    0.016,
                    0.047,
                    0.078,
                    0.109,
                    0.14,
                    0.171,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.417,
                    0.448,
                    0.479,
                    0.51,
                    0.541,
                    0.572,
                    0.602,
                    0.633,
                    0.664,
                    0.695,
                    0.726,
                    0.757,
                    0.788,
                    0.818,
                    0.849
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to rewards or consequences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm3h951yuxi666ow0t2gtw",
                        "tokens": [
                            " an",
                            " unconstitutional",
                            " redistribution",
                            " of",
                            " income",
                            " in",
                            " favor",
                            " of",
                            " the",
                            " undes",
                            "erving",
                            " rich",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Federal",
                            " bail",
                            "outs",
                            " reward",
                            " inefficient",
                            " and",
                            " corrupt",
                            " management",
                            ",",
                            " rob",
                            " taxpayers",
                            ",",
                            " hurt",
                            " smaller",
                            " and",
                            " more",
                            " responsible",
                            " private",
                            " firms",
                            ",",
                            " exacerbate",
                            " our",
                            " budget",
                            " problems",
                            ",",
                            " explode",
                            " national",
                            " debt",
                            ",",
                            " and",
                            " destroy",
                            " our",
                            " U",
                            ".",
                            "S",
                            ".",
                            " dollar",
                            ".",
                            " Even",
                            " more",
                            " importantly",
                            ",",
                            " any",
                            " bailout",
                            " of",
                            " private",
                            " industry",
                            " is",
                            " in",
                            " direct",
                            " violation",
                            " of",
                            " the",
                            " Constitution",
                            ".",
                            " It",
                            " is",
                            " a",
                            " transfer",
                            " of",
                            " wealth",
                            " from",
                            " those",
                            " who",
                            " have",
                            " earned",
                            " to",
                            " those",
                            " who",
                            " have",
                            " squ",
                            "and",
                            "ered",
                            ".\"",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            " the",
                            " j",
                            "oker",
                            " in",
                            " the",
                            " deck",
                            " is",
                            " the",
                            " word",
                            " principled",
                            " before",
                            " libertarian",
                            ",",
                            " and",
                            ",",
                            " as",
                            " many",
                            " online",
                            " commentators",
                            " have",
                            " noted",
                            ",",
                            " Rand",
                            " Paul",
                            " is",
                            " a",
                            " bit",
                            " more",
                            " inclined",
                            " to",
                            " w",
                            "affle",
                            " on"
                        ],
                        "dataIndex": null,
                        "index": "2072",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.808,
                        "maxValueTokenIndex": 19,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.136,
                            2.055,
                            0,
                            0.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.808,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.047,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.958,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.243,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:17.256Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 24.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm3h971yvii666ynn9h0wc",
                        "tokens": [
                            " an",
                            " unconstitutional",
                            " redistribution",
                            " of",
                            " income",
                            " in",
                            " favor",
                            " of",
                            " the",
                            " undes",
                            "erving",
                            " rich",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Federal",
                            " bail",
                            "outs",
                            " reward",
                            " inefficient",
                            " and",
                            " corrupt",
                            " management",
                            ",",
                            " rob",
                            " taxpayers",
                            ",",
                            " hurt",
                            " smaller",
                            " and",
                            " more",
                            " responsible",
                            " private",
                            " firms",
                            ",",
                            " exacerbate",
                            " our",
                            " budget",
                            " problems",
                            ",",
                            " explode",
                            " national",
                            " debt",
                            ",",
                            " and",
                            " destroy",
                            " our",
                            " U",
                            ".",
                            "S",
                            ".",
                            " dollar",
                            ".",
                            " Even",
                            " more",
                            " importantly",
                            ",",
                            " any",
                            " bailout",
                            " of",
                            " private",
                            " industry",
                            " is",
                            " in",
                            " direct",
                            " violation",
                            " of",
                            " the",
                            " Constitution",
                            ".",
                            " It",
                            " is",
                            " a",
                            " transfer",
                            " of",
                            " wealth",
                            " from",
                            " those",
                            " who",
                            " have",
                            " earned",
                            " to",
                            " those",
                            " who",
                            " have",
                            " squ",
                            "and",
                            "ered",
                            ".\"",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            " the",
                            " j",
                            "oker",
                            " in",
                            " the",
                            " deck",
                            " is",
                            " the",
                            " word",
                            " principled",
                            " before",
                            " libertarian",
                            ",",
                            " and",
                            ",",
                            " as",
                            " many",
                            " online",
                            " commentators",
                            " have",
                            " noted",
                            ",",
                            " Rand",
                            " Paul",
                            " is",
                            " a",
                            " bit",
                            " more",
                            " inclined",
                            " to",
                            " w",
                            "affle",
                            " on"
                        ],
                        "dataIndex": null,
                        "index": "2072",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.808,
                        "maxValueTokenIndex": 19,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.136,
                            2.055,
                            0,
                            0.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.808,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.047,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.958,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.243,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:17.256Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 19.846,
                        "binMax": 24.808,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm3h951yuyi6664m9l8vrb",
                        "tokens": [
                            "wiki",
                            "How",
                            " is",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "wiki",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " similar",
                            " to",
                            " Wikipedia",
                            ",",
                            " which",
                            " means",
                            " that",
                            " many",
                            " of",
                            " our",
                            " articles",
                            " are",
                            " co",
                            "-",
                            "written",
                            " by",
                            " multiple",
                            " authors",
                            ".",
                            " To",
                            " create",
                            " this",
                            " article",
                            ",",
                            " 31",
                            " people",
                            ",",
                            " some",
                            " anonymous",
                            ",",
                            " worked",
                            " to",
                            " edit",
                            " and",
                            " improve",
                            " it",
                            " over",
                            " time",
                            ".",
                            " This",
                            " article",
                            " has",
                            " also",
                            " been",
                            " viewed",
                            " 242",
                            ",",
                            "356",
                            " times",
                            ".",
                            " Learn",
                            " more",
                            "...",
                            "\n",
                            "\n",
                            "In",
                            " this",
                            " Article",
                            ":",
                            "Value",
                            " what",
                            " matters",
                            " to",
                            " g",
                            "eeks",
                            "Avoid",
                            " superficial",
                            "ity",
                            "Be",
                            " fair",
                            " and",
                            " inclusive",
                            "Rec",
                            "ogn",
                            "ize",
                            " and",
                            " reward",
                            " good",
                            " work",
                            "Res",
                            "pect",
                            " creativity",
                            "Re",
                            "ap",
                            " what",
                            " you",
                            " sow",
                            "Community",
                            " Q",
                            "&",
                            "AR",
                            "ef",
                            "erences",
                            "\n",
                            "\n",
                            "When",
                            " the",
                            " g",
                            "eeks",
                            " threaten",
                            " to",
                            " go",
                            " on",
                            " strike",
                            ",",
                            " everyone",
                            " is",
                            " impacted",
                            ";",
                            " from",
                            " AT",
                            "Ms",
                            " and",
                            " electronic",
                            " salary",
                            " payment",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "2072",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.632,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.632,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:17.256Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 24.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "11246",
            "description": "references to systems of rewards or incentives, particularly in the context of points and bounties",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5450355735442394,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "11246",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:18:05.251Z",
                "maxActApprox": 55.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11246,
                    47776,
                    10651,
                    4383,
                    7998,
                    4296,
                    326,
                    23822,
                    8598,
                    20374,
                    43298,
                    25010,
                    7313,
                    3867,
                    15539,
                    47844,
                    24802,
                    29378,
                    4518,
                    44315,
                    18762,
                    32894,
                    10174,
                    5585,
                    19242
                ],
                "topkCosSimValues": [
                    1,
                    0.49,
                    0.4247,
                    0.4152,
                    0.3983,
                    0.3845,
                    0.3748,
                    0.3697,
                    0.3625,
                    0.3617,
                    0.361,
                    0.3602,
                    0.3572,
                    0.3472,
                    0.3397,
                    0.3393,
                    0.3367,
                    0.3354,
                    0.3341,
                    0.3297,
                    0.3291,
                    0.3272,
                    0.3247,
                    0.3197,
                    0.3183
                ],
                "neuron_alignment_indices": [
                    288,
                    481,
                    269
                ],
                "neuron_alignment_values": [
                    0.129,
                    0.101,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    605,
                    419
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.007,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.007,
                    0.007
                ],
                "correlated_features_indices": [
                    11218,
                    11293,
                    11271
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "ppard",
                    "mus",
                    "ibur",
                    "icago",
                    "Emb",
                    " Ange",
                    "icken",
                    "alter",
                    "inem",
                    "andem"
                ],
                "neg_values": [
                    -0.818,
                    -0.785,
                    -0.768,
                    -0.753,
                    -0.74,
                    -0.725,
                    -0.717,
                    -0.712,
                    -0.707,
                    -0.683
                ],
                "pos_str": [
                    " bounty",
                    " hunter",
                    " bount",
                    " hunters",
                    " Bounty",
                    " hunting",
                    " Hunters",
                    " reward",
                    " Hunter",
                    " rewards"
                ],
                "pos_values": [
                    1.401,
                    1.291,
                    1.255,
                    1.208,
                    0.987,
                    0.906,
                    0.867,
                    0.859,
                    0.84,
                    0.802
                ],
                "frac_nonzero": 6e-05,
                "freq_hist_data_bar_heights": [
                    69,
                    34,
                    14,
                    26,
                    12,
                    13,
                    6,
                    6,
                    1,
                    4,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    2,
                    0,
                    0,
                    3,
                    2,
                    1,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.562,
                    1.674,
                    2.786,
                    3.898,
                    5.011,
                    6.123,
                    7.235,
                    8.347,
                    9.459,
                    10.571,
                    11.683,
                    12.795,
                    13.907,
                    15.02,
                    16.132,
                    17.244,
                    18.356,
                    19.468,
                    20.58,
                    21.692,
                    22.804,
                    23.917,
                    25.029,
                    26.141,
                    27.253,
                    28.365,
                    29.477,
                    30.589,
                    31.701,
                    32.813,
                    33.926,
                    35.038,
                    36.15,
                    37.262,
                    38.374,
                    39.486,
                    40.598,
                    41.71,
                    42.823,
                    43.935,
                    45.047,
                    46.159,
                    47.271,
                    48.383,
                    49.495,
                    50.607,
                    51.72,
                    52.832,
                    53.944,
                    55.056
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    4,
                    11,
                    26,
                    22,
                    64,
                    132,
                    242,
                    414,
                    681,
                    1058,
                    1663,
                    2387,
                    3175,
                    3834,
                    4348,
                    4982,
                    5083,
                    4967,
                    4419,
                    3721,
                    2843,
                    2077,
                    1437,
                    1040,
                    631,
                    373,
                    255,
                    150,
                    94,
                    48,
                    32,
                    13,
                    9,
                    4,
                    4,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.796,
                    -0.751,
                    -0.707,
                    -0.662,
                    -0.618,
                    -0.574,
                    -0.529,
                    -0.485,
                    -0.441,
                    -0.396,
                    -0.352,
                    -0.307,
                    -0.263,
                    -0.219,
                    -0.174,
                    -0.13,
                    -0.085,
                    -0.041,
                    0.003,
                    0.048,
                    0.092,
                    0.136,
                    0.181,
                    0.225,
                    0.27,
                    0.314,
                    0.358,
                    0.403,
                    0.447,
                    0.491,
                    0.536,
                    0.58,
                    0.625,
                    0.669,
                    0.713,
                    0.758,
                    0.802,
                    0.847,
                    0.891,
                    0.935,
                    0.98,
                    1.024,
                    1.068,
                    1.113,
                    1.157,
                    1.202,
                    1.246,
                    1.29,
                    1.335,
                    1.379
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to systems of rewards or incentives, particularly in the context of points and bounties",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4tq98m0x5i666j33fnks8",
                        "tokens": [
                            " by",
                            " and",
                            " starred",
                            " Clint",
                            " East",
                            "wood",
                            " (",
                            "as",
                            " the",
                            " ep",
                            "onymous",
                            " Jose",
                            "y",
                            " Wales",
                            "),",
                            " with",
                            " Chief",
                            " Dan",
                            " George",
                            ",",
                            " S",
                            "ond",
                            "ra",
                            " Locke",
                            ",",
                            " Sam",
                            " Bott",
                            "oms",
                            ",",
                            " and",
                            " Gerald",
                            "ine",
                            " Ke",
                            "ams",
                            ".[",
                            "3",
                            "]",
                            " The",
                            " film",
                            " tells",
                            " the",
                            " story",
                            " of",
                            " Jose",
                            "y",
                            " Wales",
                            ",",
                            " a",
                            " Missouri",
                            " farmer",
                            " whose",
                            " family",
                            " is",
                            " murdered",
                            " by",
                            " Union",
                            " militants",
                            " during",
                            " the",
                            " Civil",
                            " War",
                            ".",
                            " Dri",
                            "ven",
                            " to",
                            " revenge",
                            ",",
                            " Wales",
                            " joins",
                            " a",
                            " Confederate",
                            " guerrilla",
                            " band",
                            " and",
                            " fights",
                            " in",
                            " the",
                            " Civil",
                            " War",
                            ".",
                            " After",
                            " the",
                            " war",
                            ",",
                            " all",
                            " the",
                            " fighters",
                            " in",
                            " Wales",
                            "'",
                            " group",
                            " except",
                            " for",
                            " Wales",
                            " surrender",
                            " to",
                            " Union",
                            " officers",
                            ",",
                            " but",
                            " they",
                            " end",
                            " up",
                            " being",
                            " massac",
                            "red",
                            ".",
                            " Wales",
                            " becomes",
                            " an",
                            " outlaw",
                            " and",
                            " is",
                            " pursued",
                            " by",
                            " bounty",
                            " hunters",
                            " and",
                            " Union",
                            " soldiers",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " film",
                            " was",
                            " adapted"
                        ],
                        "dataIndex": null,
                        "index": "11246",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.612,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.612,
                            4.682,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:11.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.612,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4tq9am0xri666yhjzooks",
                        "tokens": [
                            " by",
                            " and",
                            " starred",
                            " Clint",
                            " East",
                            "wood",
                            " (",
                            "as",
                            " the",
                            " ep",
                            "onymous",
                            " Jose",
                            "y",
                            " Wales",
                            "),",
                            " with",
                            " Chief",
                            " Dan",
                            " George",
                            ",",
                            " S",
                            "ond",
                            "ra",
                            " Locke",
                            ",",
                            " Sam",
                            " Bott",
                            "oms",
                            ",",
                            " and",
                            " Gerald",
                            "ine",
                            " Ke",
                            "ams",
                            ".[",
                            "3",
                            "]",
                            " The",
                            " film",
                            " tells",
                            " the",
                            " story",
                            " of",
                            " Jose",
                            "y",
                            " Wales",
                            ",",
                            " a",
                            " Missouri",
                            " farmer",
                            " whose",
                            " family",
                            " is",
                            " murdered",
                            " by",
                            " Union",
                            " militants",
                            " during",
                            " the",
                            " Civil",
                            " War",
                            ".",
                            " Dri",
                            "ven",
                            " to",
                            " revenge",
                            ",",
                            " Wales",
                            " joins",
                            " a",
                            " Confederate",
                            " guerrilla",
                            " band",
                            " and",
                            " fights",
                            " in",
                            " the",
                            " Civil",
                            " War",
                            ".",
                            " After",
                            " the",
                            " war",
                            ",",
                            " all",
                            " the",
                            " fighters",
                            " in",
                            " Wales",
                            "'",
                            " group",
                            " except",
                            " for",
                            " Wales",
                            " surrender",
                            " to",
                            " Union",
                            " officers",
                            ",",
                            " but",
                            " they",
                            " end",
                            " up",
                            " being",
                            " massac",
                            "red",
                            ".",
                            " Wales",
                            " becomes",
                            " an",
                            " outlaw",
                            " and",
                            " is",
                            " pursued",
                            " by",
                            " bounty",
                            " hunters",
                            " and",
                            " Union",
                            " soldiers",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " film",
                            " was",
                            " adapted"
                        ],
                        "dataIndex": null,
                        "index": "11246",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.612,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.612,
                            4.682,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:11.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 44.49,
                        "binMax": 55.612,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4tq98m0x6i6669r97k4cy",
                        "tokens": [
                            "ur",
                            "h",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " evil",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " one",
                            " point",
                            " bounty",
                            " hunter",
                            " Carson",
                            " Wells",
                            " (",
                            "Wood",
                            "y",
                            " Har",
                            "rel",
                            "son",
                            ")",
                            " gets",
                            " asked",
                            " how",
                            " dangerous",
                            " Ch",
                            "ig",
                            "ur",
                            "h",
                            " is",
                            ".",
                            " He",
                            " replies",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "Compared",
                            " to",
                            " what",
                            "?",
                            " The",
                            " bub",
                            "onic",
                            " plague",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ch",
                            "ig",
                            "ur",
                            "h",
                            " acts",
                            " as",
                            " a",
                            " force",
                            " of",
                            " nature",
                            " in",
                            " the",
                            " film",
                            ",",
                            " not",
                            " merely",
                            " with",
                            " regard",
                            " to",
                            " his",
                            " overwhelming",
                            " power",
                            ",",
                            " but",
                            " precisely",
                            " because",
                            " he",
                            " seems",
                            " to",
                            " have",
                            " transc",
                            "ended",
                            " human",
                            " boundaries",
                            " and",
                            " achieved",
                            " a",
                            " state",
                            " of",
                            " natural",
                            " indifference",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "The",
                            " Co",
                            "en",
                            " brothers",
                            " narrow",
                            " in",
                            " on",
                            " this",
                            " elemental",
                            " evil",
                            " by",
                            " keeping",
                            " a",
                            " strong",
                            " focus",
                            " on",
                            " the",
                            " three",
                            " main",
                            " characters",
                            "\u2014",
                            "Bell",
                            ",",
                            " Ch",
                            "ig",
                            "ur",
                            "h",
                            ",",
                            " and",
                            " L",
                            "le"
                        ],
                        "dataIndex": null,
                        "index": "11246",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.365,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.365,
                            2.308,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:11.525Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.612,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "3837",
            "description": "words related to rewards and punishments in a context of incentives or consequences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5336114168167114,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "3837",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:11:28.167Z",
                "maxActApprox": 38.448,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3837,
                    4292,
                    2644,
                    3292,
                    979,
                    2926,
                    2916,
                    2168,
                    4189,
                    5967,
                    92,
                    5157,
                    6126,
                    3955,
                    5553,
                    2950,
                    3814,
                    4812,
                    4717,
                    728,
                    3160,
                    282,
                    753,
                    2962,
                    4924
                ],
                "topkCosSimValues": [
                    1,
                    0.4169,
                    0.3894,
                    0.3747,
                    0.3726,
                    0.3392,
                    0.33,
                    0.3181,
                    0.3109,
                    0.2857,
                    0.2727,
                    0.2726,
                    0.271,
                    0.2651,
                    0.2619,
                    0.2581,
                    0.2547,
                    0.252,
                    0.2496,
                    0.2481,
                    0.2426,
                    0.2421,
                    0.2417,
                    0.2352,
                    0.2345
                ],
                "neuron_alignment_indices": [
                    717,
                    288,
                    35
                ],
                "neuron_alignment_values": [
                    0.107,
                    0.106,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    717,
                    424
                ],
                "correlated_neurons_pearson": [
                    0.055,
                    0.046,
                    0.044
                ],
                "correlated_neurons_l1": [
                    0.066,
                    0.041,
                    0.039
                ],
                "correlated_features_indices": [
                    3803,
                    3754,
                    3818
                ],
                "correlated_features_pearson": [
                    0.026,
                    0.012,
                    0.01
                ],
                "correlated_features_l1": [
                    0.028,
                    0.013,
                    0.013
                ],
                "neg_str": [
                    "abases",
                    "abad",
                    "ahime",
                    "scape",
                    "nian",
                    " Lucia",
                    "pora",
                    "idis",
                    " Ange",
                    "icago"
                ],
                "neg_values": [
                    -0.824,
                    -0.752,
                    -0.723,
                    -0.704,
                    -0.697,
                    -0.691,
                    -0.686,
                    -0.677,
                    -0.676,
                    -0.668
                ],
                "pos_str": [
                    " rewarded",
                    " awarded",
                    " rewards",
                    " recipients",
                    " payout",
                    " reward",
                    " bestowed",
                    " giveaways",
                    " paid",
                    " incentive"
                ],
                "pos_values": [
                    1.006,
                    1.001,
                    0.962,
                    0.937,
                    0.936,
                    0.933,
                    0.931,
                    0.926,
                    0.922,
                    0.906
                ],
                "frac_nonzero": 0.00442,
                "freq_hist_data_bar_heights": [
                    4012,
                    2655,
                    1880,
                    1270,
                    839,
                    605,
                    475,
                    372,
                    285,
                    208,
                    164,
                    148,
                    116,
                    113,
                    83,
                    87,
                    64,
                    66,
                    59,
                    26,
                    22,
                    16,
                    26,
                    25,
                    27,
                    25,
                    25,
                    21,
                    25,
                    16,
                    20,
                    14,
                    16,
                    11,
                    6,
                    13,
                    9,
                    10,
                    6,
                    11,
                    4,
                    7,
                    5,
                    4,
                    3,
                    2,
                    2,
                    5,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.385,
                    1.153,
                    1.922,
                    2.691,
                    3.46,
                    4.229,
                    4.998,
                    5.767,
                    6.536,
                    7.305,
                    8.074,
                    8.843,
                    9.612,
                    10.381,
                    11.15,
                    11.919,
                    12.688,
                    13.457,
                    14.226,
                    14.995,
                    15.764,
                    16.533,
                    17.302,
                    18.071,
                    18.84,
                    19.609,
                    20.378,
                    21.147,
                    21.915,
                    22.684,
                    23.453,
                    24.222,
                    24.991,
                    25.76,
                    26.529,
                    27.298,
                    28.067,
                    28.836,
                    29.605,
                    30.374,
                    31.143,
                    31.912,
                    32.681,
                    33.45,
                    34.219,
                    34.988,
                    35.757,
                    36.526,
                    37.295,
                    38.064
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    4,
                    12,
                    11,
                    18,
                    36,
                    80,
                    123,
                    193,
                    296,
                    515,
                    711,
                    1060,
                    1442,
                    1882,
                    2516,
                    3028,
                    3486,
                    3866,
                    4145,
                    4154,
                    4161,
                    3714,
                    3324,
                    2783,
                    2220,
                    1781,
                    1374,
                    1021,
                    694,
                    505,
                    341,
                    235,
                    159,
                    110,
                    80,
                    45,
                    41,
                    23,
                    8,
                    18,
                    11,
                    8,
                    8,
                    2,
                    4,
                    4,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.805,
                    -0.769,
                    -0.732,
                    -0.696,
                    -0.659,
                    -0.622,
                    -0.586,
                    -0.549,
                    -0.513,
                    -0.476,
                    -0.439,
                    -0.403,
                    -0.366,
                    -0.33,
                    -0.293,
                    -0.256,
                    -0.22,
                    -0.183,
                    -0.147,
                    -0.11,
                    -0.073,
                    -0.037,
                    0,
                    0.036,
                    0.073,
                    0.11,
                    0.146,
                    0.183,
                    0.22,
                    0.256,
                    0.293,
                    0.329,
                    0.366,
                    0.403,
                    0.439,
                    0.476,
                    0.512,
                    0.549,
                    0.586,
                    0.622,
                    0.659,
                    0.695,
                    0.732,
                    0.769,
                    0.805,
                    0.842,
                    0.878,
                    0.915,
                    0.952,
                    0.988
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to rewards and punishments in a context of incentives or consequences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdte8czw8gvi666gsu7t8pd",
                        "tokens": [
                            " and",
                            " of",
                            " profit",
                            " as",
                            " the",
                            " reward",
                            " for",
                            " abst",
                            "ention",
                            " or",
                            " long",
                            " time",
                            "-",
                            "pre",
                            "ference",
                            " on",
                            " the",
                            " capitalist",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            ",",
                            " is",
                            " especially",
                            " laughable",
                            " given",
                            " the",
                            " fact",
                            " that",
                            " the",
                            " original",
                            " accumulation",
                            " of",
                            " capital",
                            " \u2014",
                            " the",
                            " concentration",
                            " of",
                            " enormous",
                            " investment",
                            " funds",
                            " in",
                            " the",
                            " hands",
                            " of",
                            " a",
                            " small",
                            " pl",
                            "ut",
                            "ocracy",
                            " \u2014",
                            " was",
                            " actually",
                            " accomplished",
                            " through",
                            " robbery",
                            " rather",
                            " than",
                            " abst",
                            "ention",
                            " or",
                            " savings",
                            ".",
                            " And",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " rendered",
                            " even",
                            " more",
                            " so",
                            " by",
                            " the",
                            " fact",
                            " that",
                            " banks",
                            " lend",
                            " money",
                            " into",
                            " existence",
                            " out",
                            " of",
                            " thin",
                            " air",
                            ",",
                            " without",
                            " even",
                            " the",
                            " pret",
                            "ense",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " backed",
                            " by",
                            " anyone",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " savings",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " radical",
                            " erosion",
                            " of",
                            " the",
                            " latter",
                            " barrier",
                            " through",
                            " ep",
                            "hemer",
                            "al",
                            " technology",
                            " (",
                            "as",
                            " described",
                            " by",
                            " Douglas",
                            " Rush",
                            "k",
                            "off"
                        ],
                        "dataIndex": null,
                        "index": "3837",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.448,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            1.563,
                            0,
                            0,
                            38.448,
                            6.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:36.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.448,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdte8d1w8hgi666hz6j29qp",
                        "tokens": [
                            " and",
                            " of",
                            " profit",
                            " as",
                            " the",
                            " reward",
                            " for",
                            " abst",
                            "ention",
                            " or",
                            " long",
                            " time",
                            "-",
                            "pre",
                            "ference",
                            " on",
                            " the",
                            " capitalist",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            ",",
                            " is",
                            " especially",
                            " laughable",
                            " given",
                            " the",
                            " fact",
                            " that",
                            " the",
                            " original",
                            " accumulation",
                            " of",
                            " capital",
                            " \u2014",
                            " the",
                            " concentration",
                            " of",
                            " enormous",
                            " investment",
                            " funds",
                            " in",
                            " the",
                            " hands",
                            " of",
                            " a",
                            " small",
                            " pl",
                            "ut",
                            "ocracy",
                            " \u2014",
                            " was",
                            " actually",
                            " accomplished",
                            " through",
                            " robbery",
                            " rather",
                            " than",
                            " abst",
                            "ention",
                            " or",
                            " savings",
                            ".",
                            " And",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " rendered",
                            " even",
                            " more",
                            " so",
                            " by",
                            " the",
                            " fact",
                            " that",
                            " banks",
                            " lend",
                            " money",
                            " into",
                            " existence",
                            " out",
                            " of",
                            " thin",
                            " air",
                            ",",
                            " without",
                            " even",
                            " the",
                            " pret",
                            "ense",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " backed",
                            " by",
                            " anyone",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " savings",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " radical",
                            " erosion",
                            " of",
                            " the",
                            " latter",
                            " barrier",
                            " through",
                            " ep",
                            "hemer",
                            "al",
                            " technology",
                            " (",
                            "as",
                            " described",
                            " by",
                            " Douglas",
                            " Rush",
                            "k",
                            "off"
                        ],
                        "dataIndex": null,
                        "index": "3837",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.448,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            1.563,
                            0,
                            0,
                            38.448,
                            6.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:36.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 30.759,
                        "binMax": 38.448,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdte8czw8gwi666wjug9unw",
                        "tokens": [
                            " keep",
                            " the",
                            " public",
                            " app",
                            "r",
                            "ised",
                            " and",
                            " to",
                            " get",
                            " feedback",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " we",
                            "'re",
                            " pleasantly",
                            " surprised",
                            " by",
                            " the",
                            " first",
                            " real",
                            " post",
                            ",",
                            " written",
                            " by",
                            " Blair",
                            " Levin",
                            " \u2013",
                            " the",
                            " man",
                            " in",
                            " charge",
                            " of",
                            " writing",
                            " the",
                            " broadband",
                            " plan",
                            ",",
                            " who",
                            " wrote",
                            " a",
                            " post",
                            " complaining",
                            " about",
                            " how",
                            " hard",
                            " it",
                            " is",
                            " to",
                            " get",
                            " food",
                            " when",
                            " you",
                            " are",
                            " working",
                            " late",
                            " at",
                            " night",
                            " on",
                            " an",
                            " N",
                            "BP",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " maybe",
                            " there",
                            " was",
                            " some",
                            " kind",
                            " of",
                            " k",
                            "arm",
                            "ic",
                            " reward",
                            " in",
                            " two",
                            " fortune",
                            " cookies",
                            " that",
                            " staff",
                            " cracked",
                            " open",
                            " at",
                            " the",
                            " end",
                            " of",
                            " our",
                            " team",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " break",
                            " for",
                            " Chinese",
                            " one",
                            " night",
                            ".",
                            " John",
                            " Hor",
                            "rigan",
                            ",",
                            " a",
                            " data",
                            " guy",
                            " we",
                            " stole",
                            " from",
                            " the",
                            " Pew",
                            " Internet",
                            " Project",
                            ",",
                            " pulled",
                            " out",
                            " a",
                            " fortune",
                            " that",
                            " read",
                            " \"",
                            "Statistics",
                            " are",
                            " no",
                            " substitute",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "3837",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.173,
                        "maxValueTokenIndex": 76,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.173,
                            6.384,
                            0,
                            0,
                            3.972,
                            0.338,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:11:36.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.448,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "80776",
            "description": "expressions related to rewards or benefits resulting from actions or investments",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5319845676422119,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "80776",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:10:23.514Z",
                "maxActApprox": 42.018,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    80776,
                    47165,
                    49358,
                    90264,
                    90057,
                    50587,
                    40625,
                    21511,
                    533,
                    29433,
                    24576,
                    71252,
                    18117,
                    93195,
                    21722,
                    19690,
                    9973,
                    8175,
                    75649,
                    62709,
                    34344,
                    14715,
                    47819,
                    12766,
                    35311
                ],
                "topkCosSimValues": [
                    1,
                    0.481,
                    0.444,
                    0.4435,
                    0.4389,
                    0.4227,
                    0.4106,
                    0.4053,
                    0.3929,
                    0.3888,
                    0.3763,
                    0.3666,
                    0.3621,
                    0.3529,
                    0.3497,
                    0.3493,
                    0.348,
                    0.3452,
                    0.3385,
                    0.3333,
                    0.3258,
                    0.3226,
                    0.3204,
                    0.3178,
                    0.3138
                ],
                "neuron_alignment_indices": [
                    239,
                    724,
                    468
                ],
                "neuron_alignment_values": [
                    0.111,
                    0.104,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    724,
                    747,
                    245
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.008,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.008,
                    0.008
                ],
                "correlated_features_indices": [
                    80658,
                    80664,
                    80678
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    "hari",
                    "ricted",
                    "\u0130\u012d",
                    "atin",
                    "udi",
                    "gemony",
                    "ffield",
                    "\u00a3\u0131",
                    "artments",
                    "shaw"
                ],
                "neg_values": [
                    -0.929,
                    -0.758,
                    -0.73,
                    -0.697,
                    -0.696,
                    -0.678,
                    -0.671,
                    -0.671,
                    -0.64,
                    -0.639
                ],
                "pos_str": [
                    " handsome",
                    " dividends",
                    "IER",
                    " dearly",
                    "amac",
                    " payoff",
                    " sooner",
                    " spectacular",
                    " eventually",
                    " nonetheless"
                ],
                "pos_values": [
                    1.028,
                    0.913,
                    0.795,
                    0.762,
                    0.711,
                    0.711,
                    0.689,
                    0.681,
                    0.658,
                    0.657
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    115,
                    56,
                    39,
                    27,
                    9,
                    12,
                    10,
                    6,
                    2,
                    2,
                    2,
                    4,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    2,
                    0,
                    0,
                    1,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.43,
                    1.27,
                    2.11,
                    2.95,
                    3.79,
                    4.631,
                    5.471,
                    6.311,
                    7.151,
                    7.991,
                    8.831,
                    9.672,
                    10.512,
                    11.352,
                    12.192,
                    13.032,
                    13.872,
                    14.713,
                    15.553,
                    16.393,
                    17.233,
                    18.073,
                    18.913,
                    19.754,
                    20.594,
                    21.434,
                    22.274,
                    23.114,
                    23.954,
                    24.795,
                    25.635,
                    26.475,
                    27.315,
                    28.155,
                    28.996,
                    29.836,
                    30.676,
                    31.516,
                    32.356,
                    33.196,
                    34.037,
                    34.877,
                    35.717,
                    36.557,
                    37.397,
                    38.237,
                    39.078,
                    39.918,
                    40.758,
                    41.598
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    1,
                    3,
                    3,
                    6,
                    12,
                    24,
                    53,
                    98,
                    166,
                    274,
                    403,
                    685,
                    1015,
                    1451,
                    2115,
                    2796,
                    3446,
                    4063,
                    4665,
                    5027,
                    4888,
                    4561,
                    3871,
                    3258,
                    2408,
                    1764,
                    1191,
                    826,
                    499,
                    271,
                    173,
                    104,
                    58,
                    32,
                    20,
                    11,
                    7,
                    4,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.909,
                    -0.87,
                    -0.831,
                    -0.792,
                    -0.753,
                    -0.714,
                    -0.674,
                    -0.635,
                    -0.596,
                    -0.557,
                    -0.518,
                    -0.479,
                    -0.44,
                    -0.4,
                    -0.361,
                    -0.322,
                    -0.283,
                    -0.244,
                    -0.205,
                    -0.166,
                    -0.126,
                    -0.087,
                    -0.048,
                    -0.009,
                    0.03,
                    0.069,
                    0.108,
                    0.148,
                    0.187,
                    0.226,
                    0.265,
                    0.304,
                    0.343,
                    0.382,
                    0.422,
                    0.461,
                    0.5,
                    0.539,
                    0.578,
                    0.617,
                    0.656,
                    0.696,
                    0.735,
                    0.774,
                    0.813,
                    0.852,
                    0.891,
                    0.93,
                    0.97,
                    1.009
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "expressions related to rewards or benefits resulting from actions or investments",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms associated with financial benefits or gains",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygij5ew0kl810ex6csllwh9",
                        "tokens": [
                            " enough",
                            " to",
                            " give",
                            " away",
                            " our",
                            " height",
                            " difference",
                            ".",
                            " Plus",
                            " I",
                            " was",
                            " forgetting",
                            " to",
                            " cheat",
                            " to",
                            " the",
                            " camera",
                            " (",
                            "more",
                            " on",
                            " that",
                            " below",
                            "),",
                            " the",
                            " way",
                            " Zuckerberg",
                            " did",
                            " with",
                            " his",
                            " cattle",
                            " ranc",
                            "her",
                            " friends",
                            ".",
                            "\n",
                            "\n",
                            "Lastly",
                            " we",
                            " tried",
                            " a",
                            " varied",
                            " group",
                            " shot",
                            ",",
                            " with",
                            " a",
                            " whole",
                            " range",
                            " of",
                            " heights",
                            ".",
                            " Our",
                            " volunteers",
                            " kindly",
                            " ignored",
                            " my",
                            " blatant",
                            " toe",
                            "-",
                            "stand",
                            " and",
                            " even",
                            " leaned",
                            " in",
                            " to",
                            " give",
                            " me",
                            " a",
                            " comparative",
                            " advantage",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " pretty",
                            " sure",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "move",
                            " toward",
                            " the",
                            " camera",
                            "\u00e2\u0122",
                            "\u013f",
                            " trick",
                            " paid",
                            " off",
                            ",",
                            " until",
                            " our",
                            " volunteers",
                            " turned",
                            " it",
                            " right",
                            " back",
                            " around",
                            " on",
                            " me",
                            ".",
                            " Again",
                            ",",
                            " the",
                            " hat",
                            " was",
                            " essential",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "We",
                            " found",
                            " three",
                            " basic",
                            " tricks",
                            " for",
                            " looking",
                            " tall",
                            " next",
                            " to",
                            " other"
                        ],
                        "dataIndex": null,
                        "index": "80776",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.018,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.589,
                            42.018,
                            4.72,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:10:30.786Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.018,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygij5ew0kl910ex628clj4i",
                        "tokens": [
                            ".",
                            " And",
                            " I",
                            " would",
                            " so",
                            " recommend",
                            " that",
                            " people",
                            " throw",
                            " themselves",
                            " in",
                            " \u2013",
                            " yeah",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " got",
                            " to",
                            " pay",
                            " a",
                            " little",
                            " bit",
                            " of",
                            " money",
                            ",",
                            " but",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " proper",
                            " investment",
                            ",",
                            " but",
                            " I",
                            " think",
                            " it",
                            " basically",
                            " increases",
                            " your",
                            " skill",
                            " set",
                            ".",
                            " And",
                            " in",
                            " journalism",
                            " right",
                            " now",
                            ",",
                            " to",
                            " have",
                            " that",
                            " range",
                            " of",
                            " skills",
                            " \u2013",
                            " to",
                            " be",
                            " able",
                            " to",
                            " write",
                            " and",
                            " code",
                            ",",
                            " two",
                            " seemingly",
                            " very",
                            " complementary",
                            " skills",
                            ",",
                            " but",
                            " at",
                            " different",
                            " ends",
                            " of",
                            " the",
                            " spectrum",
                            " \u2013",
                            " they",
                            " help",
                            " an",
                            " awful",
                            " lot",
                            ".",
                            "\n",
                            "\n",
                            "JB",
                            ":",
                            " And",
                            " obviously",
                            " this",
                            " investment",
                            " has",
                            " paid",
                            " off",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " started",
                            " to",
                            " reap",
                            " some",
                            " dividends",
                            " because",
                            " you",
                            " came",
                            " up",
                            " with",
                            " the",
                            " idea",
                            " of",
                            " Reddit",
                            " Edit",
                            " and",
                            " you",
                            " were",
                            " able",
                            " to",
                            " bring",
                            " that",
                            " concept",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "80776",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.764,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.272,
                            40.764,
                            2.198,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.889,
                            6.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:10:30.786Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.018,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygij5ey0klu10ex6n0clru3",
                        "tokens": [
                            ".",
                            " And",
                            " I",
                            " would",
                            " so",
                            " recommend",
                            " that",
                            " people",
                            " throw",
                            " themselves",
                            " in",
                            " \u2013",
                            " yeah",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " got",
                            " to",
                            " pay",
                            " a",
                            " little",
                            " bit",
                            " of",
                            " money",
                            ",",
                            " but",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " proper",
                            " investment",
                            ",",
                            " but",
                            " I",
                            " think",
                            " it",
                            " basically",
                            " increases",
                            " your",
                            " skill",
                            " set",
                            ".",
                            " And",
                            " in",
                            " journalism",
                            " right",
                            " now",
                            ",",
                            " to",
                            " have",
                            " that",
                            " range",
                            " of",
                            " skills",
                            " \u2013",
                            " to",
                            " be",
                            " able",
                            " to",
                            " write",
                            " and",
                            " code",
                            ",",
                            " two",
                            " seemingly",
                            " very",
                            " complementary",
                            " skills",
                            ",",
                            " but",
                            " at",
                            " different",
                            " ends",
                            " of",
                            " the",
                            " spectrum",
                            " \u2013",
                            " they",
                            " help",
                            " an",
                            " awful",
                            " lot",
                            ".",
                            "\n",
                            "\n",
                            "JB",
                            ":",
                            " And",
                            " obviously",
                            " this",
                            " investment",
                            " has",
                            " paid",
                            " off",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " started",
                            " to",
                            " reap",
                            " some",
                            " dividends",
                            " because",
                            " you",
                            " came",
                            " up",
                            " with",
                            " the",
                            " idea",
                            " of",
                            " Reddit",
                            " Edit",
                            " and",
                            " you",
                            " were",
                            " able",
                            " to",
                            " bring",
                            " that",
                            " concept",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "80776",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.764,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.272,
                            40.764,
                            2.198,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.889,
                            6.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:10:30.786Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 33.615,
                        "binMax": 42.018,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "27279",
            "description": "mentions of bonuses or rewards",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5318642220659029,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "27279",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:47:54.116Z",
                "maxActApprox": 55.313,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    27279,
                    7998,
                    10009,
                    29976,
                    24415,
                    12226,
                    43298,
                    47776,
                    32179,
                    42662,
                    12728,
                    25967,
                    10651,
                    46631,
                    37320,
                    9322,
                    31749,
                    33606,
                    45440,
                    25665,
                    9659,
                    25252,
                    48129,
                    6192,
                    5293
                ],
                "topkCosSimValues": [
                    1,
                    0.6415,
                    0.4841,
                    0.4324,
                    0.4308,
                    0.4212,
                    0.4148,
                    0.4032,
                    0.4016,
                    0.399,
                    0.3898,
                    0.3826,
                    0.3809,
                    0.3793,
                    0.378,
                    0.3693,
                    0.3668,
                    0.3611,
                    0.347,
                    0.3447,
                    0.3405,
                    0.332,
                    0.3225,
                    0.3195,
                    0.3137
                ],
                "neuron_alignment_indices": [
                    274,
                    0,
                    259
                ],
                "neuron_alignment_values": [
                    0.1,
                    0.091,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    274,
                    763,
                    717
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.009,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.008,
                    0.008
                ],
                "correlated_features_indices": [
                    27280,
                    27321,
                    27266
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0
                ],
                "neg_str": [
                    "tics",
                    "apest",
                    "l\u00c3\u00a9",
                    "soDeliveryDate",
                    "alter",
                    "ledge",
                    "sis",
                    "\u00d6\u00bc",
                    "uart",
                    "\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a\u00e2\u0138\u012a"
                ],
                "neg_values": [
                    -0.915,
                    -0.808,
                    -0.8,
                    -0.79,
                    -0.758,
                    -0.748,
                    -0.724,
                    -0.724,
                    -0.724,
                    -0.721
                ],
                "pos_str": [
                    " bonus",
                    "Reviewer",
                    " goodies",
                    " perk",
                    " compartment",
                    " depreciation",
                    " bonuses",
                    " redundancy",
                    " shout",
                    " insult"
                ],
                "pos_values": [
                    1.078,
                    0.785,
                    0.781,
                    0.753,
                    0.749,
                    0.744,
                    0.744,
                    0.73,
                    0.722,
                    0.722
                ],
                "frac_nonzero": 7.000000000000001e-05,
                "freq_hist_data_bar_heights": [
                    77,
                    33,
                    23,
                    14,
                    8,
                    2,
                    8,
                    1,
                    5,
                    0,
                    1,
                    1,
                    1,
                    1,
                    3,
                    2,
                    3,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    3,
                    0,
                    1,
                    2,
                    2,
                    3,
                    1,
                    0,
                    1,
                    1,
                    3,
                    0,
                    0,
                    1,
                    0,
                    2,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.578,
                    1.684,
                    2.79,
                    3.896,
                    5.001,
                    6.107,
                    7.213,
                    8.319,
                    9.424,
                    10.53,
                    11.636,
                    12.742,
                    13.847,
                    14.953,
                    16.059,
                    17.165,
                    18.27,
                    19.376,
                    20.482,
                    21.588,
                    22.693,
                    23.799,
                    24.905,
                    26.011,
                    27.116,
                    28.222,
                    29.328,
                    30.434,
                    31.539,
                    32.645,
                    33.751,
                    34.857,
                    35.962,
                    37.068,
                    38.174,
                    39.28,
                    40.385,
                    41.491,
                    42.597,
                    43.703,
                    44.808,
                    45.914,
                    47.02,
                    48.126,
                    49.231,
                    50.337,
                    51.443,
                    52.549,
                    53.654,
                    54.76
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    6,
                    6,
                    11,
                    25,
                    30,
                    64,
                    108,
                    201,
                    329,
                    484,
                    768,
                    1141,
                    1548,
                    2078,
                    2776,
                    3345,
                    3819,
                    4267,
                    4449,
                    4267,
                    4175,
                    3787,
                    3210,
                    2706,
                    2126,
                    1486,
                    1084,
                    737,
                    495,
                    298,
                    179,
                    120,
                    55,
                    26,
                    19,
                    10,
                    6,
                    8,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.895,
                    -0.855,
                    -0.815,
                    -0.775,
                    -0.735,
                    -0.695,
                    -0.656,
                    -0.616,
                    -0.576,
                    -0.536,
                    -0.496,
                    -0.456,
                    -0.416,
                    -0.377,
                    -0.337,
                    -0.297,
                    -0.257,
                    -0.217,
                    -0.177,
                    -0.137,
                    -0.098,
                    -0.058,
                    -0.018,
                    0.022,
                    0.062,
                    0.102,
                    0.142,
                    0.181,
                    0.221,
                    0.261,
                    0.301,
                    0.341,
                    0.381,
                    0.421,
                    0.46,
                    0.5,
                    0.54,
                    0.58,
                    0.62,
                    0.66,
                    0.7,
                    0.739,
                    0.779,
                    0.819,
                    0.859,
                    0.899,
                    0.939,
                    0.979,
                    1.018,
                    1.058
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of bonuses or rewards",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5vzz20sani666s0y5vokk",
                        "tokens": [
                            "d",
                            "\n",
                            "\n",
                            "The",
                            " DVD",
                            " is",
                            " comprised",
                            " of",
                            " 3",
                            " parts",
                            ":",
                            " Indiana",
                            " University",
                            " (",
                            "IU",
                            ")",
                            " Workshop",
                            ",",
                            " Ground",
                            " Zero",
                            " Workshop",
                            ",",
                            " and",
                            " Bonus",
                            " Material",
                            ".",
                            "\n",
                            "\n",
                            "Ch",
                            "apters",
                            " and",
                            " Content",
                            "\n",
                            "\n",
                            "IU",
                            " Workshop",
                            " Intro",
                            " to",
                            " Pos",
                            "itions",
                            " Concepts",
                            " Cross",
                            " side",
                            " to",
                            " Leg",
                            " Drag",
                            " Closed",
                            " Guard",
                            " Pass",
                            " Half",
                            " Guard",
                            " Butterfly",
                            " Guard",
                            " Pass",
                            " Slip",
                            " K",
                            "nee",
                            " to",
                            " Mount",
                            " Passing",
                            " Spider",
                            " Guard",
                            " Closing",
                            "\n",
                            "\n",
                            "Ground",
                            " Zero",
                            " Workshop",
                            " Basic",
                            " Leg",
                            " Drag",
                            " Position",
                            " Mend",
                            "es",
                            " Position",
                            " Reverse",
                            " Position",
                            " Attack",
                            " From",
                            " Side",
                            " Control",
                            " Back",
                            " Take",
                            " Closed",
                            " Guard",
                            " Pass",
                            " Half",
                            " Guard",
                            " Pass",
                            " Butterfly",
                            " Guard",
                            " Pass",
                            " Slip",
                            " K",
                            "nee",
                            " to",
                            " Mount",
                            " S",
                            "ider",
                            " Guard",
                            " Pass",
                            " Questions",
                            " Dr",
                            "ills",
                            " Closing",
                            "\n",
                            "\n",
                            "Bonus",
                            " Material",
                            " Basic",
                            " T",
                            "akedown",
                            " Mount",
                            " to",
                            " Leg",
                            " Drag",
                            " Leg",
                            " Drag",
                            " from",
                            " Rear",
                            " Mount",
                            " De",
                            " la",
                            " R",
                            "iva",
                            " Sweep",
                            " De"
                        ],
                        "dataIndex": null,
                        "index": "27279",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.313,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.313,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.343,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:47:57.616Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.313,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5vzz20saii666e0gnij5p",
                        "tokens": [
                            "d",
                            "\n",
                            "\n",
                            "The",
                            " DVD",
                            " is",
                            " comprised",
                            " of",
                            " 3",
                            " parts",
                            ":",
                            " Indiana",
                            " University",
                            " (",
                            "IU",
                            ")",
                            " Workshop",
                            ",",
                            " Ground",
                            " Zero",
                            " Workshop",
                            ",",
                            " and",
                            " Bonus",
                            " Material",
                            ".",
                            "\n",
                            "\n",
                            "Ch",
                            "apters",
                            " and",
                            " Content",
                            "\n",
                            "\n",
                            "IU",
                            " Workshop",
                            " Intro",
                            " to",
                            " Pos",
                            "itions",
                            " Concepts",
                            " Cross",
                            " side",
                            " to",
                            " Leg",
                            " Drag",
                            " Closed",
                            " Guard",
                            " Pass",
                            " Half",
                            " Guard",
                            " Butterfly",
                            " Guard",
                            " Pass",
                            " Slip",
                            " K",
                            "nee",
                            " to",
                            " Mount",
                            " Passing",
                            " Spider",
                            " Guard",
                            " Closing",
                            "\n",
                            "\n",
                            "Ground",
                            " Zero",
                            " Workshop",
                            " Basic",
                            " Leg",
                            " Drag",
                            " Position",
                            " Mend",
                            "es",
                            " Position",
                            " Reverse",
                            " Position",
                            " Attack",
                            " From",
                            " Side",
                            " Control",
                            " Back",
                            " Take",
                            " Closed",
                            " Guard",
                            " Pass",
                            " Half",
                            " Guard",
                            " Pass",
                            " Butterfly",
                            " Guard",
                            " Pass",
                            " Slip",
                            " K",
                            "nee",
                            " to",
                            " Mount",
                            " S",
                            "ider",
                            " Guard",
                            " Pass",
                            " Questions",
                            " Dr",
                            "ills",
                            " Closing",
                            "\n",
                            "\n",
                            "Bonus",
                            " Material",
                            " Basic",
                            " T",
                            "akedown",
                            " Mount",
                            " to",
                            " Leg",
                            " Drag",
                            " Leg",
                            " Drag",
                            " from",
                            " Rear",
                            " Mount",
                            " De",
                            " la",
                            " R",
                            "iva",
                            " Sweep",
                            " De"
                        ],
                        "dataIndex": null,
                        "index": "27279",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.313,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.313,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.343,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:47:57.616Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.313,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5vzz20saji666pdgp7e40",
                        "tokens": [
                            " of",
                            " a",
                            " backdoor",
                            " cut",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " looks",
                            " like",
                            " Bob",
                            "an",
                            " Mar",
                            "jan",
                            "ovic",
                            ",",
                            " the",
                            " 7",
                            "'",
                            " 3",
                            "\"",
                            " Serbian",
                            " center",
                            ",",
                            " is",
                            " going",
                            " to",
                            " need",
                            " some",
                            " time",
                            " to",
                            " adjust",
                            " to",
                            " the",
                            " NBA",
                            ".",
                            "\n",
                            "\n",
                            "Up",
                            " Next",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " Spurs",
                            " will",
                            " continue",
                            " the",
                            " preseason",
                            " on",
                            " the",
                            " road",
                            " when",
                            " they",
                            " visit",
                            " Mike",
                            " Bud",
                            "en",
                            "hol",
                            "zer",
                            "'s",
                            " Hawks",
                            " in",
                            " Atlanta",
                            " on",
                            " Wednesday",
                            " night",
                            ".",
                            " You",
                            " can",
                            " catch",
                            " that",
                            " game",
                            " on",
                            " NB",
                            "AT",
                            "V",
                            " at",
                            " 7",
                            " p",
                            ".",
                            "m",
                            ".",
                            " ST",
                            "T",
                            "OT",
                            "TM",
                            ".",
                            "\n",
                            "\n",
                            "Bonus",
                            " GIF",
                            ":",
                            "\n",
                            "\n",
                            "Classic",
                            ".",
                            " Tim",
                            " finished",
                            " the",
                            " game",
                            " with",
                            " 14",
                            " points",
                            " (",
                            "7",
                            "-",
                            "7",
                            " from",
                            " the",
                            " field",
                            ")",
                            " in",
                            " 18",
                            " minutes",
                            ".",
                            " He",
                            " also",
                            " grabbed",
                            " six",
                            " boards",
                            " and",
                            " had",
                            " two",
                            " assists",
                            " to",
                            " no"
                        ],
                        "dataIndex": null,
                        "index": "27279",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.293,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.293,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:47:57.616Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.313,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84596",
            "description": " words associated with rewards and their variations",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5227100849151611,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84596",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:39.970Z",
                "maxActApprox": 67.778,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84596,
                    91419,
                    16702,
                    15555,
                    61276,
                    14567,
                    16345,
                    88971,
                    55483,
                    18191,
                    43292,
                    48102,
                    1181,
                    95681,
                    70783,
                    33937,
                    7996,
                    25952,
                    20883,
                    64153,
                    95856,
                    79762,
                    2764,
                    18207,
                    54718
                ],
                "topkCosSimValues": [
                    1,
                    0.5203,
                    0.445,
                    0.4418,
                    0.4403,
                    0.4291,
                    0.4285,
                    0.4208,
                    0.4167,
                    0.416,
                    0.415,
                    0.4119,
                    0.4087,
                    0.4019,
                    0.3909,
                    0.3893,
                    0.3825,
                    0.379,
                    0.3784,
                    0.3776,
                    0.376,
                    0.3747,
                    0.3735,
                    0.3714,
                    0.3713
                ],
                "neuron_alignment_indices": [
                    566,
                    365,
                    157
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.1,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    251,
                    262,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.005
                ],
                "correlated_features_indices": [
                    84620,
                    84673,
                    84682
                ],
                "correlated_features_pearson": [
                    0.006,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.006,
                    0,
                    0
                ],
                "neg_str": [
                    " suspic",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u0128",
                    " otherwise",
                    " CPC",
                    "uously",
                    " JPM",
                    " Gemini",
                    "\u00da",
                    " \u00d8\u00a7\u00d9\u0126",
                    " \u00e8\u00a3\u0131\u00e8"
                ],
                "neg_values": [
                    -0.733,
                    -0.706,
                    -0.676,
                    -0.676,
                    -0.648,
                    -0.62,
                    -0.611,
                    -0.6,
                    -0.597,
                    -0.595
                ],
                "pos_str": [
                    "ritten",
                    "ards",
                    "atche",
                    "arded",
                    "inding",
                    "riter",
                    "rite",
                    "arding",
                    "rites",
                    "rote"
                ],
                "pos_values": [
                    1.261,
                    1.209,
                    1.173,
                    1.066,
                    1.028,
                    0.997,
                    0.984,
                    0.97,
                    0.963,
                    0.951
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    12,
                    10,
                    2,
                    1,
                    3,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.699,
                    2.054,
                    3.41,
                    4.765,
                    6.12,
                    7.475,
                    8.83,
                    10.185,
                    11.54,
                    12.895,
                    14.25,
                    15.606,
                    16.961,
                    18.316,
                    19.671,
                    21.026,
                    22.381,
                    23.736,
                    25.091,
                    26.447,
                    27.802,
                    29.157,
                    30.512,
                    31.867,
                    33.222,
                    34.577,
                    35.932,
                    37.288,
                    38.643,
                    39.998,
                    41.353,
                    42.708,
                    44.063,
                    45.418,
                    46.773,
                    48.129,
                    49.484,
                    50.839,
                    52.194,
                    53.549,
                    54.904,
                    56.259,
                    57.614,
                    58.97,
                    60.325,
                    61.68,
                    63.035,
                    64.39,
                    65.745,
                    67.1
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    2,
                    9,
                    22,
                    39,
                    75,
                    177,
                    262,
                    487,
                    847,
                    1341,
                    1936,
                    2692,
                    3487,
                    4128,
                    4646,
                    4804,
                    4652,
                    4335,
                    3606,
                    3001,
                    2389,
                    1829,
                    1426,
                    1032,
                    794,
                    602,
                    455,
                    343,
                    245,
                    172,
                    140,
                    90,
                    69,
                    43,
                    27,
                    13,
                    10,
                    10,
                    4,
                    2,
                    3,
                    2,
                    1,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.714,
                    -0.674,
                    -0.634,
                    -0.594,
                    -0.554,
                    -0.514,
                    -0.474,
                    -0.434,
                    -0.394,
                    -0.355,
                    -0.315,
                    -0.275,
                    -0.235,
                    -0.195,
                    -0.155,
                    -0.115,
                    -0.075,
                    -0.035,
                    0.004,
                    0.044,
                    0.084,
                    0.124,
                    0.164,
                    0.204,
                    0.244,
                    0.284,
                    0.323,
                    0.363,
                    0.403,
                    0.443,
                    0.483,
                    0.523,
                    0.563,
                    0.603,
                    0.643,
                    0.682,
                    0.722,
                    0.762,
                    0.802,
                    0.842,
                    0.882,
                    0.922,
                    0.962,
                    1.002,
                    1.041,
                    1.081,
                    1.121,
                    1.161,
                    1.201,
                    1.241
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " words associated with rewards and their variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " terms related to rewards and their implications within a context",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiojyq3glx10extcd7vhi9",
                        "tokens": [
                            "\"",
                            "As",
                            " you",
                            " move",
                            " further",
                            " and",
                            " further",
                            " away",
                            " from",
                            " standardized",
                            " reporting",
                            ",",
                            " investors",
                            " can",
                            " understand",
                            " it",
                            " less",
                            " and",
                            " less",
                            ".\"",
                            "\n",
                            "\n",
                            "J",
                            "ensen",
                            " said",
                            " the",
                            " O",
                            "SC",
                            " already",
                            " has",
                            " all",
                            " of",
                            " the",
                            " tools",
                            " it",
                            " needs",
                            " to",
                            " enforce",
                            " such",
                            " cases",
                            " --",
                            " it",
                            "'s",
                            " just",
                            " a",
                            " matter",
                            " of",
                            " identifying",
                            " misleading",
                            " disclosures",
                            ",",
                            " something",
                            " that",
                            " the",
                            " whistleblower",
                            " program",
                            " can",
                            " help",
                            " with",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            " of",
                            " up",
                            " to",
                            " $",
                            "5",
                            " million",
                            "\n",
                            "\n",
                            "Since",
                            " its",
                            " launch",
                            " in",
                            " July",
                            ",",
                            " the",
                            " Ontario",
                            " Securities",
                            " Commission",
                            "'s",
                            " whistleblower",
                            " program",
                            " has",
                            " already",
                            " garnered",
                            " more",
                            " than",
                            " 30",
                            " tips",
                            " detailing",
                            " the",
                            " kinds",
                            " of",
                            " securities",
                            " law",
                            " violations",
                            " that",
                            " the",
                            " regulator",
                            " is",
                            " targeting",
                            " in",
                            " its",
                            " enforcement",
                            " actions",
                            ",",
                            " Jensen",
                            " said",
                            " Tuesday",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Some",
                            " of",
                            " them",
                            " are",
                            " the",
                            " kinds",
                            " of",
                            " tips",
                            " that",
                            " we",
                            " really"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.778,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.778,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 67.778,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiojys3gmh10ex7fm7pnyg",
                        "tokens": [
                            "\"",
                            "As",
                            " you",
                            " move",
                            " further",
                            " and",
                            " further",
                            " away",
                            " from",
                            " standardized",
                            " reporting",
                            ",",
                            " investors",
                            " can",
                            " understand",
                            " it",
                            " less",
                            " and",
                            " less",
                            ".\"",
                            "\n",
                            "\n",
                            "J",
                            "ensen",
                            " said",
                            " the",
                            " O",
                            "SC",
                            " already",
                            " has",
                            " all",
                            " of",
                            " the",
                            " tools",
                            " it",
                            " needs",
                            " to",
                            " enforce",
                            " such",
                            " cases",
                            " --",
                            " it",
                            "'s",
                            " just",
                            " a",
                            " matter",
                            " of",
                            " identifying",
                            " misleading",
                            " disclosures",
                            ",",
                            " something",
                            " that",
                            " the",
                            " whistleblower",
                            " program",
                            " can",
                            " help",
                            " with",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            " of",
                            " up",
                            " to",
                            " $",
                            "5",
                            " million",
                            "\n",
                            "\n",
                            "Since",
                            " its",
                            " launch",
                            " in",
                            " July",
                            ",",
                            " the",
                            " Ontario",
                            " Securities",
                            " Commission",
                            "'s",
                            " whistleblower",
                            " program",
                            " has",
                            " already",
                            " garnered",
                            " more",
                            " than",
                            " 30",
                            " tips",
                            " detailing",
                            " the",
                            " kinds",
                            " of",
                            " securities",
                            " law",
                            " violations",
                            " that",
                            " the",
                            " regulator",
                            " is",
                            " targeting",
                            " in",
                            " its",
                            " enforcement",
                            " actions",
                            ",",
                            " Jensen",
                            " said",
                            " Tuesday",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Some",
                            " of",
                            " them",
                            " are",
                            " the",
                            " kinds",
                            " of",
                            " tips",
                            " that",
                            " we",
                            " really"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.778,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.778,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 54.222,
                        "binMax": 67.778,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiojyq3gly10ex0keyhr9r",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "ear",
                            "n",
                            " some",
                            " sweet",
                            " rewards",
                            ",",
                            " starting",
                            " at",
                            " the",
                            " $",
                            "10",
                            " level",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " will",
                            " ABC",
                            " will",
                            " use",
                            " the",
                            " money",
                            " for",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " money",
                            " we",
                            " raise",
                            " from",
                            " this",
                            " campaign",
                            " will",
                            " be",
                            " used",
                            " to",
                            " get",
                            " this",
                            " project",
                            " off",
                            " the",
                            " ground",
                            ".",
                            " We",
                            " will",
                            " be",
                            " able",
                            " to",
                            " secure",
                            " the",
                            " desired",
                            " location",
                            " in",
                            " the",
                            " heart",
                            " of",
                            " Alexandria",
                            ".",
                            "\n",
                            "\n",
                            "Tap",
                            "room",
                            ".",
                            " We",
                            " plan",
                            " to",
                            " renov",
                            "ate",
                            " an",
                            " existing",
                            " building",
                            " on",
                            " the",
                            " property",
                            " into",
                            " a",
                            " community",
                            " tap",
                            "room",
                            ",",
                            " with",
                            " a",
                            " home",
                            "-",
                            "like",
                            " feel",
                            ",",
                            " where",
                            " people",
                            " can",
                            " find",
                            " good",
                            " company",
                            " and",
                            " great",
                            " beer",
                            ".",
                            " Your",
                            " support",
                            " will",
                            " be",
                            " able",
                            " to",
                            " help",
                            " outfit",
                            " our",
                            " tap",
                            "room",
                            " and",
                            " create",
                            " a",
                            " space",
                            " for",
                            " all",
                            " to",
                            " enjoy",
                            ".",
                            "\n",
                            "\n",
                            "Rew",
                            "ards",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "84596",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 63.806,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            63.806,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:42.944Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 67.778,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "39196",
            "description": " phrases related to rewards and incentives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.522243230209159,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "39196",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:20:47.473Z",
                "maxActApprox": 45.188,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39196,
                    64410,
                    39308,
                    22365,
                    17356,
                    32074,
                    39633,
                    87467,
                    71609,
                    94002,
                    18919,
                    71576,
                    61418,
                    49749,
                    91705,
                    36943,
                    78848,
                    22012,
                    55814,
                    11427,
                    12438,
                    44011,
                    25821,
                    27290,
                    62534
                ],
                "topkCosSimValues": [
                    1,
                    0.7135,
                    0.6364,
                    0.5378,
                    0.5102,
                    0.5059,
                    0.4799,
                    0.476,
                    0.4758,
                    0.4736,
                    0.4702,
                    0.4441,
                    0.439,
                    0.4389,
                    0.4371,
                    0.4347,
                    0.4286,
                    0.4226,
                    0.4161,
                    0.4073,
                    0.4062,
                    0.4058,
                    0.4017,
                    0.3957,
                    0.3936
                ],
                "neuron_alignment_indices": [
                    288,
                    620,
                    35
                ],
                "neuron_alignment_values": [
                    0.136,
                    0.116,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    189,
                    313,
                    620
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.013,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.015,
                    0.013,
                    0.009
                ],
                "correlated_features_indices": [
                    39218,
                    39169,
                    39111
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Sloven",
                    "abases",
                    "ovie",
                    "sei",
                    " Osw",
                    " Ange",
                    "abad",
                    "icago",
                    "cling",
                    "obiles"
                ],
                "neg_values": [
                    -0.785,
                    -0.768,
                    -0.727,
                    -0.716,
                    -0.716,
                    -0.7,
                    -0.694,
                    -0.685,
                    -0.68,
                    -0.678
                ],
                "pos_str": [
                    " tiers",
                    " reward",
                    " rewards",
                    " fulfillment",
                    " recipients",
                    " tier",
                    " payout",
                    " recipient",
                    " payable",
                    " rewarded"
                ],
                "pos_values": [
                    1.014,
                    0.966,
                    0.929,
                    0.846,
                    0.811,
                    0.81,
                    0.797,
                    0.764,
                    0.759,
                    0.751
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    74,
                    54,
                    28,
                    20,
                    13,
                    16,
                    6,
                    6,
                    1,
                    1,
                    0,
                    2,
                    2,
                    1,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    4,
                    3,
                    3,
                    4,
                    1,
                    2,
                    4,
                    4,
                    6,
                    3,
                    2,
                    5,
                    7,
                    5,
                    8,
                    2,
                    6,
                    4,
                    4,
                    7,
                    6,
                    4,
                    8,
                    2,
                    5,
                    5,
                    3,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.454,
                    1.358,
                    2.261,
                    3.165,
                    4.069,
                    4.973,
                    5.876,
                    6.78,
                    7.684,
                    8.588,
                    9.491,
                    10.395,
                    11.299,
                    12.202,
                    13.106,
                    14.01,
                    14.914,
                    15.817,
                    16.721,
                    17.625,
                    18.528,
                    19.432,
                    20.336,
                    21.24,
                    22.143,
                    23.047,
                    23.951,
                    24.854,
                    25.758,
                    26.662,
                    27.566,
                    28.469,
                    29.373,
                    30.277,
                    31.181,
                    32.084,
                    32.988,
                    33.892,
                    34.795,
                    35.699,
                    36.603,
                    37.507,
                    38.41,
                    39.314,
                    40.218,
                    41.121,
                    42.025,
                    42.929,
                    43.833,
                    44.736
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    5,
                    7,
                    12,
                    21,
                    39,
                    64,
                    110,
                    186,
                    321,
                    416,
                    636,
                    916,
                    1312,
                    1689,
                    2176,
                    2764,
                    3311,
                    3709,
                    4078,
                    4269,
                    4215,
                    3905,
                    3521,
                    2997,
                    2509,
                    2027,
                    1534,
                    1078,
                    759,
                    539,
                    390,
                    257,
                    153,
                    110,
                    73,
                    46,
                    41,
                    24,
                    8,
                    11,
                    6,
                    2,
                    2,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.767,
                    -0.731,
                    -0.695,
                    -0.659,
                    -0.623,
                    -0.587,
                    -0.551,
                    -0.515,
                    -0.479,
                    -0.443,
                    -0.407,
                    -0.371,
                    -0.335,
                    -0.299,
                    -0.263,
                    -0.227,
                    -0.191,
                    -0.155,
                    -0.119,
                    -0.083,
                    -0.048,
                    -0.012,
                    0.024,
                    0.06,
                    0.096,
                    0.132,
                    0.168,
                    0.204,
                    0.24,
                    0.276,
                    0.312,
                    0.348,
                    0.384,
                    0.42,
                    0.456,
                    0.492,
                    0.528,
                    0.564,
                    0.6,
                    0.636,
                    0.672,
                    0.708,
                    0.744,
                    0.78,
                    0.816,
                    0.852,
                    0.888,
                    0.924,
                    0.96,
                    0.996
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to rewards and incentives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to rewards and incentives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggrg494zv810exr5x7tqbh",
                        "tokens": [
                            " into",
                            " book",
                            "stores",
                            " and",
                            " comic",
                            " stands",
                            " everywhere",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " greatly",
                            " value",
                            " our",
                            " contributors",
                            " and",
                            " have",
                            " a",
                            " large",
                            " range",
                            " of",
                            " rewards",
                            " for",
                            " those",
                            " who",
                            " choose",
                            " to",
                            " support",
                            " our",
                            " project",
                            ".",
                            " We",
                            " are",
                            " offering",
                            " everything",
                            " from",
                            " a",
                            " free",
                            " pre",
                            "quel",
                            " short",
                            " story",
                            " to",
                            " a",
                            " thank",
                            " you",
                            " phone",
                            " call",
                            " and",
                            " a",
                            " fictional",
                            " title",
                            " of",
                            " nobility",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "5",
                            " or",
                            " more",
                            " and",
                            " we",
                            " will",
                            " give",
                            " you",
                            " a",
                            " big",
                            " thanks",
                            " on",
                            " our",
                            " website",
                            ",",
                            " lasting",
                            " as",
                            " long",
                            " as",
                            " we",
                            " exist",
                            ".",
                            " Given",
                            " advancing",
                            " technology",
                            " and",
                            " a",
                            " successful",
                            " series",
                            " of",
                            " projects",
                            " we",
                            " plan",
                            " on",
                            " this",
                            " being",
                            " F",
                            "ORE",
                            "VER",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "7",
                            " or",
                            " more",
                            " and",
                            " you",
                            " will",
                            " get",
                            " the",
                            " previous",
                            " reward",
                            " and",
                            " a",
                            " digital",
                            " download",
                            " of",
                            " Lost",
                            " D",
                            "aim",
                            "yo",
                            ",",
                            " the",
                            " short"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.188,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.54,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrg4b4zvj10ex17gr289a",
                        "tokens": [
                            " into",
                            " book",
                            "stores",
                            " and",
                            " comic",
                            " stands",
                            " everywhere",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " greatly",
                            " value",
                            " our",
                            " contributors",
                            " and",
                            " have",
                            " a",
                            " large",
                            " range",
                            " of",
                            " rewards",
                            " for",
                            " those",
                            " who",
                            " choose",
                            " to",
                            " support",
                            " our",
                            " project",
                            ".",
                            " We",
                            " are",
                            " offering",
                            " everything",
                            " from",
                            " a",
                            " free",
                            " pre",
                            "quel",
                            " short",
                            " story",
                            " to",
                            " a",
                            " thank",
                            " you",
                            " phone",
                            " call",
                            " and",
                            " a",
                            " fictional",
                            " title",
                            " of",
                            " nobility",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "5",
                            " or",
                            " more",
                            " and",
                            " we",
                            " will",
                            " give",
                            " you",
                            " a",
                            " big",
                            " thanks",
                            " on",
                            " our",
                            " website",
                            ",",
                            " lasting",
                            " as",
                            " long",
                            " as",
                            " we",
                            " exist",
                            ".",
                            " Given",
                            " advancing",
                            " technology",
                            " and",
                            " a",
                            " successful",
                            " series",
                            " of",
                            " projects",
                            " we",
                            " plan",
                            " on",
                            " this",
                            " being",
                            " F",
                            "ORE",
                            "VER",
                            "!",
                            "\n",
                            "\n",
                            "P",
                            "ledge",
                            " $",
                            "7",
                            " or",
                            " more",
                            " and",
                            " you",
                            " will",
                            " get",
                            " the",
                            " previous",
                            " reward",
                            " and",
                            " a",
                            " digital",
                            " download",
                            " of",
                            " Lost",
                            " D",
                            "aim",
                            "yo",
                            ",",
                            " the",
                            " short"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.188,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.54,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrg494zv910exoptsu1fp",
                        "tokens": [
                            ",",
                            " and",
                            " allowing",
                            " the",
                            " fans",
                            " (",
                            "YOU",
                            "!)",
                            " to",
                            " be",
                            " much",
                            " more",
                            " involved",
                            " in",
                            " the",
                            " incentives",
                            " for",
                            " the",
                            " next",
                            " go",
                            " around",
                            ".",
                            "\n",
                            "\n",
                            "WH",
                            "Y",
                            " $",
                            "12",
                            ",",
                            "000",
                            "?:",
                            "\n",
                            "\n",
                            "After",
                            " crunch",
                            "ing",
                            " the",
                            " numbers",
                            ",",
                            " this",
                            " is",
                            " the",
                            " necessary",
                            " amount",
                            " in",
                            " order",
                            " for",
                            " me",
                            " to",
                            " accomplish",
                            " all",
                            " that",
                            " I",
                            " am",
                            " offering",
                            ".",
                            " The",
                            " money",
                            " would",
                            " fund",
                            " the",
                            " printing",
                            " of",
                            " 500",
                            " full",
                            "-",
                            "color",
                            " 100",
                            "+",
                            " page",
                            " soft",
                            " cover",
                            " copies",
                            " of",
                            " the",
                            " first",
                            " book",
                            ".",
                            " It",
                            " would",
                            " also",
                            " go",
                            " towards",
                            " creating",
                            " and",
                            " distributing",
                            " the",
                            " rewards",
                            " to",
                            " all",
                            " of",
                            " those",
                            " who",
                            " pledge",
                            ".",
                            " Last",
                            " but",
                            " not",
                            " least",
                            ",",
                            " and",
                            " I",
                            "'m",
                            " not",
                            " going",
                            " to",
                            " lie",
                            ",",
                            " a",
                            " good",
                            " portion",
                            " of",
                            " the",
                            " funding",
                            " will",
                            " enable",
                            " me",
                            " to",
                            " take",
                            " time",
                            " away",
                            " from",
                            " my",
                            " full",
                            " time",
                            " job",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "39196",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.541,
                        "maxValueTokenIndex": 87,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.293,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:58.670Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.188,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "50995",
            "description": "terms related to reinforcement and its applications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.52126145362854,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "50995",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:14.891Z",
                "maxActApprox": 68.618,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    50995,
                    15155,
                    88905,
                    79151,
                    4415,
                    74964,
                    84591,
                    51118,
                    13137,
                    35434,
                    88971,
                    2053,
                    83781,
                    94046,
                    65197,
                    52908,
                    77653,
                    10919,
                    41861,
                    40550,
                    31619,
                    65735,
                    84596,
                    52490,
                    685
                ],
                "topkCosSimValues": [
                    1,
                    0.5019,
                    0.4399,
                    0.4353,
                    0.4303,
                    0.4228,
                    0.4221,
                    0.4204,
                    0.4131,
                    0.3973,
                    0.3902,
                    0.3854,
                    0.3827,
                    0.3818,
                    0.3738,
                    0.3732,
                    0.3716,
                    0.3653,
                    0.3646,
                    0.3634,
                    0.3624,
                    0.3588,
                    0.3544,
                    0.3525,
                    0.3503
                ],
                "neuron_alignment_indices": [
                    659,
                    618,
                    651
                ],
                "neuron_alignment_values": [
                    0.143,
                    0.106,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    659,
                    618,
                    419
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    51118,
                    51053,
                    50995
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0,
                    0
                ],
                "neg_str": [
                    " Seym",
                    " laun",
                    " VICE",
                    " holders",
                    "DragonMagazine",
                    " Parables",
                    " Pixie",
                    " mileage",
                    " Gon",
                    " Iranians"
                ],
                "neg_values": [
                    -0.736,
                    -0.678,
                    -0.665,
                    -0.646,
                    -0.644,
                    -0.623,
                    -0.62,
                    -0.619,
                    -0.614,
                    -0.603
                ],
                "pos_str": [
                    "hardt",
                    "forcement",
                    "vention",
                    "forcer",
                    "wald",
                    "forced",
                    "hart",
                    "acher",
                    "itial",
                    "hard"
                ],
                "pos_values": [
                    1.47,
                    1.251,
                    1.215,
                    1.207,
                    1.083,
                    1.078,
                    1.013,
                    1.009,
                    1.003,
                    0.992
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    10,
                    8,
                    6,
                    3,
                    2,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.771,
                    2.142,
                    3.512,
                    4.883,
                    6.254,
                    7.624,
                    8.995,
                    10.365,
                    11.736,
                    13.107,
                    14.477,
                    15.848,
                    17.219,
                    18.589,
                    19.96,
                    21.331,
                    22.701,
                    24.072,
                    25.443,
                    26.813,
                    28.184,
                    29.555,
                    30.925,
                    32.296,
                    33.666,
                    35.037,
                    36.408,
                    37.778,
                    39.149,
                    40.52,
                    41.89,
                    43.261,
                    44.632,
                    46.002,
                    47.373,
                    48.744,
                    50.114,
                    51.485,
                    52.856,
                    54.226,
                    55.597,
                    56.967,
                    58.338,
                    59.709,
                    61.079,
                    62.45,
                    63.821,
                    65.191,
                    66.562,
                    67.933
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    7,
                    11,
                    25,
                    62,
                    126,
                    284,
                    518,
                    970,
                    1667,
                    2495,
                    3376,
                    4219,
                    4884,
                    5230,
                    4881,
                    4523,
                    3885,
                    3240,
                    2489,
                    1892,
                    1424,
                    1123,
                    782,
                    570,
                    476,
                    330,
                    247,
                    195,
                    106,
                    67,
                    45,
                    45,
                    24,
                    11,
                    6,
                    4,
                    5,
                    4,
                    0,
                    2,
                    0,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.713,
                    -0.669,
                    -0.625,
                    -0.581,
                    -0.537,
                    -0.493,
                    -0.449,
                    -0.405,
                    -0.361,
                    -0.316,
                    -0.272,
                    -0.228,
                    -0.184,
                    -0.14,
                    -0.096,
                    -0.052,
                    -0.008,
                    0.037,
                    0.081,
                    0.125,
                    0.169,
                    0.213,
                    0.257,
                    0.301,
                    0.345,
                    0.389,
                    0.434,
                    0.478,
                    0.522,
                    0.566,
                    0.61,
                    0.654,
                    0.698,
                    0.742,
                    0.787,
                    0.831,
                    0.875,
                    0.919,
                    0.963,
                    1.007,
                    1.051,
                    1.095,
                    1.139,
                    1.184,
                    1.228,
                    1.272,
                    1.316,
                    1.36,
                    1.404,
                    1.448
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " terminology related to reinforcement and reinforcement learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to reinforcement and its applications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghdpbxdxw010exfdbm5jut",
                        "tokens": [
                            ".",
                            " \u2013",
                            " Rein",
                            "hold",
                            " N",
                            "ie",
                            "b",
                            "uh",
                            "r",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Change",
                            " does",
                            " not",
                            " roll",
                            " in",
                            " on",
                            " the",
                            " wheels",
                            " of",
                            " inev",
                            "itability",
                            ",",
                            " but",
                            " comes",
                            " through",
                            " continuous",
                            " struggle",
                            ".",
                            " And",
                            " so",
                            " we",
                            " must",
                            " straight",
                            "en",
                            " our",
                            " backs",
                            " and",
                            " work",
                            " for",
                            " our",
                            " freedom",
                            ".",
                            " \u2013",
                            " Martin",
                            " Luther",
                            " King",
                            ",",
                            " Jr",
                            ".",
                            "\n",
                            "\n",
                            "4",
                            ".",
                            " For",
                            " the",
                            " past",
                            " 33",
                            " years",
                            ",",
                            " I",
                            " have",
                            " looked",
                            " in",
                            " the",
                            " mirror",
                            " every",
                            " morning",
                            " and",
                            " asked",
                            " myself",
                            ":",
                            " \u00e2\u0122",
                            "\u013a",
                            "If",
                            " today",
                            " were",
                            " the",
                            " last",
                            " day",
                            " of",
                            " my",
                            " life",
                            ",",
                            " would",
                            " I",
                            " want",
                            " to",
                            " do",
                            " what",
                            " I",
                            " am",
                            " about",
                            " to",
                            " do",
                            " today",
                            "?",
                            "\u00e2\u0122",
                            "\u013b",
                            " And",
                            " whenever",
                            " the",
                            " answer",
                            " has",
                            " been",
                            " \u00e2\u0122",
                            "\u013a",
                            "No",
                            "\u00e2\u0122",
                            "\u013b",
                            " for",
                            " too",
                            " many",
                            " days",
                            " in",
                            " a",
                            " row",
                            ",",
                            " I",
                            " know",
                            " I",
                            " need",
                            " to",
                            " change",
                            " something"
                        ],
                        "dataIndex": null,
                        "index": "50995",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.618,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            68.618,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:16.981Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 54.894,
                        "binMax": 68.618,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdpbvdxvf10exctfcjc4v",
                        "tokens": [
                            ".",
                            " \u2013",
                            " Rein",
                            "hold",
                            " N",
                            "ie",
                            "b",
                            "uh",
                            "r",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Change",
                            " does",
                            " not",
                            " roll",
                            " in",
                            " on",
                            " the",
                            " wheels",
                            " of",
                            " inev",
                            "itability",
                            ",",
                            " but",
                            " comes",
                            " through",
                            " continuous",
                            " struggle",
                            ".",
                            " And",
                            " so",
                            " we",
                            " must",
                            " straight",
                            "en",
                            " our",
                            " backs",
                            " and",
                            " work",
                            " for",
                            " our",
                            " freedom",
                            ".",
                            " \u2013",
                            " Martin",
                            " Luther",
                            " King",
                            ",",
                            " Jr",
                            ".",
                            "\n",
                            "\n",
                            "4",
                            ".",
                            " For",
                            " the",
                            " past",
                            " 33",
                            " years",
                            ",",
                            " I",
                            " have",
                            " looked",
                            " in",
                            " the",
                            " mirror",
                            " every",
                            " morning",
                            " and",
                            " asked",
                            " myself",
                            ":",
                            " \u00e2\u0122",
                            "\u013a",
                            "If",
                            " today",
                            " were",
                            " the",
                            " last",
                            " day",
                            " of",
                            " my",
                            " life",
                            ",",
                            " would",
                            " I",
                            " want",
                            " to",
                            " do",
                            " what",
                            " I",
                            " am",
                            " about",
                            " to",
                            " do",
                            " today",
                            "?",
                            "\u00e2\u0122",
                            "\u013b",
                            " And",
                            " whenever",
                            " the",
                            " answer",
                            " has",
                            " been",
                            " \u00e2\u0122",
                            "\u013a",
                            "No",
                            "\u00e2\u0122",
                            "\u013b",
                            " for",
                            " too",
                            " many",
                            " days",
                            " in",
                            " a",
                            " row",
                            ",",
                            " I",
                            " know",
                            " I",
                            " need",
                            " to",
                            " change",
                            " something"
                        ],
                        "dataIndex": null,
                        "index": "50995",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.618,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            68.618,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:16.981Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 68.618,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdpbvdxvg10exkx9woeod",
                        "tokens": [
                            " in",
                            " Ruins",
                            ":",
                            " Rein",
                            "force",
                            "ments",
                            " adds",
                            " to",
                            " the",
                            " already",
                            " ground",
                            " breaking",
                            " game",
                            " play",
                            " of",
                            " Europe",
                            " in",
                            " Ruins",
                            " by",
                            " adding",
                            " in",
                            " the",
                            " British",
                            " Commonwealth",
                            ",",
                            " the",
                            " Panzer",
                            " Elite",
                            ",",
                            " new",
                            " game",
                            " mode",
                            ",",
                            " a",
                            " bunch",
                            " of",
                            " new",
                            " maps",
                            ",",
                            " the",
                            " new",
                            " Ad",
                            "vant",
                            "ages",
                            " system",
                            " and",
                            " a",
                            " whole",
                            " new",
                            " back",
                            "-",
                            "end",
                            " launcher",
                            " with",
                            " new",
                            " innovative",
                            " systems",
                            " for",
                            " army",
                            " purchase",
                            " and",
                            " persistence",
                            ".",
                            " What",
                            " is",
                            " in",
                            " this",
                            " latest",
                            " release",
                            ":",
                            "<|endoftext|>",
                            "Get",
                            " Ready",
                            " For",
                            " the",
                            " Kick",
                            "off",
                            "!",
                            " Beyond",
                            " the",
                            " Sid",
                            "eline",
                            " Football",
                            " Ann",
                            "ounced",
                            " Last",
                            " week",
                            "'s",
                            " Out",
                            " of",
                            " the",
                            " Park",
                            " Baseball",
                            " 15",
                            " announcement",
                            " wasn",
                            "'t",
                            " all",
                            " we",
                            " had",
                            " planned",
                            " -",
                            " Today",
                            ",",
                            " just",
                            " in",
                            " time",
                            " for",
                            " this",
                            " Sunday",
                            "'s",
                            " big",
                            " game",
                            " between",
                            " the",
                            " Seahawks",
                            " and",
                            " the",
                            " Broncos",
                            ",",
                            " we",
                            "'re",
                            " unveiling",
                            " the",
                            " latest",
                            " addition",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "50995",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.833,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            65.833,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:16.981Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 68.618,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "94002",
            "description": "terms related to financial incentives or rewards",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5212279558181763,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "94002",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:24:49.578Z",
                "maxActApprox": 44.31,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    94002,
                    55814,
                    17356,
                    12438,
                    49749,
                    36943,
                    22365,
                    14269,
                    39196,
                    7774,
                    13756,
                    21302,
                    87467,
                    52163,
                    18919,
                    27290,
                    46592,
                    6330,
                    74043,
                    57282,
                    70444,
                    39308,
                    64410,
                    85256,
                    54369
                ],
                "topkCosSimValues": [
                    1,
                    0.6604,
                    0.5155,
                    0.5111,
                    0.5082,
                    0.4982,
                    0.4768,
                    0.4742,
                    0.4736,
                    0.4645,
                    0.4499,
                    0.4464,
                    0.4434,
                    0.4408,
                    0.4346,
                    0.4343,
                    0.4295,
                    0.4254,
                    0.4174,
                    0.4124,
                    0.4121,
                    0.409,
                    0.4079,
                    0.4066,
                    0.3983
                ],
                "neuron_alignment_indices": [
                    679,
                    241,
                    259
                ],
                "neuron_alignment_values": [
                    0.129,
                    0.106,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    717,
                    415,
                    259
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.008,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.008,
                    0.007
                ],
                "correlated_features_indices": [
                    94001,
                    94006,
                    94097
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0
                ],
                "neg_str": [
                    "scape",
                    "INK",
                    "uart",
                    "turn",
                    "Jess",
                    "theless",
                    "facing",
                    "tic",
                    "Mos",
                    "tons"
                ],
                "neg_values": [
                    -0.755,
                    -0.729,
                    -0.722,
                    -0.714,
                    -0.712,
                    -0.711,
                    -0.707,
                    -0.687,
                    -0.672,
                    -0.671
                ],
                "pos_str": [
                    " accrued",
                    " depreciation",
                    " payout",
                    " bonuses",
                    " bonus",
                    " payable",
                    " compensation",
                    " awarded",
                    " paid",
                    " payments"
                ],
                "pos_values": [
                    1.092,
                    1.07,
                    1.042,
                    1,
                    0.96,
                    0.951,
                    0.926,
                    0.893,
                    0.888,
                    0.876
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    26,
                    22,
                    12,
                    1,
                    6,
                    5,
                    1,
                    1,
                    0,
                    3,
                    2,
                    4,
                    3,
                    1,
                    4,
                    2,
                    2,
                    4,
                    1,
                    0,
                    3,
                    4,
                    2,
                    0,
                    0,
                    1,
                    0,
                    2,
                    2,
                    0,
                    2,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.495,
                    1.38,
                    2.265,
                    3.15,
                    4.035,
                    4.92,
                    5.806,
                    6.691,
                    7.576,
                    8.461,
                    9.346,
                    10.231,
                    11.117,
                    12.002,
                    12.887,
                    13.772,
                    14.657,
                    15.542,
                    16.428,
                    17.313,
                    18.198,
                    19.083,
                    19.968,
                    20.853,
                    21.739,
                    22.624,
                    23.509,
                    24.394,
                    25.279,
                    26.164,
                    27.05,
                    27.935,
                    28.82,
                    29.705,
                    30.59,
                    31.475,
                    32.36,
                    33.246,
                    34.131,
                    35.016,
                    35.901,
                    36.786,
                    37.671,
                    38.557,
                    39.442,
                    40.327,
                    41.212,
                    42.097,
                    42.982,
                    43.868
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    13,
                    21,
                    30,
                    60,
                    84,
                    115,
                    235,
                    369,
                    542,
                    800,
                    1169,
                    1490,
                    2050,
                    2343,
                    3050,
                    3498,
                    3948,
                    4099,
                    4064,
                    3860,
                    3525,
                    3203,
                    2797,
                    2241,
                    1736,
                    1364,
                    1008,
                    722,
                    568,
                    374,
                    278,
                    183,
                    140,
                    85,
                    53,
                    31,
                    36,
                    17,
                    22,
                    3,
                    9,
                    4,
                    3,
                    1,
                    2,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.737,
                    -0.7,
                    -0.663,
                    -0.626,
                    -0.589,
                    -0.552,
                    -0.515,
                    -0.478,
                    -0.441,
                    -0.404,
                    -0.367,
                    -0.33,
                    -0.293,
                    -0.256,
                    -0.219,
                    -0.182,
                    -0.145,
                    -0.109,
                    -0.072,
                    -0.035,
                    0.002,
                    0.039,
                    0.076,
                    0.113,
                    0.15,
                    0.187,
                    0.224,
                    0.261,
                    0.298,
                    0.335,
                    0.372,
                    0.409,
                    0.446,
                    0.483,
                    0.52,
                    0.557,
                    0.593,
                    0.63,
                    0.667,
                    0.704,
                    0.741,
                    0.778,
                    0.815,
                    0.852,
                    0.889,
                    0.926,
                    0.963,
                    1,
                    1.037,
                    1.074
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to financial incentives or rewards",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj1l77ak7610ex5wneyr8c",
                        "tokens": [
                            " their",
                            " unions",
                            ".",
                            " But",
                            " it",
                            "'s",
                            " not",
                            " clear",
                            " Sun",
                            " Capital",
                            "'s",
                            " offer",
                            " would",
                            " top",
                            " those",
                            " of",
                            " other",
                            " b",
                            "idd",
                            "ers",
                            " who",
                            " would",
                            " simply",
                            " produce",
                            " the",
                            " product",
                            " with",
                            " the",
                            " b",
                            "idd",
                            "ers",
                            "'",
                            " existing",
                            " facilities",
                            ",",
                            " leaving",
                            " the",
                            " Host",
                            "ess",
                            " workers",
                            " out",
                            " of",
                            " luck",
                            ".",
                            "\n",
                            "\n",
                            "Related",
                            ":",
                            " Tw",
                            "ink",
                            "ies",
                            " ho",
                            "arding",
                            " begins",
                            "\n",
                            "\n",
                            "D",
                            "rain",
                            " scheduled",
                            " another",
                            " hearing",
                            " for",
                            " Nov",
                            ".",
                            " 29",
                            ".",
                            " At",
                            " that",
                            " time",
                            ",",
                            " he",
                            " will",
                            " consider",
                            " Host",
                            "ess",
                            "'",
                            " request",
                            " for",
                            " approval",
                            " of",
                            " $",
                            "1",
                            ".",
                            "75",
                            " million",
                            " in",
                            " bonuses",
                            ",",
                            " ranging",
                            " from",
                            " $",
                            "7",
                            ",",
                            "400",
                            " to",
                            " $",
                            "130",
                            ",",
                            "500",
                            ",",
                            " to",
                            " be",
                            " paid",
                            " to",
                            " 19",
                            " executives",
                            " to",
                            " oversee",
                            " the",
                            " liquid",
                            "ation",
                            " of",
                            " the",
                            " company",
                            ".",
                            " Host",
                            "ess",
                            " said",
                            " it",
                            " needs",
                            " to",
                            " pay",
                            " the",
                            " bonuses",
                            " to",
                            " make",
                            " sure"
                        ],
                        "dataIndex": null,
                        "index": "94002",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.31,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.31,
                            0,
                            0,
                            0.241,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.001,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:51.042Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.31,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj1l77ak7710exnb1ji5uy",
                        "tokens": [
                            " their",
                            " unions",
                            ".",
                            " But",
                            " it",
                            "'s",
                            " not",
                            " clear",
                            " Sun",
                            " Capital",
                            "'s",
                            " offer",
                            " would",
                            " top",
                            " those",
                            " of",
                            " other",
                            " b",
                            "idd",
                            "ers",
                            " who",
                            " would",
                            " simply",
                            " produce",
                            " the",
                            " product",
                            " with",
                            " the",
                            " b",
                            "idd",
                            "ers",
                            "'",
                            " existing",
                            " facilities",
                            ",",
                            " leaving",
                            " the",
                            " Host",
                            "ess",
                            " workers",
                            " out",
                            " of",
                            " luck",
                            ".",
                            "\n",
                            "\n",
                            "Related",
                            ":",
                            " Tw",
                            "ink",
                            "ies",
                            " ho",
                            "arding",
                            " begins",
                            "\n",
                            "\n",
                            "D",
                            "rain",
                            " scheduled",
                            " another",
                            " hearing",
                            " for",
                            " Nov",
                            ".",
                            " 29",
                            ".",
                            " At",
                            " that",
                            " time",
                            ",",
                            " he",
                            " will",
                            " consider",
                            " Host",
                            "ess",
                            "'",
                            " request",
                            " for",
                            " approval",
                            " of",
                            " $",
                            "1",
                            ".",
                            "75",
                            " million",
                            " in",
                            " bonuses",
                            ",",
                            " ranging",
                            " from",
                            " $",
                            "7",
                            ",",
                            "400",
                            " to",
                            " $",
                            "130",
                            ",",
                            "500",
                            ",",
                            " to",
                            " be",
                            " paid",
                            " to",
                            " 19",
                            " executives",
                            " to",
                            " oversee",
                            " the",
                            " liquid",
                            "ation",
                            " of",
                            " the",
                            " company",
                            ".",
                            " Host",
                            "ess",
                            " said",
                            " it",
                            " needs",
                            " to",
                            " pay",
                            " the",
                            " bonuses",
                            " to",
                            " make",
                            " sure"
                        ],
                        "dataIndex": null,
                        "index": "94002",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.31,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.31,
                            0,
                            0,
                            0.241,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.001,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:51.042Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.31,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj1l79ak7q10excpvt4cbq",
                        "tokens": [
                            " their",
                            " unions",
                            ".",
                            " But",
                            " it",
                            "'s",
                            " not",
                            " clear",
                            " Sun",
                            " Capital",
                            "'s",
                            " offer",
                            " would",
                            " top",
                            " those",
                            " of",
                            " other",
                            " b",
                            "idd",
                            "ers",
                            " who",
                            " would",
                            " simply",
                            " produce",
                            " the",
                            " product",
                            " with",
                            " the",
                            " b",
                            "idd",
                            "ers",
                            "'",
                            " existing",
                            " facilities",
                            ",",
                            " leaving",
                            " the",
                            " Host",
                            "ess",
                            " workers",
                            " out",
                            " of",
                            " luck",
                            ".",
                            "\n",
                            "\n",
                            "Related",
                            ":",
                            " Tw",
                            "ink",
                            "ies",
                            " ho",
                            "arding",
                            " begins",
                            "\n",
                            "\n",
                            "D",
                            "rain",
                            " scheduled",
                            " another",
                            " hearing",
                            " for",
                            " Nov",
                            ".",
                            " 29",
                            ".",
                            " At",
                            " that",
                            " time",
                            ",",
                            " he",
                            " will",
                            " consider",
                            " Host",
                            "ess",
                            "'",
                            " request",
                            " for",
                            " approval",
                            " of",
                            " $",
                            "1",
                            ".",
                            "75",
                            " million",
                            " in",
                            " bonuses",
                            ",",
                            " ranging",
                            " from",
                            " $",
                            "7",
                            ",",
                            "400",
                            " to",
                            " $",
                            "130",
                            ",",
                            "500",
                            ",",
                            " to",
                            " be",
                            " paid",
                            " to",
                            " 19",
                            " executives",
                            " to",
                            " oversee",
                            " the",
                            " liquid",
                            "ation",
                            " of",
                            " the",
                            " company",
                            ".",
                            " Host",
                            "ess",
                            " said",
                            " it",
                            " needs",
                            " to",
                            " pay",
                            " the",
                            " bonuses",
                            " to",
                            " make",
                            " sure"
                        ],
                        "dataIndex": null,
                        "index": "94002",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.31,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.31,
                            0,
                            0,
                            0.241,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.001,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:51.042Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 35.448,
                        "binMax": 44.31,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "44102",
            "description": "references to reinforcement or related concepts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5206194519996643,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "44102",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:17:40.156Z",
                "maxActApprox": 65.9,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44102,
                    8963,
                    43394,
                    35507,
                    45842,
                    36591,
                    37130,
                    20124,
                    20324,
                    25605,
                    30497,
                    22371,
                    8802,
                    45035,
                    16131,
                    46573,
                    42467,
                    40598,
                    37480,
                    20591,
                    6185,
                    21287,
                    45979,
                    34850,
                    1115
                ],
                "topkCosSimValues": [
                    1,
                    0.5034,
                    0.4445,
                    0.4406,
                    0.421,
                    0.4119,
                    0.4018,
                    0.3758,
                    0.3748,
                    0.3651,
                    0.3627,
                    0.3583,
                    0.3577,
                    0.3577,
                    0.3574,
                    0.3562,
                    0.3541,
                    0.3541,
                    0.354,
                    0.3464,
                    0.3415,
                    0.3381,
                    0.3364,
                    0.3345,
                    0.3334
                ],
                "neuron_alignment_indices": [
                    659,
                    618,
                    166
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.108,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    659,
                    166,
                    419
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.006,
                    0.005
                ],
                "correlated_features_indices": [
                    44119,
                    44111,
                    44089
                ],
                "correlated_features_pearson": [
                    0.007,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.007,
                    0,
                    0
                ],
                "neg_str": [
                    " Seym",
                    " laun",
                    "DragonMagazine",
                    " holders",
                    " VICE",
                    " Parables",
                    " Pixie",
                    " Gon",
                    " mileage",
                    " Sylvia"
                ],
                "neg_values": [
                    -0.723,
                    -0.707,
                    -0.674,
                    -0.655,
                    -0.655,
                    -0.65,
                    -0.643,
                    -0.631,
                    -0.619,
                    -0.619
                ],
                "pos_str": [
                    "hardt",
                    "forcement",
                    "vention",
                    "forcer",
                    "wald",
                    "forced",
                    "acher",
                    "hart",
                    "itial",
                    "feld"
                ],
                "pos_values": [
                    1.448,
                    1.273,
                    1.226,
                    1.176,
                    1.081,
                    1.046,
                    1.021,
                    1.008,
                    1,
                    0.998
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    41,
                    27,
                    23,
                    20,
                    6,
                    6,
                    4,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    3,
                    0,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.696,
                    2.013,
                    3.33,
                    4.647,
                    5.965,
                    7.282,
                    8.599,
                    9.916,
                    11.234,
                    12.551,
                    13.868,
                    15.185,
                    16.503,
                    17.82,
                    19.137,
                    20.454,
                    21.772,
                    23.089,
                    24.406,
                    25.724,
                    27.041,
                    28.358,
                    29.675,
                    30.993,
                    32.31,
                    33.627,
                    34.944,
                    36.262,
                    37.579,
                    38.896,
                    40.213,
                    41.531,
                    42.848,
                    44.165,
                    45.482,
                    46.8,
                    48.117,
                    49.434,
                    50.751,
                    52.069,
                    53.386,
                    54.703,
                    56.02,
                    57.338,
                    58.655,
                    59.972,
                    61.289,
                    62.607,
                    63.924,
                    65.241
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    9,
                    8,
                    40,
                    64,
                    162,
                    332,
                    600,
                    1036,
                    1756,
                    2563,
                    3444,
                    4272,
                    4789,
                    5147,
                    4855,
                    4310,
                    3696,
                    3144,
                    2406,
                    1891,
                    1428,
                    1118,
                    844,
                    616,
                    453,
                    375,
                    292,
                    195,
                    145,
                    82,
                    52,
                    36,
                    43,
                    16,
                    8,
                    4,
                    5,
                    7,
                    2,
                    1,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.701,
                    -0.658,
                    -0.614,
                    -0.571,
                    -0.527,
                    -0.484,
                    -0.441,
                    -0.397,
                    -0.354,
                    -0.31,
                    -0.267,
                    -0.223,
                    -0.18,
                    -0.137,
                    -0.093,
                    -0.05,
                    -0.006,
                    0.037,
                    0.081,
                    0.124,
                    0.167,
                    0.211,
                    0.254,
                    0.298,
                    0.341,
                    0.385,
                    0.428,
                    0.471,
                    0.515,
                    0.558,
                    0.602,
                    0.645,
                    0.689,
                    0.732,
                    0.775,
                    0.819,
                    0.862,
                    0.906,
                    0.949,
                    0.993,
                    1.036,
                    1.079,
                    1.123,
                    1.166,
                    1.21,
                    1.253,
                    1.296,
                    1.34,
                    1.383,
                    1.427
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to reinforcement or related concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6ya8mgaq6i666usz813h0",
                        "tokens": [
                            "s",
                            " no",
                            " easier",
                            " way",
                            " to",
                            " start",
                            " this",
                            " habit",
                            " than",
                            " through",
                            " these",
                            " iconic",
                            " quotes",
                            " about",
                            " change",
                            " and",
                            " the",
                            " process",
                            " of",
                            " changing",
                            ",",
                            " from",
                            " some",
                            " of",
                            " the",
                            " great",
                            " thinkers",
                            ",",
                            " authors",
                            ",",
                            " actors",
                            ",",
                            " and",
                            " politicians",
                            " or",
                            " our",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " If",
                            " you",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " like",
                            " something",
                            ",",
                            " change",
                            " it",
                            ".",
                            " If",
                            " you",
                            " can",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " change",
                            " it",
                            ",",
                            " change",
                            " your",
                            " attitude",
                            ".",
                            " \u2013",
                            " Maya",
                            " Angel",
                            "ou",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " God",
                            " grant",
                            " me",
                            " the",
                            " se",
                            "ren",
                            "ity",
                            " to",
                            " accept",
                            " the",
                            " things",
                            " I",
                            " cannot",
                            " change",
                            ",",
                            " the",
                            " courage",
                            " to",
                            " change",
                            " the",
                            " things",
                            " I",
                            " can",
                            ",",
                            " and",
                            " the",
                            " wisdom",
                            " to",
                            " know",
                            " the",
                            " difference",
                            ".",
                            " \u2013",
                            " Rein",
                            "hold",
                            " N",
                            "ie",
                            "b",
                            "uh",
                            "r",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Change",
                            " does",
                            " not",
                            " roll",
                            " in",
                            " on",
                            " the",
                            " wheels"
                        ],
                        "dataIndex": null,
                        "index": "44102",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.9,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            65.9,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:43.828Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 65.9,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ya8mgaq7i6661ayy35kj",
                        "tokens": [
                            " some",
                            " truly",
                            " badly",
                            " brewed",
                            " beers",
                            ".",
                            " Maybe",
                            " it",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " fair",
                            " to",
                            " place",
                            " these",
                            " new",
                            " brewers",
                            " next",
                            " to",
                            " the",
                            " cream",
                            " of",
                            " world",
                            " class",
                            " brewing",
                            ".",
                            "\n",
                            "\n",
                            "Every",
                            " year",
                            " has",
                            " had",
                            " a",
                            " challenge",
                            " for",
                            " the",
                            " brewers",
                            ".",
                            " This",
                            " year",
                            " the",
                            " challenge",
                            " was",
                            " to",
                            " brew",
                            " a",
                            " version",
                            " of",
                            " that",
                            " evil",
                            " phenomenon",
                            " called",
                            " the",
                            " Rad",
                            "ler",
                            ",",
                            " that",
                            " takes",
                            " up",
                            " valuable",
                            " space",
                            " on",
                            " beer",
                            " shelves",
                            " across",
                            " Holland",
                            ",",
                            " through",
                            " Germany",
                            " to",
                            " Slovakia",
                            ",",
                            " even",
                            " making",
                            " occ",
                            "ass",
                            "ional",
                            " visits",
                            " here",
                            " in",
                            " Denmark",
                            ".",
                            " It",
                            " causes",
                            " every",
                            " proud",
                            ",",
                            " Rein",
                            "he",
                            "its",
                            "ge",
                            "bot",
                            "-",
                            "loving",
                            " German",
                            " brewer",
                            " to",
                            " pour",
                            " cheap",
                            " soda",
                            "-",
                            "pop",
                            " in",
                            " his",
                            " beer",
                            ",",
                            " and",
                            " it",
                            " causes",
                            " teenagers",
                            " to",
                            " believe",
                            " that",
                            " beer",
                            " can",
                            " taste",
                            " like",
                            " sugar",
                            "-",
                            "water",
                            ".",
                            "\n",
                            "\n",
                            "Luckily",
                            " the",
                            " brewers"
                        ],
                        "dataIndex": null,
                        "index": "44102",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.463,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.463,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:43.828Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 65.9,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ya8mgaq8i666p5espf5t",
                        "tokens": [
                            " said",
                            " he",
                            "'s",
                            " had",
                            " a",
                            " lifelong",
                            " love",
                            " of",
                            " the",
                            " law",
                            " and",
                            " was",
                            " hum",
                            "bled",
                            " by",
                            " the",
                            " appointment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "To",
                            " this",
                            " day",
                            ",",
                            " I",
                            " cannot",
                            " walk",
                            " into",
                            " a",
                            " courtroom",
                            " without",
                            " my",
                            " heart",
                            " skipping",
                            " a",
                            " beat",
                            ",\"",
                            " he",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " trust",
                            " that",
                            " will",
                            " never",
                            " change",
                            ".",
                            " I",
                            " trust",
                            " that",
                            " I",
                            " will",
                            " always",
                            " stand",
                            " hum",
                            "bly",
                            " before",
                            " the",
                            " law",
                            ".\"",
                            "\n",
                            "\n",
                            "Chief",
                            " Justice",
                            " Pat",
                            "ience",
                            " Rog",
                            "g",
                            "ens",
                            "ack",
                            " appeared",
                            " with",
                            " Walker",
                            " and",
                            " Kelly",
                            " and",
                            " said",
                            " she",
                            " had",
                            " known",
                            " Kelly",
                            " for",
                            " a",
                            " long",
                            " time",
                            " and",
                            " was",
                            " impressed",
                            " with",
                            " his",
                            " scholarship",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " am",
                            " very",
                            ",",
                            " very",
                            " pleased",
                            " with",
                            " the",
                            " governor",
                            "'s",
                            " appointment",
                            ",\"",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Kelly",
                            " was",
                            " with",
                            " the",
                            " large",
                            " Milwaukee",
                            " law",
                            " firm",
                            " Rein",
                            "hart",
                            " Bo",
                            "er",
                            "ner"
                        ],
                        "dataIndex": null,
                        "index": "44102",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.163,
                        "maxValueTokenIndex": 122,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.163,
                            4.568,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:43.828Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 65.9,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "4530",
            "description": "words related to rewards or bonuses",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5201398730278015,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "4530",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:50:25.749Z",
                "maxActApprox": 44.751,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4530,
                    24492,
                    18235,
                    10435,
                    12872,
                    4156,
                    18399,
                    18766,
                    1387,
                    20266,
                    7326,
                    9833,
                    1150,
                    21091,
                    13156,
                    1267,
                    5011,
                    12336,
                    22767,
                    14313,
                    13336,
                    18197,
                    11892,
                    3299,
                    15516
                ],
                "topkCosSimValues": [
                    1,
                    0.6251,
                    0.5024,
                    0.3913,
                    0.3592,
                    0.3359,
                    0.3338,
                    0.3309,
                    0.327,
                    0.3244,
                    0.3203,
                    0.314,
                    0.3087,
                    0.3068,
                    0.2857,
                    0.2812,
                    0.2747,
                    0.2716,
                    0.2711,
                    0.2688,
                    0.2661,
                    0.2633,
                    0.2561,
                    0.2513,
                    0.2479
                ],
                "neuron_alignment_indices": [
                    763,
                    647,
                    32
                ],
                "neuron_alignment_values": [
                    0.155,
                    0.097,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    763,
                    647,
                    32
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.014,
                    0.016
                ],
                "correlated_features_indices": [
                    4561,
                    4515,
                    4519
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.005,
                    0.001
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.001
                ],
                "neg_str": [
                    "adr",
                    "stem",
                    "prototype",
                    "dfx",
                    "ichen",
                    "ugu",
                    "ruary",
                    "athed",
                    "ancing",
                    "ondon"
                ],
                "neg_values": [
                    -0.834,
                    -0.721,
                    -0.689,
                    -0.684,
                    -0.664,
                    -0.662,
                    -0.659,
                    -0.655,
                    -0.654,
                    -0.648
                ],
                "pos_str": [
                    "cules",
                    "++++",
                    "\u00ef\u00b8",
                    "henko",
                    " Scotia",
                    " Plenty",
                    " Zombies",
                    "leep",
                    " surprises",
                    " Clancy"
                ],
                "pos_values": [
                    0.796,
                    0.772,
                    0.747,
                    0.664,
                    0.654,
                    0.65,
                    0.649,
                    0.634,
                    0.625,
                    0.62
                ],
                "frac_nonzero": 0.00015,
                "freq_hist_data_bar_heights": [
                    84,
                    54,
                    40,
                    35,
                    16,
                    16,
                    15,
                    10,
                    10,
                    4,
                    5,
                    2,
                    5,
                    2,
                    3,
                    7,
                    5,
                    2,
                    6,
                    5,
                    10,
                    5,
                    6,
                    6,
                    7,
                    4,
                    4,
                    5,
                    5,
                    3,
                    5,
                    7,
                    7,
                    10,
                    4,
                    4,
                    6,
                    8,
                    5,
                    4,
                    5,
                    6,
                    4,
                    3,
                    7,
                    6,
                    1,
                    1,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.351,
                    2.246,
                    3.141,
                    4.036,
                    4.931,
                    5.825,
                    6.72,
                    7.615,
                    8.51,
                    9.405,
                    10.3,
                    11.195,
                    12.089,
                    12.984,
                    13.879,
                    14.774,
                    15.669,
                    16.564,
                    17.459,
                    18.353,
                    19.248,
                    20.143,
                    21.038,
                    21.933,
                    22.828,
                    23.722,
                    24.617,
                    25.512,
                    26.407,
                    27.302,
                    28.197,
                    29.092,
                    29.986,
                    30.881,
                    31.776,
                    32.671,
                    33.566,
                    34.461,
                    35.356,
                    36.25,
                    37.145,
                    38.04,
                    38.935,
                    39.83,
                    40.725,
                    41.619,
                    42.514,
                    43.409,
                    44.304
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    2,
                    7,
                    9,
                    13,
                    26,
                    40,
                    46,
                    91,
                    118,
                    175,
                    307,
                    409,
                    639,
                    885,
                    1238,
                    1686,
                    2149,
                    2818,
                    3323,
                    3849,
                    4356,
                    4500,
                    4374,
                    4127,
                    3648,
                    3026,
                    2489,
                    1854,
                    1358,
                    962,
                    655,
                    404,
                    246,
                    160,
                    108,
                    64,
                    49,
                    12,
                    10,
                    9,
                    6,
                    5,
                    0,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.818,
                    -0.786,
                    -0.753,
                    -0.72,
                    -0.688,
                    -0.655,
                    -0.622,
                    -0.59,
                    -0.557,
                    -0.525,
                    -0.492,
                    -0.459,
                    -0.427,
                    -0.394,
                    -0.362,
                    -0.329,
                    -0.296,
                    -0.264,
                    -0.231,
                    -0.199,
                    -0.166,
                    -0.133,
                    -0.101,
                    -0.068,
                    -0.036,
                    -0.003,
                    0.03,
                    0.062,
                    0.095,
                    0.128,
                    0.16,
                    0.193,
                    0.225,
                    0.258,
                    0.291,
                    0.323,
                    0.356,
                    0.388,
                    0.421,
                    0.454,
                    0.486,
                    0.519,
                    0.551,
                    0.584,
                    0.617,
                    0.649,
                    0.682,
                    0.714,
                    0.747,
                    0.78
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to rewards or bonuses",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm7lqz4awai666c86xpsxp",
                        "tokens": [
                            " this",
                            " most",
                            " sacred",
                            " of",
                            " traditions",
                            ".",
                            " It",
                            "'s",
                            " a",
                            " little",
                            " more",
                            " forg",
                            "ivable",
                            ",",
                            " seeing",
                            " as",
                            " how",
                            " the",
                            " only",
                            " thing",
                            " to",
                            " do",
                            " in",
                            " Kentucky",
                            " just",
                            " began",
                            " the",
                            " offseason",
                            " (",
                            "Plus",
                            ",",
                            " they",
                            " just",
                            " got",
                            " this",
                            " riot",
                            " done",
                            " out",
                            " of",
                            " the",
                            " way",
                            " two",
                            " days",
                            " early",
                            ").",
                            " Had",
                            " they",
                            " won",
                            " the",
                            " National",
                            " Championship",
                            " tomorrow",
                            " night",
                            ",",
                            " there",
                            " would",
                            "'ve",
                            " been",
                            " a",
                            " celebr",
                            "atory",
                            " riot",
                            " instead",
                            " of",
                            " a",
                            " riot",
                            " fueled",
                            " by",
                            " frustration",
                            ".",
                            " Property",
                            " damage",
                            "-",
                            "wise",
                            " we",
                            " doubt",
                            " there",
                            "'d",
                            " be",
                            " a",
                            " difference",
                            ".",
                            " After",
                            " all",
                            " was",
                            " said",
                            " and",
                            " done",
                            " 31",
                            " people",
                            " were",
                            " arrested",
                            ".",
                            " Any",
                            "where",
                            ",",
                            " here",
                            "'s",
                            " some",
                            " pictures",
                            ":",
                            "\n",
                            "\n",
                            "Officers",
                            " with",
                            " protective",
                            " shields",
                            " line",
                            " the",
                            " ends",
                            " of",
                            " State",
                            " Street",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "2",
                            "t",
                            "XT",
                            "f",
                            "T",
                            "1",
                            "W"
                        ],
                        "dataIndex": null,
                        "index": "4530",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.751,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.751,
                            4.127,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:50:29.697Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.751,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm7lr04awbi666xdv6m8eb",
                        "tokens": [
                            " him",
                            " despise",
                            " it",
                            ".",
                            " Plus",
                            ",",
                            " the",
                            " ending",
                            " felt",
                            " like",
                            " there",
                            " is",
                            " a",
                            " lot",
                            " more",
                            " to",
                            " be",
                            " explored",
                            ",",
                            " leaving",
                            " open",
                            " the",
                            " possibility",
                            " of",
                            " a",
                            " sequel",
                            " but",
                            " tying",
                            " it",
                            " up",
                            " nicely",
                            " if",
                            " id",
                            " never",
                            " make",
                            " one",
                            ".",
                            "\n",
                            "\n",
                            "Unlike",
                            " most",
                            " shooters",
                            " the",
                            " past",
                            " few",
                            " years",
                            ",",
                            " this",
                            " isn",
                            "'t",
                            " focused",
                            " around",
                            " aiming",
                            " and",
                            " cover",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " you",
                            "'re",
                            " \u00e2\u013b",
                            "\u00a5",
                            "\u00e2\u013b\u00a5",
                            "\u00e2\u013b\u00a5",
                            "\u00e2\u013b\u00a5",
                            "ed",
                            " if",
                            " you",
                            " do",
                            " any",
                            " of",
                            " those",
                            " things",
                            ".",
                            " This",
                            " game",
                            " is",
                            " heavily",
                            " based",
                            " around",
                            " mobility",
                            ",",
                            " much",
                            " like",
                            " the",
                            " original",
                            " games",
                            ",",
                            " and",
                            " you",
                            " need",
                            " to",
                            " stay",
                            " on",
                            " the",
                            " move",
                            " in",
                            " order",
                            " to",
                            " survive",
                            ".",
                            " The",
                            " levels",
                            " were",
                            " made",
                            " to",
                            " fit",
                            " this",
                            " kind",
                            " of",
                            " movement",
                            ",",
                            " with",
                            " battles",
                            " happening",
                            " mainly",
                            " in",
                            " arena",
                            "-",
                            "like",
                            " zones",
                            " with",
                            " ample",
                            " space",
                            " and",
                            " vertical"
                        ],
                        "dataIndex": null,
                        "index": "4530",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.156,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            44.156,
                            1.142,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:50:29.697Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.751,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm7lr14awvi666f1rb0h3o",
                        "tokens": [
                            " him",
                            " despise",
                            " it",
                            ".",
                            " Plus",
                            ",",
                            " the",
                            " ending",
                            " felt",
                            " like",
                            " there",
                            " is",
                            " a",
                            " lot",
                            " more",
                            " to",
                            " be",
                            " explored",
                            ",",
                            " leaving",
                            " open",
                            " the",
                            " possibility",
                            " of",
                            " a",
                            " sequel",
                            " but",
                            " tying",
                            " it",
                            " up",
                            " nicely",
                            " if",
                            " id",
                            " never",
                            " make",
                            " one",
                            ".",
                            "\n",
                            "\n",
                            "Unlike",
                            " most",
                            " shooters",
                            " the",
                            " past",
                            " few",
                            " years",
                            ",",
                            " this",
                            " isn",
                            "'t",
                            " focused",
                            " around",
                            " aiming",
                            " and",
                            " cover",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " you",
                            "'re",
                            " \u00e2\u013b",
                            "\u00a5",
                            "\u00e2\u013b\u00a5",
                            "\u00e2\u013b\u00a5",
                            "\u00e2\u013b\u00a5",
                            "ed",
                            " if",
                            " you",
                            " do",
                            " any",
                            " of",
                            " those",
                            " things",
                            ".",
                            " This",
                            " game",
                            " is",
                            " heavily",
                            " based",
                            " around",
                            " mobility",
                            ",",
                            " much",
                            " like",
                            " the",
                            " original",
                            " games",
                            ",",
                            " and",
                            " you",
                            " need",
                            " to",
                            " stay",
                            " on",
                            " the",
                            " move",
                            " in",
                            " order",
                            " to",
                            " survive",
                            ".",
                            " The",
                            " levels",
                            " were",
                            " made",
                            " to",
                            " fit",
                            " this",
                            " kind",
                            " of",
                            " movement",
                            ",",
                            " with",
                            " battles",
                            " happening",
                            " mainly",
                            " in",
                            " arena",
                            "-",
                            "like",
                            " zones",
                            " with",
                            " ample",
                            " space",
                            " and",
                            " vertical"
                        ],
                        "dataIndex": null,
                        "index": "4530",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.156,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            44.156,
                            1.142,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:50:29.697Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 35.801,
                        "binMax": 44.751,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}