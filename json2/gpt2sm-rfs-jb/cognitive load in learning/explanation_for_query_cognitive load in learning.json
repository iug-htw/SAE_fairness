{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "cognitive load in learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73219",
            "description": " references to working memory tasks or concepts related to cognitive load",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5240930573773886,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73219",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 49.797,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73219,
                    73867,
                    25071,
                    29205,
                    96122,
                    86046,
                    67847,
                    91017,
                    3882,
                    85905,
                    72735,
                    76201,
                    66729,
                    46431,
                    88755,
                    34805,
                    65275,
                    63107,
                    9739,
                    63785,
                    6800,
                    81746,
                    22932,
                    77298,
                    44110
                ],
                "topkCosSimValues": [
                    1,
                    0.4843,
                    0.4402,
                    0.4248,
                    0.4246,
                    0.4228,
                    0.4176,
                    0.416,
                    0.4144,
                    0.4133,
                    0.4109,
                    0.4108,
                    0.4004,
                    0.3769,
                    0.3736,
                    0.373,
                    0.3668,
                    0.3614,
                    0.3576,
                    0.3575,
                    0.3535,
                    0.3534,
                    0.3489,
                    0.3487,
                    0.3485
                ],
                "neuron_alignment_indices": [
                    62,
                    99,
                    578
                ],
                "neuron_alignment_values": [
                    0.142,
                    0.108,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    62,
                    343,
                    578
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.007,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.007,
                    0.006
                ],
                "correlated_features_indices": [
                    73190,
                    73231,
                    73219
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "arial",
                    "idates",
                    "rule",
                    "rogens",
                    "abad",
                    "dated",
                    " Enrique",
                    " communist",
                    " Rica",
                    "inals"
                ],
                "neg_values": [
                    -0.71,
                    -0.694,
                    -0.683,
                    -0.668,
                    -0.668,
                    -0.663,
                    -0.642,
                    -0.635,
                    -0.634,
                    -0.629
                ],
                "pos_str": [
                    "ATA",
                    "FG",
                    "achine",
                    "restling",
                    "ICH",
                    "FS",
                    "NT",
                    "ting",
                    "HC",
                    "ITT"
                ],
                "pos_values": [
                    0.934,
                    0.902,
                    0.896,
                    0.822,
                    0.821,
                    0.807,
                    0.802,
                    0.789,
                    0.773,
                    0.734
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    10,
                    10,
                    2,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    1,
                    2,
                    2,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.594,
                    1.588,
                    2.582,
                    3.576,
                    4.57,
                    5.564,
                    6.558,
                    7.552,
                    8.546,
                    9.54,
                    10.534,
                    11.528,
                    12.522,
                    13.516,
                    14.51,
                    15.504,
                    16.498,
                    17.492,
                    18.486,
                    19.48,
                    20.474,
                    21.468,
                    22.462,
                    23.456,
                    24.45,
                    25.444,
                    26.438,
                    27.432,
                    28.426,
                    29.42,
                    30.414,
                    31.408,
                    32.402,
                    33.396,
                    34.39,
                    35.384,
                    36.378,
                    37.372,
                    38.366,
                    39.36,
                    40.354,
                    41.348,
                    42.342,
                    43.336,
                    44.33,
                    45.324,
                    46.318,
                    47.312,
                    48.306,
                    49.3
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    5,
                    7,
                    19,
                    27,
                    49,
                    69,
                    128,
                    211,
                    310,
                    504,
                    728,
                    1010,
                    1419,
                    1928,
                    2370,
                    3043,
                    3536,
                    3850,
                    4029,
                    4272,
                    4000,
                    3691,
                    3229,
                    2665,
                    2192,
                    1841,
                    1359,
                    1028,
                    746,
                    566,
                    401,
                    281,
                    200,
                    154,
                    130,
                    73,
                    47,
                    38,
                    35,
                    18,
                    20,
                    14,
                    0,
                    3,
                    3,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.694,
                    -0.661,
                    -0.628,
                    -0.595,
                    -0.562,
                    -0.529,
                    -0.496,
                    -0.464,
                    -0.431,
                    -0.398,
                    -0.365,
                    -0.332,
                    -0.299,
                    -0.266,
                    -0.233,
                    -0.201,
                    -0.168,
                    -0.135,
                    -0.102,
                    -0.069,
                    -0.036,
                    -0.003,
                    0.03,
                    0.062,
                    0.095,
                    0.128,
                    0.161,
                    0.194,
                    0.227,
                    0.26,
                    0.293,
                    0.325,
                    0.358,
                    0.391,
                    0.424,
                    0.457,
                    0.49,
                    0.523,
                    0.556,
                    0.588,
                    0.621,
                    0.654,
                    0.687,
                    0.72,
                    0.753,
                    0.786,
                    0.819,
                    0.852,
                    0.884,
                    0.917
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to working memory tasks or concepts related to cognitive load",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to working memory (WM) and its associated tasks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to working memory tasks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8nd1uu1d10extbttuz0v",
                        "tokens": [
                            " on",
                            " a",
                            " white",
                            " background",
                            ".",
                            " In",
                            " Experiment",
                            " 3",
                            ",",
                            " color",
                            "ized",
                            " line",
                            " drawings",
                            " of",
                            " common",
                            " objects",
                            " were",
                            " used",
                            " (",
                            "Ross",
                            "ion",
                            " &",
                            " Pour",
                            "to",
                            "is",
                            ",",
                            " 2004",
                            ").",
                            " To",
                            " accommodate",
                            " the",
                            " sim",
                            "ultan",
                            "agn",
                            "os",
                            "ia",
                            " in",
                            " both",
                            " patients",
                            " and",
                            " the",
                            " fact",
                            " par",
                            "ietal",
                            " damage",
                            " slows",
                            " visual",
                            " processing",
                            " (",
                            "Pe",
                            "ers",
                            " et",
                            " al",
                            ".,",
                            " 2005",
                            "),",
                            " all",
                            " stimuli",
                            " in",
                            " all",
                            " experiments",
                            " were",
                            " presented",
                            " sequ",
                            "entially",
                            " at",
                            " the",
                            " center",
                            " of",
                            " the",
                            " monitor",
                            " at",
                            " the",
                            " rate",
                            " of",
                            " 1000",
                            " ms",
                            "/",
                            "item",
                            ".",
                            " Per",
                            "cept",
                            "ual",
                            " Control",
                            " T",
                            "asks",
                            " To",
                            " insure",
                            " that",
                            " EE",
                            "555",
                            " and",
                            " T",
                            "Q",
                            "591",
                            "could",
                            " accurately",
                            " perceive",
                            " the",
                            " stimuli",
                            " that",
                            " were",
                            " used",
                            " in",
                            " the",
                            " WM",
                            " tasks",
                            ",",
                            " two",
                            " perceptual",
                            " control",
                            " tasks",
                            " were",
                            " administered",
                            ".",
                            " (",
                            "1",
                            ")",
                            " Perception",
                            " of",
                            " tools",
                            ".",
                            " Thirty",
                            "-",
                            "six",
                            " gr",
                            "ays"
                        ],
                        "dataIndex": null,
                        "index": "73219",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.797,
                        "maxValueTokenIndex": 105,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.797,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:20.820Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 49.797,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8nd1uu1e10exge7smav8",
                        "tokens": [
                            " the",
                            " tool",
                            " condition",
                            " and",
                            " lowest",
                            " in",
                            " the",
                            " novel",
                            " shape",
                            " condition",
                            ".",
                            " However",
                            ",",
                            " deficits",
                            " were",
                            " observed",
                            " to",
                            " a",
                            " similar",
                            " degree",
                            " for",
                            " all",
                            " three",
                            " stimulus",
                            " types",
                            ",",
                            " suggesting",
                            " that",
                            " the",
                            " WM",
                            " deficit",
                            " exists",
                            " when",
                            " a",
                            " verbal",
                            " strategy",
                            " could",
                            " be",
                            " employed",
                            " for",
                            " name",
                            "able",
                            " items",
                            ",",
                            " such",
                            " as",
                            " tools",
                            ",",
                            " and",
                            " even",
                            " when",
                            " such",
                            " a",
                            " strategy",
                            " would",
                            " be",
                            " challenging",
                            ",",
                            " such",
                            " as",
                            " with",
                            " the",
                            " novel",
                            " shape",
                            " stimuli",
                            ".",
                            "\n",
                            "\n",
                            "Exper",
                            "iments",
                            " 1",
                            "a",
                            "\u2013",
                            "2",
                            "b",
                            ":",
                            " Combined",
                            " An",
                            "alyses",
                            " To",
                            " directly",
                            " compare",
                            " patient",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " performance",
                            " on",
                            " the",
                            " recall",
                            " and",
                            " recognition",
                            " tasks",
                            ",",
                            " their",
                            " performance",
                            " was",
                            " converted",
                            " into",
                            " z",
                            "-",
                            "sc",
                            "ores",
                            " and",
                            " t",
                            "-",
                            "tests",
                            " were",
                            " performed",
                            " (",
                            "see",
                            " ).",
                            " This",
                            " showed",
                            " that",
                            " only",
                            " the",
                            " recognition",
                            " scores",
                            " differed",
                            " from",
                            " that",
                            " of",
                            " the",
                            " controls",
                            " (",
                            "t"
                        ],
                        "dataIndex": null,
                        "index": "73219",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.632,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.632,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:20.820Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 49.797,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8nd3uu2110exqy8rbf6u",
                        "tokens": [
                            " the",
                            " tool",
                            " condition",
                            " and",
                            " lowest",
                            " in",
                            " the",
                            " novel",
                            " shape",
                            " condition",
                            ".",
                            " However",
                            ",",
                            " deficits",
                            " were",
                            " observed",
                            " to",
                            " a",
                            " similar",
                            " degree",
                            " for",
                            " all",
                            " three",
                            " stimulus",
                            " types",
                            ",",
                            " suggesting",
                            " that",
                            " the",
                            " WM",
                            " deficit",
                            " exists",
                            " when",
                            " a",
                            " verbal",
                            " strategy",
                            " could",
                            " be",
                            " employed",
                            " for",
                            " name",
                            "able",
                            " items",
                            ",",
                            " such",
                            " as",
                            " tools",
                            ",",
                            " and",
                            " even",
                            " when",
                            " such",
                            " a",
                            " strategy",
                            " would",
                            " be",
                            " challenging",
                            ",",
                            " such",
                            " as",
                            " with",
                            " the",
                            " novel",
                            " shape",
                            " stimuli",
                            ".",
                            "\n",
                            "\n",
                            "Exper",
                            "iments",
                            " 1",
                            "a",
                            "\u2013",
                            "2",
                            "b",
                            ":",
                            " Combined",
                            " An",
                            "alyses",
                            " To",
                            " directly",
                            " compare",
                            " patient",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " performance",
                            " on",
                            " the",
                            " recall",
                            " and",
                            " recognition",
                            " tasks",
                            ",",
                            " their",
                            " performance",
                            " was",
                            " converted",
                            " into",
                            " z",
                            "-",
                            "sc",
                            "ores",
                            " and",
                            " t",
                            "-",
                            "tests",
                            " were",
                            " performed",
                            " (",
                            "see",
                            " ).",
                            " This",
                            " showed",
                            " that",
                            " only",
                            " the",
                            " recognition",
                            " scores",
                            " differed",
                            " from",
                            " that",
                            " of",
                            " the",
                            " controls",
                            " (",
                            "t"
                        ],
                        "dataIndex": null,
                        "index": "73219",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.632,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.632,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:20.820Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 39.838,
                        "binMax": 49.797,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "39353",
            "description": "terms related to cognitive ability and educational outcomes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4824520987386468,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "39353",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:21:03.354Z",
                "maxActApprox": 20.933,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39353,
                    31120,
                    7838,
                    92511,
                    59340,
                    12529,
                    40048,
                    36119,
                    90564,
                    96487,
                    76359,
                    40565,
                    91915,
                    72014,
                    74627,
                    6064,
                    50714,
                    77685,
                    59403,
                    55096,
                    58361,
                    78790,
                    96010,
                    73189,
                    31904
                ],
                "topkCosSimValues": [
                    1,
                    0.5429,
                    0.5287,
                    0.4944,
                    0.4842,
                    0.4795,
                    0.4681,
                    0.4644,
                    0.4413,
                    0.4375,
                    0.4324,
                    0.426,
                    0.4246,
                    0.4003,
                    0.3983,
                    0.3903,
                    0.3897,
                    0.3878,
                    0.3865,
                    0.3831,
                    0.3801,
                    0.3793,
                    0.3789,
                    0.3729,
                    0.3716
                ],
                "neuron_alignment_indices": [
                    481,
                    294,
                    415
                ],
                "neuron_alignment_values": [
                    0.213,
                    0.113,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.01,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    724,
                    575,
                    439
                ],
                "correlated_neurons_pearson": [
                    0.04,
                    0.038,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.045,
                    0.043,
                    0.036
                ],
                "correlated_features_indices": [
                    39262,
                    39280,
                    39247
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "Lens",
                    " pus",
                    "SN",
                    "operator",
                    "selage",
                    "Ly",
                    "\u00a3\u0131",
                    " Canaver",
                    "pard",
                    " Galile"
                ],
                "neg_values": [
                    -0.741,
                    -0.695,
                    -0.681,
                    -0.665,
                    -0.657,
                    -0.633,
                    -0.633,
                    -0.606,
                    -0.604,
                    -0.602
                ],
                "pos_str": [
                    " outcomes",
                    " traits",
                    " attainment",
                    " deterior",
                    "thood",
                    " indicators",
                    " correlates",
                    " impairment",
                    " wellbeing",
                    " indices"
                ],
                "pos_values": [
                    0.998,
                    0.904,
                    0.894,
                    0.89,
                    0.861,
                    0.857,
                    0.851,
                    0.832,
                    0.805,
                    0.8
                ],
                "frac_nonzero": 0.00086,
                "freq_hist_data_bar_heights": [
                    448,
                    332,
                    237,
                    225,
                    188,
                    162,
                    136,
                    118,
                    107,
                    106,
                    90,
                    75,
                    58,
                    61,
                    53,
                    39,
                    49,
                    33,
                    31,
                    22,
                    17,
                    16,
                    13,
                    11,
                    7,
                    13,
                    5,
                    5,
                    10,
                    3,
                    2,
                    2,
                    2,
                    3,
                    3,
                    0,
                    1,
                    2,
                    2,
                    0,
                    1,
                    3,
                    3,
                    1,
                    0,
                    0,
                    1,
                    2,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.21,
                    0.629,
                    1.048,
                    1.466,
                    1.885,
                    2.303,
                    2.722,
                    3.141,
                    3.559,
                    3.978,
                    4.397,
                    4.815,
                    5.234,
                    5.652,
                    6.071,
                    6.49,
                    6.908,
                    7.327,
                    7.746,
                    8.164,
                    8.583,
                    9.002,
                    9.42,
                    9.839,
                    10.257,
                    10.676,
                    11.095,
                    11.513,
                    11.932,
                    12.351,
                    12.769,
                    13.188,
                    13.607,
                    14.025,
                    14.444,
                    14.862,
                    15.281,
                    15.7,
                    16.118,
                    16.537,
                    16.956,
                    17.374,
                    17.793,
                    18.211,
                    18.63,
                    19.049,
                    19.467,
                    19.886,
                    20.305,
                    20.723
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    2,
                    4,
                    13,
                    22,
                    35,
                    57,
                    130,
                    210,
                    360,
                    542,
                    754,
                    1087,
                    1605,
                    2080,
                    2618,
                    3125,
                    3656,
                    4007,
                    4158,
                    4140,
                    4012,
                    3626,
                    3169,
                    2627,
                    2079,
                    1653,
                    1281,
                    906,
                    664,
                    450,
                    355,
                    238,
                    184,
                    103,
                    90,
                    64,
                    50,
                    28,
                    30,
                    12,
                    11,
                    4,
                    5,
                    3,
                    2,
                    2,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.724,
                    -0.689,
                    -0.654,
                    -0.619,
                    -0.585,
                    -0.55,
                    -0.515,
                    -0.48,
                    -0.446,
                    -0.411,
                    -0.376,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.167,
                    -0.133,
                    -0.098,
                    -0.063,
                    -0.028,
                    0.007,
                    0.041,
                    0.076,
                    0.111,
                    0.146,
                    0.18,
                    0.215,
                    0.25,
                    0.285,
                    0.32,
                    0.354,
                    0.389,
                    0.424,
                    0.459,
                    0.493,
                    0.528,
                    0.563,
                    0.598,
                    0.633,
                    0.667,
                    0.702,
                    0.737,
                    0.772,
                    0.806,
                    0.841,
                    0.876,
                    0.911,
                    0.946,
                    0.98
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cognitive ability and educational outcomes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggrota540g10ex62q86xfa",
                        "tokens": [
                            " black",
                            "-",
                            "white",
                            " IQ",
                            " gap",
                            " to",
                            " be",
                            " her",
                            "itable",
                            " by",
                            " 47",
                            "%",
                            " and",
                            " 50",
                            "%",
                            " respectively",
                            " among",
                            " surveyed",
                            " scientists",
                            " who",
                            " believed",
                            " that",
                            " the",
                            " available",
                            " evidence",
                            " allowed",
                            " for",
                            " a",
                            " reasonable",
                            " estimate",
                            ".",
                            " This",
                            " survey",
                            " however",
                            " yielded",
                            " a",
                            " response",
                            " rate",
                            " of",
                            " 18",
                            "%",
                            " (",
                            "228",
                            " participants",
                            ")",
                            " compared",
                            " to",
                            " Snyder",
                            "man",
                            " &",
                            " Roth",
                            "man",
                            "'s",
                            " 65",
                            "%",
                            " (",
                            "661",
                            " participants",
                            ").[",
                            "164",
                            "]",
                            "\n",
                            "\n",
                            "Spe",
                            "ar",
                            "man",
                            "'s",
                            " hypothesis",
                            "\n",
                            "\n",
                            "Spe",
                            "ar",
                            "man",
                            "'s",
                            " hypothesis",
                            " states",
                            " that",
                            " the",
                            " magnitude",
                            " of",
                            " the",
                            " black",
                            "-",
                            "white",
                            " difference",
                            " in",
                            " tests",
                            " of",
                            " cognitive",
                            " ability",
                            " is",
                            " entirely",
                            " or",
                            " mainly",
                            " a",
                            " function",
                            " of",
                            " the",
                            " extent",
                            " to",
                            " which",
                            " a",
                            " test",
                            " measures",
                            " general",
                            " mental",
                            " ability",
                            ",",
                            " or",
                            " g",
                            ".",
                            " The",
                            " hypothesis",
                            " was",
                            " first",
                            " formal",
                            "ized",
                            " by",
                            " Arthur",
                            " Jensen",
                            " who",
                            " devised",
                            " the",
                            " statistical",
                            " Method",
                            " of",
                            " Cor"
                        ],
                        "dataIndex": null,
                        "index": "39353",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.933,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0.93,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.38,
                            20.933,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.559,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:09.961Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 20.933,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrota540h10exeh2m3w5i",
                        "tokens": [
                            " in",
                            " intelligence",
                            " test",
                            " scores",
                            " are",
                            " caused",
                            " by",
                            " her",
                            "itable",
                            " factors",
                            " or",
                            " by",
                            " \"",
                            "other",
                            " correlated",
                            " demographic",
                            " variables",
                            " such",
                            " as",
                            " socioeconomic",
                            " status",
                            ",",
                            " education",
                            " level",
                            ",",
                            " and",
                            " motivation",
                            ".\"[",
                            "45",
                            "]",
                            " Hunt",
                            " and",
                            " Carlson",
                            " outlined",
                            " four",
                            " contemporary",
                            " positions",
                            " on",
                            " differences",
                            " in",
                            " IQ",
                            " based",
                            " on",
                            " race",
                            " or",
                            " ethnicity",
                            ".",
                            " The",
                            " first",
                            " is",
                            " that",
                            " these",
                            " reflect",
                            " real",
                            " differences",
                            " in",
                            " average",
                            " group",
                            " intelligence",
                            ",",
                            " which",
                            " is",
                            " caused",
                            " by",
                            " a",
                            " combination",
                            " of",
                            " environmental",
                            " factors",
                            " and",
                            " her",
                            "itable",
                            " differences",
                            " in",
                            " brain",
                            " function",
                            ".",
                            " A",
                            " second",
                            " position",
                            " is",
                            " that",
                            " differences",
                            " in",
                            " average",
                            " cognitive",
                            " ability",
                            " between",
                            " races",
                            " are",
                            " caused",
                            " entirely",
                            " by",
                            " social",
                            " and",
                            "/",
                            "or",
                            " environmental",
                            " factors",
                            ".",
                            " A",
                            " third",
                            " position",
                            " holds",
                            " that",
                            " differences",
                            " in",
                            " average",
                            " cognitive",
                            " ability",
                            " between",
                            " races",
                            " do",
                            " not",
                            " exist",
                            ",",
                            " and",
                            " that",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " test",
                            " scores",
                            " are",
                            " the",
                            " result"
                        ],
                        "dataIndex": null,
                        "index": "39353",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.616,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            7.806,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.02,
                            0,
                            0.393,
                            4.073,
                            0,
                            0,
                            3.685,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.23,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.72,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.006,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.695,
                            20.616,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.41,
                            16.326,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.611,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:09.961Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 20.933,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggrotb540u10ex0sleazr8",
                        "tokens": [
                            " in",
                            " intelligence",
                            " test",
                            " scores",
                            " are",
                            " caused",
                            " by",
                            " her",
                            "itable",
                            " factors",
                            " or",
                            " by",
                            " \"",
                            "other",
                            " correlated",
                            " demographic",
                            " variables",
                            " such",
                            " as",
                            " socioeconomic",
                            " status",
                            ",",
                            " education",
                            " level",
                            ",",
                            " and",
                            " motivation",
                            ".\"[",
                            "45",
                            "]",
                            " Hunt",
                            " and",
                            " Carlson",
                            " outlined",
                            " four",
                            " contemporary",
                            " positions",
                            " on",
                            " differences",
                            " in",
                            " IQ",
                            " based",
                            " on",
                            " race",
                            " or",
                            " ethnicity",
                            ".",
                            " The",
                            " first",
                            " is",
                            " that",
                            " these",
                            " reflect",
                            " real",
                            " differences",
                            " in",
                            " average",
                            " group",
                            " intelligence",
                            ",",
                            " which",
                            " is",
                            " caused",
                            " by",
                            " a",
                            " combination",
                            " of",
                            " environmental",
                            " factors",
                            " and",
                            " her",
                            "itable",
                            " differences",
                            " in",
                            " brain",
                            " function",
                            ".",
                            " A",
                            " second",
                            " position",
                            " is",
                            " that",
                            " differences",
                            " in",
                            " average",
                            " cognitive",
                            " ability",
                            " between",
                            " races",
                            " are",
                            " caused",
                            " entirely",
                            " by",
                            " social",
                            " and",
                            "/",
                            "or",
                            " environmental",
                            " factors",
                            ".",
                            " A",
                            " third",
                            " position",
                            " holds",
                            " that",
                            " differences",
                            " in",
                            " average",
                            " cognitive",
                            " ability",
                            " between",
                            " races",
                            " do",
                            " not",
                            " exist",
                            ",",
                            " and",
                            " that",
                            " the",
                            " differences",
                            " in",
                            " average",
                            " test",
                            " scores",
                            " are",
                            " the",
                            " result"
                        ],
                        "dataIndex": null,
                        "index": "39353",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.616,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            7.806,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.02,
                            0,
                            0.393,
                            4.073,
                            0,
                            0,
                            3.685,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.23,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.72,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.006,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.695,
                            20.616,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.41,
                            16.326,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.611,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:09.961Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 20.933,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "21306",
            "description": "questions about understanding or learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47529346045333964,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "21306",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:55:08.250Z",
                "maxActApprox": 46.771,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21306,
                    11,
                    59028,
                    24863,
                    97707,
                    62741,
                    63520,
                    60147,
                    38758,
                    90284,
                    2430,
                    23492,
                    5418,
                    42965,
                    29326,
                    29674,
                    5228,
                    58522,
                    2086,
                    15009,
                    78040,
                    23145,
                    69877,
                    2372,
                    81898
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7336,
                    0.6773,
                    0.6355,
                    0.6096,
                    0.608,
                    0.606,
                    0.5991,
                    0.5956,
                    0.5951,
                    0.5894,
                    0.5793,
                    0.5581,
                    0.5506,
                    0.5474,
                    0.5369,
                    0.5271,
                    0.5197,
                    0.4772,
                    0.4568,
                    0.4391,
                    0.4388,
                    0.3822,
                    0.3546
                ],
                "neuron_alignment_indices": [
                    243,
                    373,
                    350
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.095,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    243,
                    60,
                    350
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.019,
                    0.019
                ],
                "correlated_features_indices": [
                    21352,
                    21266,
                    21244
                ],
                "correlated_features_pearson": [
                    0.011,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.012,
                    0,
                    0
                ],
                "neg_str": [
                    "phant",
                    "UA",
                    "iture",
                    "hammad",
                    "anship",
                    "aber",
                    " Issue",
                    "reporting",
                    "aredevil",
                    "idered"
                ],
                "neg_values": [
                    -0.701,
                    -0.654,
                    -0.627,
                    -0.615,
                    -0.612,
                    -0.591,
                    -0.585,
                    -0.584,
                    -0.583,
                    -0.582
                ],
                "pos_str": [
                    " lucky",
                    "ls",
                    " much",
                    " messed",
                    "beit",
                    " hard",
                    "itzer",
                    " thankful",
                    " frustrating",
                    " grateful"
                ],
                "pos_values": [
                    0.765,
                    0.753,
                    0.752,
                    0.747,
                    0.736,
                    0.715,
                    0.71,
                    0.709,
                    0.694,
                    0.694
                ],
                "frac_nonzero": 0.0002,
                "freq_hist_data_bar_heights": [
                    104,
                    77,
                    59,
                    45,
                    42,
                    38,
                    30,
                    28,
                    19,
                    23,
                    13,
                    8,
                    17,
                    13,
                    12,
                    7,
                    7,
                    9,
                    4,
                    2,
                    2,
                    3,
                    6,
                    3,
                    3,
                    1,
                    2,
                    0,
                    2,
                    2,
                    2,
                    0,
                    3,
                    3,
                    3,
                    5,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.48,
                    1.415,
                    2.351,
                    3.286,
                    4.221,
                    5.156,
                    6.091,
                    7.026,
                    7.962,
                    8.897,
                    9.832,
                    10.767,
                    11.702,
                    12.637,
                    13.573,
                    14.508,
                    15.443,
                    16.378,
                    17.313,
                    18.248,
                    19.184,
                    20.119,
                    21.054,
                    21.989,
                    22.924,
                    23.859,
                    24.795,
                    25.73,
                    26.665,
                    27.6,
                    28.535,
                    29.47,
                    30.406,
                    31.341,
                    32.276,
                    33.211,
                    34.146,
                    35.081,
                    36.017,
                    36.952,
                    37.887,
                    38.822,
                    39.757,
                    40.692,
                    41.628,
                    42.563,
                    43.498,
                    44.433,
                    45.368,
                    46.303
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    4,
                    7,
                    19,
                    21,
                    28,
                    70,
                    109,
                    155,
                    248,
                    378,
                    484,
                    743,
                    1087,
                    1356,
                    1818,
                    2190,
                    2719,
                    3255,
                    3665,
                    3743,
                    3945,
                    3934,
                    3657,
                    3266,
                    2861,
                    2350,
                    1925,
                    1529,
                    1195,
                    882,
                    680,
                    493,
                    380,
                    291,
                    222,
                    148,
                    132,
                    99,
                    67,
                    32,
                    23,
                    16,
                    13,
                    4,
                    2,
                    3,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.686,
                    -0.657,
                    -0.628,
                    -0.598,
                    -0.569,
                    -0.54,
                    -0.51,
                    -0.481,
                    -0.452,
                    -0.422,
                    -0.393,
                    -0.364,
                    -0.334,
                    -0.305,
                    -0.276,
                    -0.247,
                    -0.217,
                    -0.188,
                    -0.159,
                    -0.129,
                    -0.1,
                    -0.071,
                    -0.041,
                    -0.012,
                    0.017,
                    0.047,
                    0.076,
                    0.105,
                    0.135,
                    0.164,
                    0.193,
                    0.223,
                    0.252,
                    0.281,
                    0.311,
                    0.34,
                    0.369,
                    0.399,
                    0.428,
                    0.457,
                    0.486,
                    0.516,
                    0.545,
                    0.574,
                    0.604,
                    0.633,
                    0.662,
                    0.692,
                    0.721,
                    0.75
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions about understanding or learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfubx4rgf010exsjeyoxom",
                        "tokens": [
                            " President",
                            " Enrique",
                            " Pe",
                            "\u00c3\u00b1a",
                            " Nieto",
                            " on",
                            " Jan",
                            ".",
                            " 27",
                            ",",
                            " according",
                            " to",
                            " a",
                            " transcript",
                            " published",
                            " Thursday",
                            " by",
                            " The",
                            " Washington",
                            " Post",
                            ".",
                            "\n",
                            "\n",
                            "[",
                            "Trump",
                            " urged",
                            " Mexican",
                            " president",
                            " to",
                            " end",
                            " his",
                            " public",
                            " defiance",
                            " on",
                            " border",
                            " wall",
                            ",",
                            " transcript",
                            " reveals",
                            "]",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Listen",
                            ",",
                            " I",
                            " know",
                            " how",
                            " tough",
                            " these",
                            " guys",
                            " are",
                            " \u2014",
                            " our",
                            " military",
                            " will",
                            " knock",
                            " them",
                            " out",
                            " like",
                            " you",
                            " never",
                            " thought",
                            " of",
                            ",",
                            " we",
                            " will",
                            " work",
                            " to",
                            " help",
                            " you",
                            " knock",
                            " them",
                            " out",
                            " because",
                            " your",
                            " country",
                            " does",
                            " not",
                            " want",
                            " that",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Trump",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " can",
                            " Trump",
                            " actually",
                            " do",
                            " that",
                            "?",
                            "\n",
                            "\n",
                            "Republican",
                            " presidential",
                            " nominee",
                            " Donald",
                            " Trump",
                            " discussed",
                            " border",
                            " security",
                            " at",
                            " the",
                            " third",
                            " and",
                            " final",
                            " presidential",
                            " debate",
                            ",",
                            " Oct",
                            ".",
                            " 19",
                            ",",
                            " in",
                            " Las",
                            " Vegas",
                            ".",
                            " (",
                            "The",
                            " Washington",
                            " Post"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.771,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.771,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx5rgf110ex2b7evkpk",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx7rgfm10exporrr5nf",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.417,
                        "binMax": 46.771,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12849",
            "description": "content related to educational psychology and learning experiences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46942162878255833,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12849",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:01:13.921Z",
                "maxActApprox": 49.117,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12849,
                    20008,
                    13240,
                    8581,
                    7804,
                    3969,
                    9365,
                    7187,
                    9709,
                    7511,
                    8895,
                    2951,
                    4849,
                    1353,
                    4375,
                    2878,
                    15591,
                    19680,
                    10990,
                    8921,
                    15005,
                    1833,
                    12980,
                    19318,
                    14797
                ],
                "topkCosSimValues": [
                    1,
                    0.7413,
                    0.5438,
                    0.4984,
                    0.4831,
                    0.4655,
                    0.4593,
                    0.4568,
                    0.4064,
                    0.3952,
                    0.3851,
                    0.3757,
                    0.3671,
                    0.3625,
                    0.3492,
                    0.3279,
                    0.3268,
                    0.322,
                    0.322,
                    0.3211,
                    0.319,
                    0.3172,
                    0.3168,
                    0.3154,
                    0.311
                ],
                "neuron_alignment_indices": [
                    271,
                    62,
                    575
                ],
                "neuron_alignment_values": [
                    0.16,
                    0.119,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.019,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.018,
                    0.015
                ],
                "correlated_features_indices": [
                    12860,
                    12818,
                    12899
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "zzi",
                    "pard",
                    "\u0124\u00aa",
                    "vati",
                    " Shipping",
                    "swick",
                    "senal",
                    "een",
                    " spraying",
                    "tar"
                ],
                "neg_values": [
                    -0.754,
                    -0.694,
                    -0.691,
                    -0.688,
                    -0.684,
                    -0.641,
                    -0.64,
                    -0.636,
                    -0.628,
                    -0.619
                ],
                "pos_str": [
                    " disabilities",
                    " Curve",
                    " curve",
                    " disability",
                    "icult",
                    " aids",
                    "learn",
                    " lessons",
                    " Clicker",
                    " disabled"
                ],
                "pos_values": [
                    1.068,
                    0.925,
                    0.915,
                    0.866,
                    0.768,
                    0.762,
                    0.754,
                    0.738,
                    0.737,
                    0.731
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    115,
                    76,
                    57,
                    36,
                    28,
                    20,
                    12,
                    15,
                    12,
                    11,
                    11,
                    9,
                    12,
                    8,
                    3,
                    5,
                    3,
                    4,
                    6,
                    4,
                    6,
                    13,
                    3,
                    2,
                    3,
                    3,
                    0,
                    4,
                    2,
                    3,
                    1,
                    3,
                    3,
                    3,
                    3,
                    1,
                    3,
                    6,
                    4,
                    1,
                    3,
                    5,
                    5,
                    0,
                    5,
                    1,
                    2,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.5,
                    1.483,
                    2.465,
                    3.447,
                    4.429,
                    5.411,
                    6.393,
                    7.376,
                    8.358,
                    9.34,
                    10.322,
                    11.304,
                    12.286,
                    13.268,
                    14.251,
                    15.233,
                    16.215,
                    17.197,
                    18.179,
                    19.161,
                    20.144,
                    21.126,
                    22.108,
                    23.09,
                    24.072,
                    25.054,
                    26.036,
                    27.019,
                    28.001,
                    28.983,
                    29.965,
                    30.947,
                    31.929,
                    32.912,
                    33.894,
                    34.876,
                    35.858,
                    36.84,
                    37.822,
                    38.804,
                    39.787,
                    40.769,
                    41.751,
                    42.733,
                    43.715,
                    44.697,
                    45.68,
                    46.662,
                    47.644,
                    48.626
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    0,
                    11,
                    21,
                    13,
                    37,
                    71,
                    116,
                    209,
                    346,
                    499,
                    780,
                    1207,
                    1642,
                    2322,
                    2971,
                    3658,
                    4074,
                    4494,
                    4561,
                    4454,
                    4010,
                    3528,
                    2942,
                    2309,
                    1782,
                    1323,
                    892,
                    664,
                    474,
                    313,
                    184,
                    107,
                    88,
                    50,
                    28,
                    24,
                    16,
                    15,
                    10,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.699,
                    -0.662,
                    -0.626,
                    -0.59,
                    -0.553,
                    -0.517,
                    -0.48,
                    -0.444,
                    -0.408,
                    -0.371,
                    -0.335,
                    -0.298,
                    -0.262,
                    -0.225,
                    -0.189,
                    -0.153,
                    -0.116,
                    -0.08,
                    -0.043,
                    -0.007,
                    0.03,
                    0.066,
                    0.102,
                    0.139,
                    0.175,
                    0.212,
                    0.248,
                    0.285,
                    0.321,
                    0.357,
                    0.394,
                    0.43,
                    0.467,
                    0.503,
                    0.539,
                    0.576,
                    0.612,
                    0.649,
                    0.685,
                    0.722,
                    0.758,
                    0.794,
                    0.831,
                    0.867,
                    0.904,
                    0.94,
                    0.977,
                    1.013,
                    1.049
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "content related to educational psychology and learning experiences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmlhmzc7l2i666fxbcpcsw",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhn0c7l6i666zbaenjoe",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhmzc7l3i66681yibbcr",
                        "tokens": [
                            " on",
                            " comparative",
                            " psychology",
                            " and",
                            " the",
                            " learning",
                            " process",
                            " led",
                            " to",
                            " the",
                            " theory",
                            " of",
                            " connection",
                            "ism",
                            " and",
                            " helped",
                            " lay",
                            " the",
                            " scientific",
                            " foundation",
                            " for",
                            " educational",
                            " psychology",
                            ".",
                            " He",
                            " also",
                            " worked",
                            " on",
                            " solving",
                            " industrial",
                            " problems",
                            ",",
                            " such",
                            " as",
                            " employee",
                            " exams",
                            " and",
                            " testing",
                            ".",
                            " He",
                            " was",
                            " a",
                            " member",
                            " of",
                            " the",
                            " board",
                            " of",
                            " the",
                            " Psychological",
                            " Corporation",
                            " and",
                            " served",
                            " as",
                            " president",
                            " of",
                            " the",
                            " American",
                            " Psychological",
                            " Association",
                            " in",
                            " 1912",
                            ".[",
                            "1",
                            "][",
                            "2",
                            "]",
                            " A",
                            " Review",
                            " of",
                            " General",
                            " Psychology",
                            " survey",
                            ",",
                            " published",
                            " in",
                            " 2002",
                            ",",
                            " ranked",
                            " Thor",
                            "nd",
                            "ike",
                            " as",
                            " the",
                            " ninth",
                            "-",
                            "most",
                            " cited",
                            " psychologist",
                            " of",
                            " the",
                            " 20",
                            "th",
                            " century",
                            ".[",
                            "3",
                            "]",
                            " Edward",
                            " Thor",
                            "nd",
                            "ike",
                            " had",
                            " a",
                            " powerful",
                            " impact",
                            " on",
                            " reinforcement",
                            " theory",
                            " and",
                            " behavior",
                            " analysis",
                            ",",
                            " providing",
                            " the",
                            " basic",
                            " framework",
                            " for",
                            " empirical",
                            " laws",
                            " in",
                            " behavior",
                            " psychology",
                            " with",
                            " his",
                            " law",
                            " of",
                            " effect",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.626,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.626,
                            2.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "89585",
            "description": " concepts related to memory and cognitive processing",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4590188338126846,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "89585",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:19:59.442Z",
                "maxActApprox": 16.098,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    89585,
                    75932,
                    45614,
                    40939,
                    11322,
                    31410,
                    62639,
                    54232,
                    36122,
                    51125,
                    90247,
                    30432,
                    39830,
                    37144,
                    89614,
                    25776,
                    67278,
                    80367,
                    90217,
                    84533,
                    41107,
                    38357,
                    60649,
                    28744,
                    32383
                ],
                "topkCosSimValues": [
                    1,
                    0.4682,
                    0.4153,
                    0.3723,
                    0.3691,
                    0.3682,
                    0.3626,
                    0.354,
                    0.3518,
                    0.3484,
                    0.3438,
                    0.3411,
                    0.3361,
                    0.3342,
                    0.3307,
                    0.3278,
                    0.3278,
                    0.3237,
                    0.3165,
                    0.3147,
                    0.3113,
                    0.3085,
                    0.3065,
                    0.3054,
                    0.3012
                ],
                "neuron_alignment_indices": [
                    568,
                    257,
                    336
                ],
                "neuron_alignment_values": [
                    0.12,
                    0.104,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    285,
                    384,
                    568
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.023,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    89614,
                    89632,
                    89631
                ],
                "correlated_features_pearson": [
                    0.119,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.12,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "!\",",
                    "iard",
                    "zai",
                    ")|",
                    " ILCS",
                    "BBC",
                    "Jet",
                    "agine",
                    ".\",",
                    "atti"
                ],
                "neg_values": [
                    -0.842,
                    -0.806,
                    -0.782,
                    -0.712,
                    -0.699,
                    -0.697,
                    -0.652,
                    -0.64,
                    -0.626,
                    -0.625
                ],
                "pos_str": [
                    " secondly",
                    " alternatively",
                    "mbuds",
                    " gradually",
                    " intangible",
                    " prag",
                    " progressives",
                    " indifference",
                    " pragmatic",
                    " Malone"
                ],
                "pos_values": [
                    0.886,
                    0.752,
                    0.692,
                    0.649,
                    0.643,
                    0.622,
                    0.618,
                    0.613,
                    0.605,
                    0.603
                ],
                "frac_nonzero": 0.00104,
                "freq_hist_data_bar_heights": [
                    669,
                    560,
                    385,
                    295,
                    255,
                    171,
                    164,
                    136,
                    81,
                    68,
                    77,
                    50,
                    47,
                    31,
                    39,
                    39,
                    32,
                    16,
                    16,
                    18,
                    19,
                    14,
                    14,
                    10,
                    10,
                    7,
                    7,
                    6,
                    4,
                    7,
                    5,
                    2,
                    5,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    3,
                    1,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.161,
                    0.483,
                    0.805,
                    1.127,
                    1.449,
                    1.771,
                    2.093,
                    2.415,
                    2.737,
                    3.059,
                    3.381,
                    3.703,
                    4.024,
                    4.346,
                    4.668,
                    4.99,
                    5.312,
                    5.634,
                    5.956,
                    6.278,
                    6.6,
                    6.922,
                    7.244,
                    7.566,
                    7.888,
                    8.21,
                    8.532,
                    8.854,
                    9.176,
                    9.498,
                    9.82,
                    10.142,
                    10.464,
                    10.786,
                    11.108,
                    11.429,
                    11.751,
                    12.073,
                    12.395,
                    12.717,
                    13.039,
                    13.361,
                    13.683,
                    14.005,
                    14.327,
                    14.649,
                    14.971,
                    15.293,
                    15.615,
                    15.937
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    0,
                    1,
                    2,
                    2,
                    13,
                    23,
                    26,
                    50,
                    86,
                    179,
                    239,
                    371,
                    543,
                    804,
                    1125,
                    1551,
                    2058,
                    2586,
                    3092,
                    3443,
                    3628,
                    3855,
                    4040,
                    3886,
                    3703,
                    3226,
                    2913,
                    2268,
                    1792,
                    1479,
                    1053,
                    781,
                    551,
                    370,
                    216,
                    143,
                    73,
                    33,
                    27,
                    15,
                    4,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.825,
                    -0.79,
                    -0.755,
                    -0.721,
                    -0.686,
                    -0.652,
                    -0.617,
                    -0.583,
                    -0.548,
                    -0.514,
                    -0.479,
                    -0.444,
                    -0.41,
                    -0.375,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.064,
                    -0.03,
                    0.005,
                    0.04,
                    0.074,
                    0.109,
                    0.143,
                    0.178,
                    0.212,
                    0.247,
                    0.281,
                    0.316,
                    0.351,
                    0.385,
                    0.42,
                    0.454,
                    0.489,
                    0.523,
                    0.558,
                    0.593,
                    0.627,
                    0.662,
                    0.696,
                    0.731,
                    0.765,
                    0.8,
                    0.834,
                    0.869
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases and discussions related to memory and cognitive functions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts related to memory and cognitive processing",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygivedy771e10exveiwt7ou",
                        "tokens": [
                            " a",
                            " few",
                            " minutes",
                            ",",
                            " but",
                            " not",
                            " in",
                            " a",
                            " few",
                            " days",
                            ".",
                            " That",
                            "'s",
                            " because",
                            " our",
                            " brains",
                            " handle",
                            " both",
                            " long",
                            "-",
                            "term",
                            " memory",
                            ",",
                            " which",
                            " enables",
                            " us",
                            " to",
                            " recall",
                            " events",
                            " from",
                            " the",
                            " distant",
                            " past",
                            ",",
                            " and",
                            " short",
                            "-",
                            "term",
                            " memory",
                            ",",
                            " also",
                            " called",
                            " working",
                            " memory",
                            ",",
                            " which",
                            " encompasses",
                            " the",
                            " most",
                            " transient",
                            ",",
                            " fleeting",
                            " memories",
                            ".",
                            "\n",
                            "\n",
                            "Research",
                            " in",
                            " mice",
                            " published",
                            " in",
                            " the",
                            " February",
                            " issue",
                            " of",
                            " the",
                            " journal",
                            " Nature",
                            " Neuroscience",
                            " found",
                            " that",
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " in",
                            " the",
                            " front",
                            " part",
                            " of",
                            " the",
                            " brain",
                            " can",
                            " hold",
                            " traces",
                            " of",
                            " memories",
                            " on",
                            " its",
                            " own",
                            " for",
                            " as",
                            " long",
                            " as",
                            " a",
                            " minute",
                            ",",
                            " possibly",
                            " even",
                            " longer",
                            ",",
                            " said",
                            " senior",
                            " author",
                            " Don",
                            " Cooper",
                            ",",
                            " assistant",
                            " professor",
                            " of",
                            " psychiatry",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Texas",
                            " South",
                            "western",
                            " Medical",
                            " Center",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " idea",
                            ",",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "89585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.098,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.278,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.896,
                            16.098,
                            5.738,
                            0,
                            0,
                            5.884,
                            1.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:20:02.292Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.098,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygivedy771f10exfos84w7c",
                        "tokens": [
                            " the",
                            " source",
                            ".",
                            " I",
                            " have",
                            " also",
                            " tried",
                            " hex",
                            "pat",
                            ",",
                            " tags",
                            "oup",
                            ",",
                            " H",
                            "XT",
                            ",",
                            " and",
                            " Ha",
                            "X",
                            "ML",
                            " X",
                            "t",
                            "ract",
                            ",",
                            " but",
                            " they",
                            " all",
                            " have",
                            " space",
                            " leaks",
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "X",
                            "Q",
                            " has",
                            " two",
                            " XML",
                            " pars",
                            "ers",
                            ":",
                            " one",
                            " that",
                            " generates",
                            " simple",
                            " rose",
                            " trees",
                            " from",
                            " XML",
                            " documents",
                            ",",
                            " which",
                            " can",
                            " be",
                            " processed",
                            " by",
                            " forward",
                            " queries",
                            " without",
                            " space",
                            " leaks",
                            ",",
                            " and",
                            " another",
                            " parser",
                            " where",
                            " each",
                            " tree",
                            " node",
                            " has",
                            " a",
                            " reference",
                            " to",
                            " its",
                            " parent",
                            ".",
                            " Some",
                            ",",
                            " but",
                            " not",
                            " all",
                            ",",
                            " backward",
                            " axis",
                            " steps",
                            " (",
                            "such",
                            " as",
                            " the",
                            " parent",
                            " axis",
                            " /",
                            "..",
                            ")",
                            " are",
                            " removed",
                            " from",
                            " a",
                            " query",
                            " using",
                            " optimization",
                            " rules",
                            ".",
                            " If",
                            " there",
                            " are",
                            " backward",
                            " axis",
                            " steps",
                            " left",
                            " in",
                            " the",
                            " query",
                            ",",
                            " then",
                            " H",
                            "X",
                            "Q",
                            " uses",
                            " the",
                            " latter",
                            " parser",
                            ",",
                            " which",
                            " may",
                            " result"
                        ],
                        "dataIndex": null,
                        "index": "89585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.563,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.882,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.45,
                            15.563,
                            6.534,
                            2.985,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:20:02.292Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.098,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygivee0771z10exuq2awae7",
                        "tokens": [
                            " the",
                            " source",
                            ".",
                            " I",
                            " have",
                            " also",
                            " tried",
                            " hex",
                            "pat",
                            ",",
                            " tags",
                            "oup",
                            ",",
                            " H",
                            "XT",
                            ",",
                            " and",
                            " Ha",
                            "X",
                            "ML",
                            " X",
                            "t",
                            "ract",
                            ",",
                            " but",
                            " they",
                            " all",
                            " have",
                            " space",
                            " leaks",
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "X",
                            "Q",
                            " has",
                            " two",
                            " XML",
                            " pars",
                            "ers",
                            ":",
                            " one",
                            " that",
                            " generates",
                            " simple",
                            " rose",
                            " trees",
                            " from",
                            " XML",
                            " documents",
                            ",",
                            " which",
                            " can",
                            " be",
                            " processed",
                            " by",
                            " forward",
                            " queries",
                            " without",
                            " space",
                            " leaks",
                            ",",
                            " and",
                            " another",
                            " parser",
                            " where",
                            " each",
                            " tree",
                            " node",
                            " has",
                            " a",
                            " reference",
                            " to",
                            " its",
                            " parent",
                            ".",
                            " Some",
                            ",",
                            " but",
                            " not",
                            " all",
                            ",",
                            " backward",
                            " axis",
                            " steps",
                            " (",
                            "such",
                            " as",
                            " the",
                            " parent",
                            " axis",
                            " /",
                            "..",
                            ")",
                            " are",
                            " removed",
                            " from",
                            " a",
                            " query",
                            " using",
                            " optimization",
                            " rules",
                            ".",
                            " If",
                            " there",
                            " are",
                            " backward",
                            " axis",
                            " steps",
                            " left",
                            " in",
                            " the",
                            " query",
                            ",",
                            " then",
                            " H",
                            "X",
                            "Q",
                            " uses",
                            " the",
                            " latter",
                            " parser",
                            ",",
                            " which",
                            " may",
                            " result"
                        ],
                        "dataIndex": null,
                        "index": "89585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.563,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.882,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.45,
                            15.563,
                            6.534,
                            2.985,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:20:02.292Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.878,
                        "binMax": 16.098,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "1457",
            "description": "academic or research-related content with a focus on brain functions, memory, study designs, and information processing",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.45227712677258225,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "1457",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:17:03.178Z",
                "maxActApprox": 31.156,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1457,
                    8007,
                    3563,
                    8264,
                    504,
                    5299,
                    10795,
                    6574,
                    6344,
                    11807,
                    6006,
                    12246,
                    7013,
                    8224,
                    8496,
                    2542,
                    7214,
                    10131,
                    10301,
                    4488,
                    5437,
                    8703,
                    2845,
                    10536,
                    6559
                ],
                "topkCosSimValues": [
                    1,
                    0.5443,
                    0.4983,
                    0.4628,
                    0.3971,
                    0.38,
                    0.3543,
                    0.3452,
                    0.3102,
                    0.3058,
                    0.2982,
                    0.2945,
                    0.2894,
                    0.2872,
                    0.2843,
                    0.2789,
                    0.2784,
                    0.2709,
                    0.2649,
                    0.2647,
                    0.264,
                    0.2544,
                    0.2454,
                    0.2441,
                    0.2429
                ],
                "neuron_alignment_indices": [
                    373,
                    423,
                    587
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.103,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    640,
                    174,
                    130
                ],
                "correlated_neurons_pearson": [
                    0.072,
                    0.044,
                    0.044
                ],
                "correlated_neurons_l1": [
                    0.081,
                    0.042,
                    0.033
                ],
                "correlated_features_indices": [
                    1502,
                    1416,
                    1455
                ],
                "correlated_features_pearson": [
                    0.012,
                    0.004,
                    0.002
                ],
                "correlated_features_l1": [
                    0.015,
                    0.005,
                    0.003
                ],
                "neg_str": [
                    " Armageddon",
                    " wont",
                    "iHUD",
                    "soDeliveryDate",
                    " creeps",
                    " lett",
                    " Tempest",
                    "terday",
                    "ById",
                    " rul"
                ],
                "neg_values": [
                    -0.725,
                    -0.704,
                    -0.683,
                    -0.681,
                    -0.643,
                    -0.641,
                    -0.636,
                    -0.634,
                    -0.633,
                    -0.618
                ],
                "pos_str": [
                    "Methods",
                    " Methods",
                    "Abstract",
                    " hypothesized",
                    "ivariate",
                    "Discussion",
                    "RESULTS",
                    "\u00f3",
                    "FIG",
                    " Comparison"
                ],
                "pos_values": [
                    1.056,
                    1.042,
                    1.011,
                    0.993,
                    0.991,
                    0.987,
                    0.979,
                    0.971,
                    0.968,
                    0.966
                ],
                "frac_nonzero": 0.0046,
                "freq_hist_data_bar_heights": [
                    3801,
                    2599,
                    1907,
                    1312,
                    928,
                    733,
                    486,
                    391,
                    319,
                    244,
                    229,
                    192,
                    157,
                    151,
                    102,
                    109,
                    72,
                    76,
                    67,
                    57,
                    54,
                    45,
                    42,
                    48,
                    32,
                    35,
                    41,
                    31,
                    34,
                    27,
                    26,
                    14,
                    21,
                    8,
                    16,
                    12,
                    16,
                    4,
                    7,
                    8,
                    3,
                    6,
                    3,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.312,
                    0.935,
                    1.558,
                    2.181,
                    2.804,
                    3.427,
                    4.05,
                    4.673,
                    5.296,
                    5.92,
                    6.543,
                    7.166,
                    7.789,
                    8.412,
                    9.035,
                    9.658,
                    10.281,
                    10.904,
                    11.528,
                    12.151,
                    12.774,
                    13.397,
                    14.02,
                    14.643,
                    15.266,
                    15.889,
                    16.512,
                    17.136,
                    17.759,
                    18.382,
                    19.005,
                    19.628,
                    20.251,
                    20.874,
                    21.497,
                    22.12,
                    22.744,
                    23.367,
                    23.99,
                    24.613,
                    25.236,
                    25.859,
                    26.482,
                    27.105,
                    27.728,
                    28.352,
                    28.975,
                    29.598,
                    30.221,
                    30.844
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    5,
                    16,
                    33,
                    57,
                    105,
                    192,
                    299,
                    506,
                    700,
                    1013,
                    1417,
                    1847,
                    2319,
                    2692,
                    3066,
                    3503,
                    3605,
                    3565,
                    3636,
                    3379,
                    3159,
                    2831,
                    2527,
                    2107,
                    1669,
                    1373,
                    1133,
                    856,
                    610,
                    531,
                    410,
                    269,
                    209,
                    161,
                    134,
                    76,
                    68,
                    66,
                    24,
                    23,
                    22,
                    7,
                    9,
                    7,
                    7,
                    4,
                    4,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.707,
                    -0.672,
                    -0.636,
                    -0.601,
                    -0.565,
                    -0.529,
                    -0.494,
                    -0.458,
                    -0.423,
                    -0.387,
                    -0.351,
                    -0.316,
                    -0.28,
                    -0.244,
                    -0.209,
                    -0.173,
                    -0.138,
                    -0.102,
                    -0.066,
                    -0.031,
                    0.005,
                    0.041,
                    0.076,
                    0.112,
                    0.147,
                    0.183,
                    0.219,
                    0.254,
                    0.29,
                    0.326,
                    0.361,
                    0.397,
                    0.432,
                    0.468,
                    0.504,
                    0.539,
                    0.575,
                    0.61,
                    0.646,
                    0.682,
                    0.717,
                    0.753,
                    0.789,
                    0.824,
                    0.86,
                    0.895,
                    0.931,
                    0.967,
                    1.002,
                    1.038
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "academic or research-related content with a focus on brain functions, memory, study designs, and information processing",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtlbhnzusxi6667qz6nca9",
                        "tokens": [
                            " future",
                            ".",
                            " Thanks",
                            " to",
                            " LED",
                            "-",
                            "Mir",
                            "ror",
                            "Knight",
                            " for",
                            " the",
                            " heads",
                            " up",
                            "!",
                            "<|endoftext|>",
                            "Abstract",
                            " Neuro",
                            "im",
                            "aging",
                            " evidence",
                            " suggests",
                            " that",
                            " the",
                            " par",
                            "ietal",
                            " lobe",
                            " has",
                            " an",
                            " important",
                            " role",
                            " in",
                            " memory",
                            " retrieval",
                            ",",
                            " yet",
                            " neuro",
                            "psych",
                            "ology",
                            " is",
                            " largely",
                            " silent",
                            " on",
                            " this",
                            " topic",
                            ".",
                            " Recently",
                            ",",
                            " we",
                            " reported",
                            " that",
                            " unilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " imp",
                            "airs",
                            " various",
                            " forms",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " when",
                            " tested",
                            " by",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Here",
                            ",",
                            " we",
                            " investigate",
                            " whether",
                            " par",
                            "ietal",
                            " lobe",
                            " working",
                            " memory",
                            " deficits",
                            " are",
                            " linked",
                            " to",
                            " problems",
                            " at",
                            " retrieval",
                            ".",
                            " We",
                            " tested",
                            " two",
                            " patients",
                            " with",
                            " bilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " in",
                            " a",
                            " series",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " tasks",
                            " that",
                            " prob",
                            "ed",
                            " recall",
                            " and",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Stim",
                            "uli",
                            " were",
                            " presented",
                            " sequ",
                            "entially",
                            " and",
                            " several",
                            " stimulus",
                            " categories"
                        ],
                        "dataIndex": null,
                        "index": "1457",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.156,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.708,
                            0,
                            2.346,
                            0,
                            0,
                            2.02,
                            3.856,
                            0.878,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.544,
                            3.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.634,
                            5.341,
                            8.266,
                            13.073,
                            9.528,
                            3.112,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.531,
                            22.668,
                            22.05,
                            19.693,
                            14.01,
                            1.759,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.156,
                            19.872,
                            7.578,
                            1.33,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.539,
                            3.236,
                            1.315,
                            1.416,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:17:06.903Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.155,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtlbhpzut9i666pa37zbhb",
                        "tokens": [
                            " future",
                            ".",
                            " Thanks",
                            " to",
                            " LED",
                            "-",
                            "Mir",
                            "ror",
                            "Knight",
                            " for",
                            " the",
                            " heads",
                            " up",
                            "!",
                            "<|endoftext|>",
                            "Abstract",
                            " Neuro",
                            "im",
                            "aging",
                            " evidence",
                            " suggests",
                            " that",
                            " the",
                            " par",
                            "ietal",
                            " lobe",
                            " has",
                            " an",
                            " important",
                            " role",
                            " in",
                            " memory",
                            " retrieval",
                            ",",
                            " yet",
                            " neuro",
                            "psych",
                            "ology",
                            " is",
                            " largely",
                            " silent",
                            " on",
                            " this",
                            " topic",
                            ".",
                            " Recently",
                            ",",
                            " we",
                            " reported",
                            " that",
                            " unilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " imp",
                            "airs",
                            " various",
                            " forms",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " when",
                            " tested",
                            " by",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Here",
                            ",",
                            " we",
                            " investigate",
                            " whether",
                            " par",
                            "ietal",
                            " lobe",
                            " working",
                            " memory",
                            " deficits",
                            " are",
                            " linked",
                            " to",
                            " problems",
                            " at",
                            " retrieval",
                            ".",
                            " We",
                            " tested",
                            " two",
                            " patients",
                            " with",
                            " bilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " in",
                            " a",
                            " series",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " tasks",
                            " that",
                            " prob",
                            "ed",
                            " recall",
                            " and",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Stim",
                            "uli",
                            " were",
                            " presented",
                            " sequ",
                            "entially",
                            " and",
                            " several",
                            " stimulus",
                            " categories"
                        ],
                        "dataIndex": null,
                        "index": "1457",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.156,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.708,
                            0,
                            2.346,
                            0,
                            0,
                            2.02,
                            3.856,
                            0.878,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.544,
                            3.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.634,
                            5.341,
                            8.266,
                            13.073,
                            9.528,
                            3.112,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.531,
                            22.668,
                            22.05,
                            19.693,
                            14.01,
                            1.759,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.156,
                            19.872,
                            7.578,
                            1.33,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.539,
                            3.236,
                            1.315,
                            1.416,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:17:06.903Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.155,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtlbhpzutbi666c5wtqpeu",
                        "tokens": [
                            " future",
                            ".",
                            " Thanks",
                            " to",
                            " LED",
                            "-",
                            "Mir",
                            "ror",
                            "Knight",
                            " for",
                            " the",
                            " heads",
                            " up",
                            "!",
                            "<|endoftext|>",
                            "Abstract",
                            " Neuro",
                            "im",
                            "aging",
                            " evidence",
                            " suggests",
                            " that",
                            " the",
                            " par",
                            "ietal",
                            " lobe",
                            " has",
                            " an",
                            " important",
                            " role",
                            " in",
                            " memory",
                            " retrieval",
                            ",",
                            " yet",
                            " neuro",
                            "psych",
                            "ology",
                            " is",
                            " largely",
                            " silent",
                            " on",
                            " this",
                            " topic",
                            ".",
                            " Recently",
                            ",",
                            " we",
                            " reported",
                            " that",
                            " unilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " imp",
                            "airs",
                            " various",
                            " forms",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " when",
                            " tested",
                            " by",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Here",
                            ",",
                            " we",
                            " investigate",
                            " whether",
                            " par",
                            "ietal",
                            " lobe",
                            " working",
                            " memory",
                            " deficits",
                            " are",
                            " linked",
                            " to",
                            " problems",
                            " at",
                            " retrieval",
                            ".",
                            " We",
                            " tested",
                            " two",
                            " patients",
                            " with",
                            " bilateral",
                            " par",
                            "ietal",
                            " lobe",
                            " damage",
                            " in",
                            " a",
                            " series",
                            " of",
                            " visual",
                            " working",
                            " memory",
                            " tasks",
                            " that",
                            " prob",
                            "ed",
                            " recall",
                            " and",
                            " old",
                            "/",
                            "new",
                            " recognition",
                            ".",
                            " Stim",
                            "uli",
                            " were",
                            " presented",
                            " sequ",
                            "entially",
                            " and",
                            " several",
                            " stimulus",
                            " categories"
                        ],
                        "dataIndex": null,
                        "index": "1457",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.156,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.708,
                            0,
                            2.346,
                            0,
                            0,
                            2.02,
                            3.856,
                            0.878,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.544,
                            3.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.634,
                            5.341,
                            8.266,
                            13.073,
                            9.528,
                            3.112,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.531,
                            22.668,
                            22.05,
                            19.693,
                            14.01,
                            1.759,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.156,
                            19.872,
                            7.578,
                            1.33,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.539,
                            3.236,
                            1.315,
                            1.416,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:17:06.903Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 31.155,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "32157",
            "description": "statements about the difficulty and importance of various tasks or concepts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.445915616045524,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "32157",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:56:43.122Z",
                "maxActApprox": 30.702,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    32157,
                    28908,
                    6541,
                    33305,
                    871,
                    41792,
                    48700,
                    16008,
                    26354,
                    28381,
                    16040,
                    15107,
                    35149,
                    20721,
                    30549,
                    18787,
                    19583,
                    43615,
                    47945,
                    33107,
                    24970,
                    16071,
                    3978,
                    33678,
                    40290
                ],
                "topkCosSimValues": [
                    1,
                    0.6702,
                    0.6491,
                    0.6215,
                    0.5744,
                    0.535,
                    0.5316,
                    0.512,
                    0.4917,
                    0.4886,
                    0.4328,
                    0.4187,
                    0.394,
                    0.39,
                    0.3881,
                    0.3872,
                    0.3868,
                    0.3812,
                    0.3811,
                    0.3788,
                    0.3757,
                    0.3708,
                    0.3698,
                    0.3675,
                    0.3661
                ],
                "neuron_alignment_indices": [
                    282,
                    512,
                    170
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.105,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    512,
                    102,
                    170
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.048,
                    0.047
                ],
                "correlated_neurons_l1": [
                    0.05,
                    0.053,
                    0.047
                ],
                "correlated_features_indices": [
                    32119,
                    32123,
                    32219
                ],
                "correlated_features_pearson": [
                    0.049,
                    0.039,
                    0.001
                ],
                "correlated_features_l1": [
                    0.05,
                    0.04,
                    0.002
                ],
                "neg_str": [
                    "stood",
                    "dylib",
                    " Ki",
                    " Monitor",
                    " Rohing",
                    "luaj",
                    " Ow",
                    " Moody",
                    "\u00e3\u0124\u00ba",
                    "worthiness"
                ],
                "neg_values": [
                    -0.715,
                    -0.692,
                    -0.664,
                    -0.618,
                    -0.606,
                    -0.598,
                    -0.593,
                    -0.59,
                    -0.58,
                    -0.577
                ],
                "pos_str": [
                    " fraught",
                    " tricky",
                    " easier",
                    " ardu",
                    " daunting",
                    " difficult",
                    " futile",
                    " cumbersome",
                    " pointless",
                    " risky"
                ],
                "pos_values": [
                    1.084,
                    1.077,
                    0.983,
                    0.979,
                    0.964,
                    0.959,
                    0.958,
                    0.955,
                    0.94,
                    0.936
                ],
                "frac_nonzero": 0.00156,
                "freq_hist_data_bar_heights": [
                    878,
                    674,
                    451,
                    379,
                    315,
                    237,
                    201,
                    174,
                    157,
                    120,
                    103,
                    99,
                    91,
                    70,
                    74,
                    54,
                    67,
                    64,
                    41,
                    48,
                    56,
                    54,
                    46,
                    43,
                    38,
                    50,
                    29,
                    29,
                    24,
                    38,
                    30,
                    28,
                    25,
                    18,
                    17,
                    13,
                    8,
                    5,
                    10,
                    9,
                    5,
                    6,
                    9,
                    3,
                    1,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.307,
                    0.921,
                    1.535,
                    2.149,
                    2.763,
                    3.377,
                    3.991,
                    4.605,
                    5.22,
                    5.834,
                    6.448,
                    7.062,
                    7.676,
                    8.29,
                    8.904,
                    9.518,
                    10.132,
                    10.746,
                    11.36,
                    11.974,
                    12.588,
                    13.202,
                    13.816,
                    14.43,
                    15.044,
                    15.658,
                    16.272,
                    16.886,
                    17.5,
                    18.114,
                    18.728,
                    19.343,
                    19.957,
                    20.571,
                    21.185,
                    21.799,
                    22.413,
                    23.027,
                    23.641,
                    24.255,
                    24.869,
                    25.483,
                    26.097,
                    26.711,
                    27.325,
                    27.939,
                    28.553,
                    29.167,
                    29.781,
                    30.395
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    1,
                    9,
                    15,
                    27,
                    52,
                    107,
                    202,
                    345,
                    539,
                    887,
                    1260,
                    1836,
                    2406,
                    3092,
                    3719,
                    4031,
                    4094,
                    4327,
                    3966,
                    3777,
                    3406,
                    2774,
                    2172,
                    1821,
                    1379,
                    1092,
                    785,
                    580,
                    441,
                    316,
                    231,
                    162,
                    111,
                    73,
                    66,
                    32,
                    38,
                    29,
                    13,
                    6,
                    4,
                    10,
                    7,
                    5,
                    5,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.697,
                    -0.661,
                    -0.625,
                    -0.589,
                    -0.553,
                    -0.517,
                    -0.481,
                    -0.445,
                    -0.409,
                    -0.373,
                    -0.337,
                    -0.301,
                    -0.265,
                    -0.229,
                    -0.193,
                    -0.157,
                    -0.121,
                    -0.085,
                    -0.05,
                    -0.014,
                    0.022,
                    0.058,
                    0.094,
                    0.13,
                    0.166,
                    0.202,
                    0.238,
                    0.274,
                    0.31,
                    0.346,
                    0.382,
                    0.418,
                    0.454,
                    0.49,
                    0.526,
                    0.562,
                    0.598,
                    0.634,
                    0.67,
                    0.706,
                    0.742,
                    0.778,
                    0.814,
                    0.85,
                    0.886,
                    0.922,
                    0.958,
                    0.994,
                    1.03,
                    1.066
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "statements about the difficulty and importance of various tasks or concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk67ckm5a4ai666fuwwj1cl",
                        "tokens": [
                            " of",
                            " rail",
                            " transit",
                            " and",
                            " demanded",
                            " much",
                            " more",
                            " careful",
                            " staff",
                            " work",
                            " on",
                            " budget",
                            ",",
                            " construction",
                            " plans",
                            " and",
                            " costs",
                            ".",
                            " She",
                            " went",
                            " public",
                            " with",
                            " bad",
                            " news",
                            ",",
                            " issuing",
                            " sharply",
                            " revised",
                            " construction",
                            " schedules",
                            ",",
                            " admitting",
                            " that",
                            " the",
                            " agency",
                            " could",
                            " only",
                            " complete",
                            " some",
                            " two",
                            "-",
                            "thirds",
                            " of",
                            " the",
                            " rail",
                            " work",
                            " it",
                            " had",
                            " promised",
                            " voters",
                            " in",
                            " 1996",
                            ".",
                            " And",
                            " she",
                            " said",
                            " the",
                            " limited",
                            " work",
                            " would",
                            " cost",
                            " more",
                            " and",
                            " take",
                            " longer",
                            ".",
                            "\n",
                            "\n",
                            "Fig",
                            "uring",
                            " out",
                            " the",
                            " changes",
                            " and",
                            " making",
                            " them",
                            " work",
                            " was",
                            " no",
                            " small",
                            " task",
                            ".",
                            " \"",
                            "It",
                            " was",
                            " so",
                            " intense",
                            ",\"",
                            " she",
                            " would",
                            " later",
                            " say",
                            " in",
                            " an",
                            " interview",
                            " with",
                            " W",
                            "SU",
                            "'s",
                            " magazine",
                            ".",
                            " \"",
                            "I",
                            " went",
                            " for",
                            " five",
                            " months",
                            " without",
                            " a",
                            " day",
                            " off",
                            ".",
                            " I",
                            " had",
                            " some",
                            " 24",
                            " hour",
                            " days",
                            " in",
                            " there",
                            " where",
                            " I",
                            " just",
                            " called",
                            " my",
                            " husband",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "32157",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.702,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.702,
                            10.369,
                            7.08,
                            1.689,
                            2.248,
                            0,
                            0,
                            2.308,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:47.173Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.702,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk67ckm5a4bi6664n3r7lmt",
                        "tokens": [
                            "T",
                            "urb",
                            "ulent",
                            ",",
                            " su",
                            "person",
                            "ic",
                            " gas",
                            " is",
                            " characterized",
                            " mainly",
                            " by",
                            " the",
                            " Reynolds",
                            " number",
                            " (",
                            "the",
                            " ratio",
                            " of",
                            " momentum",
                            " to",
                            " visc",
                            "ous",
                            " forces",
                            ",",
                            " which",
                            " determines",
                            " when",
                            " a",
                            " flow",
                            " becomes",
                            " turbulent",
                            ")",
                            " and",
                            " the",
                            " Mach",
                            " number",
                            " (",
                            "the",
                            " flow",
                            " speed",
                            " divided",
                            " by",
                            " the",
                            " local",
                            " speed",
                            " of",
                            " sound",
                            ").",
                            " These",
                            " quantities",
                            " have",
                            " been",
                            " difficult",
                            " to",
                            " measure",
                            " in",
                            " the",
                            " past",
                            ",",
                            " since",
                            " astronomers",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " able",
                            " to",
                            " get",
                            " an",
                            " adequate",
                            " picture",
                            " of",
                            " the",
                            " gas",
                            ",",
                            " but",
                            " they",
                            " do",
                            " know",
                            " that",
                            " structures",
                            " formed",
                            " by",
                            " the",
                            " turbulent",
                            " motion",
                            " range",
                            " from",
                            " 1",
                            ",",
                            "000",
                            " km",
                            " to",
                            " 100",
                            " par",
                            "sec",
                            "s",
                            " (",
                            "over",
                            " 101",
                            "5",
                            " km",
                            ").",
                            "\n",
                            "\n",
                            "Now",
                            ",",
                            " describing",
                            " the",
                            " IS",
                            "M",
                            " as",
                            " \"",
                            "gas",
                            "\"",
                            " is",
                            " a",
                            " bit",
                            " of",
                            " an",
                            " over",
                            "statement",
                            ",",
                            " if",
                            " you"
                        ],
                        "dataIndex": null,
                        "index": "32157",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.098,
                        "maxValueTokenIndex": 117,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.144,
                            0,
                            0,
                            0,
                            29.098,
                            10.016,
                            14.616,
                            1.342,
                            6.404,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:47.173Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.702,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk67ckn5a4ci666klxvwdmu",
                        "tokens": [
                            "\u013b",
                            "re",
                            " not",
                            " alone",
                            ".",
                            " Writing",
                            " a",
                            " lightning",
                            "-",
                            "speed",
                            " draft",
                            " is",
                            " not",
                            " an",
                            " easy",
                            " skill",
                            " to",
                            " master",
                            ".",
                            " However",
                            ",",
                            " for",
                            " anyone",
                            " who",
                            " wants",
                            " to",
                            " write",
                            " anything",
                            " longer",
                            " than",
                            " an",
                            " email",
                            ",",
                            " writing",
                            " a",
                            " fast",
                            " draft",
                            " is",
                            " a",
                            " crucial",
                            " skill",
                            ";",
                            " and",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " just",
                            " about",
                            " saving",
                            " time",
                            ".",
                            " Fast",
                            " writing",
                            " is",
                            " also",
                            " about",
                            " focus",
                            ",",
                            " clarity",
                            ",",
                            " and",
                            " the",
                            " freedom",
                            " to",
                            " experiment",
                            " with",
                            " competing",
                            " ideas",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " 10",
                            " tips",
                            " to",
                            " help",
                            " you",
                            " write",
                            " your",
                            " drafts",
                            " faster",
                            " than",
                            " you",
                            " ever",
                            " imagined",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "Speed",
                            " tip",
                            " #",
                            "1",
                            ":",
                            " Don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " worry",
                            " about",
                            " grammar",
                            "\n",
                            "\n",
                            "Don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " bother",
                            " putting",
                            " together",
                            " well",
                            "-",
                            "con",
                            "structed",
                            " sentences",
                            ".",
                            " Just",
                            " string",
                            " words",
                            " together",
                            " to",
                            " create",
                            " content",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "32157",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.419,
                        "maxValueTokenIndex": 11,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.419,
                            15.067,
                            2.752,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.419,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.703,
                            3.896,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:47.173Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.702,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13143",
            "description": " conditions and implications of learning and growth in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44538542953817184,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13143",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:32.988Z",
                "maxActApprox": 22.743,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13143,
                    90472,
                    45161,
                    69762,
                    69787,
                    94454,
                    69569,
                    90458,
                    31711,
                    30603,
                    78829,
                    77638,
                    84974,
                    38699,
                    8660,
                    66092,
                    22533,
                    23009,
                    69797,
                    97948,
                    16348,
                    69660,
                    68346,
                    81042,
                    37220
                ],
                "topkCosSimValues": [
                    1,
                    0.4288,
                    0.4174,
                    0.3764,
                    0.3704,
                    0.3623,
                    0.3543,
                    0.3369,
                    0.3361,
                    0.3203,
                    0.3197,
                    0.31,
                    0.3095,
                    0.3085,
                    0.3066,
                    0.3057,
                    0.301,
                    0.2959,
                    0.2957,
                    0.2954,
                    0.2903,
                    0.2884,
                    0.2875,
                    0.2795,
                    0.2772
                ],
                "neuron_alignment_indices": [
                    459,
                    279,
                    5
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.106,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    259,
                    51
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.015,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.013,
                    0.014
                ],
                "correlated_features_indices": [
                    13236,
                    13193,
                    13124
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "\u00a9\u00b6\u00e6",
                    "usp",
                    "irez",
                    "\u00ef\u00b8",
                    "hov",
                    " TED",
                    "hof",
                    "\u00be",
                    "utenant",
                    "ixties"
                ],
                "neg_values": [
                    -0.805,
                    -0.791,
                    -0.768,
                    -0.755,
                    -0.753,
                    -0.723,
                    -0.7,
                    -0.686,
                    -0.652,
                    -0.645
                ],
                "pos_str": [
                    " tend",
                    " likely",
                    "entimes",
                    " susceptible",
                    " tendency",
                    " ware",
                    "']",
                    " appear",
                    " discrim",
                    "ANCE"
                ],
                "pos_values": [
                    0.638,
                    0.631,
                    0.625,
                    0.617,
                    0.612,
                    0.608,
                    0.598,
                    0.589,
                    0.589,
                    0.584
                ],
                "frac_nonzero": 0.00039,
                "freq_hist_data_bar_heights": [
                    294,
                    173,
                    125,
                    96,
                    70,
                    50,
                    37,
                    29,
                    24,
                    17,
                    19,
                    17,
                    15,
                    17,
                    12,
                    16,
                    12,
                    4,
                    8,
                    14,
                    8,
                    9,
                    7,
                    14,
                    14,
                    4,
                    8,
                    8,
                    16,
                    6,
                    7,
                    6,
                    5,
                    7,
                    6,
                    11,
                    8,
                    6,
                    7,
                    3,
                    3,
                    4,
                    6,
                    3,
                    0,
                    2,
                    0,
                    1,
                    2,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.23,
                    0.684,
                    1.139,
                    1.594,
                    2.049,
                    2.504,
                    2.958,
                    3.413,
                    3.868,
                    4.323,
                    4.778,
                    5.233,
                    5.687,
                    6.142,
                    6.597,
                    7.052,
                    7.507,
                    7.962,
                    8.416,
                    8.871,
                    9.326,
                    9.781,
                    10.236,
                    10.69,
                    11.145,
                    11.6,
                    12.055,
                    12.51,
                    12.965,
                    13.419,
                    13.874,
                    14.329,
                    14.784,
                    15.239,
                    15.693,
                    16.148,
                    16.603,
                    17.058,
                    17.513,
                    17.968,
                    18.422,
                    18.877,
                    19.332,
                    19.787,
                    20.242,
                    20.696,
                    21.151,
                    21.606,
                    22.061,
                    22.516
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    1,
                    1,
                    1,
                    5,
                    6,
                    12,
                    14,
                    17,
                    53,
                    57,
                    81,
                    128,
                    210,
                    329,
                    449,
                    620,
                    808,
                    1110,
                    1411,
                    1906,
                    2224,
                    2661,
                    2978,
                    3295,
                    3490,
                    3609,
                    3520,
                    3521,
                    3225,
                    2941,
                    2614,
                    2191,
                    1830,
                    1350,
                    1060,
                    765,
                    553,
                    431,
                    272,
                    183,
                    117,
                    81,
                    45,
                    33,
                    17,
                    17,
                    5,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.791,
                    -0.762,
                    -0.733,
                    -0.704,
                    -0.675,
                    -0.647,
                    -0.618,
                    -0.589,
                    -0.56,
                    -0.531,
                    -0.502,
                    -0.473,
                    -0.444,
                    -0.416,
                    -0.387,
                    -0.358,
                    -0.329,
                    -0.3,
                    -0.271,
                    -0.242,
                    -0.213,
                    -0.184,
                    -0.156,
                    -0.127,
                    -0.098,
                    -0.069,
                    -0.04,
                    -0.011,
                    0.018,
                    0.047,
                    0.075,
                    0.104,
                    0.133,
                    0.162,
                    0.191,
                    0.22,
                    0.249,
                    0.278,
                    0.306,
                    0.335,
                    0.364,
                    0.393,
                    0.422,
                    0.451,
                    0.48,
                    0.509,
                    0.537,
                    0.566,
                    0.595,
                    0.624
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements about actions and their outcomes, particularly in the context of decision-making and behavior change",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases indicating difficulty related to achieving a goal or capturing something",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " conditions and implications of learning and growth in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfgmrdl9la10exwncygfdx",
                        "tokens": [
                            " on",
                            " short",
                            " flights",
                            ";",
                            " or",
                            " that",
                            " which",
                            " manages",
                            " to",
                            " hit",
                            " her",
                            " dull",
                            " and",
                            " ch",
                            "ipped",
                            " funny",
                            " bone",
                            ";",
                            " or",
                            " s",
                            "ate",
                            " her",
                            " great",
                            " appetite",
                            " for",
                            " vanilla",
                            " S",
                            "&",
                            "M",
                            " and",
                            " tr",
                            "uer",
                            " detectives",
                            ".",
                            " A",
                            " working",
                            " fallacy",
                            " results",
                            ".",
                            " Tent",
                            " poles",
                            " such",
                            " as",
                            " Game",
                            " of",
                            " Thrones",
                            ",",
                            " The",
                            " Marvel",
                            " Universe",
                            " \u2014",
                            " they",
                            " have",
                            " a",
                            " kind",
                            " of",
                            " ideological",
                            " monopoly",
                            " on",
                            " What",
                            " happens",
                            " next",
                            "?",
                            " But",
                            " the",
                            " more",
                            " we",
                            " accept",
                            " the",
                            " premise",
                            " that",
                            " what",
                            " succeeds",
                            " in",
                            " the",
                            " market",
                            " works",
                            ",",
                            " the",
                            " easier",
                            " it",
                            " is",
                            " to",
                            " convince",
                            " ourselves",
                            " that",
                            " the",
                            " market",
                            " itself",
                            " strives",
                            " to",
                            " give",
                            " us",
                            " the",
                            " culture",
                            " we",
                            " need",
                            ".",
                            " [",
                            "It",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            ".]",
                            " The",
                            " challenge",
                            " for",
                            " lit",
                            " is",
                            " the",
                            " same",
                            " for",
                            " our",
                            " culture",
                            " at",
                            " large",
                            " from",
                            " here",
                            " on",
                            ":",
                            " distinguishing",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "13143",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.743,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.181,
                            22.743,
                            19.08,
                            7.566,
                            1.792,
                            2.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:34.432Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 22.743,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfgmrfl9lq10exkcnrh4p7",
                        "tokens": [
                            " on",
                            " short",
                            " flights",
                            ";",
                            " or",
                            " that",
                            " which",
                            " manages",
                            " to",
                            " hit",
                            " her",
                            " dull",
                            " and",
                            " ch",
                            "ipped",
                            " funny",
                            " bone",
                            ";",
                            " or",
                            " s",
                            "ate",
                            " her",
                            " great",
                            " appetite",
                            " for",
                            " vanilla",
                            " S",
                            "&",
                            "M",
                            " and",
                            " tr",
                            "uer",
                            " detectives",
                            ".",
                            " A",
                            " working",
                            " fallacy",
                            " results",
                            ".",
                            " Tent",
                            " poles",
                            " such",
                            " as",
                            " Game",
                            " of",
                            " Thrones",
                            ",",
                            " The",
                            " Marvel",
                            " Universe",
                            " \u2014",
                            " they",
                            " have",
                            " a",
                            " kind",
                            " of",
                            " ideological",
                            " monopoly",
                            " on",
                            " What",
                            " happens",
                            " next",
                            "?",
                            " But",
                            " the",
                            " more",
                            " we",
                            " accept",
                            " the",
                            " premise",
                            " that",
                            " what",
                            " succeeds",
                            " in",
                            " the",
                            " market",
                            " works",
                            ",",
                            " the",
                            " easier",
                            " it",
                            " is",
                            " to",
                            " convince",
                            " ourselves",
                            " that",
                            " the",
                            " market",
                            " itself",
                            " strives",
                            " to",
                            " give",
                            " us",
                            " the",
                            " culture",
                            " we",
                            " need",
                            ".",
                            " [",
                            "It",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            ".]",
                            " The",
                            " challenge",
                            " for",
                            " lit",
                            " is",
                            " the",
                            " same",
                            " for",
                            " our",
                            " culture",
                            " at",
                            " large",
                            " from",
                            " here",
                            " on",
                            ":",
                            " distinguishing",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "13143",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.743,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.181,
                            22.743,
                            19.08,
                            7.566,
                            1.792,
                            2.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:34.432Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 22.743,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfgmrfl9lu10exlsyf6ec3",
                        "tokens": [
                            " on",
                            " short",
                            " flights",
                            ";",
                            " or",
                            " that",
                            " which",
                            " manages",
                            " to",
                            " hit",
                            " her",
                            " dull",
                            " and",
                            " ch",
                            "ipped",
                            " funny",
                            " bone",
                            ";",
                            " or",
                            " s",
                            "ate",
                            " her",
                            " great",
                            " appetite",
                            " for",
                            " vanilla",
                            " S",
                            "&",
                            "M",
                            " and",
                            " tr",
                            "uer",
                            " detectives",
                            ".",
                            " A",
                            " working",
                            " fallacy",
                            " results",
                            ".",
                            " Tent",
                            " poles",
                            " such",
                            " as",
                            " Game",
                            " of",
                            " Thrones",
                            ",",
                            " The",
                            " Marvel",
                            " Universe",
                            " \u2014",
                            " they",
                            " have",
                            " a",
                            " kind",
                            " of",
                            " ideological",
                            " monopoly",
                            " on",
                            " What",
                            " happens",
                            " next",
                            "?",
                            " But",
                            " the",
                            " more",
                            " we",
                            " accept",
                            " the",
                            " premise",
                            " that",
                            " what",
                            " succeeds",
                            " in",
                            " the",
                            " market",
                            " works",
                            ",",
                            " the",
                            " easier",
                            " it",
                            " is",
                            " to",
                            " convince",
                            " ourselves",
                            " that",
                            " the",
                            " market",
                            " itself",
                            " strives",
                            " to",
                            " give",
                            " us",
                            " the",
                            " culture",
                            " we",
                            " need",
                            ".",
                            " [",
                            "It",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            ".]",
                            " The",
                            " challenge",
                            " for",
                            " lit",
                            " is",
                            " the",
                            " same",
                            " for",
                            " our",
                            " culture",
                            " at",
                            " large",
                            " from",
                            " here",
                            " on",
                            ":",
                            " distinguishing",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "13143",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.743,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.181,
                            22.743,
                            19.08,
                            7.566,
                            1.792,
                            2.055,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:34.432Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 18.194,
                        "binMax": 22.743,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "52826",
            "description": " concepts related to advanced cognitive stages and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4438781507160515,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "52826",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:40:09.008Z",
                "maxActApprox": 15.789,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    52826,
                    96686,
                    40863,
                    97899,
                    71247,
                    24561,
                    48130,
                    55567,
                    8808,
                    71698,
                    35618,
                    28127,
                    92040,
                    57404,
                    84959,
                    81141,
                    50650,
                    6393,
                    35398,
                    60541,
                    43498,
                    33284,
                    6516,
                    4039,
                    90574
                ],
                "topkCosSimValues": [
                    1,
                    0.5445,
                    0.5429,
                    0.4984,
                    0.4932,
                    0.4931,
                    0.4881,
                    0.4847,
                    0.4611,
                    0.4355,
                    0.435,
                    0.4342,
                    0.4316,
                    0.4176,
                    0.4173,
                    0.4145,
                    0.4073,
                    0.4068,
                    0.3996,
                    0.396,
                    0.3915,
                    0.3866,
                    0.3857,
                    0.3852,
                    0.3835
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    621
                ],
                "neuron_alignment_values": [
                    0.163,
                    0.109,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    594,
                    288,
                    459
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.046,
                    0.044
                ],
                "correlated_neurons_l1": [
                    0.046,
                    0.07,
                    0.047
                ],
                "correlated_features_indices": [
                    52914,
                    52866,
                    52812
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.009,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " contagious",
                    " Antar",
                    " embassies",
                    " Stard",
                    " Kazakh",
                    " hay",
                    " Canter",
                    " pseudonym",
                    " Kush",
                    " NEO"
                ],
                "neg_values": [
                    -0.581,
                    -0.564,
                    -0.547,
                    -0.541,
                    -0.541,
                    -0.534,
                    -0.531,
                    -0.524,
                    -0.519,
                    -0.516
                ],
                "pos_str": [
                    " thereof",
                    " counterpart",
                    " meanwhile",
                    " versa",
                    "SPONSORED",
                    "ogy",
                    " likewise",
                    "JV",
                    "OPE",
                    " ones"
                ],
                "pos_values": [
                    0.797,
                    0.767,
                    0.76,
                    0.735,
                    0.693,
                    0.691,
                    0.679,
                    0.677,
                    0.664,
                    0.661
                ],
                "frac_nonzero": 0.006059999999999999,
                "freq_hist_data_bar_heights": [
                    4184,
                    3244,
                    2529,
                    1903,
                    1535,
                    1102,
                    911,
                    727,
                    590,
                    455,
                    339,
                    307,
                    239,
                    190,
                    151,
                    95,
                    84,
                    98,
                    64,
                    62,
                    50,
                    38,
                    36,
                    34,
                    19,
                    14,
                    14,
                    10,
                    8,
                    12,
                    4,
                    7,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    3,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.158,
                    0.474,
                    0.79,
                    1.105,
                    1.421,
                    1.737,
                    2.053,
                    2.368,
                    2.684,
                    3,
                    3.316,
                    3.632,
                    3.947,
                    4.263,
                    4.579,
                    4.895,
                    5.21,
                    5.526,
                    5.842,
                    6.158,
                    6.474,
                    6.789,
                    7.105,
                    7.421,
                    7.737,
                    8.052,
                    8.368,
                    8.684,
                    9,
                    9.315,
                    9.631,
                    9.947,
                    10.263,
                    10.579,
                    10.894,
                    11.21,
                    11.526,
                    11.842,
                    12.157,
                    12.473,
                    12.789,
                    13.105,
                    13.421,
                    13.736,
                    14.052,
                    14.368,
                    14.684,
                    14.999,
                    15.315,
                    15.631
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    8,
                    12,
                    32,
                    71,
                    99,
                    159,
                    283,
                    418,
                    608,
                    824,
                    1265,
                    1646,
                    2052,
                    2465,
                    2834,
                    3124,
                    3399,
                    3510,
                    3403,
                    3327,
                    3074,
                    2771,
                    2408,
                    2225,
                    1945,
                    1750,
                    1422,
                    1192,
                    993,
                    793,
                    622,
                    482,
                    339,
                    249,
                    173,
                    104,
                    63,
                    50,
                    16,
                    11,
                    8,
                    5,
                    5,
                    5,
                    2,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.567,
                    -0.539,
                    -0.512,
                    -0.484,
                    -0.457,
                    -0.429,
                    -0.402,
                    -0.374,
                    -0.347,
                    -0.319,
                    -0.291,
                    -0.264,
                    -0.236,
                    -0.209,
                    -0.181,
                    -0.154,
                    -0.126,
                    -0.099,
                    -0.071,
                    -0.043,
                    -0.016,
                    0.012,
                    0.039,
                    0.067,
                    0.094,
                    0.122,
                    0.149,
                    0.177,
                    0.205,
                    0.232,
                    0.26,
                    0.287,
                    0.315,
                    0.342,
                    0.37,
                    0.397,
                    0.425,
                    0.453,
                    0.48,
                    0.508,
                    0.535,
                    0.563,
                    0.59,
                    0.618,
                    0.645,
                    0.673,
                    0.701,
                    0.728,
                    0.756,
                    0.783
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to advanced cognitive stages and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements related to knowledge and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghg5xgfbje10exspp02x14",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xgfbjl10expd7x9tbo",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xifbk010exgakbmy4t",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.631,
                        "binMax": 15.789,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.43547607237386154,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "14572",
            "description": "terms related to learning and valuable lessons",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4353403785621963,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "14572",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:24:35.724Z",
                "maxActApprox": 36.977,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14572,
                    46722,
                    33219,
                    19723,
                    37022,
                    35811,
                    33871,
                    7882,
                    41576,
                    39623,
                    2599,
                    9870,
                    785,
                    20747,
                    23357,
                    15624,
                    15480,
                    27850,
                    35043,
                    3993,
                    22563,
                    26719,
                    26441,
                    47084,
                    46953
                ],
                "topkCosSimValues": [
                    1,
                    0.5684,
                    0.5247,
                    0.5194,
                    0.502,
                    0.4875,
                    0.4688,
                    0.4173,
                    0.417,
                    0.409,
                    0.3907,
                    0.3858,
                    0.3748,
                    0.3624,
                    0.3602,
                    0.3526,
                    0.3475,
                    0.3453,
                    0.3358,
                    0.3322,
                    0.3247,
                    0.3243,
                    0.3208,
                    0.3199,
                    0.319
                ],
                "neuron_alignment_indices": [
                    154,
                    415,
                    567
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    567,
                    154,
                    568
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.017,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.019,
                    0.014
                ],
                "correlated_features_indices": [
                    14568,
                    14530,
                    14575
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "vertisement",
                    "ItemImage",
                    "ocument",
                    "cohol",
                    "istent",
                    "lished",
                    "IUM",
                    "enance",
                    "athi",
                    "ilitary"
                ],
                "neg_values": [
                    -0.704,
                    -0.666,
                    -0.664,
                    -0.652,
                    -0.646,
                    -0.643,
                    -0.609,
                    -0.601,
                    -0.596,
                    -0.59
                ],
                "pos_str": [
                    " lesson",
                    " lessons",
                    " tricks",
                    " firsthand",
                    " Lessons",
                    " ropes",
                    " basics",
                    " valuable",
                    " skills",
                    " invaluable"
                ],
                "pos_values": [
                    1.36,
                    1.172,
                    1.003,
                    0.966,
                    0.918,
                    0.866,
                    0.853,
                    0.841,
                    0.837,
                    0.789
                ],
                "frac_nonzero": 0.0006,
                "freq_hist_data_bar_heights": [
                    457,
                    308,
                    223,
                    161,
                    100,
                    96,
                    81,
                    63,
                    52,
                    44,
                    37,
                    22,
                    23,
                    19,
                    18,
                    12,
                    18,
                    11,
                    8,
                    9,
                    8,
                    7,
                    8,
                    10,
                    7,
                    8,
                    3,
                    8,
                    8,
                    5,
                    5,
                    4,
                    3,
                    4,
                    4,
                    5,
                    7,
                    3,
                    2,
                    3,
                    2,
                    4,
                    1,
                    2,
                    2,
                    0,
                    3,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.37,
                    1.11,
                    1.849,
                    2.589,
                    3.328,
                    4.068,
                    4.808,
                    5.547,
                    6.287,
                    7.026,
                    7.766,
                    8.505,
                    9.245,
                    9.984,
                    10.724,
                    11.463,
                    12.203,
                    12.942,
                    13.682,
                    14.421,
                    15.161,
                    15.9,
                    16.64,
                    17.379,
                    18.119,
                    18.858,
                    19.598,
                    20.337,
                    21.077,
                    21.816,
                    22.556,
                    23.295,
                    24.035,
                    24.775,
                    25.514,
                    26.254,
                    26.993,
                    27.733,
                    28.472,
                    29.212,
                    29.951,
                    30.691,
                    31.43,
                    32.17,
                    32.909,
                    33.649,
                    34.388,
                    35.128,
                    35.867,
                    36.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    6,
                    15,
                    34,
                    61,
                    128,
                    254,
                    487,
                    778,
                    1137,
                    1701,
                    2612,
                    3378,
                    4370,
                    5011,
                    5269,
                    5141,
                    4818,
                    4051,
                    3325,
                    2526,
                    1831,
                    1251,
                    789,
                    514,
                    307,
                    190,
                    108,
                    61,
                    36,
                    17,
                    17,
                    10,
                    6,
                    2,
                    1,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.643,
                    -0.601,
                    -0.56,
                    -0.519,
                    -0.477,
                    -0.436,
                    -0.395,
                    -0.354,
                    -0.312,
                    -0.271,
                    -0.23,
                    -0.188,
                    -0.147,
                    -0.106,
                    -0.065,
                    -0.023,
                    0.018,
                    0.059,
                    0.1,
                    0.142,
                    0.183,
                    0.224,
                    0.266,
                    0.307,
                    0.348,
                    0.389,
                    0.431,
                    0.472,
                    0.513,
                    0.555,
                    0.596,
                    0.637,
                    0.678,
                    0.72,
                    0.761,
                    0.802,
                    0.844,
                    0.885,
                    0.926,
                    0.967,
                    1.009,
                    1.05,
                    1.091,
                    1.132,
                    1.174,
                    1.215,
                    1.256,
                    1.298,
                    1.339
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to learning and valuable lessons",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5222xp36ei6667oroi4dk",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222vp35vi6664i76pr01",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222wp35wi6660ecwqa69",
                        "tokens": [
                            ",",
                            " but",
                            " then",
                            " you",
                            " use",
                            " that",
                            " to",
                            " fight",
                            " Meg",
                            "ac",
                            "orp",
                            " B",
                            " and",
                            " probably",
                            " learn",
                            " a",
                            " little",
                            " more",
                            " about",
                            " A",
                            " to",
                            " begin",
                            " with",
                            " and",
                            "...",
                            "\n",
                            "\n",
                            "Add",
                            " to",
                            " this",
                            " the",
                            " \"",
                            "self",
                            "-",
                            "trained",
                            "\"",
                            " element",
                            " of",
                            " punk",
                            " music",
                            ".",
                            " Don",
                            "'t",
                            " use",
                            " the",
                            " corp",
                            " cyber",
                            "deck",
                            " loaded",
                            " with",
                            " spy",
                            "ware",
                            " and",
                            " apps",
                            " you",
                            " won",
                            "'t",
                            " need",
                            ",",
                            " build",
                            " one",
                            " yourself",
                            " with",
                            " eight",
                            " old",
                            " cell",
                            "phones",
                            " and",
                            " a",
                            " keyboard",
                            " you",
                            " found",
                            " at",
                            " a",
                            " recycling",
                            " plant",
                            ".",
                            " Don",
                            "'t",
                            " get",
                            " the",
                            " flesh",
                            "like",
                            " cyber",
                            " arm",
                            "--",
                            "get",
                            " the",
                            " one",
                            " that",
                            "'s",
                            " been",
                            " jail",
                            "bre",
                            "aked",
                            " and",
                            " uploaded",
                            " with",
                            " new",
                            " moves",
                            " and",
                            " works",
                            " better",
                            " so",
                            " fuck",
                            " the",
                            " warranty",
                            ".",
                            " Don",
                            "'t",
                            " summon",
                            " that",
                            " elemental",
                            "--",
                            "every",
                            " time",
                            " you",
                            " do",
                            " a",
                            " tiny",
                            " bit",
                            " of",
                            " mo",
                            "jo",
                            " is",
                            " going",
                            " back"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.822,
                        "maxValueTokenIndex": 15,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.822,
                            26.566,
                            17.44,
                            2.595,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "65294",
            "description": "references to cognitive functions and terms related to the brain",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4254700928366104,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "65294",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:53:36.776Z",
                "maxActApprox": 49.996,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    65294,
                    25433,
                    43252,
                    73405,
                    55474,
                    30690,
                    41587,
                    16006,
                    92925,
                    71956,
                    15251,
                    34695,
                    30282,
                    2244,
                    92244,
                    9352,
                    9525,
                    87983,
                    19947,
                    47649,
                    1943,
                    29798,
                    89201,
                    42539,
                    89206
                ],
                "topkCosSimValues": [
                    1,
                    0.8295,
                    0.6005,
                    0.5437,
                    0.5397,
                    0.5017,
                    0.4806,
                    0.4786,
                    0.4747,
                    0.4685,
                    0.4634,
                    0.4503,
                    0.4497,
                    0.4473,
                    0.4434,
                    0.4431,
                    0.4368,
                    0.4367,
                    0.4218,
                    0.4186,
                    0.4024,
                    0.4009,
                    0.3987,
                    0.3964,
                    0.3884
                ],
                "neuron_alignment_indices": [
                    99,
                    288,
                    526
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.104,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    99,
                    741,
                    475
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.014,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.014,
                    0.014
                ],
                "correlated_features_indices": [
                    65355,
                    65321,
                    65223
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Beckham",
                    " Arabia",
                    " Bundy",
                    " Rhod",
                    " FANTASY",
                    " Ascend",
                    " Arabian",
                    " Bowie",
                    " Rhodes",
                    " Grimes"
                ],
                "neg_values": [
                    -0.693,
                    -0.683,
                    -0.679,
                    -0.678,
                    -0.64,
                    -0.633,
                    -0.631,
                    -0.606,
                    -0.596,
                    -0.582
                ],
                "pos_str": [
                    "washed",
                    "washing",
                    "wash",
                    "stem",
                    "fuck",
                    "iac",
                    "storms",
                    "wave",
                    "waves",
                    "child"
                ],
                "pos_values": [
                    1.367,
                    1.256,
                    1.183,
                    1.14,
                    1.135,
                    1.1,
                    1.003,
                    0.971,
                    0.944,
                    0.94
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    54,
                    35,
                    15,
                    18,
                    15,
                    8,
                    10,
                    6,
                    14,
                    12,
                    7,
                    2,
                    4,
                    7,
                    8,
                    2,
                    7,
                    7,
                    4,
                    4,
                    2,
                    4,
                    2,
                    8,
                    2,
                    6,
                    3,
                    2,
                    1,
                    3,
                    3,
                    4,
                    1,
                    3,
                    3,
                    3,
                    2,
                    1,
                    2,
                    3,
                    2,
                    0,
                    1,
                    2,
                    2,
                    0,
                    5,
                    2,
                    0,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.5,
                    1.5,
                    2.5,
                    3.5,
                    4.5,
                    5.5,
                    6.5,
                    7.5,
                    8.499,
                    9.499,
                    10.499,
                    11.499,
                    12.499,
                    13.499,
                    14.499,
                    15.499,
                    16.499,
                    17.499,
                    18.499,
                    19.498,
                    20.498,
                    21.498,
                    22.498,
                    23.498,
                    24.498,
                    25.498,
                    26.498,
                    27.498,
                    28.498,
                    29.498,
                    30.497,
                    31.497,
                    32.497,
                    33.497,
                    34.497,
                    35.497,
                    36.497,
                    37.497,
                    38.497,
                    39.497,
                    40.497,
                    41.497,
                    42.496,
                    43.496,
                    44.496,
                    45.496,
                    46.496,
                    47.496,
                    48.496,
                    49.496
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    3,
                    8,
                    26,
                    51,
                    76,
                    168,
                    391,
                    651,
                    1024,
                    1534,
                    2340,
                    3112,
                    3978,
                    4507,
                    4705,
                    4844,
                    4404,
                    4059,
                    3426,
                    2807,
                    2226,
                    1658,
                    1230,
                    948,
                    667,
                    454,
                    312,
                    235,
                    143,
                    101,
                    68,
                    38,
                    15,
                    11,
                    7,
                    7,
                    5,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.672,
                    -0.631,
                    -0.59,
                    -0.548,
                    -0.507,
                    -0.466,
                    -0.425,
                    -0.384,
                    -0.342,
                    -0.301,
                    -0.26,
                    -0.219,
                    -0.178,
                    -0.136,
                    -0.095,
                    -0.054,
                    -0.013,
                    0.028,
                    0.07,
                    0.111,
                    0.152,
                    0.193,
                    0.234,
                    0.276,
                    0.317,
                    0.358,
                    0.399,
                    0.44,
                    0.482,
                    0.523,
                    0.564,
                    0.605,
                    0.646,
                    0.688,
                    0.729,
                    0.77,
                    0.811,
                    0.852,
                    0.894,
                    0.935,
                    0.976,
                    1.017,
                    1.058,
                    1.1,
                    1.141,
                    1.182,
                    1.223,
                    1.264,
                    1.306,
                    1.347
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to the brain and related concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to cognitive functions and terms related to the brain",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghxizwot7810exqww5yzdk",
                        "tokens": [
                            " never",
                            " claimed",
                            " to",
                            " be",
                            ".",
                            " Name",
                            "ly",
                            ",",
                            " a",
                            " charity",
                            " that",
                            " functions",
                            " indefinitely",
                            " at",
                            " no",
                            " profit",
                            ".",
                            " Or",
                            ",",
                            " worse",
                            ",",
                            " a",
                            " government",
                            " agency",
                            " that",
                            " pur",
                            "ports",
                            " to",
                            " serve",
                            " \"",
                            "the",
                            " public",
                            "\"",
                            " while",
                            " acting",
                            " solely",
                            " in",
                            " its",
                            " own",
                            " interests",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " to",
                            " play",
                            " by",
                            " the",
                            " rules",
                            " of",
                            " the",
                            " corrupt",
                            " politicians",
                            ",",
                            " manipulative",
                            " media",
                            ",",
                            " and",
                            " brain",
                            "washed",
                            " peers",
                            ".",
                            " When",
                            " you",
                            " subscribe",
                            " to",
                            " The",
                            " Daily",
                            " Bell",
                            ",",
                            " you",
                            " also",
                            " get",
                            " a",
                            " free",
                            " guide",
                            ":",
                            " How",
                            " to",
                            " Craft",
                            " a",
                            " Two",
                            " Year",
                            " Plan",
                            " to",
                            " Re",
                            "claim",
                            " 3",
                            " Specific",
                            " Freed",
                            "oms",
                            ".",
                            " This",
                            " guide",
                            " will",
                            " show",
                            " you",
                            " exactly",
                            " how",
                            " to",
                            " plan",
                            " your",
                            " next",
                            " two",
                            " years",
                            " to",
                            " build",
                            " the",
                            " free",
                            " life",
                            " of",
                            " your",
                            " dreams",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " as",
                            " hard",
                            " as"
                        ],
                        "dataIndex": null,
                        "index": "65294",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.996,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.996,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:41.980Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 49.996,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghxizwot7910ex76imsr7r",
                        "tokens": [
                            "We",
                            " have",
                            " contacted",
                            " the",
                            " sheriff",
                            "'s",
                            " department",
                            " seeking",
                            " additional",
                            " details",
                            " and",
                            " are",
                            " awaiting",
                            " a",
                            " response",
                            ".",
                            "\n",
                            "\n",
                            "Contact",
                            " There",
                            "se",
                            " Ap",
                            "el",
                            " at",
                            " 601",
                            "-",
                            "96",
                            "1",
                            "-",
                            "7",
                            "236",
                            " or",
                            " tap",
                            "el",
                            "@",
                            "gan",
                            "n",
                            "ett",
                            ".",
                            "com",
                            ".",
                            " Follow",
                            " her",
                            " on",
                            " Facebook",
                            " and",
                            " Twitter",
                            ".",
                            "\n",
                            "\n",
                            "Read",
                            " or",
                            " Share",
                            " this",
                            " story",
                            ":",
                            " http",
                            "://",
                            "on",
                            ".",
                            "the",
                            "c",
                            "-",
                            "l",
                            ".",
                            "com",
                            "/",
                            "2",
                            "l",
                            "A",
                            "cm",
                            "z",
                            "8",
                            "<|endoftext|>",
                            "New",
                            " Delhi",
                            ":",
                            " Adding",
                            " yet",
                            " another",
                            " feather",
                            " in",
                            " their",
                            " hat",
                            ",",
                            " Modi",
                            " government",
                            " in",
                            " the",
                            " first",
                            " week",
                            " of",
                            " July",
                            " launched",
                            " Digital",
                            " India",
                            " week",
                            " at",
                            " Delhi",
                            ".",
                            " Digital",
                            " India",
                            ",",
                            " which",
                            " is",
                            " a",
                            " brain",
                            "child",
                            " of",
                            " PM",
                            " Narendra",
                            " Modi",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " vision",
                            " to",
                            " bring",
                            " good",
                            " governance",
                            " and",
                            " reduce",
                            " corruption",
                            ",",
                            " got",
                            " excellent",
                            " response"
                        ],
                        "dataIndex": null,
                        "index": "65294",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.738,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.738,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:41.980Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 49.996,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghxizwot7a10ex1in75d0o",
                        "tokens": [
                            " from",
                            " the",
                            " bottom",
                            ".",
                            "\n",
                            "\n",
                            "House",
                            ":",
                            " Clean",
                            "ed",
                            "\n",
                            "\n",
                            "Ban",
                            "ner",
                            " completed",
                            " the",
                            " house",
                            "cle",
                            "aning",
                            " at",
                            " the",
                            " end",
                            " of",
                            " the",
                            " season",
                            ".",
                            "\n",
                            "\n",
                            "Former",
                            " top",
                            " Oakland",
                            " Raiders",
                            " executive",
                            " Mike",
                            " Lomb",
                            "ardi",
                            " was",
                            " brought",
                            " in",
                            " to",
                            " serve",
                            " as",
                            " general",
                            " manager",
                            ".",
                            " Lomb",
                            "ardi",
                            " had",
                            " spent",
                            " five",
                            " seasons",
                            " as",
                            " a",
                            " media",
                            " observer",
                            ",",
                            " with",
                            " stint",
                            "s",
                            " at",
                            " Sports",
                            " Illustrated",
                            " and",
                            " NFL",
                            ".",
                            "com",
                            " sandwic",
                            "hed",
                            " around",
                            " the",
                            " launch",
                            " of",
                            " his",
                            " brain",
                            "child",
                            ",",
                            " the",
                            " National",
                            " Football",
                            " Post",
                            ".",
                            "\n",
                            "\n",
                            "L",
                            "omb",
                            "ardi",
                            " has",
                            " fans",
                            " and",
                            " detractors",
                            " in",
                            " the",
                            " media",
                            ",",
                            " but",
                            " he",
                            " knows",
                            " the",
                            " Browns",
                            ".",
                            " He",
                            " was",
                            " a",
                            " high",
                            "-",
                            "ranking",
                            " personnel",
                            " man",
                            " in",
                            " Cleveland",
                            " from",
                            " 1987",
                            " until",
                            " the",
                            " franchise",
                            "'s",
                            " relocation",
                            " in",
                            " 1996",
                            ".",
                            " He",
                            " was",
                            " promoted",
                            " to",
                            " director",
                            " of",
                            " player"
                        ],
                        "dataIndex": null,
                        "index": "65294",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.429,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.429,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:41.980Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 49.996,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84094",
            "description": " key phrases related to understanding and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4251583054378686,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84094",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:01.279Z",
                "maxActApprox": 28.939,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84094,
                    78151,
                    32877,
                    37659,
                    84155,
                    86099,
                    97952,
                    51733,
                    92060,
                    2714,
                    8853,
                    60265,
                    94670,
                    8840,
                    97443,
                    10381,
                    70356,
                    41142,
                    91698,
                    70016,
                    97097,
                    87661,
                    37621,
                    70844,
                    98227
                ],
                "topkCosSimValues": [
                    1,
                    0.5079,
                    0.4396,
                    0.4299,
                    0.4101,
                    0.4019,
                    0.3989,
                    0.3814,
                    0.3618,
                    0.3607,
                    0.3587,
                    0.3476,
                    0.3395,
                    0.3346,
                    0.3224,
                    0.3223,
                    0.3176,
                    0.3119,
                    0.3104,
                    0.3095,
                    0.3055,
                    0.3053,
                    0.3046,
                    0.3031,
                    0.3021
                ],
                "neuron_alignment_indices": [
                    373,
                    545,
                    51
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.104,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    498,
                    687,
                    508
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.017,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.016,
                    0.016
                ],
                "correlated_features_indices": [
                    84099,
                    84087,
                    84115
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.004,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "abouts",
                    " Andromeda",
                    " promot",
                    " ({",
                    "venge",
                    " promotions",
                    " tolerated",
                    " Delivery",
                    " whine",
                    "Delivery"
                ],
                "neg_values": [
                    -0.742,
                    -0.622,
                    -0.611,
                    -0.58,
                    -0.579,
                    -0.579,
                    -0.579,
                    -0.573,
                    -0.563,
                    -0.559
                ],
                "pos_str": [
                    "chwitz",
                    "ithmetic",
                    "Firstly",
                    " Insight",
                    "\u0138\u013c",
                    "Study",
                    "ibrary",
                    " firsthand",
                    " delve",
                    "uart"
                ],
                "pos_values": [
                    0.891,
                    0.753,
                    0.733,
                    0.732,
                    0.719,
                    0.707,
                    0.689,
                    0.672,
                    0.669,
                    0.66
                ],
                "frac_nonzero": 0.00047,
                "freq_hist_data_bar_heights": [
                    420,
                    259,
                    192,
                    146,
                    79,
                    88,
                    64,
                    31,
                    33,
                    26,
                    23,
                    7,
                    13,
                    9,
                    7,
                    8,
                    5,
                    7,
                    2,
                    6,
                    3,
                    5,
                    2,
                    3,
                    1,
                    4,
                    3,
                    3,
                    2,
                    3,
                    0,
                    1,
                    1,
                    1,
                    2,
                    1,
                    2,
                    1,
                    4,
                    0,
                    0,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.291,
                    0.87,
                    1.448,
                    2.027,
                    2.606,
                    3.184,
                    3.763,
                    4.342,
                    4.921,
                    5.499,
                    6.078,
                    6.657,
                    7.236,
                    7.814,
                    8.393,
                    8.972,
                    9.551,
                    10.129,
                    10.708,
                    11.287,
                    11.866,
                    12.444,
                    13.023,
                    13.602,
                    14.181,
                    14.759,
                    15.338,
                    15.917,
                    16.496,
                    17.074,
                    17.653,
                    18.232,
                    18.811,
                    19.389,
                    19.968,
                    20.547,
                    21.126,
                    21.704,
                    22.283,
                    22.862,
                    23.441,
                    24.019,
                    24.598,
                    25.177,
                    25.756,
                    26.334,
                    26.913,
                    27.492,
                    28.071,
                    28.649
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    4,
                    8,
                    17,
                    35,
                    56,
                    101,
                    206,
                    332,
                    511,
                    724,
                    1125,
                    1434,
                    1920,
                    2484,
                    3028,
                    3263,
                    3778,
                    3999,
                    3946,
                    3748,
                    3598,
                    3154,
                    2798,
                    2377,
                    1874,
                    1463,
                    1231,
                    882,
                    646,
                    500,
                    342,
                    237,
                    140,
                    114,
                    67,
                    41,
                    30,
                    24,
                    9,
                    3,
                    2,
                    3,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.726,
                    -0.693,
                    -0.661,
                    -0.628,
                    -0.595,
                    -0.563,
                    -0.53,
                    -0.497,
                    -0.465,
                    -0.432,
                    -0.399,
                    -0.367,
                    -0.334,
                    -0.301,
                    -0.269,
                    -0.236,
                    -0.203,
                    -0.171,
                    -0.138,
                    -0.105,
                    -0.073,
                    -0.04,
                    -0.007,
                    0.025,
                    0.058,
                    0.091,
                    0.123,
                    0.156,
                    0.189,
                    0.221,
                    0.254,
                    0.287,
                    0.319,
                    0.352,
                    0.385,
                    0.417,
                    0.45,
                    0.483,
                    0.515,
                    0.548,
                    0.581,
                    0.613,
                    0.646,
                    0.679,
                    0.711,
                    0.744,
                    0.777,
                    0.809,
                    0.842,
                    0.875
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases indicating the necessity of understanding or awareness regarding specific topics",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " key phrases related to understanding and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyginsyr32c410exmyy8date",
                        "tokens": [
                            " not",
                            " successfully",
                            " serve",
                            " in",
                            " that",
                            " capacity",
                            " because",
                            " they",
                            " lack",
                            " a",
                            " particular",
                            " form",
                            " of",
                            " memory",
                            " that",
                            " is",
                            " needed",
                            ".",
                            " My",
                            " colleague",
                            " pointed",
                            " out",
                            " that",
                            " Daniel",
                            " D",
                            "ennett",
                            ",",
                            " a",
                            " philosopher",
                            " and",
                            " scientist",
                            " from",
                            " Tu",
                            "fts",
                            " University",
                            " has",
                            " stated",
                            " unamb",
                            "ig",
                            "uously",
                            " that",
                            " he",
                            " was",
                            " convinced",
                            " that",
                            " dogs",
                            " have",
                            " no",
                            " epis",
                            "odic",
                            " memory",
                            ",",
                            " and",
                            " this",
                            " is",
                            " a",
                            " viewpoint",
                            " which",
                            " is",
                            " shared",
                            " by",
                            " a",
                            " number",
                            " of",
                            " other",
                            " philosophers",
                            " and",
                            " some",
                            " behavioral",
                            " scientists",
                            ".",
                            "\n",
                            "\n",
                            "To",
                            " understand",
                            " what",
                            " he",
                            " meant",
                            " you",
                            " must",
                            " first",
                            " know",
                            " that",
                            " there",
                            " are",
                            " many",
                            " types",
                            " of",
                            " memory",
                            ".",
                            " Psych",
                            "ologists",
                            " often",
                            " start",
                            " by",
                            " dividing",
                            " memory",
                            " into",
                            " to",
                            " large",
                            " group",
                            "ings",
                            " that",
                            " they",
                            " call",
                            " \u00e2\u0122",
                            "\u013e",
                            "expl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "impl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " memory",
                            ".",
                            " The",
                            " easiest",
                            " way",
                            " to",
                            " distinguish",
                            " these",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "84094",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.939,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.336,
                            26.047,
                            28.939,
                            15.661,
                            8.512,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.887,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.751
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:07.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.939,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyginsys32c710exukpqa833",
                        "tokens": [
                            " not",
                            " successfully",
                            " serve",
                            " in",
                            " that",
                            " capacity",
                            " because",
                            " they",
                            " lack",
                            " a",
                            " particular",
                            " form",
                            " of",
                            " memory",
                            " that",
                            " is",
                            " needed",
                            ".",
                            " My",
                            " colleague",
                            " pointed",
                            " out",
                            " that",
                            " Daniel",
                            " D",
                            "ennett",
                            ",",
                            " a",
                            " philosopher",
                            " and",
                            " scientist",
                            " from",
                            " Tu",
                            "fts",
                            " University",
                            " has",
                            " stated",
                            " unamb",
                            "ig",
                            "uously",
                            " that",
                            " he",
                            " was",
                            " convinced",
                            " that",
                            " dogs",
                            " have",
                            " no",
                            " epis",
                            "odic",
                            " memory",
                            ",",
                            " and",
                            " this",
                            " is",
                            " a",
                            " viewpoint",
                            " which",
                            " is",
                            " shared",
                            " by",
                            " a",
                            " number",
                            " of",
                            " other",
                            " philosophers",
                            " and",
                            " some",
                            " behavioral",
                            " scientists",
                            ".",
                            "\n",
                            "\n",
                            "To",
                            " understand",
                            " what",
                            " he",
                            " meant",
                            " you",
                            " must",
                            " first",
                            " know",
                            " that",
                            " there",
                            " are",
                            " many",
                            " types",
                            " of",
                            " memory",
                            ".",
                            " Psych",
                            "ologists",
                            " often",
                            " start",
                            " by",
                            " dividing",
                            " memory",
                            " into",
                            " to",
                            " large",
                            " group",
                            "ings",
                            " that",
                            " they",
                            " call",
                            " \u00e2\u0122",
                            "\u013e",
                            "expl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "impl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " memory",
                            ".",
                            " The",
                            " easiest",
                            " way",
                            " to",
                            " distinguish",
                            " these",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "84094",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.939,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.336,
                            26.047,
                            28.939,
                            15.661,
                            8.512,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.887,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.751
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:07.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.939,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyginsyt32cp10ex4mbu8jkq",
                        "tokens": [
                            " not",
                            " successfully",
                            " serve",
                            " in",
                            " that",
                            " capacity",
                            " because",
                            " they",
                            " lack",
                            " a",
                            " particular",
                            " form",
                            " of",
                            " memory",
                            " that",
                            " is",
                            " needed",
                            ".",
                            " My",
                            " colleague",
                            " pointed",
                            " out",
                            " that",
                            " Daniel",
                            " D",
                            "ennett",
                            ",",
                            " a",
                            " philosopher",
                            " and",
                            " scientist",
                            " from",
                            " Tu",
                            "fts",
                            " University",
                            " has",
                            " stated",
                            " unamb",
                            "ig",
                            "uously",
                            " that",
                            " he",
                            " was",
                            " convinced",
                            " that",
                            " dogs",
                            " have",
                            " no",
                            " epis",
                            "odic",
                            " memory",
                            ",",
                            " and",
                            " this",
                            " is",
                            " a",
                            " viewpoint",
                            " which",
                            " is",
                            " shared",
                            " by",
                            " a",
                            " number",
                            " of",
                            " other",
                            " philosophers",
                            " and",
                            " some",
                            " behavioral",
                            " scientists",
                            ".",
                            "\n",
                            "\n",
                            "To",
                            " understand",
                            " what",
                            " he",
                            " meant",
                            " you",
                            " must",
                            " first",
                            " know",
                            " that",
                            " there",
                            " are",
                            " many",
                            " types",
                            " of",
                            " memory",
                            ".",
                            " Psych",
                            "ologists",
                            " often",
                            " start",
                            " by",
                            " dividing",
                            " memory",
                            " into",
                            " to",
                            " large",
                            " group",
                            "ings",
                            " that",
                            " they",
                            " call",
                            " \u00e2\u0122",
                            "\u013e",
                            "expl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "impl",
                            "icit",
                            "\u00e2\u0122",
                            "\u013f",
                            " memory",
                            ".",
                            " The",
                            " easiest",
                            " way",
                            " to",
                            " distinguish",
                            " these",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "84094",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.939,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.336,
                            26.047,
                            28.939,
                            15.661,
                            8.512,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.887,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.751
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:07.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 23.151,
                        "binMax": 28.939,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3427",
            "description": "concepts related to teaching and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4228908511530368,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3427",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:27.928Z",
                "maxActApprox": 15.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3427,
                    77561,
                    60325,
                    73728,
                    50077,
                    33640,
                    55572,
                    46187,
                    52346,
                    44237,
                    71908,
                    41600,
                    11,
                    70412,
                    53181,
                    83314,
                    42965,
                    79098,
                    21161,
                    23492,
                    28490,
                    42202,
                    93440,
                    42300,
                    59028
                ],
                "topkCosSimValues": [
                    1,
                    0.5752,
                    0.5313,
                    0.518,
                    0.4759,
                    0.4686,
                    0.4422,
                    0.3923,
                    0.391,
                    0.3864,
                    0.3785,
                    0.3768,
                    0.3757,
                    0.3679,
                    0.367,
                    0.367,
                    0.3629,
                    0.3589,
                    0.3481,
                    0.3475,
                    0.3419,
                    0.3416,
                    0.3379,
                    0.3346,
                    0.3338
                ],
                "neuron_alignment_indices": [
                    635,
                    603,
                    263
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.094,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    263,
                    236,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    3457,
                    3415,
                    3391
                ],
                "correlated_features_pearson": [
                    0.054,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.054,
                    0.009,
                    0.001
                ],
                "neg_str": [
                    "Rum",
                    "storm",
                    "inqu",
                    " Inqu",
                    "estate",
                    "luster",
                    " inquiries",
                    " Noel",
                    " Bellev",
                    " Graves"
                ],
                "neg_values": [
                    -0.653,
                    -0.639,
                    -0.636,
                    -0.612,
                    -0.604,
                    -0.598,
                    -0.595,
                    -0.589,
                    -0.588,
                    -0.586
                ],
                "pos_str": [
                    " versatility",
                    " ropes",
                    " prowess",
                    "agy",
                    " horizont",
                    " ingenuity",
                    "alore",
                    "emade",
                    " vectors",
                    " flexibility"
                ],
                "pos_values": [
                    0.9,
                    0.817,
                    0.79,
                    0.753,
                    0.746,
                    0.734,
                    0.699,
                    0.698,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00055,
                "freq_hist_data_bar_heights": [
                    266,
                    194,
                    153,
                    123,
                    145,
                    105,
                    91,
                    85,
                    57,
                    50,
                    46,
                    43,
                    51,
                    29,
                    23,
                    30,
                    31,
                    15,
                    26,
                    22,
                    20,
                    8,
                    9,
                    10,
                    12,
                    7,
                    6,
                    6,
                    6,
                    6,
                    7,
                    8,
                    4,
                    6,
                    0,
                    3,
                    2,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.164,
                    0.483,
                    0.802,
                    1.121,
                    1.439,
                    1.758,
                    2.077,
                    2.396,
                    2.715,
                    3.033,
                    3.352,
                    3.671,
                    3.99,
                    4.308,
                    4.627,
                    4.946,
                    5.265,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.858,
                    7.177,
                    7.496,
                    7.815,
                    8.133,
                    8.452,
                    8.771,
                    9.09,
                    9.408,
                    9.727,
                    10.046,
                    10.365,
                    10.683,
                    11.002,
                    11.321,
                    11.64,
                    11.958,
                    12.277,
                    12.596,
                    12.915,
                    13.233,
                    13.552,
                    13.871,
                    14.19,
                    14.508,
                    14.827,
                    15.146,
                    15.465,
                    15.784
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    6,
                    21,
                    29,
                    57,
                    67,
                    144,
                    219,
                    332,
                    505,
                    720,
                    983,
                    1366,
                    1739,
                    2245,
                    2684,
                    3097,
                    3501,
                    3914,
                    3820,
                    3809,
                    3646,
                    3331,
                    2951,
                    2520,
                    2074,
                    1696,
                    1302,
                    1023,
                    739,
                    528,
                    402,
                    246,
                    194,
                    117,
                    80,
                    50,
                    29,
                    18,
                    14,
                    10,
                    10,
                    6,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.638,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.203,
                    -0.172,
                    -0.141,
                    -0.11,
                    -0.079,
                    -0.048,
                    -0.016,
                    0.015,
                    0.046,
                    0.077,
                    0.108,
                    0.139,
                    0.17,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.418,
                    0.449,
                    0.48,
                    0.511,
                    0.542,
                    0.574,
                    0.605,
                    0.636,
                    0.667,
                    0.698,
                    0.729,
                    0.76,
                    0.791,
                    0.822,
                    0.853,
                    0.884
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and instructions related to methods and processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to teaching and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf154kdwgm10ex7gzz8956",
                        "tokens": [
                            " Al",
                            "inea",
                            " outside",
                            " Chicago",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " chance",
                            " to",
                            " present",
                            " their",
                            " cooking",
                            " in",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " disc",
                            "erning",
                            " food",
                            " city",
                            " without",
                            " the",
                            " full",
                            "-",
                            "time",
                            " commitment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " can",
                            "'t",
                            " tell",
                            " you",
                            " how",
                            " many",
                            " chefs",
                            " have",
                            " said",
                            " to",
                            " me",
                            ",",
                            " '",
                            "Yeah",
                            ",",
                            " you",
                            "'re",
                            " a",
                            " big",
                            " fish",
                            " in",
                            " a",
                            " small",
                            " pond",
                            ".",
                            " The",
                            " only",
                            " reason",
                            " you",
                            "'re",
                            " so",
                            " popular",
                            " is",
                            " because",
                            " you",
                            "'re",
                            " in",
                            " the",
                            " Midwest",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " In",
                            " a",
                            " way",
                            ",",
                            " we",
                            "'re",
                            " am",
                            "ped",
                            " up",
                            ",\"",
                            " A",
                            "chat",
                            "z",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " want",
                            " to",
                            " introduce",
                            " Al",
                            "inea",
                            " food",
                            " to",
                            " the",
                            " j",
                            "aded",
                            " New",
                            " Yorker",
                            ".",
                            " We",
                            "'re",
                            " going",
                            " to",
                            " show",
                            " New",
                            " Yorkers",
                            " what",
                            " Chicago",
                            " food",
                            " is",
                            " all",
                            " about",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " collaboration"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.943,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            1.683,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.943,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgn10exy3t5v2tt",
                        "tokens": [
                            " has",
                            " come",
                            " to",
                            " this",
                            " particular",
                            " point",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Load",
                            " third",
                            " party",
                            " embed",
                            "\n",
                            "\n",
                            "As",
                            " an",
                            " avid",
                            " bike",
                            ",",
                            " parks",
                            " and",
                            " neighborhood",
                            " advocate",
                            ",",
                            " Ford",
                            " has",
                            " been",
                            " fighting",
                            " the",
                            " decline",
                            " of",
                            " Detroit",
                            " for",
                            " years",
                            ".",
                            " To",
                            " see",
                            " his",
                            " hometown",
                            " become",
                            " trendy",
                            " with",
                            " everyone",
                            " from",
                            " tech",
                            " developers",
                            " to",
                            " hip",
                            "ster",
                            " craft",
                            "-",
                            "l",
                            "iqu",
                            "or",
                            " dist",
                            "ill",
                            "ers",
                            " makes",
                            " him",
                            " laugh",
                            " with",
                            " joy",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Being",
                            " a",
                            " unique",
                            " individual",
                            " showcasing",
                            " your",
                            " talent",
                            " is",
                            " like",
                            " the",
                            " new",
                            " hot",
                            " thing",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Everybody",
                            " wants",
                            " to",
                            " show",
                            " us",
                            " what",
                            " they",
                            " can",
                            " do",
                            ".",
                            " People",
                            " are",
                            " coming",
                            " here",
                            " from",
                            " all",
                            " over",
                            " the",
                            " country",
                            ",",
                            " because",
                            " of",
                            " the",
                            " access",
                            " to",
                            " material",
                            ",",
                            " talent",
                            " and",
                            " overall",
                            " attitude",
                            " to",
                            " get"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.881,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.746,
                            1.82,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.881,
                            4.034,
                            4.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgo10exkj0oeyt1",
                        "tokens": [
                            " I",
                            " would",
                            " love",
                            " to",
                            " show",
                            " how",
                            " the",
                            " card",
                            " handle",
                            " but",
                            " I",
                            "'m",
                            " not",
                            " really",
                            " good",
                            " a",
                            " that",
                            ",",
                            " this",
                            " video",
                            " is",
                            " the",
                            " best",
                            " i",
                            " could",
                            " do",
                            "...",
                            " Sorry",
                            " :(",
                            " https",
                            "://",
                            "www",
                            ".",
                            "youtube",
                            ".",
                            "com",
                            "/",
                            "watch",
                            "?",
                            "v",
                            "=",
                            "U",
                            "An",
                            "8",
                            "g",
                            "U",
                            "5",
                            "r",
                            "61",
                            "s",
                            " ***",
                            " #",
                            "Le",
                            " Website",
                            " To",
                            " make",
                            " all",
                            " this",
                            " a",
                            " little",
                            " less",
                            " complicated",
                            " i",
                            " set",
                            " up",
                            " a",
                            " website",
                            " with",
                            " the",
                            " very",
                            " original",
                            " and",
                            " thought",
                            "-",
                            "through",
                            " name",
                            " [",
                            "L",
                            "OL",
                            "Playing",
                            "C",
                            "ards",
                            ".",
                            "com",
                            "](",
                            "http",
                            "://",
                            "www",
                            ".",
                            "lol",
                            "playing",
                            "cards",
                            ".",
                            "com",
                            "/",
                            ").",
                            " here",
                            " are",
                            " some",
                            " screenshots",
                            ":",
                            " Front",
                            " page",
                            " with",
                            " the",
                            " story",
                            " and",
                            " stuff",
                            "s",
                            ":",
                            " http",
                            "://",
                            "i",
                            ".",
                            "imgur",
                            ".",
                            "com",
                            "/",
                            "q",
                            "fy",
                            "B",
                            "10",
                            "Z",
                            ".",
                            "png",
                            " A",
                            " page"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.408,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.408,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "23291",
            "description": "terms related to cognitive function and performance",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4218432996459872,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "23291",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:14:32.844Z",
                "maxActApprox": 76.134,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23291,
                    14641,
                    19318,
                    19029,
                    24358,
                    6238,
                    6523,
                    21089,
                    16115,
                    10998,
                    14714,
                    21166,
                    7780,
                    20285,
                    19680,
                    15005,
                    9008,
                    21952,
                    1528,
                    17733,
                    23522,
                    2606,
                    18872,
                    16572,
                    4611
                ],
                "topkCosSimValues": [
                    1,
                    0.5696,
                    0.524,
                    0.5172,
                    0.4743,
                    0.4621,
                    0.4572,
                    0.4307,
                    0.4292,
                    0.4113,
                    0.3926,
                    0.3854,
                    0.3826,
                    0.3809,
                    0.3803,
                    0.379,
                    0.3772,
                    0.3767,
                    0.3724,
                    0.368,
                    0.3673,
                    0.3657,
                    0.3617,
                    0.3601,
                    0.3598
                ],
                "neuron_alignment_indices": [
                    288,
                    271,
                    578
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.122,
                    0.12
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    271,
                    365,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.018,
                    0.017
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.014,
                    0.017
                ],
                "correlated_features_indices": [
                    23194,
                    23277,
                    23184
                ],
                "correlated_features_pearson": [
                    0.039,
                    0.011,
                    0.002
                ],
                "correlated_features_l1": [
                    0.039,
                    0.011,
                    0.003
                ],
                "neg_str": [
                    "wives",
                    " Mex",
                    "EGA",
                    "encer",
                    "olicited",
                    "ourced",
                    "FORE",
                    " Khe",
                    "arov",
                    "export"
                ],
                "neg_values": [
                    -0.833,
                    -0.727,
                    -0.724,
                    -0.711,
                    -0.69,
                    -0.69,
                    -0.685,
                    -0.675,
                    -0.658,
                    -0.656
                ],
                "pos_str": [
                    " disson",
                    " enh",
                    " impairment",
                    " faculties",
                    " behavioural",
                    " enhancement",
                    " behavi",
                    " impair",
                    " behavioral",
                    " enhancing"
                ],
                "pos_values": [
                    1.391,
                    1.092,
                    1.011,
                    1.003,
                    0.952,
                    0.941,
                    0.879,
                    0.847,
                    0.845,
                    0.844
                ],
                "frac_nonzero": 0.00025,
                "freq_hist_data_bar_heights": [
                    268,
                    157,
                    94,
                    81,
                    58,
                    30,
                    13,
                    4,
                    5,
                    5,
                    3,
                    2,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    4,
                    6,
                    6,
                    8,
                    9,
                    9,
                    6,
                    7,
                    2,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.762,
                    2.285,
                    3.807,
                    5.33,
                    6.853,
                    8.375,
                    9.898,
                    11.421,
                    12.943,
                    14.466,
                    15.989,
                    17.511,
                    19.034,
                    20.557,
                    22.079,
                    23.602,
                    25.125,
                    26.647,
                    28.17,
                    29.693,
                    31.215,
                    32.738,
                    34.261,
                    35.783,
                    37.306,
                    38.829,
                    40.351,
                    41.874,
                    43.397,
                    44.919,
                    46.442,
                    47.965,
                    49.487,
                    51.01,
                    52.533,
                    54.055,
                    55.578,
                    57.101,
                    58.623,
                    60.146,
                    61.669,
                    63.191,
                    64.714,
                    66.237,
                    67.759,
                    69.282,
                    70.805,
                    72.327,
                    73.85,
                    75.373
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    3,
                    6,
                    14,
                    28,
                    50,
                    109,
                    184,
                    370,
                    600,
                    903,
                    1488,
                    2116,
                    2997,
                    3919,
                    4700,
                    4988,
                    5058,
                    4843,
                    4098,
                    3500,
                    2900,
                    2151,
                    1625,
                    1153,
                    859,
                    547,
                    388,
                    250,
                    157,
                    101,
                    61,
                    34,
                    24,
                    14,
                    6,
                    5,
                    1,
                    1,
                    1,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.81,
                    -0.766,
                    -0.721,
                    -0.677,
                    -0.632,
                    -0.588,
                    -0.543,
                    -0.499,
                    -0.455,
                    -0.41,
                    -0.366,
                    -0.321,
                    -0.277,
                    -0.232,
                    -0.188,
                    -0.143,
                    -0.099,
                    -0.054,
                    -0.01,
                    0.035,
                    0.079,
                    0.123,
                    0.168,
                    0.212,
                    0.257,
                    0.301,
                    0.346,
                    0.39,
                    0.435,
                    0.479,
                    0.524,
                    0.568,
                    0.613,
                    0.657,
                    0.702,
                    0.746,
                    0.79,
                    0.835,
                    0.879,
                    0.924,
                    0.968,
                    1.013,
                    1.057,
                    1.102,
                    1.146,
                    1.191,
                    1.235,
                    1.28,
                    1.324,
                    1.369
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cognitive function and performance",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn2pvjm4ydi666c8haxwg0",
                        "tokens": [
                            " asked",
                            " to",
                            " call",
                            " the",
                            " Mant",
                            "eca",
                            " Police",
                            " Department",
                            " at",
                            " (",
                            "209",
                            ")",
                            " 4",
                            "56",
                            "-",
                            "81",
                            "01",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " following",
                            " is",
                            " the",
                            " vehicle",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " description",
                            ",",
                            " along",
                            " with",
                            " their",
                            " license",
                            " plate",
                            " numbers",
                            ":",
                            "\n",
                            "\n",
                            "-",
                            "2008",
                            " Ford",
                            " F",
                            "350",
                            ",",
                            " Oregon",
                            " License",
                            " plate",
                            " number",
                            " Y",
                            "11",
                            "68",
                            "21",
                            "\n",
                            "\n",
                            "-",
                            "Well",
                            "s",
                            " Cargo",
                            " Trailer",
                            ",",
                            " Oregon",
                            " License",
                            " plate",
                            " number",
                            " TF",
                            "11",
                            "44",
                            "\n",
                            "\n",
                            "-",
                            "1964",
                            " VW",
                            " Mini",
                            " Bus",
                            ",",
                            " Oregon",
                            " License",
                            " plate",
                            " number",
                            " Y",
                            "UM",
                            "4",
                            "\n",
                            "\n",
                            "-",
                            "1966",
                            " VW",
                            " Mini",
                            " Bus",
                            ",",
                            " Oregon",
                            " License",
                            " plate",
                            " number",
                            " Y",
                            "UM",
                            "5",
                            "\n",
                            "\n",
                            "-",
                            "1959",
                            " VW",
                            " Mini",
                            " Bus",
                            ",",
                            " Oregon",
                            " License",
                            " plate",
                            " number",
                            " Y",
                            "UM",
                            "6",
                            "<|endoftext|>",
                            "The",
                            " aim",
                            " of",
                            " this",
                            " study",
                            " was",
                            " to",
                            " investigate",
                            " the",
                            " cognitive",
                            " as",
                            " well",
                            " as"
                        ],
                        "dataIndex": null,
                        "index": "23291",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 76.134,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            76.134,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:41.386Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.134,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn2pvjm4yei66664qoz8y9",
                        "tokens": [
                            " (",
                            "or",
                            " cognitive",
                            ")",
                            " thinking",
                            ".",
                            " However",
                            ",",
                            " when",
                            " asked",
                            " a",
                            " moral",
                            " dilemma",
                            " question",
                            " involving",
                            " harm",
                            ",",
                            " women",
                            " were",
                            " significantly",
                            " more",
                            " likely",
                            " to",
                            " use",
                            " de",
                            "ont",
                            "ological",
                            " (",
                            "em",
                            "otional",
                            ")",
                            " thinking",
                            " than",
                            " men",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " current",
                            " findings",
                            " cast",
                            " doubt",
                            " on",
                            " the",
                            " hypothesis",
                            " that",
                            " men",
                            " and",
                            " women",
                            " differ",
                            " in",
                            " terms",
                            " of",
                            " their",
                            " cognitive",
                            " evaluations",
                            " of",
                            " outcomes",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " according",
                            " to",
                            " F",
                            "ries",
                            "d",
                            "orf",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Both",
                            " men",
                            " and",
                            " women",
                            " are",
                            " governed",
                            " by",
                            " lines",
                            " of",
                            " intellect",
                            "\u2014",
                            " women",
                            ":",
                            " additionally",
                            " by",
                            " curves",
                            " of",
                            " emotion",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "<|endoftext|>",
                            "The",
                            " Danish",
                            " ambassador",
                            " to",
                            " Germany",
                            " singled",
                            " out",
                            " the",
                            " US",
                            " for",
                            " criticism",
                            " for",
                            " not",
                            " taking",
                            " more",
                            " refugees",
                            ",",
                            " and",
                            " said",
                            " that",
                            " Dan",
                            "es",
                            " do",
                            " not",
                            " want",
                            " more",
                            " refugees",
                            " than",
                            " they",
                            " already",
                            " have",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "23291",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 73.616,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            73.616,
                            0.273,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            63.968,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:41.386Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.134,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn2pvjm4yfi666yubz51v5",
                        "tokens": [
                            " of",
                            " caffeine",
                            " was",
                            " in",
                            "versely",
                            " associated",
                            " with",
                            " the",
                            " cognitive",
                            " decline",
                            " associated",
                            " with",
                            " aging",
                            " as",
                            " well",
                            " as",
                            " the",
                            " incidence",
                            " of",
                            " Alzheimer",
                            "'s",
                            " disease",
                            ",\"",
                            " Mend",
                            "on",
                            "ca",
                            " and",
                            " C",
                            "un",
                            "ha",
                            " said",
                            " in",
                            " a",
                            " statement",
                            ".",
                            " \"",
                            "This",
                            " was",
                            " paralle",
                            "led",
                            " by",
                            " animal",
                            " studies",
                            " showing",
                            " that",
                            " chronic",
                            " caffeine",
                            " administration",
                            " prevented",
                            " memory",
                            " deterioration",
                            " and",
                            " neuro",
                            "deg",
                            "ener",
                            "ation",
                            " in",
                            " animal",
                            " models",
                            " of",
                            " aging",
                            " and",
                            " of",
                            " Alzheimer",
                            "'s",
                            " disease",
                            ".\"",
                            "\n",
                            "\n",
                            "M",
                            "endon",
                            "ca",
                            " and",
                            " C",
                            "un",
                            "ha",
                            " have",
                            " observed",
                            " one",
                            " of",
                            " the",
                            " most",
                            " prevalent",
                            " complications",
                            " of",
                            " Alzheimer",
                            "'s",
                            " disease",
                            " is",
                            " mood",
                            " change",
                            " --",
                            " especially",
                            " depression",
                            " --",
                            " and",
                            " they",
                            " suggest",
                            " caffeine",
                            " might",
                            " be",
                            " a",
                            " mood",
                            " normal",
                            "izer",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " manager",
                            " of",
                            " an",
                            " Indiana",
                            " Pizza",
                            " Hut",
                            " has",
                            " been",
                            " offered",
                            " his",
                            " job",
                            " back",
                            " after",
                            " claiming",
                            " he",
                            " was",
                            " fired",
                            " for",
                            " refusing"
                        ],
                        "dataIndex": null,
                        "index": "23291",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 73.216,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            73.216,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.034,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:41.386Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.134,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "740",
            "description": "terms related to cognitive activities and abilities",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.42116100535857914,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "740",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:15:33.409Z",
                "maxActApprox": 28.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    740,
                    8273,
                    7053,
                    9637,
                    9630,
                    10316,
                    7147,
                    3708,
                    2311,
                    2442,
                    9506,
                    6691,
                    8475,
                    10627,
                    2414,
                    3611,
                    10198,
                    11163,
                    7459,
                    3290,
                    7533,
                    3261,
                    3578,
                    306,
                    8265
                ],
                "topkCosSimValues": [
                    1,
                    0.415,
                    0.4061,
                    0.3895,
                    0.3517,
                    0.343,
                    0.3342,
                    0.3301,
                    0.3245,
                    0.3187,
                    0.3179,
                    0.3158,
                    0.3146,
                    0.3128,
                    0.3065,
                    0.3055,
                    0.3033,
                    0.2954,
                    0.2931,
                    0.288,
                    0.284,
                    0.269,
                    0.2655,
                    0.2653,
                    0.2636
                ],
                "neuron_alignment_indices": [
                    167,
                    746,
                    107
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.097,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    232,
                    288,
                    48
                ],
                "correlated_neurons_pearson": [
                    0.048,
                    0.04,
                    0.038
                ],
                "correlated_neurons_l1": [
                    0.049,
                    0.048,
                    0.037
                ],
                "correlated_features_indices": [
                    669,
                    707,
                    747
                ],
                "correlated_features_pearson": [
                    0.073,
                    0.024,
                    0.011
                ],
                "correlated_features_l1": [
                    0.073,
                    0.024,
                    0.013
                ],
                "neg_str": [
                    "BACK",
                    " Falk",
                    " Kimber",
                    "BOX",
                    " Belt",
                    " chuck",
                    "ORGE",
                    "MAN",
                    "FIN",
                    " sand"
                ],
                "neg_values": [
                    -0.739,
                    -0.694,
                    -0.647,
                    -0.619,
                    -0.618,
                    -0.615,
                    -0.602,
                    -0.597,
                    -0.596,
                    -0.583
                ],
                "pos_str": [
                    "eties",
                    "ostic",
                    "acists",
                    "acy",
                    "ostics",
                    "acist",
                    "acies",
                    "etics",
                    "emies",
                    "etic"
                ],
                "pos_values": [
                    1.389,
                    1.347,
                    1.285,
                    1.245,
                    1.2,
                    1.176,
                    1.172,
                    1.124,
                    1.12,
                    1.117
                ],
                "frac_nonzero": 0.00178,
                "freq_hist_data_bar_heights": [
                    996,
                    752,
                    585,
                    483,
                    392,
                    367,
                    288,
                    220,
                    219,
                    211,
                    142,
                    135,
                    97,
                    98,
                    78,
                    63,
                    39,
                    35,
                    36,
                    34,
                    39,
                    33,
                    22,
                    23,
                    21,
                    27,
                    23,
                    16,
                    22,
                    20,
                    16,
                    15,
                    10,
                    9,
                    5,
                    3,
                    6,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.284,
                    0.852,
                    1.42,
                    1.988,
                    2.556,
                    3.123,
                    3.691,
                    4.259,
                    4.827,
                    5.395,
                    5.963,
                    6.531,
                    7.099,
                    7.666,
                    8.234,
                    8.802,
                    9.37,
                    9.938,
                    10.506,
                    11.074,
                    11.641,
                    12.209,
                    12.777,
                    13.345,
                    13.913,
                    14.481,
                    15.049,
                    15.617,
                    16.184,
                    16.752,
                    17.32,
                    17.888,
                    18.456,
                    19.024,
                    19.592,
                    20.159,
                    20.727,
                    21.295,
                    21.863,
                    22.431,
                    22.999,
                    23.567,
                    24.135,
                    24.702,
                    25.27,
                    25.838,
                    26.406,
                    26.974,
                    27.542,
                    28.11
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    4,
                    10,
                    28,
                    44,
                    115,
                    218,
                    423,
                    686,
                    1234,
                    1903,
                    2896,
                    3763,
                    4590,
                    5215,
                    5173,
                    4769,
                    4232,
                    3338,
                    2620,
                    1965,
                    1513,
                    1168,
                    890,
                    785,
                    585,
                    467,
                    370,
                    319,
                    241,
                    197,
                    119,
                    102,
                    80,
                    59,
                    42,
                    26,
                    20,
                    13,
                    14,
                    1,
                    8,
                    3,
                    1,
                    2,
                    1,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.718,
                    -0.675,
                    -0.633,
                    -0.59,
                    -0.548,
                    -0.505,
                    -0.463,
                    -0.42,
                    -0.377,
                    -0.335,
                    -0.292,
                    -0.25,
                    -0.207,
                    -0.165,
                    -0.122,
                    -0.079,
                    -0.037,
                    0.006,
                    0.048,
                    0.091,
                    0.133,
                    0.176,
                    0.218,
                    0.261,
                    0.304,
                    0.346,
                    0.389,
                    0.431,
                    0.474,
                    0.516,
                    0.559,
                    0.602,
                    0.644,
                    0.687,
                    0.729,
                    0.772,
                    0.814,
                    0.857,
                    0.9,
                    0.942,
                    0.985,
                    1.027,
                    1.07,
                    1.112,
                    1.155,
                    1.197,
                    1.24,
                    1.283,
                    1.325,
                    1.368
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cognitive activities and abilities",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtjkcvz60ti666h1lhhb18",
                        "tokens": [
                            " a",
                            " shot",
                            " of",
                            " cogn",
                            "ac",
                            " to",
                            " make",
                            " it",
                            " more",
                            " pal",
                            "atable",
                            ".",
                            "\n",
                            "\n",
                            "En",
                            "s",
                            "con",
                            "ced",
                            " in",
                            " his",
                            " lounge",
                            " chair",
                            ",",
                            " miles",
                            " away",
                            " from",
                            " the",
                            " cut",
                            " and",
                            " thrust",
                            " of",
                            " life",
                            " on",
                            " the",
                            " \"",
                            "flat",
                            " lands",
                            "\",",
                            " Hans",
                            " finds",
                            " himself",
                            " questioning",
                            " long",
                            "-",
                            "held",
                            " notions",
                            " of",
                            " honour",
                            " and",
                            " mortality",
                            ".",
                            " Up",
                            " here",
                            ",",
                            " the",
                            " snow",
                            " is",
                            " \"",
                            "et",
                            "ernal",
                            "\",",
                            " and",
                            " time",
                            " itself",
                            " becomes",
                            " slippery",
                            " and",
                            " can",
                            " no",
                            " longer",
                            " be",
                            " trusted",
                            " to",
                            " behave",
                            " as",
                            " one",
                            " would",
                            " expect",
                            ".",
                            " This",
                            " is",
                            " indeed",
                            " another",
                            " world",
                            ":",
                            " of",
                            " never",
                            "-",
                            "ending",
                            " soup",
                            " and",
                            " ritual",
                            "ised",
                            " \u2013",
                            " almost",
                            " fetish",
                            "ised",
                            " \u2013",
                            " therm",
                            "ometer",
                            " readings",
                            ";",
                            " of",
                            " rest",
                            " cures",
                            " and",
                            " lectures",
                            " on",
                            " love",
                            "-",
                            "as",
                            "-",
                            "a",
                            "-",
                            "d",
                            "ise",
                            "ase",
                            ";",
                            " of",
                            " petty",
                            " rival",
                            "ries",
                            " and",
                            " g",
                            "iddy",
                            " flirt",
                            "ations"
                        ],
                        "dataIndex": null,
                        "index": "740",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.394,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            28.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:44.992Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 28.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtjkcxz61ei666ii4c6xsk",
                        "tokens": [
                            " a",
                            " shot",
                            " of",
                            " cogn",
                            "ac",
                            " to",
                            " make",
                            " it",
                            " more",
                            " pal",
                            "atable",
                            ".",
                            "\n",
                            "\n",
                            "En",
                            "s",
                            "con",
                            "ced",
                            " in",
                            " his",
                            " lounge",
                            " chair",
                            ",",
                            " miles",
                            " away",
                            " from",
                            " the",
                            " cut",
                            " and",
                            " thrust",
                            " of",
                            " life",
                            " on",
                            " the",
                            " \"",
                            "flat",
                            " lands",
                            "\",",
                            " Hans",
                            " finds",
                            " himself",
                            " questioning",
                            " long",
                            "-",
                            "held",
                            " notions",
                            " of",
                            " honour",
                            " and",
                            " mortality",
                            ".",
                            " Up",
                            " here",
                            ",",
                            " the",
                            " snow",
                            " is",
                            " \"",
                            "et",
                            "ernal",
                            "\",",
                            " and",
                            " time",
                            " itself",
                            " becomes",
                            " slippery",
                            " and",
                            " can",
                            " no",
                            " longer",
                            " be",
                            " trusted",
                            " to",
                            " behave",
                            " as",
                            " one",
                            " would",
                            " expect",
                            ".",
                            " This",
                            " is",
                            " indeed",
                            " another",
                            " world",
                            ":",
                            " of",
                            " never",
                            "-",
                            "ending",
                            " soup",
                            " and",
                            " ritual",
                            "ised",
                            " \u2013",
                            " almost",
                            " fetish",
                            "ised",
                            " \u2013",
                            " therm",
                            "ometer",
                            " readings",
                            ";",
                            " of",
                            " rest",
                            " cures",
                            " and",
                            " lectures",
                            " on",
                            " love",
                            "-",
                            "as",
                            "-",
                            "a",
                            "-",
                            "d",
                            "ise",
                            "ase",
                            ";",
                            " of",
                            " petty",
                            " rival",
                            "ries",
                            " and",
                            " g",
                            "iddy",
                            " flirt",
                            "ations"
                        ],
                        "dataIndex": null,
                        "index": "740",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.394,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            28.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:44.992Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 22.715,
                        "binMax": 28.394,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtjkcvz60ui666ozejpfrc",
                        "tokens": [
                            " inc",
                            "ogn",
                            "ito",
                            " live",
                            " system",
                            " continues",
                            " today",
                            ",",
                            " January",
                            " 13",
                            ",",
                            " 2016",
                            ",",
                            " with",
                            " the",
                            " RC",
                            "1",
                            " (",
                            "Release",
                            " Candidate",
                            " 1",
                            ")",
                            " build",
                            ",",
                            " which",
                            " is",
                            " now",
                            " available",
                            " for",
                            " download",
                            " and",
                            " testing",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "ails",
                            " 2",
                            ".",
                            "0",
                            " RC",
                            "1",
                            " brings",
                            " a",
                            " great",
                            " number",
                            " of",
                            " changes",
                            " since",
                            " the",
                            " Beta",
                            " build",
                            ",",
                            " among",
                            " which",
                            " we",
                            " can",
                            " mention",
                            " support",
                            " for",
                            " the",
                            " pass",
                            "phrase",
                            " strength",
                            " indicator",
                            " in",
                            " the",
                            " GNOME",
                            " Disk",
                            " Utility",
                            " (",
                            "Dis",
                            "ks",
                            ")",
                            " software",
                            ",",
                            " the",
                            " TOR",
                            " Browser",
                            " 5",
                            ".",
                            "5",
                            " Alpha",
                            " 6",
                            " anonymous",
                            " web",
                            " browser",
                            " based",
                            " on",
                            " the",
                            " Tor",
                            " project",
                            ",",
                            " and",
                            " the",
                            " replacement",
                            " of",
                            " the",
                            " Cl",
                            "aws",
                            " Mail",
                            " app",
                            " with",
                            " the",
                            " I",
                            "ced",
                            "ove",
                            " email",
                            " client",
                            ".",
                            "\n",
                            "\n",
                            "Additionally",
                            ",",
                            " the",
                            " first",
                            " Release",
                            " Candidate",
                            " version",
                            " of",
                            " T",
                            "ails",
                            " 2",
                            ".",
                            "0",
                            ",",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "740",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 26.044,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            26.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:44.992Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 28.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "31668",
            "description": " questions related to learning or techniques",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.41707308088862227,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "31668",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:55:46.146Z",
                "maxActApprox": 37.731,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    31668,
                    40923,
                    24267,
                    44587,
                    19499,
                    37248,
                    21693,
                    12466,
                    42630,
                    35075,
                    29139,
                    42105,
                    27914,
                    46385,
                    2774,
                    37998,
                    9097,
                    10982,
                    48850,
                    5506,
                    1406,
                    45508,
                    17188,
                    12685,
                    23029
                ],
                "topkCosSimValues": [
                    1,
                    0.7366,
                    0.7068,
                    0.7041,
                    0.689,
                    0.6878,
                    0.6812,
                    0.6211,
                    0.6175,
                    0.5816,
                    0.51,
                    0.5098,
                    0.4955,
                    0.4398,
                    0.4242,
                    0.4238,
                    0.4211,
                    0.4201,
                    0.4162,
                    0.4095,
                    0.4054,
                    0.4048,
                    0.395,
                    0.3871,
                    0.3857
                ],
                "neuron_alignment_indices": [
                    534,
                    393,
                    483
                ],
                "neuron_alignment_values": [
                    0.092,
                    0.092,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    236,
                    60,
                    483
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.034,
                    0.032
                ],
                "correlated_neurons_l1": [
                    0.036,
                    0.033,
                    0.03
                ],
                "correlated_features_indices": [
                    31613,
                    31632,
                    31668
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    "Rum",
                    "oubted",
                    "holder",
                    "estate",
                    "icker",
                    "aredevil",
                    "inion",
                    " Tanz",
                    "luster",
                    "ige"
                ],
                "neg_values": [
                    -0.673,
                    -0.646,
                    -0.617,
                    -0.588,
                    -0.581,
                    -0.565,
                    -0.564,
                    -0.563,
                    -0.55,
                    -0.539
                ],
                "pos_str": [
                    "soever",
                    "itzer",
                    " ropes",
                    " efficiently",
                    "ls",
                    "lers",
                    "beit",
                    " feasible",
                    "ells",
                    "itz"
                ],
                "pos_values": [
                    0.943,
                    0.711,
                    0.701,
                    0.695,
                    0.693,
                    0.686,
                    0.676,
                    0.64,
                    0.638,
                    0.636
                ],
                "frac_nonzero": 0.00047,
                "freq_hist_data_bar_heights": [
                    226,
                    131,
                    127,
                    82,
                    94,
                    79,
                    59,
                    53,
                    56,
                    46,
                    51,
                    52,
                    33,
                    27,
                    13,
                    32,
                    35,
                    17,
                    26,
                    28,
                    19,
                    17,
                    13,
                    13,
                    12,
                    15,
                    9,
                    11,
                    9,
                    8,
                    7,
                    7,
                    4,
                    6,
                    7,
                    5,
                    6,
                    4,
                    5,
                    3,
                    5,
                    5,
                    5,
                    2,
                    1,
                    2,
                    2,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.378,
                    1.133,
                    1.888,
                    2.642,
                    3.397,
                    4.151,
                    4.906,
                    5.661,
                    6.415,
                    7.17,
                    7.924,
                    8.679,
                    9.434,
                    10.188,
                    10.943,
                    11.697,
                    12.452,
                    13.207,
                    13.961,
                    14.716,
                    15.47,
                    16.225,
                    16.979,
                    17.734,
                    18.489,
                    19.243,
                    19.998,
                    20.752,
                    21.507,
                    22.262,
                    23.016,
                    23.771,
                    24.525,
                    25.28,
                    26.035,
                    26.789,
                    27.544,
                    28.298,
                    29.053,
                    29.808,
                    30.562,
                    31.317,
                    32.071,
                    32.826,
                    33.581,
                    34.335,
                    35.09,
                    35.844,
                    36.599,
                    37.353
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    2,
                    4,
                    24,
                    29,
                    61,
                    113,
                    172,
                    288,
                    412,
                    663,
                    972,
                    1280,
                    1830,
                    2291,
                    2870,
                    3327,
                    3732,
                    4051,
                    4187,
                    3974,
                    3670,
                    3458,
                    2989,
                    2421,
                    1996,
                    1592,
                    1178,
                    923,
                    594,
                    430,
                    263,
                    180,
                    111,
                    61,
                    40,
                    26,
                    12,
                    11,
                    10,
                    1,
                    5,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.657,
                    -0.624,
                    -0.592,
                    -0.56,
                    -0.527,
                    -0.495,
                    -0.463,
                    -0.431,
                    -0.398,
                    -0.366,
                    -0.334,
                    -0.301,
                    -0.269,
                    -0.237,
                    -0.204,
                    -0.172,
                    -0.14,
                    -0.107,
                    -0.075,
                    -0.043,
                    -0.01,
                    0.022,
                    0.054,
                    0.086,
                    0.119,
                    0.151,
                    0.183,
                    0.216,
                    0.248,
                    0.28,
                    0.313,
                    0.345,
                    0.377,
                    0.41,
                    0.442,
                    0.474,
                    0.506,
                    0.539,
                    0.571,
                    0.603,
                    0.636,
                    0.668,
                    0.7,
                    0.733,
                    0.765,
                    0.797,
                    0.83,
                    0.862,
                    0.894,
                    0.926
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " questions related to learning or techniques",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk665it4tuki666i1by1v5t",
                        "tokens": [
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "They",
                            " where",
                            " (",
                            "sic",
                            ")",
                            " massively",
                            " outnumbered",
                            " and",
                            " out",
                            "gun",
                            "ned",
                            " but",
                            " fearless",
                            " in",
                            " the",
                            " face",
                            " of",
                            " this",
                            " as",
                            " they",
                            " knew",
                            " another",
                            " ISIS",
                            " death",
                            " meant",
                            " saving",
                            " the",
                            " lives",
                            " of",
                            " countless",
                            " civilians",
                            ".",
                            " He",
                            " was",
                            " a",
                            " fearless",
                            " and",
                            " exceptional",
                            " soldier",
                            " as",
                            " well",
                            " a",
                            " great",
                            " man",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "A",
                            " fellow",
                            " Western",
                            " YPG",
                            " fighter",
                            ",",
                            " New",
                            " York",
                            " man",
                            " Robert",
                            " Rose",
                            ",",
                            " said",
                            " he",
                            " was",
                            " heart",
                            "broken",
                            " over",
                            " his",
                            " Australian",
                            " friend",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " death",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "RIP",
                            " to",
                            " my",
                            " he",
                            "val",
                            " (",
                            "friend",
                            ")",
                            " Ash",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mr",
                            " Rose",
                            " posted",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "He",
                            " was",
                            " the",
                            " first",
                            " 1",
                            " when",
                            " I",
                            " got",
                            " in",
                            " country",
                            " to",
                            " teach",
                            " the",
                            " basics",
                            " of",
                            " my",
                            " Ak",
                            " 47",
                            " how",
                            " to",
                            " strip",
                            " it",
                            " assemble",
                            " it",
                            " and",
                            " how"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.731,
                        "maxValueTokenIndex": 119,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.112,
                            0,
                            0,
                            0,
                            37.731,
                            2.228,
                            0,
                            0,
                            2.705,
                            0,
                            0,
                            28.266
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 37.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk665it4tuli66651kv6fk0",
                        "tokens": [
                            " death",
                            " will",
                            " need",
                            " to",
                            " be",
                            " registered",
                            " with",
                            " The",
                            " British",
                            " Columbia",
                            " Vital",
                            " Statistics",
                            " Agency",
                            ",",
                            " where",
                            " a",
                            " disposition",
                            " permit",
                            " will",
                            " be",
                            " issued",
                            " to",
                            " confirm",
                            " where",
                            " the",
                            " body",
                            " will",
                            " be",
                            " buried",
                            ",",
                            " or",
                            " crem",
                            "ated",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " funeral",
                            " home",
                            " is",
                            " not",
                            " moving",
                            " the",
                            " body",
                            ",",
                            " then",
                            " a",
                            " private",
                            " transport",
                            " permit",
                            " must",
                            " be",
                            " applied",
                            " for",
                            " through",
                            " Consumer",
                            " Protection",
                            " BC",
                            ".",
                            " Without",
                            " this",
                            " form",
                            ",",
                            " transporting",
                            " a",
                            " body",
                            " violates",
                            " the",
                            " Fun",
                            "eral",
                            " Services",
                            " Act",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " death",
                            " dou",
                            "la",
                            " can",
                            " also",
                            " teach",
                            " people",
                            " how",
                            " to",
                            " care",
                            " for",
                            " a",
                            " dead",
                            " body",
                            ".",
                            " They",
                            " are",
                            " not",
                            " registered",
                            " funeral",
                            " providers",
                            " and",
                            " cannot",
                            " be",
                            " paid",
                            " to",
                            " wash",
                            " a",
                            " body",
                            ",",
                            " but",
                            " they",
                            " can",
                            " provide",
                            " instruction",
                            " and",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " never",
                            " have",
                            " too",
                            " much",
                            " ice",
                            "\n",
                            "\n",
                            "Dead"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.626,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.626,
                            0.423,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 37.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk665iv4tv7i66648ys75d6",
                        "tokens": [
                            " death",
                            " will",
                            " need",
                            " to",
                            " be",
                            " registered",
                            " with",
                            " The",
                            " British",
                            " Columbia",
                            " Vital",
                            " Statistics",
                            " Agency",
                            ",",
                            " where",
                            " a",
                            " disposition",
                            " permit",
                            " will",
                            " be",
                            " issued",
                            " to",
                            " confirm",
                            " where",
                            " the",
                            " body",
                            " will",
                            " be",
                            " buried",
                            ",",
                            " or",
                            " crem",
                            "ated",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " funeral",
                            " home",
                            " is",
                            " not",
                            " moving",
                            " the",
                            " body",
                            ",",
                            " then",
                            " a",
                            " private",
                            " transport",
                            " permit",
                            " must",
                            " be",
                            " applied",
                            " for",
                            " through",
                            " Consumer",
                            " Protection",
                            " BC",
                            ".",
                            " Without",
                            " this",
                            " form",
                            ",",
                            " transporting",
                            " a",
                            " body",
                            " violates",
                            " the",
                            " Fun",
                            "eral",
                            " Services",
                            " Act",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " death",
                            " dou",
                            "la",
                            " can",
                            " also",
                            " teach",
                            " people",
                            " how",
                            " to",
                            " care",
                            " for",
                            " a",
                            " dead",
                            " body",
                            ".",
                            " They",
                            " are",
                            " not",
                            " registered",
                            " funeral",
                            " providers",
                            " and",
                            " cannot",
                            " be",
                            " paid",
                            " to",
                            " wash",
                            " a",
                            " body",
                            ",",
                            " but",
                            " they",
                            " can",
                            " provide",
                            " instruction",
                            " and",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " never",
                            " have",
                            " too",
                            " much",
                            " ice",
                            "\n",
                            "\n",
                            "Dead"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.626,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.626,
                            0.423,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 30.185,
                        "binMax": 37.731,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "48572",
            "description": "expertise and levels of proficiency in various subjects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4165819386742218,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "48572",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:35:37.044Z",
                "maxActApprox": 31.384,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    48572,
                    89672,
                    75543,
                    6383,
                    46595,
                    233,
                    93004,
                    89896,
                    90210,
                    51137,
                    98011,
                    46877,
                    88114,
                    50417,
                    67713,
                    82603,
                    9389,
                    96322,
                    61546,
                    44262,
                    88716,
                    66888,
                    22392,
                    46537,
                    280
                ],
                "topkCosSimValues": [
                    1,
                    0.602,
                    0.4965,
                    0.4489,
                    0.4483,
                    0.4155,
                    0.41,
                    0.4025,
                    0.3879,
                    0.3793,
                    0.376,
                    0.374,
                    0.373,
                    0.3698,
                    0.3626,
                    0.358,
                    0.3445,
                    0.3444,
                    0.3426,
                    0.3408,
                    0.3252,
                    0.3237,
                    0.3234,
                    0.3195,
                    0.3134
                ],
                "neuron_alignment_indices": [
                    86,
                    288,
                    88
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.102,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    88,
                    568,
                    310
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.007,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.006,
                    0.006
                ],
                "correlated_features_indices": [
                    48619,
                    48657,
                    48563
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    " goodbye",
                    "VILLE",
                    " Sakuya",
                    " Aadhaar",
                    "Flickr",
                    "ktop",
                    "Lago",
                    "mallow",
                    " Gothic",
                    "mable"
                ],
                "neg_values": [
                    -0.658,
                    -0.654,
                    -0.618,
                    -0.612,
                    -0.605,
                    -0.604,
                    -0.59,
                    -0.588,
                    -0.584,
                    -0.577
                ],
                "pos_str": [
                    "ise",
                    "inent",
                    "izations",
                    "icial",
                    "ises",
                    "ition",
                    "ising",
                    "structed",
                    "ices",
                    "iation"
                ],
                "pos_values": [
                    1.23,
                    1.064,
                    0.919,
                    0.903,
                    0.87,
                    0.867,
                    0.821,
                    0.819,
                    0.817,
                    0.8
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    28,
                    14,
                    8,
                    6,
                    5,
                    3,
                    6,
                    5,
                    3,
                    2,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.318,
                    0.946,
                    1.573,
                    2.201,
                    2.828,
                    3.456,
                    4.084,
                    4.711,
                    5.339,
                    5.966,
                    6.594,
                    7.222,
                    7.849,
                    8.477,
                    9.104,
                    9.732,
                    10.36,
                    10.987,
                    11.615,
                    12.242,
                    12.87,
                    13.498,
                    14.125,
                    14.753,
                    15.38,
                    16.008,
                    16.636,
                    17.263,
                    17.891,
                    18.519,
                    19.146,
                    19.774,
                    20.401,
                    21.029,
                    21.657,
                    22.284,
                    22.912,
                    23.539,
                    24.167,
                    24.795,
                    25.422,
                    26.05,
                    26.677,
                    27.305,
                    27.933,
                    28.56,
                    29.188,
                    29.815,
                    30.443,
                    31.071
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    7,
                    11,
                    26,
                    40,
                    81,
                    172,
                    302,
                    530,
                    867,
                    1410,
                    1860,
                    2643,
                    3244,
                    4039,
                    4336,
                    4548,
                    4692,
                    4344,
                    3880,
                    3220,
                    2664,
                    2064,
                    1474,
                    1075,
                    763,
                    602,
                    422,
                    281,
                    190,
                    135,
                    98,
                    75,
                    46,
                    34,
                    30,
                    19,
                    15,
                    7,
                    3,
                    2,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.639,
                    -0.601,
                    -0.563,
                    -0.526,
                    -0.488,
                    -0.45,
                    -0.412,
                    -0.374,
                    -0.337,
                    -0.299,
                    -0.261,
                    -0.223,
                    -0.186,
                    -0.148,
                    -0.11,
                    -0.072,
                    -0.035,
                    0.003,
                    0.041,
                    0.079,
                    0.116,
                    0.154,
                    0.192,
                    0.23,
                    0.267,
                    0.305,
                    0.343,
                    0.381,
                    0.418,
                    0.456,
                    0.494,
                    0.532,
                    0.569,
                    0.607,
                    0.645,
                    0.683,
                    0.72,
                    0.758,
                    0.796,
                    0.834,
                    0.871,
                    0.909,
                    0.947,
                    0.985,
                    1.022,
                    1.06,
                    1.098,
                    1.136,
                    1.173,
                    1.211
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "expertise and levels of proficiency in various subjects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to expertise and certifications in various fields",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghab0tc43710exh5qo9h2e",
                        "tokens": [
                            " Memorial",
                            " Stones",
                            " Stage",
                            " 5",
                            " Expert",
                            " \u2013",
                            " 4",
                            "*",
                            " Aer",
                            "os",
                            "mith",
                            " Det",
                            "ector",
                            "\n",
                            "\n",
                            "\u2013",
                            " 4",
                            "*",
                            " Stage",
                            " 6",
                            " Expert",
                            " \u2013",
                            " JJ",
                            "BA",
                            " Scene",
                            " +",
                            " 400",
                            " Memorial",
                            " Stones",
                            " +",
                            " 3",
                            " Jump",
                            " Or",
                            "bs",
                            "\n",
                            "\n",
                            "Point",
                            " Shop",
                            " Clear",
                            "\n",
                            "\n",
                            "The",
                            " store",
                            " has",
                            " a",
                            " ton",
                            " of",
                            " good",
                            " stuff",
                            " in",
                            " it",
                            ",",
                            " buy",
                            " what",
                            " you",
                            " want",
                            "/",
                            "need",
                            " and",
                            " if",
                            " needed",
                            " you",
                            " can",
                            " keep",
                            " farming",
                            " the",
                            " event",
                            " for",
                            " Power",
                            " Up",
                            " G",
                            "acha",
                            " Tickets",
                            ".",
                            " This",
                            " event",
                            " is",
                            " a",
                            " great",
                            " one",
                            " to",
                            " farm",
                            " though",
                            " so",
                            " if",
                            " you",
                            " do",
                            " happen",
                            " to",
                            " clear",
                            " out",
                            " the",
                            " store",
                            " then",
                            " that",
                            " wouldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " be",
                            " a",
                            " surprise",
                            "!",
                            "\n",
                            "\n",
                            "Each",
                            " day",
                            " there",
                            " will",
                            " be",
                            " daily",
                            " store",
                            " items",
                            ",",
                            " these",
                            " items",
                            " will",
                            " only",
                            " be",
                            " available",
                            " for",
                            " 24",
                            " hours",
                            " then",
                            " they",
                            " will",
                            " switch"
                        ],
                        "dataIndex": null,
                        "index": "48572",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.384,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            31.384,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.962,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:38.512Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.384,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghab0uc43j10ex8vmqf394",
                        "tokens": [
                            " Memorial",
                            " Stones",
                            " Stage",
                            " 5",
                            " Expert",
                            " \u2013",
                            " 4",
                            "*",
                            " Aer",
                            "os",
                            "mith",
                            " Det",
                            "ector",
                            "\n",
                            "\n",
                            "\u2013",
                            " 4",
                            "*",
                            " Stage",
                            " 6",
                            " Expert",
                            " \u2013",
                            " JJ",
                            "BA",
                            " Scene",
                            " +",
                            " 400",
                            " Memorial",
                            " Stones",
                            " +",
                            " 3",
                            " Jump",
                            " Or",
                            "bs",
                            "\n",
                            "\n",
                            "Point",
                            " Shop",
                            " Clear",
                            "\n",
                            "\n",
                            "The",
                            " store",
                            " has",
                            " a",
                            " ton",
                            " of",
                            " good",
                            " stuff",
                            " in",
                            " it",
                            ",",
                            " buy",
                            " what",
                            " you",
                            " want",
                            "/",
                            "need",
                            " and",
                            " if",
                            " needed",
                            " you",
                            " can",
                            " keep",
                            " farming",
                            " the",
                            " event",
                            " for",
                            " Power",
                            " Up",
                            " G",
                            "acha",
                            " Tickets",
                            ".",
                            " This",
                            " event",
                            " is",
                            " a",
                            " great",
                            " one",
                            " to",
                            " farm",
                            " though",
                            " so",
                            " if",
                            " you",
                            " do",
                            " happen",
                            " to",
                            " clear",
                            " out",
                            " the",
                            " store",
                            " then",
                            " that",
                            " wouldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " be",
                            " a",
                            " surprise",
                            "!",
                            "\n",
                            "\n",
                            "Each",
                            " day",
                            " there",
                            " will",
                            " be",
                            " daily",
                            " store",
                            " items",
                            ",",
                            " these",
                            " items",
                            " will",
                            " only",
                            " be",
                            " available",
                            " for",
                            " 24",
                            " hours",
                            " then",
                            " they",
                            " will",
                            " switch"
                        ],
                        "dataIndex": null,
                        "index": "48572",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.384,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            31.384,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.962,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:38.512Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.384,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghab0vc43t10exb7d32utx",
                        "tokens": [
                            " Memorial",
                            " Stones",
                            " Stage",
                            " 5",
                            " Expert",
                            " \u2013",
                            " 4",
                            "*",
                            " Aer",
                            "os",
                            "mith",
                            " Det",
                            "ector",
                            "\n",
                            "\n",
                            "\u2013",
                            " 4",
                            "*",
                            " Stage",
                            " 6",
                            " Expert",
                            " \u2013",
                            " JJ",
                            "BA",
                            " Scene",
                            " +",
                            " 400",
                            " Memorial",
                            " Stones",
                            " +",
                            " 3",
                            " Jump",
                            " Or",
                            "bs",
                            "\n",
                            "\n",
                            "Point",
                            " Shop",
                            " Clear",
                            "\n",
                            "\n",
                            "The",
                            " store",
                            " has",
                            " a",
                            " ton",
                            " of",
                            " good",
                            " stuff",
                            " in",
                            " it",
                            ",",
                            " buy",
                            " what",
                            " you",
                            " want",
                            "/",
                            "need",
                            " and",
                            " if",
                            " needed",
                            " you",
                            " can",
                            " keep",
                            " farming",
                            " the",
                            " event",
                            " for",
                            " Power",
                            " Up",
                            " G",
                            "acha",
                            " Tickets",
                            ".",
                            " This",
                            " event",
                            " is",
                            " a",
                            " great",
                            " one",
                            " to",
                            " farm",
                            " though",
                            " so",
                            " if",
                            " you",
                            " do",
                            " happen",
                            " to",
                            " clear",
                            " out",
                            " the",
                            " store",
                            " then",
                            " that",
                            " wouldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " be",
                            " a",
                            " surprise",
                            "!",
                            "\n",
                            "\n",
                            "Each",
                            " day",
                            " there",
                            " will",
                            " be",
                            " daily",
                            " store",
                            " items",
                            ",",
                            " these",
                            " items",
                            " will",
                            " only",
                            " be",
                            " available",
                            " for",
                            " 24",
                            " hours",
                            " then",
                            " they",
                            " will",
                            " switch"
                        ],
                        "dataIndex": null,
                        "index": "48572",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.384,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            31.384,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.962,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:38.512Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 25.108,
                        "binMax": 31.384,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "11943",
            "description": "phrases related to cognitive performance and memory",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.41435496039927777,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "11943",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:32:20.746Z",
                "maxActApprox": 28.509,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11943,
                    9145,
                    6001,
                    1308,
                    287,
                    11566,
                    4719,
                    4540,
                    8496,
                    8612,
                    7013,
                    3334,
                    5606,
                    9134,
                    8705,
                    4556,
                    4854,
                    12251,
                    2086,
                    7163,
                    7320,
                    6108,
                    2910,
                    9884,
                    8341
                ],
                "topkCosSimValues": [
                    1,
                    0.402,
                    0.3796,
                    0.3694,
                    0.354,
                    0.3443,
                    0.3324,
                    0.3322,
                    0.317,
                    0.3076,
                    0.3046,
                    0.3028,
                    0.2886,
                    0.2848,
                    0.2845,
                    0.2797,
                    0.2786,
                    0.2728,
                    0.2724,
                    0.2719,
                    0.2702,
                    0.2698,
                    0.2662,
                    0.2661,
                    0.2628
                ],
                "neuron_alignment_indices": [
                    255,
                    575,
                    540
                ],
                "neuron_alignment_values": [
                    0.124,
                    0.111,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    575,
                    255,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.064,
                    0.061,
                    0.057
                ],
                "correlated_neurons_l1": [
                    0.073,
                    0.063,
                    0.069
                ],
                "correlated_features_indices": [
                    11973,
                    11988,
                    11994
                ],
                "correlated_features_pearson": [
                    0.024,
                    0.014,
                    0.014
                ],
                "correlated_features_l1": [
                    0.026,
                    0.015,
                    0.015
                ],
                "neg_str": [
                    "oil",
                    "govtrack",
                    " Franch",
                    " BaseType",
                    " Konami",
                    "wered",
                    "ounty",
                    "ranch",
                    " Armory",
                    " Bans"
                ],
                "neg_values": [
                    -0.762,
                    -0.756,
                    -0.756,
                    -0.735,
                    -0.7,
                    -0.699,
                    -0.694,
                    -0.688,
                    -0.683,
                    -0.68
                ],
                "pos_str": [
                    " impairment",
                    " stimuli",
                    " cognition",
                    " behaviors",
                    " cognitive",
                    " behaviours",
                    " impaired",
                    " subsc",
                    " comprehension",
                    " skills"
                ],
                "pos_values": [
                    1.104,
                    1.1,
                    1.088,
                    1.079,
                    1.032,
                    1.022,
                    0.989,
                    0.989,
                    0.983,
                    0.977
                ],
                "frac_nonzero": 0.00416,
                "freq_hist_data_bar_heights": [
                    3159,
                    2192,
                    1623,
                    1244,
                    896,
                    728,
                    557,
                    468,
                    336,
                    290,
                    234,
                    206,
                    166,
                    122,
                    128,
                    88,
                    77,
                    75,
                    68,
                    56,
                    54,
                    35,
                    38,
                    33,
                    20,
                    21,
                    21,
                    13,
                    20,
                    13,
                    14,
                    9,
                    6,
                    9,
                    7,
                    5,
                    6,
                    4,
                    9,
                    4,
                    4,
                    9,
                    4,
                    0,
                    3,
                    1,
                    0,
                    0,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.285,
                    0.855,
                    1.425,
                    1.996,
                    2.566,
                    3.136,
                    3.706,
                    4.276,
                    4.847,
                    5.417,
                    5.987,
                    6.557,
                    7.127,
                    7.697,
                    8.268,
                    8.838,
                    9.408,
                    9.978,
                    10.548,
                    11.119,
                    11.689,
                    12.259,
                    12.829,
                    13.399,
                    13.969,
                    14.54,
                    15.11,
                    15.68,
                    16.25,
                    16.82,
                    17.391,
                    17.961,
                    18.531,
                    19.101,
                    19.671,
                    20.241,
                    20.812,
                    21.382,
                    21.952,
                    22.522,
                    23.092,
                    23.663,
                    24.233,
                    24.803,
                    25.373,
                    25.943,
                    26.513,
                    27.084,
                    27.654,
                    28.224
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    4,
                    10,
                    22,
                    24,
                    62,
                    108,
                    166,
                    273,
                    383,
                    571,
                    897,
                    1225,
                    1588,
                    2022,
                    2539,
                    3089,
                    3381,
                    3845,
                    3912,
                    4054,
                    3782,
                    3569,
                    3138,
                    2605,
                    2041,
                    1734,
                    1274,
                    1021,
                    768,
                    536,
                    404,
                    331,
                    210,
                    182,
                    136,
                    85,
                    81,
                    49,
                    34,
                    34,
                    15,
                    17,
                    10,
                    7,
                    3,
                    6,
                    1,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.744,
                    -0.706,
                    -0.669,
                    -0.632,
                    -0.594,
                    -0.557,
                    -0.52,
                    -0.482,
                    -0.445,
                    -0.408,
                    -0.37,
                    -0.333,
                    -0.296,
                    -0.258,
                    -0.221,
                    -0.184,
                    -0.146,
                    -0.109,
                    -0.072,
                    -0.034,
                    0.003,
                    0.04,
                    0.078,
                    0.115,
                    0.152,
                    0.189,
                    0.227,
                    0.264,
                    0.301,
                    0.339,
                    0.376,
                    0.413,
                    0.451,
                    0.488,
                    0.525,
                    0.563,
                    0.6,
                    0.637,
                    0.675,
                    0.712,
                    0.749,
                    0.787,
                    0.824,
                    0.861,
                    0.899,
                    0.936,
                    0.973,
                    1.011,
                    1.048,
                    1.085
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to cognitive performance and memory",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu4z1p9x5pi6665pb0il5t",
                        "tokens": [
                            " study",
                            " from",
                            " a",
                            " correlated",
                            " trait",
                            " (",
                            "educ",
                            "ational",
                            " attainment",
                            ")",
                            " to",
                            " pre",
                            "-",
                            "select",
                            " a",
                            " small",
                            " number",
                            " of",
                            " genetic",
                            " variants",
                            ".",
                            " These",
                            " were",
                            " then",
                            " tested",
                            " for",
                            " association",
                            " with",
                            " cognitive",
                            " performance",
                            " \u2013",
                            " a",
                            " bit",
                            " like",
                            " leveraging",
                            " a",
                            " large",
                            " study",
                            " on",
                            " the",
                            " genetics",
                            " of",
                            " weight",
                            " to",
                            " find",
                            " genes",
                            " for",
                            " diabetes",
                            ".",
                            "\n",
                            "\n",
                            "Three",
                            " genetic",
                            " variants",
                            " (",
                            "out",
                            " of",
                            " thousands",
                            ")",
                            "\n",
                            "\n",
                            "Previously",
                            ",",
                            " using",
                            " a",
                            " genome",
                            "-",
                            "wide",
                            " study",
                            " in",
                            " a",
                            " sample",
                            " of",
                            " 18",
                            ",",
                            "000",
                            " individuals",
                            ",",
                            " we",
                            " could",
                            " not",
                            " identify",
                            " a",
                            " single",
                            " genetic",
                            " variant",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " Using",
                            " the",
                            " new",
                            " proxy",
                            " strategy",
                            ",",
                            " though",
                            ",",
                            " we",
                            " identified",
                            " three",
                            " genetic",
                            " variants",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " As",
                            " expected",
                            " from",
                            " the",
                            " calculation",
                            ",",
                            " the",
                            " effects",
                            " of",
                            " these",
                            " variants",
                            " on",
                            " cognitive",
                            " performance",
                            " are",
                            " tiny",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "11943",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.509,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            5.805,
                            0.873,
                            5.963,
                            8.808,
                            10.212,
                            4.161,
                            0,
                            0,
                            1.251,
                            2.08,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.075,
                            0,
                            28.509,
                            20.21,
                            2.242,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.693,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.27,
                            17.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.194,
                            11.772,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.545,
                            13.583,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:32:23.882Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 28.509,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu4z1p9x5oi66660q91h3k",
                        "tokens": [
                            " study",
                            " from",
                            " a",
                            " correlated",
                            " trait",
                            " (",
                            "educ",
                            "ational",
                            " attainment",
                            ")",
                            " to",
                            " pre",
                            "-",
                            "select",
                            " a",
                            " small",
                            " number",
                            " of",
                            " genetic",
                            " variants",
                            ".",
                            " These",
                            " were",
                            " then",
                            " tested",
                            " for",
                            " association",
                            " with",
                            " cognitive",
                            " performance",
                            " \u2013",
                            " a",
                            " bit",
                            " like",
                            " leveraging",
                            " a",
                            " large",
                            " study",
                            " on",
                            " the",
                            " genetics",
                            " of",
                            " weight",
                            " to",
                            " find",
                            " genes",
                            " for",
                            " diabetes",
                            ".",
                            "\n",
                            "\n",
                            "Three",
                            " genetic",
                            " variants",
                            " (",
                            "out",
                            " of",
                            " thousands",
                            ")",
                            "\n",
                            "\n",
                            "Previously",
                            ",",
                            " using",
                            " a",
                            " genome",
                            "-",
                            "wide",
                            " study",
                            " in",
                            " a",
                            " sample",
                            " of",
                            " 18",
                            ",",
                            "000",
                            " individuals",
                            ",",
                            " we",
                            " could",
                            " not",
                            " identify",
                            " a",
                            " single",
                            " genetic",
                            " variant",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " Using",
                            " the",
                            " new",
                            " proxy",
                            " strategy",
                            ",",
                            " though",
                            ",",
                            " we",
                            " identified",
                            " three",
                            " genetic",
                            " variants",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " As",
                            " expected",
                            " from",
                            " the",
                            " calculation",
                            ",",
                            " the",
                            " effects",
                            " of",
                            " these",
                            " variants",
                            " on",
                            " cognitive",
                            " performance",
                            " are",
                            " tiny",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "11943",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.509,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            5.805,
                            0.873,
                            5.963,
                            8.808,
                            10.212,
                            4.161,
                            0,
                            0,
                            1.251,
                            2.08,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.075,
                            0,
                            28.509,
                            20.21,
                            2.242,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.693,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.27,
                            17.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.194,
                            11.772,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.545,
                            13.583,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:32:23.882Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 28.509,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu4z1q9x63i6664tt6emcu",
                        "tokens": [
                            " study",
                            " from",
                            " a",
                            " correlated",
                            " trait",
                            " (",
                            "educ",
                            "ational",
                            " attainment",
                            ")",
                            " to",
                            " pre",
                            "-",
                            "select",
                            " a",
                            " small",
                            " number",
                            " of",
                            " genetic",
                            " variants",
                            ".",
                            " These",
                            " were",
                            " then",
                            " tested",
                            " for",
                            " association",
                            " with",
                            " cognitive",
                            " performance",
                            " \u2013",
                            " a",
                            " bit",
                            " like",
                            " leveraging",
                            " a",
                            " large",
                            " study",
                            " on",
                            " the",
                            " genetics",
                            " of",
                            " weight",
                            " to",
                            " find",
                            " genes",
                            " for",
                            " diabetes",
                            ".",
                            "\n",
                            "\n",
                            "Three",
                            " genetic",
                            " variants",
                            " (",
                            "out",
                            " of",
                            " thousands",
                            ")",
                            "\n",
                            "\n",
                            "Previously",
                            ",",
                            " using",
                            " a",
                            " genome",
                            "-",
                            "wide",
                            " study",
                            " in",
                            " a",
                            " sample",
                            " of",
                            " 18",
                            ",",
                            "000",
                            " individuals",
                            ",",
                            " we",
                            " could",
                            " not",
                            " identify",
                            " a",
                            " single",
                            " genetic",
                            " variant",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " Using",
                            " the",
                            " new",
                            " proxy",
                            " strategy",
                            ",",
                            " though",
                            ",",
                            " we",
                            " identified",
                            " three",
                            " genetic",
                            " variants",
                            " associated",
                            " with",
                            " cognitive",
                            " performance",
                            ".",
                            " As",
                            " expected",
                            " from",
                            " the",
                            " calculation",
                            ",",
                            " the",
                            " effects",
                            " of",
                            " these",
                            " variants",
                            " on",
                            " cognitive",
                            " performance",
                            " are",
                            " tiny",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "11943",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.509,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            5.805,
                            0.873,
                            5.963,
                            8.808,
                            10.212,
                            4.161,
                            0,
                            0,
                            1.251,
                            2.08,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.075,
                            0,
                            28.509,
                            20.21,
                            2.242,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.693,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.27,
                            17.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.194,
                            11.772,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.545,
                            13.583,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:32:23.882Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 28.509,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36759",
            "description": " actions related to learning and practicing skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4121087000240474,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 13.291,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36759,
                    80530,
                    6057,
                    64733,
                    34954,
                    14052,
                    96770,
                    33115,
                    29063,
                    11105,
                    55382,
                    59850,
                    97527,
                    84712,
                    15165,
                    57852,
                    52248,
                    22083,
                    50986,
                    6850,
                    76062,
                    26071,
                    49673,
                    7364,
                    10485
                ],
                "topkCosSimValues": [
                    1,
                    0.5951,
                    0.5934,
                    0.5701,
                    0.5328,
                    0.4929,
                    0.4908,
                    0.4778,
                    0.4684,
                    0.4549,
                    0.4378,
                    0.4362,
                    0.4357,
                    0.4286,
                    0.428,
                    0.4258,
                    0.4207,
                    0.4182,
                    0.4174,
                    0.417,
                    0.4154,
                    0.4034,
                    0.4003,
                    0.3977,
                    0.396
                ],
                "neuron_alignment_indices": [
                    756,
                    393,
                    447
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.137,
                    0.131
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.061,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.07,
                    0.034
                ],
                "correlated_features_indices": [
                    36790,
                    36840,
                    36787
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.021,
                    0.006,
                    0.003
                ],
                "neg_str": [
                    "ortment",
                    "aran",
                    "emonic",
                    "advertising",
                    "oris",
                    "rin",
                    "hon",
                    "odon",
                    "grad",
                    "arty"
                ],
                "neg_values": [
                    -0.622,
                    -0.585,
                    -0.584,
                    -0.573,
                    -0.57,
                    -0.555,
                    -0.553,
                    -0.553,
                    -0.55,
                    -0.545
                ],
                "pos_str": [
                    " differently",
                    " freely",
                    " separately",
                    " excessively",
                    " directly",
                    " continuously",
                    " blindly",
                    " extensively",
                    " elsewhere",
                    " anyway"
                ],
                "pos_values": [
                    0.846,
                    0.829,
                    0.822,
                    0.779,
                    0.767,
                    0.766,
                    0.765,
                    0.764,
                    0.763,
                    0.759
                ],
                "frac_nonzero": 0.00365,
                "freq_hist_data_bar_heights": [
                    1695,
                    1427,
                    1185,
                    1012,
                    832,
                    711,
                    617,
                    515,
                    484,
                    401,
                    352,
                    293,
                    274,
                    220,
                    195,
                    180,
                    157,
                    135,
                    112,
                    104,
                    75,
                    73,
                    67,
                    54,
                    53,
                    48,
                    34,
                    21,
                    26,
                    21,
                    18,
                    18,
                    15,
                    9,
                    10,
                    4,
                    6,
                    8,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.93,
                    1.196,
                    1.462,
                    1.728,
                    1.994,
                    2.26,
                    2.525,
                    2.791,
                    3.057,
                    3.323,
                    3.589,
                    3.854,
                    4.12,
                    4.386,
                    4.652,
                    4.918,
                    5.184,
                    5.449,
                    5.715,
                    5.981,
                    6.247,
                    6.513,
                    6.779,
                    7.044,
                    7.31,
                    7.576,
                    7.842,
                    8.108,
                    8.373,
                    8.639,
                    8.905,
                    9.171,
                    9.437,
                    9.703,
                    9.968,
                    10.234,
                    10.5,
                    10.766,
                    11.032,
                    11.297,
                    11.563,
                    11.829,
                    12.095,
                    12.361,
                    12.627,
                    12.892,
                    13.158
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    14,
                    18,
                    19,
                    42,
                    76,
                    97,
                    180,
                    250,
                    398,
                    595,
                    849,
                    1222,
                    1681,
                    2166,
                    2679,
                    3186,
                    3622,
                    4005,
                    4027,
                    4002,
                    3965,
                    3469,
                    3043,
                    2447,
                    1988,
                    1546,
                    1160,
                    930,
                    685,
                    499,
                    360,
                    264,
                    190,
                    138,
                    101,
                    80,
                    54,
                    64,
                    28,
                    36,
                    24,
                    17,
                    12,
                    6,
                    8,
                    7,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.608,
                    -0.578,
                    -0.549,
                    -0.519,
                    -0.49,
                    -0.461,
                    -0.431,
                    -0.402,
                    -0.373,
                    -0.343,
                    -0.314,
                    -0.284,
                    -0.255,
                    -0.226,
                    -0.196,
                    -0.167,
                    -0.138,
                    -0.108,
                    -0.079,
                    -0.049,
                    -0.02,
                    0.009,
                    0.039,
                    0.068,
                    0.097,
                    0.127,
                    0.156,
                    0.186,
                    0.215,
                    0.244,
                    0.274,
                    0.303,
                    0.332,
                    0.362,
                    0.391,
                    0.42,
                    0.45,
                    0.479,
                    0.509,
                    0.538,
                    0.567,
                    0.597,
                    0.626,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.773,
                    0.802,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions related to learning and practicing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and typing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmwa335lx10exco67ax55",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa335m610exgnqozkf4",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa535mk10exsw1a50vs",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.633,
                        "binMax": 13.291,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}