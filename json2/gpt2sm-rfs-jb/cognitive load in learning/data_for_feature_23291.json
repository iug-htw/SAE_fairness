{
    "modelId": "gpt2-small",
    "layer": "8-res_fs24576-jb",
    "index": "23291",
    "sourceSetName": "res_fs24576-jb",
    "creatorId": null,
    "createdAt": "2024-06-13T19:14:32.844Z",
    "maxActApprox": 76.134,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        23291,
        14641,
        19318,
        19029,
        24358,
        6238,
        6523,
        21089,
        16115,
        10998,
        14714,
        21166,
        7780,
        20285,
        19680,
        15005,
        9008,
        21952,
        1528,
        17733,
        23522,
        2606,
        18872,
        16572,
        4611
    ],
    "topkCosSimValues": [
        1,
        0.5696,
        0.524,
        0.5172,
        0.4743,
        0.4621,
        0.4572,
        0.4307,
        0.4292,
        0.4113,
        0.3926,
        0.3854,
        0.3826,
        0.3809,
        0.3803,
        0.379,
        0.3772,
        0.3767,
        0.3724,
        0.368,
        0.3673,
        0.3657,
        0.3617,
        0.3601,
        0.3598
    ],
    "neuron_alignment_indices": [
        288,
        271,
        578
    ],
    "neuron_alignment_values": [
        0.153,
        0.122,
        0.12
    ],
    "neuron_alignment_l1": [
        0.007,
        0.006,
        0.006
    ],
    "correlated_neurons_indices": [
        271,
        365,
        288
    ],
    "correlated_neurons_pearson": [
        0.02,
        0.018,
        0.017
    ],
    "correlated_neurons_l1": [
        0.019,
        0.014,
        0.017
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "wives",
        " Mex",
        "EGA",
        "encer",
        "olicited",
        "ourced",
        "FORE",
        " Khe",
        "arov",
        "export"
    ],
    "neg_values": [
        -0.833,
        -0.727,
        -0.724,
        -0.711,
        -0.69,
        -0.69,
        -0.685,
        -0.675,
        -0.658,
        -0.656
    ],
    "pos_str": [
        " disson",
        " enh",
        " impairment",
        " faculties",
        " behavioural",
        " enhancement",
        " behavi",
        " impair",
        " behavioral",
        " enhancing"
    ],
    "pos_values": [
        1.391,
        1.092,
        1.011,
        1.003,
        0.952,
        0.941,
        0.879,
        0.847,
        0.845,
        0.844
    ],
    "frac_nonzero": 0.00025,
    "freq_hist_data_bar_heights": [
        268,
        157,
        94,
        81,
        58,
        30,
        13,
        4,
        5,
        5,
        3,
        2,
        1,
        2,
        0,
        0,
        0,
        0,
        2,
        2,
        2,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        2,
        0,
        1,
        4,
        6,
        6,
        8,
        9,
        9,
        6,
        7,
        2,
        2,
        1
    ],
    "freq_hist_data_bar_values": [
        0.762,
        2.285,
        3.807,
        5.33,
        6.853,
        8.375,
        9.898,
        11.421,
        12.943,
        14.466,
        15.989,
        17.511,
        19.034,
        20.557,
        22.079,
        23.602,
        25.125,
        26.647,
        28.17,
        29.693,
        31.215,
        32.738,
        34.261,
        35.783,
        37.306,
        38.829,
        40.351,
        41.874,
        43.397,
        44.919,
        46.442,
        47.965,
        49.487,
        51.01,
        52.533,
        54.055,
        55.578,
        57.101,
        58.623,
        60.146,
        61.669,
        63.191,
        64.714,
        66.237,
        67.759,
        69.282,
        70.805,
        72.327,
        73.85,
        75.373
    ],
    "logits_hist_data_bar_heights": [
        1,
        0,
        3,
        6,
        14,
        28,
        50,
        109,
        184,
        370,
        600,
        903,
        1488,
        2116,
        2997,
        3919,
        4700,
        4988,
        5058,
        4843,
        4098,
        3500,
        2900,
        2151,
        1625,
        1153,
        859,
        547,
        388,
        250,
        157,
        101,
        61,
        34,
        24,
        14,
        6,
        5,
        1,
        1,
        1,
        2,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        1
    ],
    "logits_hist_data_bar_values": [
        -0.81,
        -0.766,
        -0.721,
        -0.677,
        -0.632,
        -0.588,
        -0.543,
        -0.499,
        -0.455,
        -0.41,
        -0.366,
        -0.321,
        -0.277,
        -0.232,
        -0.188,
        -0.143,
        -0.099,
        -0.054,
        -0.01,
        0.035,
        0.079,
        0.123,
        0.168,
        0.212,
        0.257,
        0.301,
        0.346,
        0.39,
        0.435,
        0.479,
        0.524,
        0.568,
        0.613,
        0.657,
        0.702,
        0.746,
        0.79,
        0.835,
        0.879,
        0.924,
        0.968,
        1.013,
        1.057,
        1.102,
        1.146,
        1.191,
        1.235,
        1.28,
        1.324,
        1.369
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "8-res_fs24576-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.8.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_feature_splitting_experiment",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/8-res_fs24576-jb",
            "checkpoint_path": "checkpoints/cbvk8gtc",
            "use_ghost_grads": true,
            "expansion_factor": 32,
            "hook_point_layer": 8,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.8.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb-feature-splitting",
        "saelensSaeId": "blocks.8.hook_resid_pre_24576",
        "hfRepoId": "jbloom/GPT2-Small-Feature-Splitting-Experiment-Layer-8",
        "hfFolderId": "blocks.8.hook_resid_pre_24576",
        "visibility": "PUBLIC",
        "setName": "res_fs24576-jb",
        "creatorId": "clkht01d40000jv08hvalcvly",
        "hasUmap": false,
        "hasUmapLogSparsity": false,
        "hasUmapClusters": false,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res_fs24576-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "GPT2-Small Feature Splitting Experiment - 24576",
        "type": "Residual Feature Splitting 24576",
        "creatorName": "Joseph Bloom",
        "urls": [],
        "creatorEmail": null,
        "creatorId": "clkht01d40000jv08hvalcvly",
        "releaseName": "gpt2sm-rfs-jb",
        "defaultRange": 1,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": true,
        "showHeadAttribution": false,
        "showUmap": false,
        "serverHost": "https://1ynud2kk7vnhjo-5002.proxy.runpod.net",
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clxdn2pvjm4ydi666c8haxwg0",
            "tokens": [
                " asked",
                " to",
                " call",
                " the",
                " Mant",
                "eca",
                " Police",
                " Department",
                " at",
                " (",
                "209",
                ")",
                " 4",
                "56",
                "-",
                "81",
                "01",
                ".",
                "\n",
                "\n",
                "The",
                " following",
                " is",
                " the",
                " vehicle",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " description",
                ",",
                " along",
                " with",
                " their",
                " license",
                " plate",
                " numbers",
                ":",
                "\n",
                "\n",
                "-",
                "2008",
                " Ford",
                " F",
                "350",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "11",
                "68",
                "21",
                "\n",
                "\n",
                "-",
                "Well",
                "s",
                " Cargo",
                " Trailer",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " TF",
                "11",
                "44",
                "\n",
                "\n",
                "-",
                "1964",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "4",
                "\n",
                "\n",
                "-",
                "1966",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "5",
                "\n",
                "\n",
                "-",
                "1959",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "6",
                "<|endoftext|>",
                "The",
                " aim",
                " of",
                " this",
                " study",
                " was",
                " to",
                " investigate",
                " the",
                " cognitive",
                " as",
                " well",
                " as"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 76.134,
            "maxValueTokenIndex": 123,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                76.134,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4yei66664qoz8y9",
            "tokens": [
                " (",
                "or",
                " cognitive",
                ")",
                " thinking",
                ".",
                " However",
                ",",
                " when",
                " asked",
                " a",
                " moral",
                " dilemma",
                " question",
                " involving",
                " harm",
                ",",
                " women",
                " were",
                " significantly",
                " more",
                " likely",
                " to",
                " use",
                " de",
                "ont",
                "ological",
                " (",
                "em",
                "otional",
                ")",
                " thinking",
                " than",
                " men",
                ".",
                "\n",
                "\n",
                "\u00e2\u0122",
                "\u013e",
                "The",
                " current",
                " findings",
                " cast",
                " doubt",
                " on",
                " the",
                " hypothesis",
                " that",
                " men",
                " and",
                " women",
                " differ",
                " in",
                " terms",
                " of",
                " their",
                " cognitive",
                " evaluations",
                " of",
                " outcomes",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " according",
                " to",
                " F",
                "ries",
                "d",
                "orf",
                ".",
                " \u00e2\u0122",
                "\u013e",
                "Both",
                " men",
                " and",
                " women",
                " are",
                " governed",
                " by",
                " lines",
                " of",
                " intellect",
                "\u2014",
                " women",
                ":",
                " additionally",
                " by",
                " curves",
                " of",
                " emotion",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "<|endoftext|>",
                "The",
                " Danish",
                " ambassador",
                " to",
                " Germany",
                " singled",
                " out",
                " the",
                " US",
                " for",
                " criticism",
                " for",
                " not",
                " taking",
                " more",
                " refugees",
                ",",
                " and",
                " said",
                " that",
                " Dan",
                "es",
                " do",
                " not",
                " want",
                " more",
                " refugees",
                " than",
                " they",
                " already",
                " have",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 73.616,
            "maxValueTokenIndex": 2,
            "minValue": 0,
            "values": [
                0,
                0,
                73.616,
                0.273,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.968,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4yfi666yubz51v5",
            "tokens": [
                " of",
                " caffeine",
                " was",
                " in",
                "versely",
                " associated",
                " with",
                " the",
                " cognitive",
                " decline",
                " associated",
                " with",
                " aging",
                " as",
                " well",
                " as",
                " the",
                " incidence",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                ",\"",
                " Mend",
                "on",
                "ca",
                " and",
                " C",
                "un",
                "ha",
                " said",
                " in",
                " a",
                " statement",
                ".",
                " \"",
                "This",
                " was",
                " paralle",
                "led",
                " by",
                " animal",
                " studies",
                " showing",
                " that",
                " chronic",
                " caffeine",
                " administration",
                " prevented",
                " memory",
                " deterioration",
                " and",
                " neuro",
                "deg",
                "ener",
                "ation",
                " in",
                " animal",
                " models",
                " of",
                " aging",
                " and",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                ".\"",
                "\n",
                "\n",
                "M",
                "endon",
                "ca",
                " and",
                " C",
                "un",
                "ha",
                " have",
                " observed",
                " one",
                " of",
                " the",
                " most",
                " prevalent",
                " complications",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                " is",
                " mood",
                " change",
                " --",
                " especially",
                " depression",
                " --",
                " and",
                " they",
                " suggest",
                " caffeine",
                " might",
                " be",
                " a",
                " mood",
                " normal",
                "izer",
                ".",
                "<|endoftext|>",
                "The",
                " manager",
                " of",
                " an",
                " Indiana",
                " Pizza",
                " Hut",
                " has",
                " been",
                " offered",
                " his",
                " job",
                " back",
                " after",
                " claiming",
                " he",
                " was",
                " fired",
                " for",
                " refusing"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 73.216,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                73.216,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.034,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z5i6668ru6ta31",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 72.604,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.43,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                72.604,
                5.738,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.018,
                0.91,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.402,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                59.811,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 45.68,
            "binMax": 60.907,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4ygi6665qscs9kd",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 72.604,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.43,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                72.604,
                5.738,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.018,
                0.91,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.402,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                59.811,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4yhi666ansequ1v",
            "tokens": [
                " of",
                " these",
                " risks",
                " are",
                " currently",
                " considered",
                " \u00e2\u0122",
                "\u013e",
                "red",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " i",
                ".",
                "e",
                ".,",
                " they",
                " have",
                " both",
                " a",
                " high",
                " likelihood",
                " of",
                " happening",
                " \u2014",
                " defined",
                " as",
                " greater",
                " than",
                " a",
                " 1",
                " percent",
                " chance",
                " of",
                " occurring",
                ",",
                " and",
                " high",
                " stakes",
                " (",
                "i",
                ".",
                "e",
                ".,",
                " death",
                ",",
                " permanent",
                " disability",
                " or",
                " long",
                "-",
                "term",
                " health",
                " impact",
                ")",
                " if",
                " they",
                " do",
                ":",
                " space",
                " radiation",
                ",",
                " visual",
                " impairment",
                ",",
                " cognitive",
                " or",
                " behavioral",
                " conditions",
                ",",
                " the",
                " long",
                "-",
                "term",
                " storage",
                " of",
                " medications",
                ",",
                " inadequate",
                " food",
                " and",
                " nutrition",
                ",",
                " team",
                " performance",
                " issues",
                ",",
                " in",
                "-",
                "flight",
                " medical",
                " conditions",
                ",",
                " user",
                " issues",
                " with",
                " onboard",
                " technology",
                " and",
                " bone",
                " fracture",
                ".",
                " These",
                " are",
                " high",
                " priority",
                " and",
                " \u00e2\u0122",
                "\u013e",
                "really",
                " have",
                " to",
                " get",
                " worked",
                " out",
                "\u00e2\u0122",
                "\u013f",
                " before",
                " we",
                " go",
                " to",
                " Mars",
                ",",
                " said",
                " William",
                " Pal",
                "os"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.644,
            "maxValueTokenIndex": 65,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.644,
                1.482,
                10.065,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z1i666a1ldcsan",
            "tokens": [
                " of",
                " these",
                " risks",
                " are",
                " currently",
                " considered",
                " \u00e2\u0122",
                "\u013e",
                "red",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " i",
                ".",
                "e",
                ".,",
                " they",
                " have",
                " both",
                " a",
                " high",
                " likelihood",
                " of",
                " happening",
                " \u2014",
                " defined",
                " as",
                " greater",
                " than",
                " a",
                " 1",
                " percent",
                " chance",
                " of",
                " occurring",
                ",",
                " and",
                " high",
                " stakes",
                " (",
                "i",
                ".",
                "e",
                ".,",
                " death",
                ",",
                " permanent",
                " disability",
                " or",
                " long",
                "-",
                "term",
                " health",
                " impact",
                ")",
                " if",
                " they",
                " do",
                ":",
                " space",
                " radiation",
                ",",
                " visual",
                " impairment",
                ",",
                " cognitive",
                " or",
                " behavioral",
                " conditions",
                ",",
                " the",
                " long",
                "-",
                "term",
                " storage",
                " of",
                " medications",
                ",",
                " inadequate",
                " food",
                " and",
                " nutrition",
                ",",
                " team",
                " performance",
                " issues",
                ",",
                " in",
                "-",
                "flight",
                " medical",
                " conditions",
                ",",
                " user",
                " issues",
                " with",
                " onboard",
                " technology",
                " and",
                " bone",
                " fracture",
                ".",
                " These",
                " are",
                " high",
                " priority",
                " and",
                " \u00e2\u0122",
                "\u013e",
                "really",
                " have",
                " to",
                " get",
                " worked",
                " out",
                "\u00e2\u0122",
                "\u013f",
                " before",
                " we",
                " go",
                " to",
                " Mars",
                ",",
                " said",
                " William",
                " Pal",
                "os"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.644,
            "maxValueTokenIndex": 65,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.644,
                1.482,
                10.065,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 60.907,
            "binMax": 76.134,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4yii6661ebt3j6i",
            "tokens": [
                " shown",
                " that",
                " our",
                " reasoning",
                " is",
                " riddled",
                " with",
                " cognitive",
                " bugs",
                " and",
                " biases",
                ".",
                " The",
                " confirmation",
                " bias",
                " is",
                " one",
                " of",
                " the",
                " most",
                " insidious",
                ".",
                " We",
                " are",
                " highly",
                " likely",
                " to",
                " believe",
                " or",
                " at",
                " least",
                " accept",
                " and",
                " repeat",
                " statements",
                " that",
                " support",
                " our",
                " established",
                " views",
                ",",
                " even",
                " when",
                " little",
                " or",
                " no",
                " evidence",
                " is",
                " given",
                " to",
                " support",
                " those",
                " statements",
                ".",
                " Yet",
                " we",
                " are",
                " unlikely",
                " to",
                " accept",
                " or",
                " repeat",
                " statements",
                " that",
                " go",
                " counter",
                " to",
                " our",
                " established",
                " views",
                ",",
                " even",
                " when",
                " they",
                " are",
                " well",
                "-",
                "supported",
                " by",
                " evidence",
                ".",
                " This",
                " bias",
                " is",
                " the",
                " engine",
                " that",
                " drives",
                " the",
                " click",
                "-",
                "by",
                "-",
                "click",
                " spread",
                " of",
                " fake",
                " news",
                " and",
                " other",
                " dangerous",
                " nonsense",
                ".",
                "\n",
                "\n",
                "Ten",
                " of",
                " the",
                " best",
                " March",
                " for",
                " Science",
                " signs",
                " \u2013",
                " in",
                " pictures",
                " Read",
                " more",
                "\n",
                "\n",
                "The",
                " second",
                " thing",
                " is",
                " that",
                " humans",
                " are"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.553,
            "maxValueTokenIndex": 7,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.553,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z2i666ndn7k799",
            "tokens": [
                ".",
                "\n",
                "\n",
                "Education",
                " attainment",
                " is",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ",",
                " so",
                " given",
                " these",
                " two",
                " observations",
                ",",
                " we",
                " tested",
                " the",
                " genetic",
                " variants",
                " for",
                " education",
                " attainment",
                " with",
                " their",
                " associations",
                " with",
                " cognitive",
                " performance",
                ",",
                " which",
                " we",
                " report",
                " in",
                " P",
                "NAS",
                " today",
                ".",
                "\n",
                "\n",
                "We",
                " tested",
                " 69",
                " genetic",
                " variants",
                " from",
                " the",
                " educational",
                " attainment",
                " study",
                " (",
                "of",
                " almost",
                " 107",
                ",",
                "000",
                " people",
                ")",
                " in",
                " independent",
                " samples",
                " of",
                " 24",
                ",",
                "000",
                " people",
                " who",
                " had",
                " a",
                " cognitive",
                " performance",
                " score",
                ".",
                " This",
                " two",
                "-",
                "stage",
                " strategy",
                " is",
                " called",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "proxy",
                "-",
                "phen",
                "otype",
                " method",
                "\u00e2\u0122",
                "\u013f",
                " since",
                " educational",
                " attainment",
                " is",
                " a",
                " proxy",
                " phenotype",
                " (",
                "an",
                " observable",
                " characteristic",
                " or",
                " trait",
                ")",
                " for",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "The",
                " essence",
                " of",
                " this",
                " design",
                " was",
                " to",
                " pig",
                "gy",
                "-",
                "back",
                " on",
                " a",
                " much",
                " larger"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.227,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.227,
                2.695,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.267,
                0.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.837,
                5.558,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.36,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 45.68,
            "binMax": 60.907,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvjm4yji666qcybp8hu",
            "tokens": [
                ".",
                "\n",
                "\n",
                "Education",
                " attainment",
                " is",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ",",
                " so",
                " given",
                " these",
                " two",
                " observations",
                ",",
                " we",
                " tested",
                " the",
                " genetic",
                " variants",
                " for",
                " education",
                " attainment",
                " with",
                " their",
                " associations",
                " with",
                " cognitive",
                " performance",
                ",",
                " which",
                " we",
                " report",
                " in",
                " P",
                "NAS",
                " today",
                ".",
                "\n",
                "\n",
                "We",
                " tested",
                " 69",
                " genetic",
                " variants",
                " from",
                " the",
                " educational",
                " attainment",
                " study",
                " (",
                "of",
                " almost",
                " 107",
                ",",
                "000",
                " people",
                ")",
                " in",
                " independent",
                " samples",
                " of",
                " 24",
                ",",
                "000",
                " people",
                " who",
                " had",
                " a",
                " cognitive",
                " performance",
                " score",
                ".",
                " This",
                " two",
                "-",
                "stage",
                " strategy",
                " is",
                " called",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "proxy",
                "-",
                "phen",
                "otype",
                " method",
                "\u00e2\u0122",
                "\u013f",
                " since",
                " educational",
                " attainment",
                " is",
                " a",
                " proxy",
                " phenotype",
                " (",
                "an",
                " observable",
                " characteristic",
                " or",
                " trait",
                ")",
                " for",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "The",
                " essence",
                " of",
                " this",
                " design",
                " was",
                " to",
                " pig",
                "gy",
                "-",
                "back",
                " on",
                " a",
                " much",
                " larger"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.227,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.227,
                2.695,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.267,
                0.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.837,
                5.558,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.36,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4ypi666erip7j56",
            "tokens": [
                ".",
                "\n",
                "\n",
                "Education",
                " attainment",
                " is",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ",",
                " so",
                " given",
                " these",
                " two",
                " observations",
                ",",
                " we",
                " tested",
                " the",
                " genetic",
                " variants",
                " for",
                " education",
                " attainment",
                " with",
                " their",
                " associations",
                " with",
                " cognitive",
                " performance",
                ",",
                " which",
                " we",
                " report",
                " in",
                " P",
                "NAS",
                " today",
                ".",
                "\n",
                "\n",
                "We",
                " tested",
                " 69",
                " genetic",
                " variants",
                " from",
                " the",
                " educational",
                " attainment",
                " study",
                " (",
                "of",
                " almost",
                " 107",
                ",",
                "000",
                " people",
                ")",
                " in",
                " independent",
                " samples",
                " of",
                " 24",
                ",",
                "000",
                " people",
                " who",
                " had",
                " a",
                " cognitive",
                " performance",
                " score",
                ".",
                " This",
                " two",
                "-",
                "stage",
                " strategy",
                " is",
                " called",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "proxy",
                "-",
                "phen",
                "otype",
                " method",
                "\u00e2\u0122",
                "\u013f",
                " since",
                " educational",
                " attainment",
                " is",
                " a",
                " proxy",
                " phenotype",
                " (",
                "an",
                " observable",
                " characteristic",
                " or",
                " trait",
                ")",
                " for",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "The",
                " essence",
                " of",
                " this",
                " design",
                " was",
                " to",
                " pig",
                "gy",
                "-",
                "back",
                " on",
                " a",
                " much",
                " larger"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.227,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.227,
                2.695,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.267,
                0.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.837,
                5.558,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.36,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yki666arvh5xmc",
            "tokens": [
                "their",
                " viewpoints",
                ",",
                " or",
                " invalid",
                "ate",
                " their",
                " viewpoints",
                " is",
                " actually",
                " extremely",
                " able",
                "ist",
                " (",
                "and",
                " often",
                " san",
                "ist",
                ",",
                " neuro",
                "typ",
                "ical",
                "ist",
                ",",
                " aud",
                "ist",
                ",",
                " or",
                " v",
                "id",
                "ist",
                ").",
                "For",
                " example",
                ",",
                " I",
                " am",
                " talking",
                " about",
                " using",
                " the",
                " language",
                " of",
                " mental",
                " illness",
                " (\"",
                "crazy",
                ",\"",
                " \"",
                "ins",
                "ane",
                ",\"",
                " \"",
                "psy",
                "cho",
                ",\"",
                " or",
                " \"",
                "w",
                "ack",
                "o",
                ",\"",
                " for",
                " example",
                "),",
                " cognitive",
                " disability",
                " (\"",
                "ret",
                "arded",
                ",\"",
                " \"",
                "slow",
                ",\"",
                " or",
                " \"",
                "mor",
                "on",
                ",\"",
                " for",
                " example",
                "),",
                " or",
                " physical",
                " disability",
                " (\"",
                "c",
                "ripp",
                "led",
                "\"",
                " or",
                " \"",
                "completely",
                " blind",
                "/",
                "de",
                "af",
                ",\"",
                " for",
                " example",
                ").",
                " In",
                " another",
                " example",
                ",",
                " I",
                " am",
                " also",
                " talking",
                " about",
                " using",
                " disability",
                " as",
                " metaphor",
                ".",
                "Using",
                " the",
                " language",
                " of",
                " disability",
                " to",
                " den",
                "igrate",
                " or",
                " insult",
                " in",
                " our"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.606,
            "maxValueTokenIndex": 65,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.606,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yli666c7y2p73c",
            "tokens": [
                "Int",
                "elligence",
                ",",
                " cognitive",
                " ability",
                " or",
                " cognitive",
                " performance",
                " is",
                " usually",
                " measured",
                " by",
                " a",
                " battery",
                " of",
                " tests",
                " that",
                " aim",
                " to",
                " quantify",
                " skills",
                " such",
                " as",
                " memory",
                " and",
                " analytical",
                " ability",
                ".",
                " There",
                " is",
                " loads",
                " of",
                " variation",
                " between",
                " people",
                " in",
                " how",
                " they",
                " perform",
                " on",
                " such",
                " tests",
                ",",
                " and",
                " these",
                " differences",
                " can",
                " be",
                " due",
                " to",
                " genetic",
                " and",
                " environment",
                " factors",
                ",",
                " and",
                " their",
                " inter",
                "play",
                ".",
                "\n",
                "\n",
                "In",
                " research",
                " published",
                " in",
                " the",
                " Proceedings",
                " of",
                " the",
                " National",
                " Academy",
                " of",
                " Science",
                " (",
                "PN",
                "AS",
                ")",
                " today",
                ",",
                " we",
                " show",
                " three",
                " genetic",
                " variants",
                " in",
                " humans",
                " that",
                " can",
                " account",
                " for",
                " a",
                " couple",
                " of",
                " IQ",
                " points",
                " \u2013",
                " but",
                " before",
                " you",
                " get",
                " excited",
                ",",
                " these",
                " are",
                " only",
                " three",
                " variants",
                " out",
                " of",
                " likely",
                " thousands",
                ".",
                "\n",
                "\n",
                "The",
                " genetics",
                " of",
                " cognitive",
                " performance",
                "\n",
                "\n",
                "While",
                " a",
                " measure",
                " of",
                " \u00e2\u0122"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.581,
            "maxValueTokenIndex": 3,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                70.581,
                1.434,
                0,
                63.981,
                1.836,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.103,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.247,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4ymi66626h2iuh7",
            "tokens": [
                "Abstract",
                " Early",
                " retirement",
                " appears",
                " to",
                " have",
                " a",
                " significant",
                " negative",
                " impact",
                " on",
                " the",
                " cognitive",
                " ability",
                " of",
                " people",
                " in",
                " their",
                " early",
                " 60",
                "s",
                " that",
                " is",
                " both",
                " quant",
                "itatively",
                " important",
                " and",
                " causal",
                ".",
                " We",
                " obtain",
                " this",
                " finding",
                " using",
                " cross",
                "-",
                "n",
                "ationally",
                " comparable",
                " survey",
                " data",
                " from",
                " the",
                " United",
                " States",
                ",",
                " England",
                ",",
                " and",
                " Europe",
                " that",
                " allow",
                " us",
                " to",
                " relate",
                " cognition",
                " and",
                " labor",
                " force",
                " status",
                ".",
                " We",
                " argue",
                " that",
                " the",
                " effect",
                " is",
                " causal",
                " by",
                " making",
                " use",
                " of",
                " a",
                " substantial",
                " body",
                " of",
                " research",
                " showing",
                " that",
                " variation",
                " in",
                " pension",
                ",",
                " tax",
                ",",
                " and",
                " disability",
                " policies",
                " explain",
                " most",
                " variation",
                " across",
                " countries",
                " in",
                " average",
                " retirement",
                " rates",
                ".",
                " (",
                "In",
                " an",
                " informal",
                " manner",
                ",",
                " we",
                " are",
                " arguing",
                " that",
                " public",
                " policies",
                " that",
                " affect",
                " the",
                " age",
                " of",
                " retirement",
                " may",
                " be",
                " used",
                " as",
                " instrumental",
                " variables",
                " to",
                " generate",
                " cross",
                "-"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.452,
            "maxValueTokenIndex": 12,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.452,
                2.498,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.17,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zei666seb5kr3g",
            "tokens": [
                "Abstract",
                " Early",
                " retirement",
                " appears",
                " to",
                " have",
                " a",
                " significant",
                " negative",
                " impact",
                " on",
                " the",
                " cognitive",
                " ability",
                " of",
                " people",
                " in",
                " their",
                " early",
                " 60",
                "s",
                " that",
                " is",
                " both",
                " quant",
                "itatively",
                " important",
                " and",
                " causal",
                ".",
                " We",
                " obtain",
                " this",
                " finding",
                " using",
                " cross",
                "-",
                "n",
                "ationally",
                " comparable",
                " survey",
                " data",
                " from",
                " the",
                " United",
                " States",
                ",",
                " England",
                ",",
                " and",
                " Europe",
                " that",
                " allow",
                " us",
                " to",
                " relate",
                " cognition",
                " and",
                " labor",
                " force",
                " status",
                ".",
                " We",
                " argue",
                " that",
                " the",
                " effect",
                " is",
                " causal",
                " by",
                " making",
                " use",
                " of",
                " a",
                " substantial",
                " body",
                " of",
                " research",
                " showing",
                " that",
                " variation",
                " in",
                " pension",
                ",",
                " tax",
                ",",
                " and",
                " disability",
                " policies",
                " explain",
                " most",
                " variation",
                " across",
                " countries",
                " in",
                " average",
                " retirement",
                " rates",
                ".",
                " (",
                "In",
                " an",
                " informal",
                " manner",
                ",",
                " we",
                " are",
                " arguing",
                " that",
                " public",
                " policies",
                " that",
                " affect",
                " the",
                " age",
                " of",
                " retirement",
                " may",
                " be",
                " used",
                " as",
                " instrumental",
                " variables",
                " to",
                " generate",
                " cross",
                "-"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.452,
            "maxValueTokenIndex": 12,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.452,
                2.498,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.17,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 15.227,
            "binMax": 30.454,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yni6668jm84wnw",
            "tokens": [
                ",",
                " was",
                " evaluated",
                " against",
                " pent",
                "yl",
                "en",
                "et",
                "et",
                "raz",
                "ole",
                " (",
                "PT",
                "Z",
                ")-",
                "induced",
                " seizures",
                ",",
                " cognitive",
                " impairment",
                " and",
                " oxidative",
                " stress",
                " in",
                " rats",
                ".",
                " Tian",
                "ept",
                "ine",
                " was",
                " administered",
                " in",
                " three",
                " doses",
                " (",
                "20",
                ",",
                " 40",
                " and",
                " 80",
                " mg",
                "/",
                "kg",
                ")",
                " 30",
                " min",
                " before",
                " PT",
                "Z",
                " (",
                "60",
                " mg",
                "/",
                "kg",
                ",",
                " intra",
                "per",
                "itone",
                "ally",
                ").",
                " MK",
                "801",
                ",",
                " an",
                " N",
                "-",
                "methyl",
                "-",
                "D",
                "-",
                "as",
                "part",
                "ate",
                " antagonist",
                ",",
                " and",
                " n",
                "al",
                "ox",
                "one",
                ",",
                " an",
                " opioid",
                " receptor",
                " antagonist",
                ",",
                " were",
                " administered",
                " with",
                " t",
                "ian",
                "ept",
                "ine",
                " to",
                " evaluate",
                " the",
                " involvement",
                " of",
                " N",
                "-",
                "methyl",
                "-",
                "D",
                "-",
                "as",
                "part",
                "ate",
                " and",
                " opioid",
                " receptors",
                ",",
                " respectively",
                ".",
                " Morris",
                " water",
                " maze",
                ",",
                " elevated",
                " plus",
                " maze",
                " and",
                " passive",
                " avoidance",
                " tests",
                " were",
                " performed",
                " for"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.324,
            "maxValueTokenIndex": 18,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.324,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yoi666qinslvji",
            "tokens": [
                ".",
                " The",
                " answers",
                " are",
                " to",
                " be",
                " found",
                " in",
                " cognitive",
                " processes",
                ",",
                " perception",
                ",",
                " and",
                " neuro",
                "phys",
                "iology",
                ".",
                " In",
                " order",
                " to",
                " begin",
                " a",
                " search",
                " for",
                " how",
                " biology",
                " influences",
                " architecture",
                " and",
                " urban",
                "ism",
                ",",
                " we",
                " must",
                " establish",
                " some",
                " overall",
                " map",
                " of",
                " the",
                " problem",
                ".",
                " Because",
                " this",
                " is",
                " a",
                " vast",
                " subject",
                ",",
                " it",
                " is",
                " useful",
                " to",
                " divide",
                " it",
                " into",
                " a",
                " series",
                " of",
                " questions",
                " like",
                " the",
                " following",
                ".",
                " This",
                " is",
                " not",
                " meant",
                " to",
                " be",
                " a",
                " complete",
                " set",
                " of",
                " questions",
                ";",
                " only",
                " a",
                " starting",
                " point",
                " for",
                " an",
                " investigation",
                ".",
                " Why",
                " do",
                " some",
                " built",
                " forms",
                " resemble",
                " biological",
                " forms",
                "?",
                " What",
                " types",
                " of",
                " built",
                " forms",
                " correspond",
                " more",
                " closely",
                " to",
                " biological",
                " prototypes",
                "?",
                " Are",
                " human",
                " beings",
                " pred",
                "isp",
                "osed",
                " to",
                " like",
                " and",
                " feel",
                " comfortable",
                " with",
                " certain",
                " types",
                " of",
                " forms",
                "?",
                " Are",
                " human",
                " beings",
                " also"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.275,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.275,
                3.596,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yqi6669i65k2j3",
            "tokens": [
                " that",
                " cognitive",
                " performance",
                " is",
                " her",
                "itable",
                ",",
                " but",
                " where",
                " are",
                " the",
                " genes",
                "?",
                " Despite",
                " considerable",
                " attempts",
                " to",
                " find",
                " genes",
                " for",
                " cognitive",
                " performance",
                ",",
                " no",
                " specific",
                " genes",
                " had",
                " been",
                " found",
                " and",
                " replicated",
                ".",
                "\n",
                "\n",
                "One",
                " reason",
                " for",
                " this",
                " puzzle",
                " is",
                " that",
                " there",
                " are",
                " a",
                " lot",
                " of",
                " genes",
                " involved",
                " \u2013",
                " thousands",
                ",",
                " even",
                " \u2013",
                " and",
                " their",
                " individual",
                " gene",
                " effect",
                " sizes",
                " are",
                " tiny",
                ".",
                " Past",
                " studies",
                " couldn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " find",
                " them",
                " because",
                " sample",
                " sizes",
                " were",
                " not",
                " large",
                " enough",
                " to",
                " detect",
                " genes",
                " with",
                " statistical",
                " significance",
                ".",
                "\n",
                "\n",
                "So",
                " how",
                " did",
                " we",
                " overcome",
                " this",
                " problem",
                "?",
                "\n",
                "\n",
                "Last",
                " year",
                ",",
                " a",
                " huge",
                " international",
                " collaborative",
                " study",
                " of",
                " more",
                " than",
                " 126",
                ",",
                "000",
                " people",
                " correlated",
                " millions",
                " of",
                " genetic",
                " variants",
                " with",
                " educational",
                " attainment",
                " and",
                " discovered",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " it"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.818,
            "maxValueTokenIndex": 1,
            "minValue": 0,
            "values": [
                0,
                69.818,
                4.543,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.44,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yxi666hz2ch99g",
            "tokens": [
                " that",
                " cognitive",
                " performance",
                " is",
                " her",
                "itable",
                ",",
                " but",
                " where",
                " are",
                " the",
                " genes",
                "?",
                " Despite",
                " considerable",
                " attempts",
                " to",
                " find",
                " genes",
                " for",
                " cognitive",
                " performance",
                ",",
                " no",
                " specific",
                " genes",
                " had",
                " been",
                " found",
                " and",
                " replicated",
                ".",
                "\n",
                "\n",
                "One",
                " reason",
                " for",
                " this",
                " puzzle",
                " is",
                " that",
                " there",
                " are",
                " a",
                " lot",
                " of",
                " genes",
                " involved",
                " \u2013",
                " thousands",
                ",",
                " even",
                " \u2013",
                " and",
                " their",
                " individual",
                " gene",
                " effect",
                " sizes",
                " are",
                " tiny",
                ".",
                " Past",
                " studies",
                " couldn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " find",
                " them",
                " because",
                " sample",
                " sizes",
                " were",
                " not",
                " large",
                " enough",
                " to",
                " detect",
                " genes",
                " with",
                " statistical",
                " significance",
                ".",
                "\n",
                "\n",
                "So",
                " how",
                " did",
                " we",
                " overcome",
                " this",
                " problem",
                "?",
                "\n",
                "\n",
                "Last",
                " year",
                ",",
                " a",
                " huge",
                " international",
                " collaborative",
                " study",
                " of",
                " more",
                " than",
                " 126",
                ",",
                "000",
                " people",
                " correlated",
                " millions",
                " of",
                " genetic",
                " variants",
                " with",
                " educational",
                " attainment",
                " and",
                " discovered",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " it"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.818,
            "maxValueTokenIndex": 1,
            "minValue": 0,
            "values": [
                0,
                69.818,
                4.543,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.44,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 60.907,
            "binMax": 76.134,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvkm4yri666w4t0b0m5",
            "tokens": [
                "Tell",
                " me",
                " lies",
                "\n",
                "\n",
                "The",
                " findings",
                " did",
                " surprise",
                " He",
                "ber",
                "lein",
                " somewhat",
                ".",
                "\n",
                "\n",
                "\"",
                "They",
                " really",
                " have",
                " the",
                " capacity",
                " from",
                " the",
                " cognitive",
                " aspect",
                " to",
                " use",
                " such",
                " a",
                " strategy",
                " to",
                " have",
                " a",
                " benefit",
                " in",
                " their",
                " lives",
                ",\"",
                " He",
                "ber",
                "lein",
                " said",
                ".",
                " \"",
                "It",
                "'s",
                " tactical",
                " deception",
                ",",
                " basically",
                ".\"",
                "\n",
                "\n",
                "D",
                "aph",
                "na",
                " Buch",
                "s",
                "baum",
                ",",
                " assistant",
                " professor",
                " at",
                " the",
                " University",
                " of",
                " Toronto",
                "'s",
                " department",
                " of",
                " psychology",
                ",",
                " said",
                " that",
                " this",
                " is",
                " a",
                " good",
                " step",
                " in",
                " studying",
                " the",
                " social",
                " reasoning",
                " abilities",
                " of",
                " dogs",
                ".",
                "\n",
                "\n",
                "Hum",
                "ans",
                " tend",
                " to",
                " think",
                " of",
                " themselves",
                " as",
                " unique",
                ",",
                " and",
                " cognitive",
                " abilities",
                " is",
                " one",
                " of",
                " those",
                " things",
                " that",
                " some",
                " believe",
                " sets",
                " us",
                " apart",
                " \u2014",
                " and",
                " above",
                " \u2014",
                " other",
                " animals",
                ".",
                " But",
                " more",
                " and",
                " more",
                ","
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.58,
            "maxValueTokenIndex": 24,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.58,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.459,
                0.428,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.076,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4ysi666cieafbpj",
            "tokens": [
                "B",
                "ask",
                " in",
                " the",
                " cognitive",
                " disson",
                "ance",
                ":",
                "\n",
                "\n",
                "Enjoy",
                " the",
                " fragile",
                " ego",
                ":",
                "\n",
                "\n",
                "\u00e2\u0122",
                "\u013e",
                "Some",
                " within",
                " the",
                " establishment",
                " don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " like",
                " the",
                " fact",
                " that",
                " I",
                " won",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " back",
                " down",
                " to",
                " a",
                " good",
                "-",
                "old",
                "-",
                "boys",
                " club",
                ".",
                " A",
                " lot",
                " of",
                " this",
                " has",
                " to",
                " do",
                " with",
                " control",
                ",",
                " power",
                ",",
                " money",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "\n",
                "\n",
                "Watch",
                " the",
                " paranoid",
                " bonding",
                ":",
                "\n",
                "\n",
                "Just",
                " two",
                " years",
                " ago",
                ",",
                " Tom",
                " T",
                "anc",
                "redo",
                " was",
                " a",
                " ver",
                "itable",
                " out",
                "cast",
                " of",
                " the",
                " Republican",
                " Party",
                ".",
                " Karl",
                " Rove",
                " was",
                " screaming",
                " at",
                " him",
                ",",
                " John",
                " McCain",
                " scoff",
                "ed",
                " at",
                " him",
                ",",
                " GOP",
                " poll",
                "sters",
                " viewed",
                " him",
                " as",
                " a",
                " sab",
                "ote",
                "ur",
                " within",
                " their",
                " midst",
                ".",
                " T",
                "anc",
                "redo",
                "'s",
                " one",
                " issue",
                "--"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.575,
            "maxValueTokenIndex": 4,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                69.575,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yti666ctaudf16",
            "tokens": [
                " of",
                " virtual",
                " reality",
                " in",
                " cognitive",
                " and",
                " physical",
                " therapy",
                " treatment",
                " by",
                " leading",
                " psychologists",
                " and",
                " clinicians",
                "\u2014",
                "which",
                " goes",
                " way",
                " beyond",
                " gaming",
                ";",
                " it",
                " has",
                " the",
                " potential",
                " to",
                " change",
                " the",
                " way",
                " we",
                " think",
                " about",
                " therapy",
                " altogether",
                ".",
                "\n",
                "\n",
                "Despite",
                " the",
                " recent",
                " surge",
                " in",
                " VR",
                " development",
                " over",
                " the",
                " last",
                " few",
                " years",
                ",",
                " the",
                " idea",
                " of",
                " using",
                " virtual",
                " reality",
                " in",
                " a",
                " therapeutic",
                " setting",
                " isn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " a",
                " new",
                " idea",
                ".",
                " Research",
                " regarding",
                " VR",
                " simulations",
                " to",
                " treat",
                " specific",
                " ph",
                "ob",
                "ias",
                " was",
                " around",
                " as",
                " early",
                " as",
                " the",
                " nin",
                "eties",
                ",",
                " but",
                " the",
                " technology",
                " simply",
                " wasn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " advanced",
                " enough",
                " for",
                " such",
                " treatment",
                " to",
                " be",
                " feasible",
                ".",
                " Head",
                " mounted",
                " displays",
                " were",
                " cl",
                "unky",
                ",",
                " computer",
                " processing",
                " speeds",
                " laughable",
                ",",
                " and",
                " 3",
                "D",
                " graphics",
                " downright",
                " primitive",
                " in",
                " comparison",
                " to",
                " what",
                "\u00e2\u0122"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.218,
            "maxValueTokenIndex": 4,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                69.218,
                1.899,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yui666b4jqwq1o",
            "tokens": [
                " were",
                " enhanced",
                " 15",
                " min",
                " following",
                " fat",
                " or",
                " glucose",
                " ingestion",
                " and",
                " working",
                " memory",
                " was",
                " enhanced",
                " 15",
                " min",
                " following",
                " protein",
                " ingestion",
                ".",
                " S",
                "ixty",
                " minutes",
                " post",
                " drink",
                " memory",
                " enhancements",
                " were",
                " observed",
                " after",
                " protein",
                " and",
                " memory",
                " impairment",
                " was",
                " observed",
                " following",
                " glucose",
                ".",
                " All",
                " drinks",
                " increased",
                " ratings",
                " of",
                " alert",
                "ness",
                ".",
                " The",
                " findings",
                " suggest",
                " that",
                " mac",
                "ron",
                "ut",
                "rients",
                ":",
                " (",
                "i",
                ")",
                " have",
                " different",
                " windows",
                " of",
                " opportunity",
                " for",
                " effects",
                " (",
                "ii",
                ")",
                " target",
                " different",
                " cognitive",
                " domains",
                ".",
                "\n",
                "\n",
                "Copyright",
                " \u00c2\u00a9",
                " 2012",
                " Else",
                "vier",
                " B",
                ".",
                "V",
                ".",
                " All",
                " rights",
                " reserved",
                ".",
                "<|endoftext|>",
                "This",
                " article",
                " is",
                " over",
                " 3",
                " years",
                " old",
                "\n",
                "\n",
                "Z",
                "hang",
                " M",
                "iao",
                " was",
                " detained",
                " nine",
                " months",
                " ago",
                " after",
                " covering",
                " the",
                " Hong",
                " Kong",
                " democracy",
                " protests",
                " for",
                " Die",
                " Zeit",
                " newspaper",
                "\n",
                "\n",
                "A",
                " Chinese",
                " journalist",
                " will",
                " be",
                " freed"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.105,
            "maxValueTokenIndex": 71,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.686,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.226,
                0,
                0,
                0,
                0,
                0,
                0,
                6.787,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.808,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.105,
                3.001,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yvi666s1miy0vj",
            "tokens": [
                " same",
                "-",
                "day",
                " delivery",
                " service",
                ".",
                " It",
                "'s",
                " also",
                " hoping",
                " the",
                " holiday",
                " season",
                " helps",
                " beef",
                " up",
                " online",
                " sales",
                ".",
                "<|endoftext|>",
                "Gaming",
                " for",
                " therapy",
                " and",
                " cognitive",
                " development",
                "?!",
                " It",
                " turns",
                " out",
                " there",
                " is",
                " a",
                " myriad",
                " of",
                " benefits",
                " gained",
                " from",
                " hobby",
                "!",
                " Feel",
                " the",
                " z",
                "en",
                "!",
                "\n",
                "\n",
                "In",
                " this",
                " video",
                " I",
                " talk",
                " in",
                " response",
                " to",
                " an",
                " article",
                " by",
                " Geek",
                " and",
                " Sund",
                "ry",
                " which",
                " looks",
                " at",
                " using",
                " Dungeons",
                " and",
                " Dragons",
                " as",
                " a",
                " therapeutic",
                " intervention",
                " for",
                " children",
                " with",
                " learning",
                " difficulties",
                " and",
                " expand",
                " that",
                " to",
                " discuss",
                " how",
                " it",
                " can",
                " be",
                " applied",
                " to",
                " all",
                " us",
                " us",
                ".",
                "\n",
                "\n",
                "This",
                " includes",
                " the",
                " social",
                " aspect",
                " of",
                " meeting",
                " people",
                ",",
                " the",
                " behavioral",
                " activation",
                " properties",
                " of",
                " having",
                " things",
                " to",
                " look",
                " forward",
                " to",
                " as",
                " well",
                " as",
                " having",
                " achievements",
                " such",
                " as",
                " painting",
                " some",
                " of",
                " your",
                " led"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.345,
            "maxValueTokenIndex": 24,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.345,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.967,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4ywi666yck4uo2g",
            "tokens": [
                "ingu",
                "ish",
                " whether",
                " men",
                " are",
                " more",
                " utilitarian",
                " than",
                " women",
                ",",
                " or",
                " women",
                " are",
                " more",
                " de",
                "ont",
                "ological",
                " than",
                " men",
                ",",
                " it",
                " is",
                " necessary",
                " to",
                " measure",
                " [",
                "these",
                "]",
                "in",
                "cl",
                "inations",
                " independently",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " said",
                " F",
                "ries",
                "d",
                "orf",
                ".",
                "\n",
                "\n",
                "The",
                " Results",
                "\n",
                "\n",
                "The",
                " findings",
                " from",
                " the",
                " study",
                " challenge",
                " the",
                " traditional",
                " theory",
                " that",
                " men",
                " prefer",
                " cognitive",
                " decisions",
                " and",
                " women",
                " prefer",
                " emotional",
                " ones",
                ".",
                " After",
                " separating",
                " the",
                " variables",
                ",",
                " researchers",
                " discovered",
                " that",
                " men",
                " and",
                " women",
                " use",
                " cognitive",
                " reasoning",
                " about",
                " equally",
                ".",
                " However",
                ",",
                " women",
                " were",
                " much",
                " more",
                " likely",
                " to",
                " use",
                " emotional",
                " reasoning",
                " than",
                " men",
                " when",
                " one",
                " factor",
                " is",
                " involved",
                ":",
                " harm",
                ".",
                "\n",
                "\n",
                "When",
                " asked",
                " a",
                " moral",
                " dilemma",
                " question",
                " that",
                " did",
                " not",
                " involve",
                " harm",
                ",",
                " women",
                " and",
                " men",
                " both",
                " tended",
                " to",
                " use",
                " utilitarian"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.302,
            "maxValueTokenIndex": 59,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.302,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.918,
                4.498,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 76.134,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yzi66613hg9v6r",
            "tokens": [
                " is",
                " premature",
                " to",
                " suggest",
                " the",
                " biological",
                " function",
                " of",
                " the",
                " genes",
                " identified",
                ",",
                " our",
                " additional",
                " analysis",
                " suggests",
                " that",
                " the",
                " genes",
                " are",
                " related",
                " to",
                " synaptic",
                " plastic",
                "ity",
                " \u2013",
                " the",
                " main",
                " mechanism",
                " in",
                " the",
                " brain",
                " for",
                " learning",
                " and",
                " memory",
                ".",
                "\n",
                "\n",
                "The",
                " take",
                "-",
                "away",
                " message",
                "\n",
                "\n",
                "This",
                " study",
                " of",
                " normal",
                " variation",
                " in",
                " cognitive",
                " performance",
                " confirms",
                " that",
                " there",
                " is",
                " no",
                " gene",
                " with",
                " a",
                " large",
                " effect",
                " on",
                " this",
                " trait",
                ".",
                " There",
                " is",
                " no",
                " \u00e2\u0122",
                "\u013e",
                "g",
                "ene",
                " for",
                " intelligence",
                "\u00e2\u0122",
                "\u013f",
                " \u2013",
                " instead",
                ",",
                " cognitive",
                " performance",
                " is",
                " likely",
                " to",
                " be",
                " influenced",
                " by",
                " thousands",
                " of",
                " genes",
                ",",
                " each",
                " having",
                " a",
                " small",
                " effect",
                ".",
                "\n",
                "\n",
                "While",
                " the",
                " individual",
                " effect",
                " of",
                " the",
                " genetic",
                " variants",
                " are",
                " extremely",
                " small",
                ",",
                " their",
                " identification",
                " may",
                " lead",
                " to",
                " knowledge",
                " of",
                " the",
                " biological",
                " pathways",
                " involved",
                " in",
                " cognitive"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.122,
            "maxValueTokenIndex": 52,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.034,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.122,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.704,
                0.886,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                59.924
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 60.907,
            "binMax": 76.134,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4yyi6665k901rtj",
            "tokens": [
                " that",
                " processes",
                " information",
                " grows",
                " during",
                " childhood",
                " and",
                " then",
                " starts",
                " to",
                " p",
                "are",
                " down",
                ",",
                " reaching",
                " a",
                " peak",
                " level",
                " of",
                " cognitive",
                " development",
                " when",
                " girls",
                " are",
                " between",
                " 12",
                " and",
                " 13",
                " years",
                " old",
                " and",
                " when",
                " boys",
                " are",
                " 15",
                " to",
                " 16",
                " years",
                " old",
                ",",
                " generally",
                " speaking",
                ".",
                "\n",
                "\n",
                "\u00e2\u0122",
                "\u013e",
                "The",
                " girls",
                " have",
                " a",
                " level",
                " of",
                " organization",
                " where",
                " they",
                "\u00e2\u0122",
                "\u013b",
                "re",
                " doing",
                " complex",
                " scheduling",
                " and",
                " social",
                " arrangements",
                ",",
                " and",
                " making",
                " lists",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " Jensen",
                " said",
                ".",
                " \u00e2\u0122",
                "\u013e",
                "Meanwhile",
                ",",
                " boys",
                " at",
                " that",
                " same",
                " age",
                ",",
                " you",
                "\u00e2\u0122",
                "\u013b",
                "re",
                " lucky",
                " if",
                " they",
                " remember",
                " to",
                " bring",
                " their",
                " books",
                " home",
                " from",
                " school",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "\n",
                "\n",
                "That",
                " means",
                " boys",
                " and",
                " girls",
                " may",
                " be",
                " ready",
                " for",
                " challenging",
                " subjects",
                " \u2014",
                " like",
                " complex",
                " math",
                " and",
                " science",
                " \u2014",
                " at",
                " different",
                " points",
                "."
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.89,
            "maxValueTokenIndex": 19,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.89,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 60.907,
            "binMax": 76.134,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zdi666e0wnmzco",
            "tokens": [
                " one",
                " hand",
                ",",
                " and",
                " inherited",
                " structures",
                " in",
                " the",
                " human",
                " brain",
                " that",
                " influence",
                " the",
                " function",
                " of",
                " \"",
                "mind",
                "\",",
                " on",
                " the",
                " other",
                ".",
                " A",
                " group",
                " of",
                " innovative",
                " architects",
                " and",
                " thinkers",
                " are",
                " beginning",
                " to",
                " formulate",
                " the",
                " basis",
                " for",
                " a",
                " new",
                " architecture",
                " that",
                " arises",
                " out",
                " of",
                " human",
                " needs",
                ",",
                " and",
                " which",
                " is",
                " supported",
                " by",
                " an",
                " improved",
                " understanding",
                " of",
                " biological",
                " structure",
                ".",
                " Our",
                " cognition",
                " makes",
                " us",
                " human",
                ";",
                " it",
                " is",
                " certainly",
                " responsible",
                " for",
                " how",
                " we",
                " perceive",
                " structure",
                ".",
                " Human",
                " neuro",
                "phys",
                "iology",
                " is",
                " therefore",
                " essential",
                " for",
                " answering",
                " at",
                " least",
                " some",
                " of",
                " the",
                " above",
                " questions",
                ".",
                " For",
                " guidance",
                " in",
                " this",
                " task",
                ",",
                " I",
                " turn",
                " to",
                " the",
                " work",
                " of",
                " Steven",
                " Pink",
                "er",
                ",",
                " Professor",
                " of",
                " Psychology",
                " at",
                " MIT",
                ",",
                " a",
                " world",
                " authority",
                " on",
                " cognitive",
                " neuroscience",
                ",",
                " and",
                " the",
                " author",
                " of",
                " \"",
                "The",
                " Language"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.589,
            "maxValueTokenIndex": 117,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                29.948,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.589,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 15.227,
            "binMax": 30.454,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvlm4z0i6664vhuetu3",
            "tokens": [
                "re",
                "aking",
                "@",
                "t",
                "ribune",
                ".",
                "com",
                "<|endoftext|>",
                "Draw",
                "ing",
                " is",
                " ancient",
                ";",
                " it",
                " is",
                " the",
                " only",
                " childhood",
                " cognitive",
                " behavior",
                " for",
                " which",
                " there",
                " is",
                " any",
                " direct",
                " evidence",
                " from",
                " the",
                " Upper",
                " Pale",
                "olithic",
                ".",
                " Do",
                " genes",
                " influence",
                " individual",
                " differences",
                " in",
                " this",
                " species",
                "-",
                "typ",
                "ical",
                " behavior",
                ",",
                " and",
                " is",
                " drawing",
                " related",
                " to",
                " intelligence",
                " (",
                " g",
                " )",
                " in",
                " modern",
                " children",
                "?",
                " We",
                " report",
                " on",
                " the",
                " first",
                " genetically",
                " informative",
                " study",
                " of",
                " children",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " figure",
                " drawing",
                ".",
                " In",
                " a",
                " study",
                " of",
                " 7",
                ",",
                "752",
                " pairs",
                " of",
                " twins",
                ",",
                " we",
                " found",
                " that",
                " genetic",
                " differences",
                " exert",
                " a",
                " greater",
                " influence",
                " on",
                " children",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " figure",
                " drawing",
                " at",
                " age",
                " 4",
                " than",
                " do",
                " between",
                "-",
                "family",
                " environmental",
                " differences",
                ".",
                " Figure",
                " drawing",
                " was",
                " as",
                " her",
                "itable",
                " as",
                " g",
                " at",
                " age",
                " 4",
                " (",
                "her",
                "itability"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.257,
            "maxValueTokenIndex": 18,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.257,
                4.468,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 60.907,
            "binMax": 76.134,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z7i666drkyig70",
            "tokens": [
                " two",
                " apart",
                ",",
                " it",
                " is",
                " likely",
                " that",
                " they",
                " identified",
                " each",
                " person",
                " by",
                " their",
                " face",
                ".",
                "\n",
                "\n",
                "This",
                " conclusion",
                " is",
                " backed",
                " up",
                " by",
                " the",
                " fact",
                " that",
                " the",
                " wind",
                "y",
                " Antarctic",
                " conditions",
                " make",
                " it",
                " difficult",
                " to",
                " pick",
                " up",
                " smells",
                ",",
                " so",
                " it",
                " is",
                " unlikely",
                " that",
                " the",
                " sk",
                "u",
                "as",
                " used",
                " o",
                "lf",
                "actory",
                " signals",
                " to",
                " identify",
                " intr",
                "uders",
                ".",
                " Furthermore",
                ",",
                " previous",
                " studies",
                " have",
                " shown",
                " that",
                " c",
                "rows",
                " also",
                " apparently",
                " recognize",
                " the",
                " faces",
                " of",
                " individual",
                " humans",
                ",",
                " suggesting",
                " that",
                " birds",
                " with",
                " high",
                " cognition",
                " levels",
                " can",
                " indeed",
                " tell",
                " people",
                " apart",
                " in",
                " this",
                " way",
                ".",
                "\n",
                "\n",
                "As",
                " such",
                ",",
                " the",
                " study",
                " authors",
                " conclude",
                " that",
                " the",
                " sk",
                "u",
                "as",
                "\u00e2\u0122",
                "\u013b",
                " ability",
                " to",
                " discriminate",
                " between",
                " people",
                " is",
                " indicative",
                " of",
                " similarly",
                " high",
                " cognitive",
                " abilities",
                ".",
                " While",
                " some",
                " less",
                " intelligent",
                " species",
                " have"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.165,
            "maxValueTokenIndex": 118,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                30.655,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.165,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 30.454,
            "binMax": 45.68,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z4i6664et4xs24",
            "tokens": [
                " up",
                " against",
                " the",
                " wall",
                " and",
                " see",
                " if",
                " it",
                " sticks",
                ".",
                " It",
                " will",
                " be",
                " as",
                " exciting",
                " as",
                " the",
                " 1930",
                "s",
                ",",
                " greater",
                " than",
                " the",
                " Reagan",
                " revolution",
                " \u2014",
                " conservatives",
                ",",
                " plus",
                " popul",
                "ists",
                ",",
                " in",
                " an",
                " economic",
                " nationalist",
                " movement",
                ".\"",
                "\n",
                "\n",
                "If",
                " you",
                " experienced",
                " a",
                " bit",
                " of",
                " cognitive",
                " disson",
                "ance",
                " reading",
                " about",
                " that",
                " infrastructure",
                " idea",
                " because",
                " it",
                " sounds",
                " quite",
                " a",
                " bit",
                " like",
                " something",
                " heard",
                " for",
                " a",
                " decade",
                " from",
                " large",
                " portions",
                " of",
                " the",
                " left",
                "\u2014",
                "orig",
                "inally",
                " from",
                " outside",
                " the",
                " Democratic",
                " Party",
                ",",
                " and",
                " subsequently",
                " from",
                " many",
                " prominent",
                " members",
                " in",
                " it",
                "\u2014",
                "you",
                "\u00e2\u0122",
                "\u013b",
                "re",
                " right",
                ".",
                "<|endoftext|>",
                "Ale",
                "c",
                " Ross",
                ",",
                " Former",
                " Senior",
                " Advisor",
                " to",
                " Hillary",
                " Clinton",
                " and",
                " the",
                " Author",
                " of",
                " The",
                " Industries",
                " of",
                " the",
                " Future",
                ":",
                "\n",
                "\n",
                "In",
                " ten",
                " years",
                ",",
                " the",
                " deaf",
                " and",
                " mute"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 60.548,
            "maxValueTokenIndex": 46,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.548,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 45.68,
            "binMax": 60.907,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z6i666nweehicf",
            "tokens": [
                " Hammond",
                ",",
                " who",
                " was",
                " genuinely",
                " hilarious",
                " with",
                " his",
                " e",
                "bull",
                "ient",
                ",",
                " indef",
                "at",
                "ig",
                "able",
                ",",
                " perpetually",
                "-",
                "up",
                "beat",
                "-",
                "even",
                "-",
                "in",
                "-",
                "the",
                "-",
                "most",
                "-",
                "rid",
                "ic",
                "ulous",
                "-",
                "circ",
                "um",
                "st",
                "ances",
                ",",
                " version",
                " of",
                " Trump",
                " was",
                " replaced",
                " with",
                " Alec",
                " Baldwin",
                ",",
                " whose",
                " Trump",
                " is",
                " a",
                " sort",
                " of",
                " dark",
                ",",
                " ominous",
                ",",
                " ugly",
                ",",
                " ogre",
                "-",
                "like",
                " version",
                " of",
                " the",
                " character",
                ".",
                "\n",
                "\n",
                "That",
                " is",
                " not",
                " by",
                " accident",
                ",",
                " and",
                " I",
                " think",
                " it",
                " is",
                " a",
                " measure",
                " of",
                " how",
                " thoroughly",
                " the",
                " cognitive",
                " scientists",
                " behind",
                " the",
                " scenes",
                " have",
                " gotten",
                " a",
                " grip",
                " on",
                " the",
                " entirely",
                " of",
                " the",
                " media",
                " machinery",
                ",",
                " all",
                " to",
                " manipulate",
                " the",
                " perceptions",
                " which",
                " the",
                " populace",
                " holds",
                " of",
                " Donald",
                " Trump",
                ".",
                "\n",
                "\n",
                "Trump",
                " knows",
                " all",
                " of",
                " this",
                ",",
                " of",
                " course"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 58.854,
            "maxValueTokenIndex": 87,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                58.854,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 45.68,
            "binMax": 60.907,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z3i666vnd117ln",
            "tokens": [
                " one",
                " island",
                " to",
                " the",
                " next",
                ",",
                " you",
                " must",
                " cross",
                " a",
                " he",
                "aving",
                " sea",
                " of",
                " psychological",
                " confusion",
                ",",
                " in",
                " which",
                " the",
                " previous",
                " mode",
                " no",
                " longer",
                " seems",
                " functional",
                ",",
                " but",
                " you",
                " cannot",
                " yet",
                " operate",
                " in",
                " the",
                " next",
                " mode",
                " reliably",
                ".",
                " These",
                " stage",
                " transitions",
                " are",
                " emotionally",
                " and",
                " cognitive",
                "ly",
                " difficult",
                ",",
                " and",
                " typically",
                " take",
                " several",
                " years",
                ",",
                " during",
                " which",
                " one",
                " may",
                " think",
                ",",
                " feel",
                ",",
                " and",
                " act",
                " inconsist",
                "ently",
                ".",
                "\n",
                "\n",
                "Ide",
                "ally",
                ",",
                " a",
                " society",
                " and",
                " culture",
                " provides",
                " \u00e2\u0122",
                "\u013e",
                "brid",
                "ges",
                "\u00e2\u0122",
                "\u013f",
                " of",
                " support",
                " from",
                " one",
                " stage",
                " to",
                " the",
                " next",
                ".",
                " To",
                " some",
                " extent",
                ",",
                " ours",
                " does",
                ".",
                " However",
                ",",
                " Ke",
                "gan",
                " pointed",
                " out",
                " that",
                " we",
                " have",
                " allowed",
                " the",
                " bridge",
                " from",
                " stage",
                " 3",
                " to",
                " 4",
                " to",
                " fall",
                " into",
                " dis",
                "repair",
                ".",
                " We",
                " are",
                " not",
                " adequately",
                " teaching"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 55.482,
            "maxValueTokenIndex": 44,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                55.482,
                8.572,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 45.68,
            "binMax": 60.907,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z8i666d05rvmzd",
            "tokens": [
                "country",
                " variation",
                " in",
                " retirement",
                " behavior",
                " in",
                " order",
                " to",
                " identify",
                " the",
                " causal",
                " effect",
                " of",
                " retirement",
                " on",
                " cognition",
                ".)",
                "\n",
                "\n",
                "C",
                "itation",
                " Roh",
                "wed",
                "der",
                ",",
                " Sus",
                "ann",
                ",",
                " and",
                " Robert",
                " J",
                ".",
                " Willis",
                ".",
                " 2010",
                ".",
                " \"",
                "M",
                "ental",
                " Retirement",
                ".\"",
                " Journal",
                " of",
                " Economic",
                " Perspect",
                "ives",
                " ,",
                " 24",
                " (",
                "1",
                "):",
                " 119",
                "-",
                "38",
                " .",
                " DOI",
                ":",
                " 10",
                ".",
                "12",
                "57",
                "/",
                "j",
                "ep",
                ".",
                "24",
                ".",
                "1",
                ".",
                "119",
                " Choose",
                " Format",
                ":",
                " Bib",
                "TeX",
                " End",
                "Note",
                " Refer",
                "/",
                "B",
                "ib",
                "IX",
                " RIS",
                " Tab",
                "-",
                "Del",
                "im",
                "ited",
                "<|endoftext|>",
                "A",
                " Florida",
                " man",
                " who",
                " was",
                " denied",
                " a",
                " room",
                " at",
                " a",
                " hotel",
                " drove",
                " his",
                " vehicle",
                " into",
                " the",
                " hotel",
                " and",
                " a",
                " law",
                " enforcement",
                " vehicle",
                ".",
                "\n",
                "\n",
                "Wal",
                "ter",
                " Chuck",
                " Christie",
                ",",
                " 55",
                ",",
                " of",
                " Carm",
                "el",
                ",",
                " told",
                " employee"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 35.228,
            "maxValueTokenIndex": 15,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                35.228,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 30.454,
            "binMax": 45.68,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvmm4z9i66624wj737p",
            "tokens": [
                " hallmark",
                " of",
                " cognition",
                " or",
                " intelligence",
                ",'",
                " says",
                " Professor",
                " G",
                "ero",
                " M",
                "ies",
                "en",
                "b",
                "\u00c3\u00b6",
                "ck",
                ",",
                " in",
                " whose",
                " laboratory",
                " the",
                " new",
                " research",
                " was",
                " performed",
                ".",
                " '",
                "What",
                " our",
                " findings",
                " show",
                " is",
                " that",
                " fruit",
                " flies",
                " have",
                " a",
                " surprising",
                " mental",
                " capacity",
                " that",
                " has",
                " previously",
                " been",
                " unrecogn",
                "ised",
                ".'",
                "\n",
                "\n",
                "The",
                " researchers",
                " also",
                " showed",
                " that",
                " the",
                " gene",
                " Fox",
                "P",
                ",",
                " active",
                " in",
                " a",
                " small",
                " set",
                " of",
                " around",
                " 200",
                " neurons",
                ",",
                " is",
                " involved",
                " in",
                " the",
                " decision",
                "-",
                "making",
                " process",
                " in",
                " the",
                " fruit",
                " fly",
                " brain",
                ".",
                "\n",
                "\n",
                "The",
                " team",
                " reports",
                " its",
                " findings",
                " in",
                " the",
                " journal",
                " Science",
                ".",
                " The",
                " group",
                " was",
                " funded",
                " by",
                " the",
                " Well",
                "come",
                " Trust",
                ",",
                " the",
                " G",
                "ats",
                "by",
                " Char",
                "itable",
                " Foundation",
                ",",
                " the",
                " US",
                " National",
                " Institutes",
                " of",
                " Health",
                " and",
                " the",
                " Oxford",
                " Martin",
                " School",
                ".",
                "\n",
                "\n"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 31.723,
            "maxValueTokenIndex": 2,
            "minValue": 0,
            "values": [
                0,
                0,
                31.723,
                0,
                1.58,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.503,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 30.454,
            "binMax": 45.68,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zai666q5th879r",
            "tokens": [
                "kn",
                "ock",
                " jokes",
                " and",
                " offer",
                " answers",
                " to",
                " a",
                " range",
                " of",
                " \u00e2\u0122",
                "\u013a",
                "who",
                "\u00e2\u0122",
                "\u013b",
                ",",
                " \u00e2\u0122",
                "\u013a",
                "why",
                "\u00e2\u0122",
                "\u013b",
                ",",
                " \u00e2\u0122",
                "\u013a",
                "where",
                "\u00e2\u0122",
                "\u013b",
                " and",
                " \u00e2\u0122",
                "\u013a",
                "when",
                "\u00e2\u0122",
                "\u013b",
                " questions",
                ".",
                "\n",
                "\n",
                "Parents",
                " will",
                " be",
                " able",
                " to",
                " monitor",
                " their",
                " child",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " progress",
                " with",
                " their",
                " Cogn",
                "i",
                "Toy",
                " through",
                " a",
                " cloud",
                "-",
                "dash",
                "board",
                " which",
                " will",
                " give",
                " them",
                " real",
                "-",
                "time",
                " data",
                " on",
                " learning",
                " and",
                " interests",
                " as",
                " well",
                " as",
                " allowing",
                " them",
                " to",
                " moderate",
                " the",
                " content",
                " that",
                " comes",
                " out",
                " of",
                " the",
                " d",
                "ino",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " mouth",
                ".",
                "\n",
                "\n",
                "Perhaps",
                " conscious",
                " of",
                " the",
                " recent",
                " high",
                "-",
                "profile",
                " hacking",
                " of",
                " another",
                " internet",
                "-",
                "connected",
                " talking",
                " doll",
                ",",
                " Cay",
                "la",
                ",",
                " the",
                " Cogn",
                "i",
                "T",
                "oys",
                " team",
                " make",
                " a",
                " big",
                " point",
                " of",
                " emphas"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.891,
            "maxValueTokenIndex": 51,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.891,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.237,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 15.227,
            "binMax": 30.454,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zci666wp43nq02",
            "tokens": [
                "A",
                " U",
                "CL",
                "-",
                "led",
                " study",
                " of",
                " 9",
                ",",
                "050",
                " English",
                " people",
                " with",
                " an",
                " average",
                " age",
                " of",
                " 65",
                " found",
                " that",
                " the",
                " people",
                " with",
                " the",
                " greatest",
                " wellbeing",
                " were",
                " 30",
                "%",
                " less",
                " likely",
                " to",
                " die",
                " during",
                " the",
                " average",
                " eight",
                " and",
                " a",
                " half",
                " year",
                " follow",
                "-",
                "up",
                " period",
                " than",
                " those",
                " with",
                " the",
                " least",
                " wellbeing",
                ".",
                "\n",
                "\n",
                "The",
                " study",
                ",",
                " published",
                " in",
                " The",
                " Lancet",
                " as",
                " part",
                " of",
                " a",
                " special",
                " series",
                " on",
                " ageing",
                ",",
                " was",
                " conducted",
                " by",
                " researchers",
                " from",
                " U",
                "CL",
                ",",
                " Princeton",
                " University",
                " and",
                " St",
                "ony",
                " Brook",
                " University",
                ".",
                " It",
                " used",
                " questionnaire",
                " answers",
                " to",
                " measure",
                " a",
                " type",
                " of",
                " wellbeing",
                " called",
                " '",
                "e",
                "ud",
                "emonic",
                " wellbeing",
                "',",
                " which",
                " relates",
                " to",
                " your",
                " sense",
                " of",
                " control",
                ",",
                " feeling",
                " that",
                " what",
                " you",
                " do",
                " is",
                " worthwhile",
                ",",
                " and",
                " your",
                " sense",
                " of",
                " purpose",
                " in",
                " life",
                "."
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.233,
            "maxValueTokenIndex": 100,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.233,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 15.227,
            "binMax": 30.454,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zbi666k6611rdj",
            "tokens": [
                " small",
                " amount",
                " of",
                " Latin",
                " in",
                " the",
                " course",
                " of",
                " her",
                " education",
                " but",
                " she",
                " greatly",
                " desired",
                " to",
                " read",
                " and",
                " learn",
                ".",
                " Her",
                " husband",
                " had",
                " a",
                " remarkable",
                " library",
                " that",
                " included",
                " many",
                " medieval",
                " classics",
                " like",
                " \u00e2\u0122",
                "\u013e",
                "L",
                "ancel",
                "ot",
                "\u00e2\u0122",
                "\u013f",
                " and",
                " \u00e2\u0122",
                "\u013e",
                "The",
                " Roman",
                " de",
                " la",
                " Rose",
                "\u00e2\u0122",
                "\u013f",
                " along",
                " with",
                " works",
                " by",
                " Dante",
                ",",
                " Petr",
                "arch",
                ",",
                " Christine",
                " de",
                " P",
                "iz",
                "an",
                " and",
                " B",
                "occ",
                "acc",
                "io",
                ".",
                " Charles",
                " and",
                " Louise",
                " shared",
                " a",
                " love",
                " of",
                " books",
                " and",
                " their",
                " marriage",
                " was",
                " relatively",
                " happy",
                ".",
                " For",
                " the",
                " most",
                " part",
                " they",
                " lived",
                " a",
                " quiet",
                " life",
                " in",
                " Cogn",
                "ac",
                ".",
                " The",
                " couple",
                " visited",
                " the",
                " court",
                " of",
                " King",
                " Charles",
                " VIII",
                " in",
                " 14",
                "90",
                "/",
                "91",
                ".",
                "\n",
                "\n",
                "Lou",
                "ise",
                " gave",
                " birth",
                " to",
                " a",
                " daughter",
                " Marg",
                "uer",
                "ite",
                " on",
                " April",
                " 11",
                ","
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 15.745,
            "maxValueTokenIndex": 93,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.745,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 15.227,
            "binMax": 30.454,
            "binContains": 0,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zfi66609yk7lv4",
            "tokens": [
                " funding",
                " renewable",
                " energy",
                " research",
                " and",
                " regulating",
                " carbon",
                " dioxide",
                " as",
                " a",
                " pollut",
                "ant",
                ".",
                " And",
                " people",
                " from",
                " both",
                " parties",
                " are",
                " generally",
                " supportive",
                " of",
                " ending",
                " all",
                " fossil",
                " fuel",
                " subsidies",
                ",",
                " although",
                " Democrats",
                " (",
                "67",
                " percent",
                ")",
                " are",
                " more",
                " supportive",
                " of",
                " that",
                " policy",
                " than",
                " Republicans",
                " (",
                "52",
                " percent",
                ").",
                "<|endoftext|>",
                "This",
                " Article",
                " Comes",
                " From",
                " the",
                " Heart",
                " and",
                " Discuss",
                "es",
                " an",
                " Issue",
                " We",
                " All",
                " Have",
                " in",
                " Common",
                "\n",
                "\n",
                "The",
                " problem",
                " is",
                " being",
                " normal",
                ".",
                " What",
                " is",
                " being",
                " normal",
                "?",
                " It",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " doing",
                " things",
                " that",
                " an",
                " average",
                " person",
                " does",
                ".",
                "\n",
                "\n",
                "An",
                " average",
                " person",
                " for",
                " example",
                " comes",
                " home",
                " from",
                " their",
                " boring",
                " 9",
                "-",
                "5",
                " job",
                " to",
                " either",
                " play",
                " video",
                " games",
                ",",
                " watch",
                " T",
                ".",
                "V",
                ".,",
                " or",
                " watch",
                " porn",
                " maybe",
                " that",
                " person",
                " will",
                " do",
                " all",
                " of",
                " those",
                " things"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 15.227,
            "binContains": 0.9999800000000001,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zgi6666f7f5yv4",
            "tokens": [
                " by",
                " a",
                " human",
                " player",
                " waiting",
                " for",
                " new",
                "bies",
                " to",
                " wander",
                " into",
                " firing",
                " range",
                ".",
                "\n",
                "\n",
                "Und",
                "ead",
                " also",
                " offer",
                " more",
                " risk",
                " than",
                " reward",
                ".",
                " Zombie",
                "-",
                "pop",
                "ulated",
                " towns",
                " are",
                " scattered",
                " with",
                " goodies",
                " like",
                " bottles",
                " of",
                " water",
                " and",
                " food",
                " and",
                " medical",
                " supplies",
                ",",
                " but",
                " little",
                " is",
                " worth",
                " risking",
                " life",
                " and",
                " limb",
                " over",
                ",",
                " especially",
                " given",
                " the",
                " need",
                " to",
                " run",
                " those",
                " g",
                "auntlets",
                " set",
                " up",
                " by",
                " other",
                " players",
                ".",
                " You",
                " can",
                " also",
                " be",
                " quickly",
                " overwhelmed",
                " by",
                " gangs",
                " of",
                " zombies",
                " who",
                " pop",
                " up",
                " out",
                " of",
                " nowhere",
                " and",
                " move",
                " more",
                " quickly",
                " than",
                " you",
                " might",
                " expect",
                ".",
                "\n",
                "\n",
                "Here",
                "'s",
                " a",
                " message",
                " you",
                " see",
                " a",
                " lot",
                " in",
                " The",
                " War",
                " Z",
                ".",
                "\n",
                "\n",
                "Combat",
                " isn",
                "'t",
                " particularly",
                " difficult",
                ";",
                " you",
                " can",
                " generally",
                " button",
                "-",
                "m",
                "ash",
                " the",
                " undead",
                " go"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 15.227,
            "binContains": 0.9999800000000001,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zhi666gzchi5fy",
            "tokens": [
                " Indiana",
                " Jones",
                ",",
                " Professor",
                " Plum",
                " of",
                " \"",
                "Cl",
                "ue",
                " University",
                ",\"",
                " and",
                " G",
                "ild",
                "er",
                "oy",
                " Lock",
                "hart",
                " from",
                " Harry",
                " Potter",
                "'s",
                " Hogwarts",
                " School",
                " of",
                " Witch",
                "craft",
                " and",
                " Wizard",
                "ry",
                ",",
                " among",
                " others",
                ".",
                "\n",
                "\n",
                "Professor",
                " Watch",
                "list",
                ",",
                " launched",
                " Monday",
                ",",
                " is",
                " a",
                " project",
                " of",
                " Turning",
                " Point",
                " USA",
                ".",
                " The",
                " group",
                "'s",
                " mission",
                " is",
                " to",
                " \"",
                "ident",
                "ify",
                ",",
                " educate",
                ",",
                " train",
                " and",
                " organize",
                " students",
                " to",
                " promote",
                " the",
                " principles",
                " of",
                " fiscal",
                " responsibility",
                ",",
                " free",
                " markets",
                " and",
                " limited",
                " government",
                ".\"",
                " Its",
                " national",
                " college",
                " and",
                " university",
                " field",
                " program",
                " works",
                " to",
                " \"",
                "ident",
                "ify",
                " young",
                " conservative",
                " activists",
                ",",
                " build",
                " and",
                " maintain",
                " effective",
                " student",
                " groups",
                ",",
                " advertise",
                " and",
                " re",
                "brand",
                " conservative",
                " values",
                ",",
                " engage",
                " in",
                " face",
                "-",
                "to",
                "-",
                "face",
                " and",
                " peer",
                "-",
                "to",
                "-",
                "peer",
                " conversations",
                " about",
                " the"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 15.227,
            "binContains": 0.9999800000000001,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvnm4zii666qsgyl7ci",
            "tokens": [
                " university",
                " says",
                " the",
                " investigation",
                " is",
                " ongoing",
                ".",
                "<|endoftext|>",
                "If",
                " you",
                "'re",
                " watching",
                " the",
                " air",
                "-",
                "cool",
                "ed",
                " Porsche",
                " 911",
                " market",
                " as",
                " closely",
                " as",
                " we",
                " are",
                ",",
                " you",
                "'d",
                " know",
                " prices",
                " have",
                " been",
                " rising",
                " at",
                " an",
                " astronomical",
                " rate",
                ".",
                " The",
                " days",
                " of",
                " the",
                " $",
                "20",
                ",",
                "000",
                " 911",
                "SC",
                " are",
                " long",
                " gone",
                ",",
                " and",
                " good",
                " examples",
                " of",
                " a",
                " standard",
                " 9",
                "64",
                " can",
                " reach",
                " over",
                " sixty",
                " grand",
                ".",
                " While",
                " these",
                " prices",
                " seem",
                " high",
                ",",
                " nothing",
                " can",
                " prepare",
                " you",
                " for",
                " how",
                " much",
                " this",
                " ultra",
                "-",
                "ra",
                "re",
                " 1995",
                " 9",
                "93",
                " GT",
                "2",
                " sold",
                " for",
                ".",
                " $",
                "2",
                ".",
                "4",
                " million",
                " dollars",
                ".",
                " Yep",
                ".",
                "\n",
                "\n",
                "The",
                " 9",
                "93",
                " was",
                " Porsche",
                "'s",
                " last",
                " air",
                "-",
                "cool",
                "ed",
                " generation",
                " of",
                " the",
                " 911",
                ",",
                " before",
                " Porsche",
                " decided",
                " to",
                " start",
                " cooling",
                " its",
                " engines"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 15.227,
            "binContains": 0.9999800000000001,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdn2pvom4zji666c1gs6g95",
            "tokens": [
                "\u013e",
                "the",
                " increase",
                " in",
                " \u00e2\u0122\u00a6",
                " temperature",
                " to",
                " well",
                " below",
                " 2",
                " \u00c2\u00b0",
                "C",
                " \u00e2\u0122\u00a6",
                " and",
                " to",
                " pursue",
                " efforts",
                " to",
                " limit",
                " the",
                " temperature",
                " increase",
                " to",
                " 1",
                ".",
                "5",
                " \u00c2\u00b0",
                "C",
                "\u00e2\u0122",
                "\u013f",
                ".",
                "\n",
                "\n",
                "To",
                " achieve",
                " such",
                " goals",
                " demands",
                " urgent",
                " and",
                " significant",
                " cuts",
                " in",
                " emissions",
                ".",
                " But",
                " rather",
                " than",
                " requiring",
                " that",
                " nations",
                " reduce",
                " emissions",
                " in",
                " the",
                " short",
                "-",
                "to",
                "-",
                "medium",
                " term",
                ",",
                " the",
                " Paris",
                " agreement",
                " instead",
                " rests",
                " on",
                " the",
                " assumption",
                " that",
                " the",
                " world",
                " will",
                " successfully",
                " suck",
                " the",
                " carbon",
                " pollution",
                " it",
                " produces",
                " back",
                " from",
                " the",
                " atmosphere",
                " in",
                " the",
                " longer",
                " term",
                ".",
                " A",
                " few",
                " years",
                " ago",
                ",",
                " these",
                " exotic",
                " Dr",
                " Str",
                "angel",
                "ove",
                " options",
                " were",
                " discussed",
                " only",
                " as",
                " last",
                "-",
                "d",
                "itch",
                " conting",
                "encies",
                ".",
                " Now",
                " they",
                " are",
                " Plan",
                " A",
                ".",
                "\n",
                "\n",
                "Govern",
                "ments",
                ",",
                " prompted",
                " by",
                " their"
            ],
            "dataIndex": null,
            "index": "23291",
            "layer": "8-res_fs24576-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T19:14:41.386Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 15.227,
            "binContains": 0.9999800000000001,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clytqcha904382ywt9tosi5wv",
            "description": "terms related to cognitive function and performance",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}