{
    "modelId": "gpt2-small",
    "layer": "8-res_fs12288-jb",
    "index": "11943",
    "sourceSetName": "res_fs12288-jb",
    "creatorId": null,
    "createdAt": "2024-06-13T22:32:20.746Z",
    "maxActApprox": 28.509,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        11943,
        9145,
        6001,
        1308,
        287,
        11566,
        4719,
        4540,
        8496,
        8612,
        7013,
        3334,
        5606,
        9134,
        8705,
        4556,
        4854,
        12251,
        2086,
        7163,
        7320,
        6108,
        2910,
        9884,
        8341
    ],
    "topkCosSimValues": [
        1,
        0.402,
        0.3796,
        0.3694,
        0.354,
        0.3443,
        0.3324,
        0.3322,
        0.317,
        0.3076,
        0.3046,
        0.3028,
        0.2886,
        0.2848,
        0.2845,
        0.2797,
        0.2786,
        0.2728,
        0.2724,
        0.2719,
        0.2702,
        0.2698,
        0.2662,
        0.2661,
        0.2628
    ],
    "neuron_alignment_indices": [
        255,
        575,
        540
    ],
    "neuron_alignment_values": [
        0.124,
        0.111,
        0.105
    ],
    "neuron_alignment_l1": [
        0.006,
        0.005,
        0.005
    ],
    "correlated_neurons_indices": [
        575,
        255,
        288
    ],
    "correlated_neurons_pearson": [
        0.064,
        0.061,
        0.057
    ],
    "correlated_neurons_l1": [
        0.073,
        0.063,
        0.069
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "oil",
        "govtrack",
        " Franch",
        " BaseType",
        " Konami",
        "wered",
        "ounty",
        "ranch",
        " Armory",
        " Bans"
    ],
    "neg_values": [
        -0.762,
        -0.756,
        -0.756,
        -0.735,
        -0.7,
        -0.699,
        -0.694,
        -0.688,
        -0.683,
        -0.68
    ],
    "pos_str": [
        " impairment",
        " stimuli",
        " cognition",
        " behaviors",
        " cognitive",
        " behaviours",
        " impaired",
        " subsc",
        " comprehension",
        " skills"
    ],
    "pos_values": [
        1.104,
        1.1,
        1.088,
        1.079,
        1.032,
        1.022,
        0.989,
        0.989,
        0.983,
        0.977
    ],
    "frac_nonzero": 0.00416,
    "freq_hist_data_bar_heights": [
        3159,
        2192,
        1623,
        1244,
        896,
        728,
        557,
        468,
        336,
        290,
        234,
        206,
        166,
        122,
        128,
        88,
        77,
        75,
        68,
        56,
        54,
        35,
        38,
        33,
        20,
        21,
        21,
        13,
        20,
        13,
        14,
        9,
        6,
        9,
        7,
        5,
        6,
        4,
        9,
        4,
        4,
        9,
        4,
        0,
        3,
        1,
        0,
        0,
        0,
        3
    ],
    "freq_hist_data_bar_values": [
        0.285,
        0.855,
        1.425,
        1.996,
        2.566,
        3.136,
        3.706,
        4.276,
        4.847,
        5.417,
        5.987,
        6.557,
        7.127,
        7.697,
        8.268,
        8.838,
        9.408,
        9.978,
        10.548,
        11.119,
        11.689,
        12.259,
        12.829,
        13.399,
        13.969,
        14.54,
        15.11,
        15.68,
        16.25,
        16.82,
        17.391,
        17.961,
        18.531,
        19.101,
        19.671,
        20.241,
        20.812,
        21.382,
        21.952,
        22.522,
        23.092,
        23.663,
        24.233,
        24.803,
        25.373,
        25.943,
        26.513,
        27.084,
        27.654,
        28.224
    ],
    "logits_hist_data_bar_heights": [
        4,
        4,
        10,
        22,
        24,
        62,
        108,
        166,
        273,
        383,
        571,
        897,
        1225,
        1588,
        2022,
        2539,
        3089,
        3381,
        3845,
        3912,
        4054,
        3782,
        3569,
        3138,
        2605,
        2041,
        1734,
        1274,
        1021,
        768,
        536,
        404,
        331,
        210,
        182,
        136,
        85,
        81,
        49,
        34,
        34,
        15,
        17,
        10,
        7,
        3,
        6,
        1,
        1,
        4
    ],
    "logits_hist_data_bar_values": [
        -0.744,
        -0.706,
        -0.669,
        -0.632,
        -0.594,
        -0.557,
        -0.52,
        -0.482,
        -0.445,
        -0.408,
        -0.37,
        -0.333,
        -0.296,
        -0.258,
        -0.221,
        -0.184,
        -0.146,
        -0.109,
        -0.072,
        -0.034,
        0.003,
        0.04,
        0.078,
        0.115,
        0.152,
        0.189,
        0.227,
        0.264,
        0.301,
        0.339,
        0.376,
        0.413,
        0.451,
        0.488,
        0.525,
        0.563,
        0.6,
        0.637,
        0.675,
        0.712,
        0.749,
        0.787,
        0.824,
        0.861,
        0.899,
        0.936,
        0.973,
        1.011,
        1.048,
        1.085
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "8-res_fs12288-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 12288,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "12288-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.8.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_feature_splitting_experiment",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/8-res_fs12288-jb",
            "checkpoint_path": "checkpoints/83dxxo6a",
            "use_ghost_grads": true,
            "expansion_factor": 16,
            "hook_point_layer": 8,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.8.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb-feature-splitting",
        "saelensSaeId": "blocks.8.hook_resid_pre_12288",
        "hfRepoId": "jbloom/GPT2-Small-Feature-Splitting-Experiment-Layer-8",
        "hfFolderId": "blocks.8.hook_resid_pre_12288",
        "visibility": "PUBLIC",
        "setName": "res_fs12288-jb",
        "creatorId": "clkht01d40000jv08hvalcvly",
        "hasUmap": false,
        "hasUmapLogSparsity": false,
        "hasUmapClusters": false,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res_fs12288-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "GPT2-Small Feature Splitting Experiment - 12288",
        "type": "Residual Feature Splitting 12288",
        "creatorName": "Joseph Bloom",
        "urls": [],
        "creatorEmail": null,
        "creatorId": "clkht01d40000jv08hvalcvly",
        "releaseName": "gpt2sm-rfs-jb",
        "defaultRange": 1,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": true,
        "showHeadAttribution": false,
        "showUmap": false,
        "serverHost": "https://1ynud2kk7vnhjo-5002.proxy.runpod.net",
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clxdu4z1q9x63i6664tt6emcu",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.509,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.805,
                0.873,
                5.963,
                8.808,
                10.212,
                4.161,
                0,
                0,
                1.251,
                2.08,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.075,
                0,
                28.509,
                20.21,
                2.242,
                1.211,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.693,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.27,
                17.853,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.194,
                11.772,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.545,
                13.583,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5pi6665pb0il5t",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.509,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.805,
                0.873,
                5.963,
                8.808,
                10.212,
                4.161,
                0,
                0,
                1.251,
                2.08,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.075,
                0,
                28.509,
                20.21,
                2.242,
                1.211,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.693,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.27,
                17.853,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.194,
                11.772,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.545,
                13.583,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x69i666k8fviq9a",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.509,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.805,
                0.873,
                5.963,
                8.808,
                10.212,
                4.161,
                0,
                0,
                1.251,
                2.08,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.075,
                0,
                28.509,
                20.21,
                2.242,
                1.211,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.693,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.27,
                17.853,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.194,
                11.772,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.545,
                13.583,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 22.807,
            "binMax": 28.509,
            "binContains": 1e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5oi66660q91h3k",
            "tokens": [
                " study",
                " from",
                " a",
                " correlated",
                " trait",
                " (",
                "educ",
                "ational",
                " attainment",
                ")",
                " to",
                " pre",
                "-",
                "select",
                " a",
                " small",
                " number",
                " of",
                " genetic",
                " variants",
                ".",
                " These",
                " were",
                " then",
                " tested",
                " for",
                " association",
                " with",
                " cognitive",
                " performance",
                " \u2013",
                " a",
                " bit",
                " like",
                " leveraging",
                " a",
                " large",
                " study",
                " on",
                " the",
                " genetics",
                " of",
                " weight",
                " to",
                " find",
                " genes",
                " for",
                " diabetes",
                ".",
                "\n",
                "\n",
                "Three",
                " genetic",
                " variants",
                " (",
                "out",
                " of",
                " thousands",
                ")",
                "\n",
                "\n",
                "Previously",
                ",",
                " using",
                " a",
                " genome",
                "-",
                "wide",
                " study",
                " in",
                " a",
                " sample",
                " of",
                " 18",
                ",",
                "000",
                " individuals",
                ",",
                " we",
                " could",
                " not",
                " identify",
                " a",
                " single",
                " genetic",
                " variant",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " Using",
                " the",
                " new",
                " proxy",
                " strategy",
                ",",
                " though",
                ",",
                " we",
                " identified",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " cognitive",
                " performance",
                ".",
                " As",
                " expected",
                " from",
                " the",
                " calculation",
                ",",
                " the",
                " effects",
                " of",
                " these",
                " variants",
                " on",
                " cognitive",
                " performance",
                " are",
                " tiny",
                ".",
                "\n"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.509,
            "maxValueTokenIndex": 28,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.805,
                0.873,
                5.963,
                8.808,
                10.212,
                4.161,
                0,
                0,
                1.251,
                2.08,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.075,
                0,
                28.509,
                20.21,
                2.242,
                1.211,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.693,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.27,
                17.853,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.194,
                11.772,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.545,
                13.583,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5qi666duhtnfo2",
            "tokens": [
                " can",
                " receive",
                " from",
                " breast",
                " milk",
                " alone",
                ".",
                "<|endoftext|>",
                "The",
                " role",
                " of",
                " carbohydrates",
                " on",
                " mood",
                " and",
                " cognition",
                " is",
                " fairly",
                " well",
                " established",
                ",",
                " however",
                " research",
                " examining",
                " the",
                " behavioural",
                " effects",
                " of",
                " the",
                " other",
                " mac",
                "ron",
                "ut",
                "rients",
                " is",
                " limited",
                ".",
                " The",
                " current",
                " study",
                " compared",
                " the",
                " effects",
                " of",
                " a",
                " 25",
                " g",
                " glucose",
                " drink",
                " to",
                " ener",
                "get",
                "ically",
                " matched",
                " protein",
                " and",
                " fat",
                " drinks",
                " and",
                " an",
                " inert",
                " placebo",
                ".",
                " Following",
                " a",
                " blind",
                ",",
                " placebo",
                "-",
                "controlled",
                ",",
                " random",
                "ised",
                " crossover",
                " design",
                ",",
                " 18",
                " healthy",
                " young",
                " adults",
                " consumed",
                " drinks",
                " containing",
                " fat",
                ",",
                " glucose",
                ",",
                " protein",
                " and",
                " placebo",
                ".",
                " Cognitive",
                " performance",
                " was",
                " examined",
                " at",
                " baseline",
                " and",
                " again",
                " 15",
                "-",
                " and",
                " 60",
                " min",
                " post",
                " drink",
                ".",
                " Mood",
                " was",
                " assessed",
                " at",
                " baseline",
                " and",
                " then",
                " 10",
                "-,",
                " 35",
                "-",
                " and",
                " 80",
                " min",
                " post",
                " drink",
                ".",
                " Attention",
                " and",
                " speed"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.03,
            "maxValueTokenIndex": 91,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.204,
                4.086,
                19.744,
                0.554,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.868,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.954,
                0,
                1.444,
                0.669,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.03,
                22.007,
                6.512,
                2.004,
                2.543,
                0.9,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.871,
                6.221,
                6.694,
                2.979,
                0.719,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.908,
                10.469,
                17.723
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x6ci666k9375uzy",
            "tokens": [
                " can",
                " receive",
                " from",
                " breast",
                " milk",
                " alone",
                ".",
                "<|endoftext|>",
                "The",
                " role",
                " of",
                " carbohydrates",
                " on",
                " mood",
                " and",
                " cognition",
                " is",
                " fairly",
                " well",
                " established",
                ",",
                " however",
                " research",
                " examining",
                " the",
                " behavioural",
                " effects",
                " of",
                " the",
                " other",
                " mac",
                "ron",
                "ut",
                "rients",
                " is",
                " limited",
                ".",
                " The",
                " current",
                " study",
                " compared",
                " the",
                " effects",
                " of",
                " a",
                " 25",
                " g",
                " glucose",
                " drink",
                " to",
                " ener",
                "get",
                "ically",
                " matched",
                " protein",
                " and",
                " fat",
                " drinks",
                " and",
                " an",
                " inert",
                " placebo",
                ".",
                " Following",
                " a",
                " blind",
                ",",
                " placebo",
                "-",
                "controlled",
                ",",
                " random",
                "ised",
                " crossover",
                " design",
                ",",
                " 18",
                " healthy",
                " young",
                " adults",
                " consumed",
                " drinks",
                " containing",
                " fat",
                ",",
                " glucose",
                ",",
                " protein",
                " and",
                " placebo",
                ".",
                " Cognitive",
                " performance",
                " was",
                " examined",
                " at",
                " baseline",
                " and",
                " again",
                " 15",
                "-",
                " and",
                " 60",
                " min",
                " post",
                " drink",
                ".",
                " Mood",
                " was",
                " assessed",
                " at",
                " baseline",
                " and",
                " then",
                " 10",
                "-,",
                " 35",
                "-",
                " and",
                " 80",
                " min",
                " post",
                " drink",
                ".",
                " Attention",
                " and",
                " speed"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.03,
            "maxValueTokenIndex": 91,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.204,
                4.086,
                19.744,
                0.554,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.868,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.954,
                0,
                1.444,
                0.669,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.03,
                22.007,
                6.512,
                2.004,
                2.543,
                0.9,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.871,
                6.221,
                6.694,
                2.979,
                0.719,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.908,
                10.469,
                17.723
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 22.807,
            "binMax": 28.509,
            "binContains": 1e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x5zi6665j9r467v",
            "tokens": [
                " can",
                " receive",
                " from",
                " breast",
                " milk",
                " alone",
                ".",
                "<|endoftext|>",
                "The",
                " role",
                " of",
                " carbohydrates",
                " on",
                " mood",
                " and",
                " cognition",
                " is",
                " fairly",
                " well",
                " established",
                ",",
                " however",
                " research",
                " examining",
                " the",
                " behavioural",
                " effects",
                " of",
                " the",
                " other",
                " mac",
                "ron",
                "ut",
                "rients",
                " is",
                " limited",
                ".",
                " The",
                " current",
                " study",
                " compared",
                " the",
                " effects",
                " of",
                " a",
                " 25",
                " g",
                " glucose",
                " drink",
                " to",
                " ener",
                "get",
                "ically",
                " matched",
                " protein",
                " and",
                " fat",
                " drinks",
                " and",
                " an",
                " inert",
                " placebo",
                ".",
                " Following",
                " a",
                " blind",
                ",",
                " placebo",
                "-",
                "controlled",
                ",",
                " random",
                "ised",
                " crossover",
                " design",
                ",",
                " 18",
                " healthy",
                " young",
                " adults",
                " consumed",
                " drinks",
                " containing",
                " fat",
                ",",
                " glucose",
                ",",
                " protein",
                " and",
                " placebo",
                ".",
                " Cognitive",
                " performance",
                " was",
                " examined",
                " at",
                " baseline",
                " and",
                " again",
                " 15",
                "-",
                " and",
                " 60",
                " min",
                " post",
                " drink",
                ".",
                " Mood",
                " was",
                " assessed",
                " at",
                " baseline",
                " and",
                " then",
                " 10",
                "-,",
                " 35",
                "-",
                " and",
                " 80",
                " min",
                " post",
                " drink",
                ".",
                " Attention",
                " and",
                " speed"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.03,
            "maxValueTokenIndex": 91,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.204,
                4.086,
                19.744,
                0.554,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.868,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.954,
                0,
                1.444,
                0.669,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.03,
                22.007,
                6.512,
                2.004,
                2.543,
                0.9,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.871,
                6.221,
                6.694,
                2.979,
                0.719,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.908,
                10.469,
                17.723
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6ei666ugb4ez85",
            "tokens": [
                " is",
                " premature",
                " to",
                " suggest",
                " the",
                " biological",
                " function",
                " of",
                " the",
                " genes",
                " identified",
                ",",
                " our",
                " additional",
                " analysis",
                " suggests",
                " that",
                " the",
                " genes",
                " are",
                " related",
                " to",
                " synaptic",
                " plastic",
                "ity",
                " \u2013",
                " the",
                " main",
                " mechanism",
                " in",
                " the",
                " brain",
                " for",
                " learning",
                " and",
                " memory",
                ".",
                "\n",
                "\n",
                "The",
                " take",
                "-",
                "away",
                " message",
                "\n",
                "\n",
                "This",
                " study",
                " of",
                " normal",
                " variation",
                " in",
                " cognitive",
                " performance",
                " confirms",
                " that",
                " there",
                " is",
                " no",
                " gene",
                " with",
                " a",
                " large",
                " effect",
                " on",
                " this",
                " trait",
                ".",
                " There",
                " is",
                " no",
                " \u00e2\u0122",
                "\u013e",
                "g",
                "ene",
                " for",
                " intelligence",
                "\u00e2\u0122",
                "\u013f",
                " \u2013",
                " instead",
                ",",
                " cognitive",
                " performance",
                " is",
                " likely",
                " to",
                " be",
                " influenced",
                " by",
                " thousands",
                " of",
                " genes",
                ",",
                " each",
                " having",
                " a",
                " small",
                " effect",
                ".",
                "\n",
                "\n",
                "While",
                " the",
                " individual",
                " effect",
                " of",
                " the",
                " genetic",
                " variants",
                " are",
                " extremely",
                " small",
                ",",
                " their",
                " identification",
                " may",
                " lead",
                " to",
                " knowledge",
                " of",
                " the",
                " biological",
                " pathways",
                " involved",
                " in",
                " cognitive"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 26.054,
            "maxValueTokenIndex": 52,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.196,
                4.191,
                8.201,
                0.026,
                0,
                0,
                0,
                0,
                0,
                2.652,
                0,
                19.466,
                8.051,
                22.081,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                26.054,
                13.228,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.225,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                17.659,
                0,
                0,
                0,
                0,
                0,
                21.837,
                14.914,
                4.773,
                2.27,
                0.744,
                2.293,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.815,
                0,
                0,
                0,
                0,
                0,
                0,
                21.71
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 17.105,
            "binMax": 22.807,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5ri666zm6da0p8",
            "tokens": [
                " is",
                " premature",
                " to",
                " suggest",
                " the",
                " biological",
                " function",
                " of",
                " the",
                " genes",
                " identified",
                ",",
                " our",
                " additional",
                " analysis",
                " suggests",
                " that",
                " the",
                " genes",
                " are",
                " related",
                " to",
                " synaptic",
                " plastic",
                "ity",
                " \u2013",
                " the",
                " main",
                " mechanism",
                " in",
                " the",
                " brain",
                " for",
                " learning",
                " and",
                " memory",
                ".",
                "\n",
                "\n",
                "The",
                " take",
                "-",
                "away",
                " message",
                "\n",
                "\n",
                "This",
                " study",
                " of",
                " normal",
                " variation",
                " in",
                " cognitive",
                " performance",
                " confirms",
                " that",
                " there",
                " is",
                " no",
                " gene",
                " with",
                " a",
                " large",
                " effect",
                " on",
                " this",
                " trait",
                ".",
                " There",
                " is",
                " no",
                " \u00e2\u0122",
                "\u013e",
                "g",
                "ene",
                " for",
                " intelligence",
                "\u00e2\u0122",
                "\u013f",
                " \u2013",
                " instead",
                ",",
                " cognitive",
                " performance",
                " is",
                " likely",
                " to",
                " be",
                " influenced",
                " by",
                " thousands",
                " of",
                " genes",
                ",",
                " each",
                " having",
                " a",
                " small",
                " effect",
                ".",
                "\n",
                "\n",
                "While",
                " the",
                " individual",
                " effect",
                " of",
                " the",
                " genetic",
                " variants",
                " are",
                " extremely",
                " small",
                ",",
                " their",
                " identification",
                " may",
                " lead",
                " to",
                " knowledge",
                " of",
                " the",
                " biological",
                " pathways",
                " involved",
                " in",
                " cognitive"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 26.054,
            "maxValueTokenIndex": 52,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.196,
                4.191,
                8.201,
                0.026,
                0,
                0,
                0,
                0,
                0,
                2.652,
                0,
                19.466,
                8.051,
                22.081,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                26.054,
                13.228,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.225,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                17.659,
                0,
                0,
                0,
                0,
                0,
                21.837,
                14.914,
                4.773,
                2.27,
                0.744,
                2.293,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.815,
                0,
                0,
                0,
                0,
                0,
                0,
                21.71
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5si666t6bssihz",
            "tokens": [
                " Ep",
                "ile",
                "psy",
                " Research",
                " UK",
                ",",
                " we",
                " were",
                " able",
                " to",
                " obtain",
                " a",
                " further",
                " grant",
                " from",
                " the",
                " Dun",
                "hill",
                " Medical",
                " Trust",
                " to",
                " conduct",
                " a",
                " pilot",
                " study",
                " to",
                " establish",
                " whether",
                " treatment",
                " of",
                " temporal",
                " lobe",
                " epilepsy",
                " improves",
                " performance",
                " on",
                " a",
                " range",
                " of",
                " memory",
                " tests",
                ".",
                " These",
                " will",
                " include",
                " non",
                "-",
                "standard",
                " tests",
                " to",
                " probe",
                " the",
                " accelerated",
                " loss",
                " of",
                " memories",
                " (",
                "\u00e2\u0122",
                "\u013a",
                "ac",
                "celer",
                "ated",
                " long",
                "-",
                "term",
                " forgetting",
                "\u00e2\u0122",
                "\u013b",
                " or",
                " AL",
                "F",
                ")",
                " that",
                " sometimes",
                " under",
                "lies",
                " autobi",
                "ographical",
                " am",
                "nesia",
                ".",
                "\n",
                "\n",
                "The",
                " work",
                " funded",
                " by",
                " Ep",
                "ile",
                "psy",
                " Research",
                " UK",
                " has",
                " enabled",
                " us",
                " to",
                ":",
                " measure",
                " a",
                " previously",
                " elusive",
                " form",
                " of",
                " memory",
                " impairment",
                " that",
                " occurs",
                " commonly",
                " in",
                " epilepsy",
                ";",
                " locate",
                " its",
                " source",
                " in",
                " the",
                " brain",
                ",",
                " and",
                " launch",
                " a",
                " study",
                " that",
                " will",
                " guide",
                " our",
                " approach"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 25.439,
            "maxValueTokenIndex": 39,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.896,
                4.02,
                0,
                0,
                13.993,
                4.889,
                2.643,
                0,
                1.65,
                25.439,
                8.177,
                0,
                0,
                0,
                0,
                0,
                0,
                0.621,
                0.746,
                0,
                0,
                0.347,
                4.188,
                2.262,
                1.31,
                17.101,
                0.29,
                0,
                0,
                0,
                0,
                0.763,
                4.248,
                1.986,
                0.039,
                17.39,
                0,
                0,
                0,
                0,
                1.561,
                2.327,
                0,
                0,
                0,
                0,
                11.638,
                9.834,
                0,
                9.498,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.408,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.031,
                6.176,
                0,
                0,
                0,
                0,
                0,
                0,
                1.419,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5ti666g93gt1oo",
            "tokens": [
                " of",
                " caffeine",
                " was",
                " in",
                "versely",
                " associated",
                " with",
                " the",
                " cognitive",
                " decline",
                " associated",
                " with",
                " aging",
                " as",
                " well",
                " as",
                " the",
                " incidence",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                ",\"",
                " Mend",
                "on",
                "ca",
                " and",
                " C",
                "un",
                "ha",
                " said",
                " in",
                " a",
                " statement",
                ".",
                " \"",
                "This",
                " was",
                " paralle",
                "led",
                " by",
                " animal",
                " studies",
                " showing",
                " that",
                " chronic",
                " caffeine",
                " administration",
                " prevented",
                " memory",
                " deterioration",
                " and",
                " neuro",
                "deg",
                "ener",
                "ation",
                " in",
                " animal",
                " models",
                " of",
                " aging",
                " and",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                ".\"",
                "\n",
                "\n",
                "M",
                "endon",
                "ca",
                " and",
                " C",
                "un",
                "ha",
                " have",
                " observed",
                " one",
                " of",
                " the",
                " most",
                " prevalent",
                " complications",
                " of",
                " Alzheimer",
                "'s",
                " disease",
                " is",
                " mood",
                " change",
                " --",
                " especially",
                " depression",
                " --",
                " and",
                " they",
                " suggest",
                " caffeine",
                " might",
                " be",
                " a",
                " mood",
                " normal",
                "izer",
                ".",
                "<|endoftext|>",
                "The",
                " manager",
                " of",
                " an",
                " Indiana",
                " Pizza",
                " Hut",
                " has",
                " been",
                " offered",
                " his",
                " job",
                " back",
                " after",
                " claiming",
                " he",
                " was",
                " fired",
                " for",
                " refusing"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 25.293,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                25.293,
                5.078,
                1.224,
                0,
                3.125,
                0,
                1.415,
                0.412,
                0.839,
                0,
                0,
                1.905,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                21.751,
                6.2,
                0.415,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.941,
                0,
                0,
                0.732,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.207,
                0,
                0,
                0,
                5.77,
                5.256,
                0.726,
                0,
                2.745,
                1.895,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.006,
                0.883,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1p9x5ui666gi8s2w3o",
            "tokens": [
                " asked",
                " to",
                " call",
                " the",
                " Mant",
                "eca",
                " Police",
                " Department",
                " at",
                " (",
                "209",
                ")",
                " 4",
                "56",
                "-",
                "81",
                "01",
                ".",
                "\n",
                "\n",
                "The",
                " following",
                " is",
                " the",
                " vehicle",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " description",
                ",",
                " along",
                " with",
                " their",
                " license",
                " plate",
                " numbers",
                ":",
                "\n",
                "\n",
                "-",
                "2008",
                " Ford",
                " F",
                "350",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "11",
                "68",
                "21",
                "\n",
                "\n",
                "-",
                "Well",
                "s",
                " Cargo",
                " Trailer",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " TF",
                "11",
                "44",
                "\n",
                "\n",
                "-",
                "1964",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "4",
                "\n",
                "\n",
                "-",
                "1966",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "5",
                "\n",
                "\n",
                "-",
                "1959",
                " VW",
                " Mini",
                " Bus",
                ",",
                " Oregon",
                " License",
                " plate",
                " number",
                " Y",
                "UM",
                "6",
                "<|endoftext|>",
                "The",
                " aim",
                " of",
                " this",
                " study",
                " was",
                " to",
                " investigate",
                " the",
                " cognitive",
                " as",
                " well",
                " as"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 25.289,
            "maxValueTokenIndex": 123,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                25.289,
                2.067,
                3.403,
                3.325
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x5vi666hxm0cdrp",
            "tokens": [
                ",",
                " was",
                " evaluated",
                " against",
                " pent",
                "yl",
                "en",
                "et",
                "et",
                "raz",
                "ole",
                " (",
                "PT",
                "Z",
                ")-",
                "induced",
                " seizures",
                ",",
                " cognitive",
                " impairment",
                " and",
                " oxidative",
                " stress",
                " in",
                " rats",
                ".",
                " Tian",
                "ept",
                "ine",
                " was",
                " administered",
                " in",
                " three",
                " doses",
                " (",
                "20",
                ",",
                " 40",
                " and",
                " 80",
                " mg",
                "/",
                "kg",
                ")",
                " 30",
                " min",
                " before",
                " PT",
                "Z",
                " (",
                "60",
                " mg",
                "/",
                "kg",
                ",",
                " intra",
                "per",
                "itone",
                "ally",
                ").",
                " MK",
                "801",
                ",",
                " an",
                " N",
                "-",
                "methyl",
                "-",
                "D",
                "-",
                "as",
                "part",
                "ate",
                " antagonist",
                ",",
                " and",
                " n",
                "al",
                "ox",
                "one",
                ",",
                " an",
                " opioid",
                " receptor",
                " antagonist",
                ",",
                " were",
                " administered",
                " with",
                " t",
                "ian",
                "ept",
                "ine",
                " to",
                " evaluate",
                " the",
                " involvement",
                " of",
                " N",
                "-",
                "methyl",
                "-",
                "D",
                "-",
                "as",
                "part",
                "ate",
                " and",
                " opioid",
                " receptors",
                ",",
                " respectively",
                ".",
                " Morris",
                " water",
                " maze",
                ",",
                " elevated",
                " plus",
                " maze",
                " and",
                " passive",
                " avoidance",
                " tests",
                " were",
                " performed",
                " for"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 24.347,
            "maxValueTokenIndex": 18,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.593,
                0,
                24.347,
                9.39,
                2.363,
                0.362,
                3.226,
                0.483,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                12.6,
                3.513,
                0,
                0,
                10.807,
                1.156,
                5.063,
                17.004,
                6.508,
                0.184,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x5wi666qib079hl",
            "tokens": [
                " are",
                " at",
                " their",
                " best",
                " in",
                " the",
                " spring",
                " when",
                " cows",
                " can",
                " gra",
                "ze",
                " on",
                " the",
                " fast",
                "-",
                "growing",
                " and",
                " lush",
                " grass",
                "es",
                " of",
                " spring",
                ".",
                " Spring",
                "time",
                " butter",
                " and",
                " cream",
                " from",
                " grass",
                "-",
                "fed",
                " cows",
                " are",
                " extraordinarily",
                " rich",
                " in",
                " nour",
                "ishing",
                " fats",
                ":",
                " conj",
                "ug",
                "ated",
                " lin",
                "ole",
                "ic",
                " acid",
                " which",
                " shows",
                " promise",
                " in",
                " reducing",
                " the",
                " risk",
                " of",
                " cancers",
                " and",
                " metabolic",
                " syndrome",
                ",",
                " as",
                " well",
                " as",
                " trans",
                "-",
                "pal",
                "mit",
                "ole",
                "ic",
                " acid",
                " which",
                " shows",
                " promise",
                " in",
                " mitigating",
                " the",
                " risk",
                " of",
                " cardiovascular",
                " disease",
                ".",
                "\n",
                "\n",
                "But",
                "ter",
                " and",
                " cream",
                " from",
                " grass",
                "-",
                "fed",
                " cows",
                " are",
                " also",
                " rich",
                " sources",
                " of",
                " fat",
                "-",
                "sol",
                "uble",
                " vitamins",
                " particularly",
                " vitamins",
                " A",
                ",",
                " E",
                " and",
                " K",
                "2",
                ".",
                " These",
                " fat",
                "-",
                "sol",
                "uble",
                " vitamins",
                " support",
                " cognitive",
                " function",
                ",",
                " heart",
                " health",
                ",",
                " bone"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 24.176,
            "maxValueTokenIndex": 120,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                24.176,
                13.774,
                4.24,
                0,
                3.002,
                0.863,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x5xi666shmid9ic",
            "tokens": [
                "\u013e",
                "intelligence",
                "\u00e2\u0122",
                "\u013f",
                " can",
                " be",
                " controversial",
                ",",
                " cognitive",
                " performance",
                " scores",
                " are",
                " widely",
                " used",
                " because",
                " of",
                " their",
                " predictive",
                " ability",
                ".",
                " Educational",
                " attainment",
                ",",
                " income",
                ",",
                " job",
                " performance",
                " and",
                " health",
                " are",
                " all",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "By",
                " comparing",
                " the",
                " cognitive",
                " performance",
                " between",
                " family",
                " members",
                ",",
                " including",
                " comparisons",
                " between",
                " identical",
                " and",
                " non",
                "-",
                "ident",
                "ical",
                " twins",
                ",",
                " scientists",
                " are",
                " able",
                " to",
                " quantify",
                " the",
                " contribution",
                " of",
                " genetic",
                " and",
                " environmental",
                " causes",
                " of",
                " individual",
                " differences",
                ".",
                "\n",
                "\n",
                "Dec",
                "ades",
                " of",
                " research",
                " have",
                " shown",
                " that",
                " genetic",
                " factors",
                " account",
                " for",
                " about",
                " half",
                " of",
                " the",
                " causes",
                " of",
                " individual",
                " difference",
                " in",
                " cognitive",
                " performance",
                ",",
                " and",
                " recent",
                " studies",
                " using",
                " unrelated",
                " people",
                " have",
                " confirmed",
                " that",
                " a",
                " substantial",
                " proportion",
                " of",
                " individual",
                " difference",
                " is",
                " due",
                " to",
                " genetic",
                " factors",
                ".",
                "\n",
                "\n",
                "So",
                ",",
                " we",
                " know",
                " now"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 24.022,
            "maxValueTokenIndex": 96,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                14.626,
                14.539,
                8.635,
                0,
                0,
                0,
                0,
                0,
                0,
                4.188,
                10.126,
                0,
                9.507,
                8.09,
                1.647,
                1.187,
                0,
                0.582,
                5.828,
                0,
                0,
                0,
                0,
                0,
                0,
                21.423,
                13.339,
                0,
                0,
                0,
                0,
                0,
                0,
                19.466,
                10.372,
                0.819,
                0,
                0,
                0,
                0,
                0,
                0,
                1.684,
                0,
                0,
                0,
                0,
                1.802,
                0.27,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.106,
                1.058,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.64,
                3.925,
                0,
                24.022,
                14.844,
                0,
                0,
                0,
                0,
                0,
                3.558,
                0.819,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.24,
                3.078,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x5yi666h3j58tdv",
            "tokens": [
                ".",
                "\n",
                "\n",
                "Education",
                " attainment",
                " is",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ",",
                " so",
                " given",
                " these",
                " two",
                " observations",
                ",",
                " we",
                " tested",
                " the",
                " genetic",
                " variants",
                " for",
                " education",
                " attainment",
                " with",
                " their",
                " associations",
                " with",
                " cognitive",
                " performance",
                ",",
                " which",
                " we",
                " report",
                " in",
                " P",
                "NAS",
                " today",
                ".",
                "\n",
                "\n",
                "We",
                " tested",
                " 69",
                " genetic",
                " variants",
                " from",
                " the",
                " educational",
                " attainment",
                " study",
                " (",
                "of",
                " almost",
                " 107",
                ",",
                "000",
                " people",
                ")",
                " in",
                " independent",
                " samples",
                " of",
                " 24",
                ",",
                "000",
                " people",
                " who",
                " had",
                " a",
                " cognitive",
                " performance",
                " score",
                ".",
                " This",
                " two",
                "-",
                "stage",
                " strategy",
                " is",
                " called",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "proxy",
                "-",
                "phen",
                "otype",
                " method",
                "\u00e2\u0122",
                "\u013f",
                " since",
                " educational",
                " attainment",
                " is",
                " a",
                " proxy",
                " phenotype",
                " (",
                "an",
                " observable",
                " characteristic",
                " or",
                " trait",
                ")",
                " for",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "The",
                " essence",
                " of",
                " this",
                " design",
                " was",
                " to",
                " pig",
                "gy",
                "-",
                "back",
                " on",
                " a",
                " much",
                " larger"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.96,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.195,
                1.058,
                0,
                0,
                23.96,
                14.84,
                2.073,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.833,
                7.123,
                0,
                0,
                0,
                0,
                23.516,
                13.554,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.752,
                7.653,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                22.155,
                15.735,
                6.504,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.92,
                4.58,
                2.231,
                0,
                0,
                0,
                0,
                0,
                0,
                2.734,
                0,
                3.937,
                0,
                0,
                19.295,
                11.964,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x64i666jp3zaj94",
            "tokens": [
                ".",
                "\n",
                "\n",
                "Education",
                " attainment",
                " is",
                " correlated",
                " with",
                " cognitive",
                " performance",
                ",",
                " so",
                " given",
                " these",
                " two",
                " observations",
                ",",
                " we",
                " tested",
                " the",
                " genetic",
                " variants",
                " for",
                " education",
                " attainment",
                " with",
                " their",
                " associations",
                " with",
                " cognitive",
                " performance",
                ",",
                " which",
                " we",
                " report",
                " in",
                " P",
                "NAS",
                " today",
                ".",
                "\n",
                "\n",
                "We",
                " tested",
                " 69",
                " genetic",
                " variants",
                " from",
                " the",
                " educational",
                " attainment",
                " study",
                " (",
                "of",
                " almost",
                " 107",
                ",",
                "000",
                " people",
                ")",
                " in",
                " independent",
                " samples",
                " of",
                " 24",
                ",",
                "000",
                " people",
                " who",
                " had",
                " a",
                " cognitive",
                " performance",
                " score",
                ".",
                " This",
                " two",
                "-",
                "stage",
                " strategy",
                " is",
                " called",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "proxy",
                "-",
                "phen",
                "otype",
                " method",
                "\u00e2\u0122",
                "\u013f",
                " since",
                " educational",
                " attainment",
                " is",
                " a",
                " proxy",
                " phenotype",
                " (",
                "an",
                " observable",
                " characteristic",
                " or",
                " trait",
                ")",
                " for",
                " cognitive",
                " performance",
                ".",
                "\n",
                "\n",
                "The",
                " essence",
                " of",
                " this",
                " design",
                " was",
                " to",
                " pig",
                "gy",
                "-",
                "back",
                " on",
                " a",
                " much",
                " larger"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.96,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                5.195,
                1.058,
                0,
                0,
                23.96,
                14.84,
                2.073,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.833,
                7.123,
                0,
                0,
                0,
                0,
                23.516,
                13.554,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.752,
                7.653,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                22.155,
                15.735,
                6.504,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.92,
                4.58,
                2.231,
                0,
                0,
                0,
                0,
                0,
                0,
                2.734,
                0,
                3.937,
                0,
                0,
                19.295,
                11.964,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x60i666b09vdihr",
            "tokens": [
                " behavioural",
                " assessment",
                ".",
                " Brain",
                " mal",
                "ond",
                "ial",
                "de",
                "hyde",
                " and",
                " reduced",
                " glut",
                "ath",
                "ione",
                " levels",
                " were",
                " estimated",
                " as",
                " markers",
                " of",
                " oxidative",
                " stress",
                ".",
                " Tian",
                "ept",
                "ine",
                " showed",
                " dose",
                "-",
                "dependent",
                " protection",
                " against",
                " PT",
                "Z",
                " seizures",
                ".",
                " C",
                "oad",
                "minist",
                "ration",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                " with",
                " MK",
                "801",
                " potent",
                "iated",
                " the",
                " ant",
                "icon",
                "v",
                "uls",
                "ant",
                " effect",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                ".",
                " The",
                " protective",
                " effect",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                " against",
                " PT",
                "Z",
                " seizures",
                " was",
                " mit",
                "igated",
                " when",
                " t",
                "ian",
                "ept",
                "ine",
                " was",
                " administered",
                " with",
                " n",
                "al",
                "ox",
                "one",
                ".",
                " Imp",
                "air",
                "ment",
                " of",
                " learning",
                " and",
                " memory",
                " by",
                " PT",
                "Z",
                " was",
                " prevented",
                " by",
                " t",
                "ian",
                "ept",
                "ine",
                ".",
                " Tian",
                "ept",
                "ine",
                " also",
                " atten",
                "uated",
                " the",
                " seizure",
                "-",
                "induced",
                " increased",
                " oxidative",
                " stress",
                ".",
                " Thus",
                ",",
                " t",
                "ian"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.898,
            "maxValueTokenIndex": 97,
            "minValue": 0,
            "values": [
                1.35,
                1.703,
                0,
                1.876,
                0,
                0,
                0.845,
                0,
                0,
                0,
                0.929,
                2.413,
                0,
                0.053,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.354,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.337,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.726,
                2.606,
                0.053,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.166,
                11.146,
                23.898,
                0,
                1.998,
                1.288,
                0,
                0.955,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.36,
                5.493,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x6ai666bns5gngr",
            "tokens": [
                " behavioural",
                " assessment",
                ".",
                " Brain",
                " mal",
                "ond",
                "ial",
                "de",
                "hyde",
                " and",
                " reduced",
                " glut",
                "ath",
                "ione",
                " levels",
                " were",
                " estimated",
                " as",
                " markers",
                " of",
                " oxidative",
                " stress",
                ".",
                " Tian",
                "ept",
                "ine",
                " showed",
                " dose",
                "-",
                "dependent",
                " protection",
                " against",
                " PT",
                "Z",
                " seizures",
                ".",
                " C",
                "oad",
                "minist",
                "ration",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                " with",
                " MK",
                "801",
                " potent",
                "iated",
                " the",
                " ant",
                "icon",
                "v",
                "uls",
                "ant",
                " effect",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                ".",
                " The",
                " protective",
                " effect",
                " of",
                " t",
                "ian",
                "ept",
                "ine",
                " against",
                " PT",
                "Z",
                " seizures",
                " was",
                " mit",
                "igated",
                " when",
                " t",
                "ian",
                "ept",
                "ine",
                " was",
                " administered",
                " with",
                " n",
                "al",
                "ox",
                "one",
                ".",
                " Imp",
                "air",
                "ment",
                " of",
                " learning",
                " and",
                " memory",
                " by",
                " PT",
                "Z",
                " was",
                " prevented",
                " by",
                " t",
                "ian",
                "ept",
                "ine",
                ".",
                " Tian",
                "ept",
                "ine",
                " also",
                " atten",
                "uated",
                " the",
                " seizure",
                "-",
                "induced",
                " increased",
                " oxidative",
                " stress",
                ".",
                " Thus",
                ",",
                " t",
                "ian"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.898,
            "maxValueTokenIndex": 97,
            "minValue": 0,
            "values": [
                1.35,
                1.703,
                0,
                1.876,
                0,
                0,
                0.845,
                0,
                0,
                0,
                0.929,
                2.413,
                0,
                0.053,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.354,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.337,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.726,
                2.606,
                0.053,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.166,
                11.146,
                23.898,
                0,
                1.998,
                1.288,
                0,
                0.955,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.36,
                5.493,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 22.807,
            "binMax": 28.509,
            "binContains": 1e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x61i666lsxqjzve",
            "tokens": [
                ",",
                " professor",
                " of",
                " neuro",
                "ph",
                "armac",
                "ology",
                " at",
                " Em",
                "ory",
                " University",
                ",",
                " who",
                " was",
                " not",
                " involved",
                " with",
                " the",
                " research",
                ".",
                "\n",
                "\n",
                "One",
                " distant",
                " but",
                " possible",
                " implication",
                " is",
                " that",
                " medication",
                " focusing",
                " on",
                " the",
                " neuron",
                " receptors",
                " investigated",
                " in",
                " this",
                " study",
                " would",
                " help",
                " someone",
                " who",
                " has",
                " serious",
                " problems",
                " with",
                " attention",
                " and",
                " executive",
                " decisions",
                ",",
                " he",
                " said",
                ".",
                "\n",
                "\n",
                "Although",
                " the",
                " study",
                " was",
                " conducted",
                " on",
                " mice",
                ",",
                " when",
                " speaking",
                " about",
                " individual",
                " nerve",
                " cells",
                ",",
                " it",
                "'s",
                " reasonable",
                " to",
                " say",
                " that",
                " an",
                " isolated",
                " mouse",
                " nerve",
                " cell",
                " is",
                " the",
                " same",
                " as",
                " a",
                " human",
                " one",
                ",",
                " Kuh",
                "ar",
                " said",
                ".",
                " The",
                " two",
                " differ",
                " more",
                " markedly",
                " in",
                " complicated",
                " neural",
                " pathways",
                " and",
                " circuits",
                ",",
                " he",
                " said",
                ".",
                "\n",
                "\n",
                "Hold",
                "ing",
                " for",
                " the",
                " long",
                " term",
                "\n",
                "\n",
                "So",
                ",",
                " what",
                " about",
                " remembering",
                " things",
                " in"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.827,
            "maxValueTokenIndex": 49,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.226,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                22.123,
                8.014,
                23.827,
                12.615,
                1.846,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.268,
                1.427,
                1.957,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.137,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.112,
                4.432,
                2.044
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1q9x62i6669p3an7kn",
            "tokens": [
                "Abstract",
                " Early",
                " retirement",
                " appears",
                " to",
                " have",
                " a",
                " significant",
                " negative",
                " impact",
                " on",
                " the",
                " cognitive",
                " ability",
                " of",
                " people",
                " in",
                " their",
                " early",
                " 60",
                "s",
                " that",
                " is",
                " both",
                " quant",
                "itatively",
                " important",
                " and",
                " causal",
                ".",
                " We",
                " obtain",
                " this",
                " finding",
                " using",
                " cross",
                "-",
                "n",
                "ationally",
                " comparable",
                " survey",
                " data",
                " from",
                " the",
                " United",
                " States",
                ",",
                " England",
                ",",
                " and",
                " Europe",
                " that",
                " allow",
                " us",
                " to",
                " relate",
                " cognition",
                " and",
                " labor",
                " force",
                " status",
                ".",
                " We",
                " argue",
                " that",
                " the",
                " effect",
                " is",
                " causal",
                " by",
                " making",
                " use",
                " of",
                " a",
                " substantial",
                " body",
                " of",
                " research",
                " showing",
                " that",
                " variation",
                " in",
                " pension",
                ",",
                " tax",
                ",",
                " and",
                " disability",
                " policies",
                " explain",
                " most",
                " variation",
                " across",
                " countries",
                " in",
                " average",
                " retirement",
                " rates",
                ".",
                " (",
                "In",
                " an",
                " informal",
                " manner",
                ",",
                " we",
                " are",
                " arguing",
                " that",
                " public",
                " policies",
                " that",
                " affect",
                " the",
                " age",
                " of",
                " retirement",
                " may",
                " be",
                " used",
                " as",
                " instrumental",
                " variables",
                " to",
                " generate",
                " cross",
                "-"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.749,
            "maxValueTokenIndex": 12,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                1.364,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.749,
                15.598,
                0.526,
                0.945,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.424,
                1.052,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.52,
                0.987,
                1.789,
                0,
                0.787,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x65i666fbvmawhl",
            "tokens": [
                " that",
                " cognitive",
                " performance",
                " is",
                " her",
                "itable",
                ",",
                " but",
                " where",
                " are",
                " the",
                " genes",
                "?",
                " Despite",
                " considerable",
                " attempts",
                " to",
                " find",
                " genes",
                " for",
                " cognitive",
                " performance",
                ",",
                " no",
                " specific",
                " genes",
                " had",
                " been",
                " found",
                " and",
                " replicated",
                ".",
                "\n",
                "\n",
                "One",
                " reason",
                " for",
                " this",
                " puzzle",
                " is",
                " that",
                " there",
                " are",
                " a",
                " lot",
                " of",
                " genes",
                " involved",
                " \u2013",
                " thousands",
                ",",
                " even",
                " \u2013",
                " and",
                " their",
                " individual",
                " gene",
                " effect",
                " sizes",
                " are",
                " tiny",
                ".",
                " Past",
                " studies",
                " couldn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " find",
                " them",
                " because",
                " sample",
                " sizes",
                " were",
                " not",
                " large",
                " enough",
                " to",
                " detect",
                " genes",
                " with",
                " statistical",
                " significance",
                ".",
                "\n",
                "\n",
                "So",
                " how",
                " did",
                " we",
                " overcome",
                " this",
                " problem",
                "?",
                "\n",
                "\n",
                "Last",
                " year",
                ",",
                " a",
                " huge",
                " international",
                " collaborative",
                " study",
                " of",
                " more",
                " than",
                " 126",
                ",",
                "000",
                " people",
                " correlated",
                " millions",
                " of",
                " genetic",
                " variants",
                " with",
                " educational",
                " attainment",
                " and",
                " discovered",
                " three",
                " genetic",
                " variants",
                " associated",
                " with",
                " it"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.509,
            "maxValueTokenIndex": 20,
            "minValue": 0,
            "values": [
                0,
                17.158,
                15.172,
                5.097,
                0,
                0.275,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                23.509,
                13.362,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.937,
                9.428,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x66i666fyvg4zeo",
            "tokens": [
                " two",
                " apart",
                ",",
                " it",
                " is",
                " likely",
                " that",
                " they",
                " identified",
                " each",
                " person",
                " by",
                " their",
                " face",
                ".",
                "\n",
                "\n",
                "This",
                " conclusion",
                " is",
                " backed",
                " up",
                " by",
                " the",
                " fact",
                " that",
                " the",
                " wind",
                "y",
                " Antarctic",
                " conditions",
                " make",
                " it",
                " difficult",
                " to",
                " pick",
                " up",
                " smells",
                ",",
                " so",
                " it",
                " is",
                " unlikely",
                " that",
                " the",
                " sk",
                "u",
                "as",
                " used",
                " o",
                "lf",
                "actory",
                " signals",
                " to",
                " identify",
                " intr",
                "uders",
                ".",
                " Furthermore",
                ",",
                " previous",
                " studies",
                " have",
                " shown",
                " that",
                " c",
                "rows",
                " also",
                " apparently",
                " recognize",
                " the",
                " faces",
                " of",
                " individual",
                " humans",
                ",",
                " suggesting",
                " that",
                " birds",
                " with",
                " high",
                " cognition",
                " levels",
                " can",
                " indeed",
                " tell",
                " people",
                " apart",
                " in",
                " this",
                " way",
                ".",
                "\n",
                "\n",
                "As",
                " such",
                ",",
                " the",
                " study",
                " authors",
                " conclude",
                " that",
                " the",
                " sk",
                "u",
                "as",
                "\u00e2\u0122",
                "\u013b",
                " ability",
                " to",
                " discriminate",
                " between",
                " people",
                " is",
                " indicative",
                " of",
                " similarly",
                " high",
                " cognitive",
                " abilities",
                ".",
                " While",
                " some",
                " less",
                " intelligent",
                " species",
                " have"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.46,
            "maxValueTokenIndex": 118,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.241,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.103,
                2.64,
                1.797,
                0.687,
                0.847,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.838,
                0,
                3.856,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.357,
                2.421,
                0.363,
                0,
                1.685,
                3.312,
                1.392,
                0.65,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.921,
                0.99,
                10.357,
                1.668,
                2.926,
                1.862,
                0,
                0,
                1.812,
                0.064,
                23.46,
                10.415,
                0,
                0,
                0,
                0,
                3.79,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x67i66696lohhru",
            "tokens": [
                ",",
                " said",
                " senior",
                " author",
                " Don",
                " Cooper",
                ",",
                " assistant",
                " professor",
                " of",
                " psychiatry",
                " at",
                " the",
                " University",
                " of",
                " Texas",
                " South",
                "western",
                " Medical",
                " Center",
                ".",
                "\n",
                "\n",
                "This",
                " idea",
                ",",
                " that",
                " an",
                " individual",
                " nerve",
                " cell",
                " can",
                " hold",
                " a",
                " trace",
                " memory",
                ",",
                " is",
                " also",
                " related",
                " to",
                " drug",
                " addiction",
                ",",
                " the",
                " study",
                " found",
                ".",
                " By",
                " giving",
                " cocaine",
                " to",
                " mice",
                " in",
                " the",
                " laboratory",
                ",",
                " the",
                " researchers",
                " explained",
                " why",
                " the",
                " drug",
                " imp",
                "airs",
                " short",
                " term",
                " memory",
                ":",
                " Coc",
                "aine",
                " causes",
                " a",
                " buildup",
                " of",
                " dopamine",
                ",",
                " a",
                " brain",
                " chemical",
                " that",
                " decreases",
                " the",
                " individual",
                " nerve",
                " cells",
                "'",
                " ability",
                " to",
                " hold",
                " moment",
                "-",
                "to",
                "-",
                "mom",
                "ent",
                " information",
                ".",
                "\n",
                "\n",
                "The",
                " study",
                " is",
                " an",
                " important",
                " contribution",
                " to",
                " the",
                " field",
                " of",
                " working",
                " memory",
                " because",
                " it",
                " shows",
                " the",
                " molecular",
                " mechanisms",
                " involved",
                " in",
                " the",
                " process",
                ",",
                " said",
                " Michael",
                " Kuh",
                "ar"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.42,
            "maxValueTokenIndex": 67,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.47,
                0,
                0,
                0,
                0,
                0,
                0,
                15.4,
                1.124,
                0,
                0,
                0,
                0,
                0,
                2.848,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.45,
                1.453,
                23.42,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.671,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.094,
                0,
                1.73,
                3.3,
                1.854,
                0,
                0,
                0,
                1.97,
                8.019,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                20.69,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": -1,
            "binMax": 28.509,
            "binContains": -1,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x6bi666nr6w5lo5",
            "tokens": [
                " or",
                " even",
                " court",
                " another",
                " human",
                ".",
                " The",
                " complexity",
                " is",
                " amazing",
                "\u00e2\u0122\u00a6",
                " how",
                " does",
                " our",
                " brain",
                " manage",
                " that",
                "?!",
                " By",
                " first",
                " studying",
                " it",
                " in",
                " the",
                " simpler",
                " brains",
                " of",
                " fruit",
                " flies",
                ",",
                " we",
                " can",
                " gain",
                " a",
                " basic",
                " understanding",
                " that",
                " we",
                " can",
                " apply",
                " to",
                " our",
                " complex",
                " mammalian",
                " brains",
                ".",
                "\n",
                "\n",
                "Stud",
                "ying",
                " courts",
                "hip",
                " behavior",
                " can",
                " provide",
                " us",
                " with",
                " an",
                " understanding",
                " for",
                " how",
                " neurons",
                " communicate",
                " and",
                " integrate",
                " information",
                " to",
                " make",
                " decisions",
                ",",
                " but",
                " researchers",
                " can",
                " do",
                " even",
                " more",
                " with",
                " it",
                ".",
                " As",
                " our",
                " understanding",
                " of",
                " courts",
                "hip",
                " increases",
                ",",
                " we",
                " can",
                " use",
                " it",
                " to",
                " investigate",
                " other",
                " behaviors",
                " that",
                " seem",
                " more",
                " directly",
                " related",
                " to",
                " human",
                " health",
                ",",
                " such",
                " as",
                " learning",
                " and",
                " memory",
                ",",
                " sleep",
                ",",
                " and",
                " addiction",
                ".",
                "\n",
                "\n",
                "For",
                " example",
                ",",
                " the",
                " courts",
                "hip",
                " ritual",
                " is",
                " most",
                " commonly"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 23.24,
            "maxValueTokenIndex": 108,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.148,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.603,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.386,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.868,
                5.351,
                7.182,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.306,
                0,
                0.364,
                4.021,
                0,
                0,
                6.068,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.679,
                6.868,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.685,
                0.316,
                0,
                0,
                0,
                1.685,
                0,
                0,
                0,
                0,
                0,
                0,
                15.158,
                10.188,
                23.24,
                2.841,
                11.051,
                2.996,
                1.57,
                4.862,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.488,
                7.865,
                2.383,
                1.373,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 22.807,
            "binMax": 28.509,
            "binContains": 1e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1r9x68i6668u4n4zpq",
            "tokens": [
                ",",
                " which",
                " evolved",
                " and",
                " lived",
                " in",
                " human",
                "-",
                "free",
                " habitats",
                ",",
                " recognized",
                " individual",
                " humans",
                " just",
                " after",
                " three",
                " or",
                " four",
                " visits",
                ".",
                " It",
                " seems",
                " that",
                " they",
                " have",
                " very",
                " high",
                " levels",
                " of",
                " cognitive",
                " abilities",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "<|endoftext|>",
                "\"",
                "He",
                " isn",
                "'t",
                " so",
                " bad",
                " once",
                " you",
                " get",
                " to",
                " know",
                " him",
                ".",
                " He",
                "'s",
                " just",
                " misunderstood",
                "\"",
                "\n",
                "\n",
                "Q",
                " Junior",
                " was",
                " the",
                " son",
                " of",
                " Q",
                " and",
                " Q",
                ".",
                " He",
                " was",
                " conceived",
                " during",
                " the",
                " Q",
                " Civil",
                " War",
                " as",
                " a",
                " way",
                " to",
                " help",
                " restore",
                " the",
                " status",
                " quo",
                " of",
                " the",
                " Q",
                " Contin",
                "uum",
                " and",
                " end",
                " the",
                " conflict",
                ".",
                " Shortly",
                " after",
                " his",
                " birth",
                ",",
                " Captain",
                " Kathryn",
                " Jan",
                "eway",
                " agreed",
                " to",
                " be",
                " his",
                " god",
                "mother",
                ",",
                " based",
                " on",
                " the",
                " fact",
                " that",
                " she",
                " had",
                " supported",
                " and",
                " encouraged",
                " Q",
                " during",
                " the",
                " civil",
                " war",
                ".",
                " (",
                "V"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 22.87,
            "maxValueTokenIndex": 30,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.516,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                22.87,
                10.795,
                0.176,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 22.807,
            "binMax": 28.509,
            "binContains": 1e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6li666y4muvyjh",
            "tokens": [
                " future",
                ".",
                " Thanks",
                " to",
                " LED",
                "-",
                "Mir",
                "ror",
                "Knight",
                " for",
                " the",
                " heads",
                " up",
                "!",
                "<|endoftext|>",
                "Abstract",
                " Neuro",
                "im",
                "aging",
                " evidence",
                " suggests",
                " that",
                " the",
                " par",
                "ietal",
                " lobe",
                " has",
                " an",
                " important",
                " role",
                " in",
                " memory",
                " retrieval",
                ",",
                " yet",
                " neuro",
                "psych",
                "ology",
                " is",
                " largely",
                " silent",
                " on",
                " this",
                " topic",
                ".",
                " Recently",
                ",",
                " we",
                " reported",
                " that",
                " unilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " imp",
                "airs",
                " various",
                " forms",
                " of",
                " visual",
                " working",
                " memory",
                " when",
                " tested",
                " by",
                " old",
                "/",
                "new",
                " recognition",
                ".",
                " Here",
                ",",
                " we",
                " investigate",
                " whether",
                " par",
                "ietal",
                " lobe",
                " working",
                " memory",
                " deficits",
                " are",
                " linked",
                " to",
                " problems",
                " at",
                " retrieval",
                ".",
                " We",
                " tested",
                " two",
                " patients",
                " with",
                " bilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " in",
                " a",
                " series",
                " of",
                " visual",
                " working",
                " memory",
                " tasks",
                " that",
                " prob",
                "ed",
                " recall",
                " and",
                " old",
                "/",
                "new",
                " recognition",
                ".",
                " Stim",
                "uli",
                " were",
                " presented",
                " sequ",
                "entially",
                " and",
                " several",
                " stimulus",
                " categories"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 22.514,
            "maxValueTokenIndex": 31,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.718,
                0.61,
                0,
                0,
                0,
                0,
                0,
                8.221,
                4.232,
                0,
                0,
                0,
                0,
                0.212,
                22.514,
                20.646,
                4.696,
                0,
                0,
                4.928,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.448,
                2.229,
                5.499,
                1.629,
                0,
                0,
                0,
                0.268,
                0,
                0,
                19.176,
                10.717,
                21.725,
                0,
                0,
                0,
                0,
                0,
                1.046,
                18.432,
                0,
                0,
                0,
                0,
                0,
                0,
                1.414,
                4.519,
                0.126,
                12.55,
                21.554,
                4.336,
                0,
                0,
                0,
                1.114,
                0,
                16.442,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.117,
                0,
                0,
                0,
                0,
                0,
                0,
                15.234,
                13.256,
                18.198,
                9.988,
                1.956,
                1.941,
                2.55,
                21.034,
                4.519,
                5.56,
                0,
                5.923,
                16.327,
                0,
                0,
                2.579,
                0,
                1.379,
                0,
                0,
                0,
                0,
                1.863,
                0.332
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 11.404,
            "binMax": 17.105,
            "binContains": 8.999999999999999e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6di66663ul1auw",
            "tokens": [
                " future",
                ".",
                " Thanks",
                " to",
                " LED",
                "-",
                "Mir",
                "ror",
                "Knight",
                " for",
                " the",
                " heads",
                " up",
                "!",
                "<|endoftext|>",
                "Abstract",
                " Neuro",
                "im",
                "aging",
                " evidence",
                " suggests",
                " that",
                " the",
                " par",
                "ietal",
                " lobe",
                " has",
                " an",
                " important",
                " role",
                " in",
                " memory",
                " retrieval",
                ",",
                " yet",
                " neuro",
                "psych",
                "ology",
                " is",
                " largely",
                " silent",
                " on",
                " this",
                " topic",
                ".",
                " Recently",
                ",",
                " we",
                " reported",
                " that",
                " unilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " imp",
                "airs",
                " various",
                " forms",
                " of",
                " visual",
                " working",
                " memory",
                " when",
                " tested",
                " by",
                " old",
                "/",
                "new",
                " recognition",
                ".",
                " Here",
                ",",
                " we",
                " investigate",
                " whether",
                " par",
                "ietal",
                " lobe",
                " working",
                " memory",
                " deficits",
                " are",
                " linked",
                " to",
                " problems",
                " at",
                " retrieval",
                ".",
                " We",
                " tested",
                " two",
                " patients",
                " with",
                " bilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " in",
                " a",
                " series",
                " of",
                " visual",
                " working",
                " memory",
                " tasks",
                " that",
                " prob",
                "ed",
                " recall",
                " and",
                " old",
                "/",
                "new",
                " recognition",
                ".",
                " Stim",
                "uli",
                " were",
                " presented",
                " sequ",
                "entially",
                " and",
                " several",
                " stimulus",
                " categories"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 22.514,
            "maxValueTokenIndex": 31,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.718,
                0.61,
                0,
                0,
                0,
                0,
                0,
                8.221,
                4.232,
                0,
                0,
                0,
                0,
                0.212,
                22.514,
                20.646,
                4.696,
                0,
                0,
                4.928,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.448,
                2.229,
                5.499,
                1.629,
                0,
                0,
                0,
                0.268,
                0,
                0,
                19.176,
                10.717,
                21.725,
                0,
                0,
                0,
                0,
                0,
                1.046,
                18.432,
                0,
                0,
                0,
                0,
                0,
                0,
                1.414,
                4.519,
                0.126,
                12.55,
                21.554,
                4.336,
                0,
                0,
                0,
                1.114,
                0,
                16.442,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.117,
                0,
                0,
                0,
                0,
                0,
                0,
                15.234,
                13.256,
                18.198,
                9.988,
                1.956,
                1.941,
                2.55,
                21.034,
                4.519,
                5.56,
                0,
                5.923,
                16.327,
                0,
                0,
                2.579,
                0,
                1.379,
                0,
                0,
                0,
                0,
                1.863,
                0.332
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 17.105,
            "binMax": 22.807,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6gi666ntsjkulc",
            "tokens": [
                " of",
                " 14",
                " patients",
                " with",
                " Trans",
                "ient",
                " Ep",
                "ile",
                "ptic",
                " Am",
                "nesia",
                ",",
                " a",
                " sub",
                "type",
                " of",
                " temporal",
                " lobe",
                " epilepsy",
                ".",
                " These",
                " patients",
                " performed",
                " normally",
                " on",
                " \u00e2\u0122",
                "\u013a",
                "standard",
                "\u00e2\u0122",
                "\u013b",
                " memory",
                " tests",
                ".",
                " However",
                ",",
                " when",
                " a",
                " more",
                " detailed",
                " method",
                " of",
                " assessment",
                " was",
                " used",
                " (",
                "designed",
                " to",
                " establish",
                " whether",
                " people",
                " can",
                " really",
                " \u00e2\u0122",
                "\u013a",
                "remember",
                " what",
                " it",
                " was",
                " like",
                " to",
                " be",
                " there",
                "\u00e2\u0122",
                "\u013b",
                "),",
                " a",
                " marked",
                " reduction",
                " in",
                " autobi",
                "ographical",
                " memory",
                " was",
                " found",
                " in",
                " the",
                " patient",
                " group",
                ",",
                " which",
                " extended",
                " all",
                " the",
                " way",
                " back",
                " to",
                " the",
                " patients",
                "\u00e2\u0122",
                "\u013b",
                " earliest",
                " memories",
                ".",
                " There",
                " was",
                " also",
                " a",
                " more",
                " subtle",
                " reduction",
                " in",
                " memory",
                " for",
                " recent",
                " public",
                " events",
                ".",
                "\n",
                "\n",
                "This",
                " study",
                " helped",
                " to",
                " make",
                " sense",
                " of",
                " the",
                " memory",
                " complaints",
                " of",
                " people",
                " whose",
                " performance",
                " on",
                " standard",
                " tests",
                " of"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 22.372,
            "maxValueTokenIndex": 30,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.223,
                0,
                0,
                0,
                0,
                0,
                5.567,
                2.566,
                0,
                0,
                0,
                0,
                0,
                0.409,
                0,
                0,
                0,
                0,
                0,
                0,
                22.372,
                3.456,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.924,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.782,
                0,
                13.027,
                0.485,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.773,
                11.71,
                20.544,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.966,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.822,
                5.451,
                0.209,
                1.188,
                2.597,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.215,
                0,
                0,
                0,
                0,
                8.508,
                4.685,
                4.179,
                3.084,
                2.301
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 17.105,
            "binMax": 22.807,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6hi666q7u663ke",
            "tokens": [
                " were",
                " tested",
                ".",
                " The",
                " results",
                " of",
                " these",
                " experiments",
                " show",
                " that",
                " par",
                "ietal",
                " lobe",
                " damage",
                " disproportionately",
                " imp",
                "airs",
                " old",
                "/",
                "new",
                " recognition",
                " as",
                " compared",
                " to",
                " c",
                "ued",
                " recall",
                " across",
                " stimulus",
                " categories",
                ".",
                " The",
                " observed",
                " performance",
                " diss",
                "ociation",
                " suggests",
                " that",
                " the",
                " posterior",
                " par",
                "ietal",
                " lobe",
                " plays",
                " a",
                " particularly",
                " vital",
                " role",
                " in",
                " working",
                " memory",
                " retrieval",
                ".",
                "\n",
                "\n",
                "General",
                " Methods",
                " Participants",
                " Patients",
                " with",
                " bilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " are",
                " extremely",
                " rare",
                ".",
                " The",
                " survival",
                " rate",
                " after",
                " suffering",
                " the",
                " type",
                " of",
                " cere",
                "bro",
                "v",
                "ascular",
                " event",
                " that",
                " produces",
                " bilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " is",
                " low",
                ".",
                " We",
                " were",
                " able",
                " to",
                " identify",
                " to",
                " patients",
                " with",
                " bilateral",
                " par",
                "ietal",
                " lobe",
                " damage",
                " in",
                " our",
                " database",
                ".",
                " These",
                " patients",
                " have",
                " been",
                " discussed",
                " previously",
                " (",
                "Berry",
                "hill",
                ",",
                " Ph",
                "u",
                "ong",
                ",",
                " Pic",
                "asso",
                ",",
                " C"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 22.289,
            "maxValueTokenIndex": 50,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.213,
                5.189,
                0,
                0,
                0,
                0,
                0.475,
                0,
                0.932,
                19.51,
                1.665,
                0,
                0,
                1.176,
                6.412,
                18.338,
                3.28,
                6.988,
                8.676,
                0,
                0,
                0,
                11.021,
                1.176,
                5.577,
                0,
                0,
                0,
                3.006,
                3.221,
                3.842,
                0.299,
                0.023,
                0,
                0,
                0,
                0,
                0,
                6.926,
                22.289,
                18.437,
                0,
                0,
                0,
                1.979,
                0,
                0,
                0,
                0,
                0,
                0.297,
                0.831,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.424,
                0,
                0,
                0,
                0,
                0,
                0,
                1.388,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 17.105,
            "binMax": 22.807,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6fi6668cf770d8",
            "tokens": [
                "ingu",
                "ish",
                " whether",
                " men",
                " are",
                " more",
                " utilitarian",
                " than",
                " women",
                ",",
                " or",
                " women",
                " are",
                " more",
                " de",
                "ont",
                "ological",
                " than",
                " men",
                ",",
                " it",
                " is",
                " necessary",
                " to",
                " measure",
                " [",
                "these",
                "]",
                "in",
                "cl",
                "inations",
                " independently",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " said",
                " F",
                "ries",
                "d",
                "orf",
                ".",
                "\n",
                "\n",
                "The",
                " Results",
                "\n",
                "\n",
                "The",
                " findings",
                " from",
                " the",
                " study",
                " challenge",
                " the",
                " traditional",
                " theory",
                " that",
                " men",
                " prefer",
                " cognitive",
                " decisions",
                " and",
                " women",
                " prefer",
                " emotional",
                " ones",
                ".",
                " After",
                " separating",
                " the",
                " variables",
                ",",
                " researchers",
                " discovered",
                " that",
                " men",
                " and",
                " women",
                " use",
                " cognitive",
                " reasoning",
                " about",
                " equally",
                ".",
                " However",
                ",",
                " women",
                " were",
                " much",
                " more",
                " likely",
                " to",
                " use",
                " emotional",
                " reasoning",
                " than",
                " men",
                " when",
                " one",
                " factor",
                " is",
                " involved",
                ":",
                " harm",
                ".",
                "\n",
                "\n",
                "When",
                " asked",
                " a",
                " moral",
                " dilemma",
                " question",
                " that",
                " did",
                " not",
                " involve",
                " harm",
                ",",
                " women",
                " and",
                " men",
                " both",
                " tended",
                " to",
                " use",
                " utilitarian"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 20.4,
            "maxValueTokenIndex": 59,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                7.6,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.375,
                0,
                0.084,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.154,
                0.221,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.751,
                20.4,
                8.866,
                0.511,
                0,
                0.318,
                5.092,
                0.842,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.731,
                19.846,
                16.639,
                4.904,
                3.917,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.201,
                5.842,
                10.649,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.588,
                0,
                8.743,
                3.895,
                6.93,
                1.218,
                0,
                0,
                0,
                1.207,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.279,
                7.219
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 17.105,
            "binMax": 22.807,
            "binContains": 2e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6ji6669r95wotm",
            "tokens": [
                " instructor",
                "'s",
                " notes",
                " or",
                " a",
                " distraction",
                "-",
                "free",
                " place",
                " to",
                " study",
                ".",
                "\n",
                "\n",
                "A",
                " growing",
                " number",
                " of",
                " students",
                " with",
                " learning",
                " disabilities",
                " are",
                " enroll",
                "ing",
                " in",
                " college",
                ",",
                " yet",
                " few",
                " are",
                " likely",
                " to",
                " get",
                " the",
                " level",
                " of",
                " support",
                " and",
                " encouragement",
                " available",
                " at",
                " Land",
                "mark",
                " College",
                ",",
                " one",
                " of",
                " a",
                " few",
                " small",
                ",",
                " private",
                " colleges",
                " that",
                " specialize",
                " in",
                " educating",
                " students",
                " who",
                " struggle",
                " with",
                " conditions",
                " such",
                " as",
                " dys",
                "lex",
                "ia",
                " or",
                " attention",
                "-",
                "def",
                "icit",
                " disorder",
                ".",
                "\n",
                "\n",
                "Nearly",
                " nine",
                " out",
                " of",
                " 10",
                " of",
                " the",
                " nation",
                "'s",
                " two",
                "-",
                " and",
                " four",
                "-",
                "year",
                " colleges",
                " enroll",
                " students",
                " with",
                " disabilities",
                ",",
                " and",
                " of",
                " the",
                " 86",
                "%",
                " of",
                " those",
                " that",
                " enroll",
                " students",
                " with",
                " learning",
                " disabilities",
                ",",
                " only",
                " 24",
                "%",
                " say",
                " they",
                " can",
                " help",
                " disabled",
                " students",
                " \"",
                "to",
                " a",
                " major",
                " extent",
                ",\""
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 17.363,
            "maxValueTokenIndex": 69,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0.925,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.39,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.196,
                4.067,
                0,
                17.363,
                11.625,
                8.918,
                10.741,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.971,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.074,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 11.404,
            "binMax": 17.105,
            "binContains": 8.999999999999999e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6ni666ijsyj2yk",
            "tokens": [
                " weaker",
                " signals",
                " of",
                " genetic",
                " related",
                "ness",
                " might",
                " exist",
                " year",
                " round",
                " could",
                " provide",
                " a",
                " mechanism",
                " to",
                " explain",
                " ne",
                "pot",
                "ism",
                " between",
                " unfamiliar",
                " kin",
                ".",
                "\n",
                "\n",
                "Like",
                " other",
                " verte",
                "brates",
                ",",
                " primates",
                " recognize",
                " their",
                " relatives",
                ",",
                " primarily",
                " to",
                " minimize",
                " in",
                "breeding",
                ",",
                " but",
                " also",
                " to",
                " facilitate",
                " ne",
                "pot",
                "ism",
                ".",
                " Although",
                " associ",
                "ative",
                ",",
                " social",
                " learning",
                " is",
                " typically",
                " credited",
                " for",
                " discrimination",
                " of",
                " familiar",
                " kin",
                ",",
                " discrimination",
                " of",
                " unfamiliar",
                " kin",
                " remains",
                " unexplained",
                ".",
                " As",
                " sex",
                "-",
                "biased",
                " dispers",
                "al",
                " in",
                " long",
                "-",
                "lived",
                " species",
                " cannot",
                " consistently",
                " prevent",
                " encounters",
                " between",
                " unfamiliar",
                " kin",
                ",",
                " in",
                "breeding",
                " remains",
                " a",
                " threat",
                " and",
                " mechanisms",
                " to",
                " avoid",
                " it",
                " beg",
                " explanation",
                ".",
                " Using",
                " a",
                " molecular",
                " approach",
                " that",
                " combined",
                " analyses",
                " of",
                " biochemical",
                " and",
                " micro",
                "s",
                "atellite",
                " markers",
                " in",
                " 17",
                " female",
                " and",
                " 19",
                " male",
                " ring",
                "-",
                "tailed",
                " le"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 16.511,
            "maxValueTokenIndex": 54,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                4.478,
                4.625,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.409,
                0,
                0,
                2.32,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.533,
                0,
                0,
                0,
                0,
                1.489,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.418,
                7.058,
                0,
                10.839,
                16.511,
                4.757,
                2.788,
                0,
                0,
                9.456,
                0,
                3.626,
                3.612,
                0,
                4.691,
                0.031,
                0.156,
                3.013,
                0,
                0,
                0,
                0,
                0,
                0.934,
                0,
                0.999,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.337,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 5.702,
            "binMax": 11.404,
            "binContains": 0.00039,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6ki666py21rerx",
            "tokens": [
                " performance",
                " on",
                " the",
                " auditory",
                " tests",
                " of",
                " the",
                " Western",
                " A",
                "phas",
                "ia",
                " Battery",
                " (",
                "K",
                "ert",
                "es",
                "z",
                ",",
                " 1982",
                "),",
                " which",
                " were",
                " uniformly",
                " at",
                " ceiling",
                ".",
                " Reading",
                " and",
                " writing",
                " are",
                " impaired",
                " due",
                " to",
                " her",
                " sim",
                "ultan",
                "agn",
                "os",
                "ia",
                " and",
                " spatial",
                " dis",
                "orient",
                "ation",
                ".",
                " Her",
                " visual",
                " ac",
                "uity",
                " is",
                " normal",
                ".",
                " EE",
                "555",
                " was",
                " tested",
                " 1",
                ".",
                "5",
                " \u2013",
                " 2",
                ".",
                "5",
                " years",
                " post",
                " insult",
                ".",
                " Patient",
                " T",
                "Q",
                "591",
                " is",
                " a",
                " 49",
                "-",
                "year",
                "-",
                "old",
                " former",
                " preschool",
                " teacher",
                " with",
                " 15",
                " years",
                " of",
                " education",
                ".",
                " She",
                " suffered",
                " bilateral",
                " par",
                "iet",
                "o",
                "-",
                "occ",
                "ip",
                "ital",
                " damage",
                " due",
                " to",
                " CNS",
                " cerebral",
                " vas",
                "cul",
                "itis",
                " in",
                " March",
                " 2006",
                ".",
                " T",
                "Q",
                "591",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " MRI",
                " revealed",
                " signs",
                " of",
                " previous",
                " sub",
                "ac",
                "ute",
                " posterior",
                " cerebral",
                " artery",
                " inf"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 16.434,
            "maxValueTokenIndex": 40,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                10.451,
                4.471,
                0.806,
                1.002,
                0,
                0,
                6.214,
                6.419,
                0.184,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.798,
                0,
                0.678,
                0,
                0,
                0,
                0,
                14.052,
                6.115,
                14.232,
                5.16,
                8.397,
                0,
                0,
                0,
                3.489,
                0,
                0,
                0,
                0.705,
                0,
                16.434,
                3.68,
                8.887,
                7.781,
                0.468,
                0,
                14.774,
                5.431,
                9.998,
                5.399,
                1.782,
                0,
                1.003,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.579,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.543,
                1.074,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.002,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.34,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 11.404,
            "binMax": 17.105,
            "binContains": 8.999999999999999e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6mi6660xyimwlo",
            "tokens": [
                " have",
                " debated",
                " the",
                " cause",
                " of",
                " these",
                " cr",
                "amps",
                " for",
                " years",
                ".",
                " Part",
                " of",
                " the",
                " reason",
                " is",
                " that",
                " they",
                "'re",
                " hard",
                " to",
                " study",
                " \u2014",
                " you",
                " can",
                "'t",
                " really",
                " put",
                " people",
                " in",
                " a",
                " lab",
                " and",
                " try",
                " to",
                " induce",
                " muscle",
                " cr",
                "amps",
                " in",
                " them",
                ",",
                " because",
                " they",
                " happen",
                " so",
                " randomly",
                ".",
                "\n",
                "\n",
                "both",
                " of",
                " the",
                " mechanisms",
                " can",
                " be",
                " driven",
                " by",
                " excessive",
                " heat",
                "\n",
                "\n",
                "Over",
                " time",
                ",",
                " two",
                " hypotheses",
                " about",
                " the",
                " cause",
                " of",
                " cr",
                "amps",
                " emerged",
                ".",
                " One",
                " held",
                " that",
                " repeated",
                " over",
                "use",
                " of",
                " specific",
                " muscles",
                " leads",
                " to",
                " excessive",
                " activity",
                " in",
                " sensory",
                " receptors",
                " inside",
                " them",
                ",",
                " called",
                " muscle",
                " sp",
                "ind",
                "les",
                ".",
                " This",
                " activity",
                " then",
                " triggers",
                " a",
                " cascade",
                " of",
                " changes",
                " in",
                " the",
                " nervous",
                " system",
                ",",
                " ultimately",
                " disabling",
                " the",
                " mechanisms",
                " that",
                " are",
                " normally",
                " responsible",
                " for",
                " making",
                " sure",
                " muscles",
                " don",
                "'t"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 12.92,
            "maxValueTokenIndex": 89,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.269,
                0,
                12.92,
                3.274,
                0,
                0,
                0,
                0,
                0,
                1.343,
                0,
                0.658,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 11.404,
            "binMax": 17.105,
            "binContains": 8.999999999999999e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1s9x6ii666zkmn6jda",
            "tokens": [
                " towards",
                " a",
                " headphone",
                " sound",
                ".",
                " This",
                " can",
                " be",
                " obvious",
                " as",
                " every",
                " human",
                " is",
                " different",
                " and",
                " the",
                " like",
                " and",
                " disl",
                "ikes",
                " to",
                " a",
                " particular",
                " headphone",
                " sound",
                " mostly",
                " depends",
                " upon",
                " which",
                " sound",
                " is",
                " more",
                " like",
                "able",
                " to",
                " a",
                " particular",
                " human",
                ".",
                "\n",
                "\n",
                "H",
                "earing",
                " ability",
                " varies",
                "\n",
                "\n",
                "The",
                " hearing",
                " capability",
                " of",
                " a",
                " human",
                " undergo",
                "es",
                " changes",
                " with",
                " age",
                ".",
                " If",
                " the",
                " human",
                " ear",
                " is",
                " exposed",
                " to",
                " loud",
                " sounds",
                " continuously",
                ",",
                " it",
                " might",
                " result",
                " in",
                " low",
                " hearing",
                " capabilities",
                " in",
                " the",
                " long",
                " run",
                " as",
                " the",
                " ear",
                " might",
                " have",
                " lost",
                " hearing",
                " efficiency",
                " at",
                " loud",
                " sounds",
                ".",
                " Also",
                ",",
                " as",
                " you",
                " grow",
                " old",
                " with",
                " age",
                ",",
                " the",
                " hearing",
                " aid",
                " of",
                " humans",
                " starts",
                " to",
                " show",
                " changes",
                ",",
                " the",
                " efficiency",
                " of",
                " which",
                " slowly",
                " w",
                "ither",
                "s",
                " away",
                " with",
                " time",
                ".",
                "\n",
                "\n",
                "Reference"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 12.865,
            "maxValueTokenIndex": 87,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.325,
                6.319,
                0,
                0,
                0,
                0,
                10.776,
                3.57,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.576,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.429,
                5.686,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                12.865,
                3.196,
                0,
                0,
                1.838,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.008,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 11.404,
            "binMax": 17.105,
            "binContains": 8.999999999999999e-05,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6ri666jifbh0c1",
            "tokens": [
                "Standing",
                " at",
                " 198",
                "cm",
                " and",
                " tipping",
                " the",
                " scales",
                " at",
                " 110",
                "kg",
                ",",
                " Lane",
                " was",
                " touted",
                " as",
                " a",
                " future",
                " Origin",
                " star",
                " when",
                " he",
                " burst",
                " onto",
                " the",
                " scene",
                " last",
                " year",
                " but",
                " his",
                " progress",
                " has",
                " been",
                " halted",
                " by",
                " the",
                " resurg",
                "ent",
                " form",
                " of",
                " Tony",
                " Williams",
                " and",
                " Des",
                " Has",
                "ler",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " preference",
                " to",
                " carry",
                " Adam",
                " Elliott",
                " on",
                " his",
                " bench",
                ".",
                "<|endoftext|>",
                "By",
                " Tan",
                "ja",
                " Bab",
                "ic",
                ",",
                " PhD",
                "\n",
                "\n",
                "In",
                " the",
                " modern",
                " world",
                ",",
                " success",
                " of",
                " corporations",
                " is",
                " often",
                " driven",
                " by",
                " their",
                " employees",
                " and",
                " teams",
                ".",
                " Understanding",
                " how",
                " human",
                " behaviors",
                " affect",
                " the",
                " workplace",
                " is",
                " the",
                " main",
                " objective",
                " of",
                " industrial",
                " and",
                " organizational",
                " psychology",
                ",",
                " also",
                " known",
                " as",
                " I",
                "/",
                "O",
                " psychology",
                ".",
                " I",
                "/",
                "O",
                " psychologists",
                " study",
                " factors",
                " that",
                " promote",
                " motivation",
                ",",
                " team",
                " work",
                " and",
                " productivity",
                ",",
                " as",
                " well"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 12.791,
            "maxValueTokenIndex": 118,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.794,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.13,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.643,
                0,
                0,
                0,
                0,
                0,
                12.791,
                1.629,
                4.14,
                5.896,
                0.042,
                7.159,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 5.702,
            "binMax": 11.404,
            "binContains": 0.00039,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6pi666qilp17zs",
            "tokens": [
                " from",
                " a",
                " pervasive",
                " feeling",
                " that",
                " the",
                " intense",
                " focus",
                " on",
                " formal",
                " academics",
                " has",
                " inadvertently",
                " neglected",
                " the",
                " rest",
                " of",
                " a",
                " child",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " personality",
                " and",
                " humanity",
                ".",
                " While",
                " employers",
                ",",
                " psychologists",
                " and",
                " other",
                " researchers",
                " have",
                " repeatedly",
                " noted",
                " that",
                " social",
                " and",
                " emotional",
                " skills",
                " like",
                " empathy",
                " are",
                " some",
                " of",
                " the",
                " most",
                " important",
                " ones",
                " for",
                " success",
                ",",
                " many",
                " schools",
                " still",
                " lag",
                " in",
                " developing",
                " effective",
                " programs",
                " to",
                " nurture",
                " those",
                " soft",
                " skills",
                ".",
                "\n",
                "\n",
                "Soc",
                "ietal",
                " norms",
                " posit",
                " girls",
                " as",
                " being",
                " more",
                " emotionally",
                " intelligent",
                " than",
                " boys",
                ",",
                " but",
                " the",
                " subtle",
                " ways",
                " that",
                " teachers",
                " and",
                " parents",
                " reinforce",
                " that",
                " gender",
                " stereotype",
                " can",
                " harm",
                " boys",
                ",",
                " who",
                " need",
                " to",
                " learn",
                " empathy",
                " as",
                " an",
                " important",
                " life",
                " skill",
                " for",
                " connecting",
                " with",
                " others",
                ",",
                " problem",
                "-",
                "s",
                "olving",
                " and",
                " developing",
                " moral",
                " courage",
                ".",
                " Many",
                " of",
                " these",
                " interpersonal",
                " skills"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 12.228,
            "maxValueTokenIndex": 42,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.497,
                0,
                0.576,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.973,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.48,
                0.608,
                6.38,
                10.62,
                1.916,
                12.228,
                3.29,
                0,
                0,
                0.656,
                0,
                0,
                0,
                0,
                4.294,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.237,
                0,
                0,
                0,
                0,
                0,
                0.513,
                0,
                0,
                0,
                0,
                0,
                5.194,
                9.702,
                0,
                1.743,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.429,
                0,
                0,
                0,
                0,
                4.996,
                10.412,
                0,
                1.701,
                0.513,
                1.379,
                5.926,
                0.601,
                2.686,
                2.755,
                4.412,
                0.581,
                0,
                0,
                0,
                10.234,
                4.893,
                1.827,
                10.045,
                8.006,
                0,
                0,
                0,
                0,
                8.681,
                7.456
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 5.702,
            "binMax": 11.404,
            "binContains": 0.00039,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6qi666so7jl3e6",
            "tokens": [
                " from",
                " a",
                " pervasive",
                " feeling",
                " that",
                " the",
                " intense",
                " focus",
                " on",
                " formal",
                " academics",
                " has",
                " inadvertently",
                " neglected",
                " the",
                " rest",
                " of",
                " a",
                " child",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " personality",
                " and",
                " humanity",
                ".",
                " While",
                " employers",
                ",",
                " psychologists",
                " and",
                " other",
                " researchers",
                " have",
                " repeatedly",
                " noted",
                " that",
                " social",
                " and",
                " emotional",
                " skills",
                " like",
                " empathy",
                " are",
                " some",
                " of",
                " the",
                " most",
                " important",
                " ones",
                " for",
                " success",
                ",",
                " many",
                " schools",
                " still",
                " lag",
                " in",
                " developing",
                " effective",
                " programs",
                " to",
                " nurture",
                " those",
                " soft",
                " skills",
                ".",
                "\n",
                "\n",
                "Soc",
                "ietal",
                " norms",
                " posit",
                " girls",
                " as",
                " being",
                " more",
                " emotionally",
                " intelligent",
                " than",
                " boys",
                ",",
                " but",
                " the",
                " subtle",
                " ways",
                " that",
                " teachers",
                " and",
                " parents",
                " reinforce",
                " that",
                " gender",
                " stereotype",
                " can",
                " harm",
                " boys",
                ",",
                " who",
                " need",
                " to",
                " learn",
                " empathy",
                " as",
                " an",
                " important",
                " life",
                " skill",
                " for",
                " connecting",
                " with",
                " others",
                ",",
                " problem",
                "-",
                "s",
                "olving",
                " and",
                " developing",
                " moral",
                " courage",
                ".",
                " Many",
                " of",
                " these",
                " interpersonal",
                " skills"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 12.228,
            "maxValueTokenIndex": 42,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.497,
                0,
                0.576,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.973,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.48,
                0.608,
                6.38,
                10.62,
                1.916,
                12.228,
                3.29,
                0,
                0,
                0.656,
                0,
                0,
                0,
                0,
                4.294,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.237,
                0,
                0,
                0,
                0,
                0,
                0.513,
                0,
                0,
                0,
                0,
                0,
                5.194,
                9.702,
                0,
                1.743,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.429,
                0,
                0,
                0,
                0,
                4.996,
                10.412,
                0,
                1.701,
                0.513,
                1.379,
                5.926,
                0.601,
                2.686,
                2.755,
                4.412,
                0.581,
                0,
                0,
                0,
                10.234,
                4.893,
                1.827,
                10.045,
                8.006,
                0,
                0,
                0,
                0,
                8.681,
                7.456
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 5.702,
            "binMax": 11.404,
            "binContains": 0.00039,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6oi66683x4kusw",
            "tokens": [
                " against",
                " doesn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " simply",
                " render",
                " our",
                " physical",
                " attributes",
                " useless",
                ";",
                " computers",
                " can",
                " outper",
                "form",
                " us",
                " in",
                " a",
                " wider",
                " variety",
                " of",
                " far",
                " more",
                " complex",
                " tasks",
                ".",
                " In",
                " fact",
                ",",
                " the",
                " only",
                " jobs",
                " in",
                " which",
                " we",
                " trump",
                " machines",
                " are",
                " those",
                " that",
                " require",
                " social",
                " intelligence",
                " (",
                "e",
                ".",
                "g",
                ".",
                " persuasion",
                " and",
                " negotiation",
                ")",
                " or",
                " creative",
                " intelligence",
                " (",
                "which",
                " is",
                " simply",
                " the",
                " ability",
                " to",
                " imagine",
                " new",
                " ideas",
                ").",
                " This",
                " means",
                " nearly",
                " 50",
                " percent",
                " of",
                " jobs",
                " are",
                " potentially",
                " autom",
                "atable",
                " within",
                " a",
                " decade",
                " or",
                " two",
                ".",
                "\n",
                "\n",
                "But",
                " we",
                " shouldn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                ";",
                " while",
                " automation",
                " may",
                " eliminate",
                " certain",
                " jobs",
                ",",
                " it",
                " will",
                " also",
                " create",
                " new",
                " ones",
                " that",
                " require",
                " social",
                " and",
                " creative",
                " intelligence",
                ".",
                " However",
                ",",
                " this",
                " kind",
                " of",
                " intellect",
                " is",
                " much",
                " harder",
                " to",
                " acquire",
                ".",
                " More"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.216,
            "maxValueTokenIndex": 55,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.478,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.213,
                7.033,
                0.304,
                0,
                0,
                0,
                0,
                6.8,
                1.257,
                7.322,
                1.888,
                0,
                5.682,
                9.216,
                0,
                0,
                0,
                0,
                0,
                4.466,
                0.656,
                2.594,
                0,
                1.439,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.271,
                0.664,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.92,
                0.231,
                7.148,
                6.365,
                0,
                0,
                0,
                0,
                0,
                0,
                6.614,
                0,
                0,
                0,
                0,
                3.133,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 5.702,
            "binMax": 11.404,
            "binContains": 0.00039,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1u9x6ui66628rejhgh",
            "tokens": [
                " journalists",
                ",",
                " but",
                " also",
                " violate",
                " the",
                " standards",
                " of",
                " NBC",
                " News",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "\n",
                "\n",
                "Chris",
                " Matthews",
                " did",
                " not",
                " return",
                " calls",
                " for",
                " comment",
                ".",
                "\n",
                "\n",
                "\u00e2\u0122",
                "\u013e",
                "Working",
                " women",
                " know",
                " it",
                " is",
                " possible",
                " to",
                " have",
                " their",
                " own",
                " career",
                " and",
                " not",
                " depend",
                " on",
                " their",
                " spouse",
                " for",
                " success",
                ",",
                "\u00e2\u0122",
                "\u013f",
                " said",
                " Kathleen",
                " Matthews",
                "\u00e2\u0122",
                "\u013b",
                " campaign",
                " manager",
                ",",
                " Ethan",
                " Sus",
                "sel",
                "es",
                ".",
                "<|endoftext|>",
                "WASHINGTON",
                " (",
                "Reuters",
                ")",
                " -",
                " President",
                " Barack",
                " Obama",
                ",",
                " leading",
                " in",
                " the",
                " polls",
                " among",
                " women",
                " voters",
                ",",
                " said",
                " on",
                " Friday",
                " he",
                " wants",
                " to",
                " help",
                " working",
                " women",
                " fight",
                " discrimination",
                " and",
                " jugg",
                "le",
                " the",
                " demands",
                " of",
                " mother",
                "hood",
                " but",
                " stopped",
                " short",
                " of",
                " making",
                " promises",
                " on",
                " gender",
                " equality",
                " if",
                " he",
                " wins",
                " re",
                "-",
                "election",
                ".",
                "\n",
                "\n",
                "U",
                ".",
                "S",
                ".",
                " President",
                " Barack",
                " Obama",
                " waves",
                " after"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0.153,
            "maxValueTokenIndex": 79,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.153,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 5.702,
            "binContains": 0.9995,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6si666utl7o19w",
            "tokens": [
                " psychological",
                " impact",
                " could",
                " be",
                " out",
                " of",
                " proportion",
                " to",
                " the",
                " size",
                " of",
                " the",
                " reduction",
                ",",
                " according",
                " to",
                " Howard",
                " Archer",
                " of",
                " independent",
                " consultancy",
                " I",
                "HS",
                " Global",
                " Insight",
                ".",
                "\n",
                "\n",
                "\u00e2\u0122",
                "\u013a",
                "The",
                " fact",
                " of",
                " no",
                " longer",
                " having",
                " a",
                " \u00e2\u0122",
                "\u013e",
                "one",
                "\u00e2\u0122",
                "\u013f",
                " in",
                " front",
                " of",
                " the",
                " decimal",
                " point",
                " and",
                " having",
                " a",
                " n",
                "ought",
                " instead",
                " may",
                " weigh",
                " with",
                " some",
                " people",
                ",",
                "\u00e2\u0122",
                "\u013b",
                " he",
                " said",
                ".",
                " \u00e2\u0122",
                "\u013a",
                "More",
                " worrying",
                " is",
                " the",
                " possibility",
                " of",
                " a",
                " flat",
                " or",
                " negative",
                " number",
                " in",
                " the",
                " fourth",
                " quarter",
                ".",
                " Much",
                " will",
                " hinge",
                " on",
                " spending",
                " over",
                " Christmas",
                ".",
                "\u00e2\u0122",
                "\u013b",
                "\n",
                "\n",
                "He",
                " said",
                " higher",
                " than",
                " expected",
                " inflation",
                " may",
                " make",
                " people",
                " more",
                " concerned",
                " and",
                " this",
                ",",
                " in",
                " turn",
                ",",
                " could",
                " make",
                " worries",
                " about",
                " negative",
                " growth",
                " in",
                " the",
                " first",
                " quarter",
                " of",
                " next",
                " year",
                " into",
                " a"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 5.702,
            "binContains": 0.9995,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1t9x6ti666p949kfnz",
            "tokens": [
                " March",
                " 26",
                ".",
                "\n",
                "\n",
                "Tickets",
                " to",
                " the",
                " match",
                " can",
                " be",
                " purchased",
                " HERE",
                ".",
                "\n",
                "\n",
                "#",
                "Gl",
                "ory",
                "Is",
                "O",
                "urs",
                "<|endoftext|>",
                "The",
                " end",
                " of",
                " May",
                " saw",
                " interest",
                " in",
                " Russia",
                "-",
                "D",
                "PR",
                "K",
                " relations",
                " briefly",
                " surge",
                " with",
                " news",
                " that",
                " two",
                " North",
                " Korean",
                " migrants",
                " \u2014",
                " both",
                " men",
                " and",
                " both",
                " living",
                " legally",
                " outside",
                " the",
                " DPRK",
                " \u2014",
                " had",
                " been",
                " found",
                " dead",
                " in",
                " a",
                " Moscow",
                " accommodation",
                " block",
                ".",
                " Details",
                " of",
                " the",
                " case",
                " continue",
                " to",
                " be",
                " in",
                " short",
                " supply",
                ",",
                " but",
                " the",
                " two",
                " appear",
                " to",
                " have",
                " died",
                " of",
                " acute",
                " heart",
                " failure",
                ";",
                " an",
                " extraordinary",
                " turn",
                " of",
                " events",
                " given",
                " that",
                " one",
                " was",
                " only",
                " in",
                " his",
                " late",
                " 30",
                "s",
                " and",
                " the",
                " other",
                " just",
                " 22",
                " years",
                " old",
                " (",
                "seven",
                " more",
                " individuals",
                ",",
                " at",
                " least",
                " two",
                " of",
                " them",
                " North",
                " Korean",
                ",",
                " reported",
                " symptoms",
                ")."
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 5.702,
            "binContains": 0.9995,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1u9x6vi666qlm4nh1c",
            "tokens": [
                " prisoners",
                " three",
                " times",
                " higher",
                " than",
                " in",
                " the",
                " rest",
                " of",
                " the",
                " population",
                " in",
                " Ukraine",
                ".",
                " Out",
                " of",
                " nearly",
                " 150",
                ",",
                "000",
                " prisoners",
                " in",
                " 2012",
                ",",
                " more",
                " than",
                " 3",
                ",",
                "000",
                " were",
                " suffering",
                " from",
                " TB",
                ".",
                "\n",
                "\n",
                "Early",
                " detection",
                " and",
                " treatment",
                " are",
                " essential",
                ".",
                " Both",
                " have",
                " been",
                " disrupted",
                " by",
                " Ukraine",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " unrest",
                ".",
                " Moreover",
                ",",
                " Ukraine",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " laws",
                " don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " force",
                " people",
                " to",
                " get",
                " treated",
                " if",
                " they",
                " refuse",
                ".",
                " A",
                " person",
                " who",
                " advances",
                " to",
                " the",
                " multi",
                "-",
                "drug",
                " resistant",
                " stage",
                " of",
                " TB",
                " must",
                " undergo",
                " long",
                ",",
                " painful",
                " and",
                " more",
                " expensive",
                " treatment",
                " \u2013",
                " nearly",
                " $",
                "50",
                " a",
                " day",
                ".",
                " Some",
                " 10",
                ",",
                "000",
                " such",
                " cases",
                " are",
                " registered",
                ".",
                "\n",
                "\n",
                "P",
                "ris",
                "ons",
                " with",
                " TB",
                "\n",
                "\n",
                "Ser",
                "hi",
                "y",
                " Pet",
                "ru",
                "k"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 5.702,
            "binContains": 0.9995,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clxdu4z1u9x6wi6661i1fmiz0",
            "tokens": [
                "\n",
                "Only",
                " 5",
                " of",
                " those",
                " 50",
                " will",
                " be",
                " protected",
                " bike",
                " lanes",
                ",",
                " which",
                " studies",
                " show",
                " decrease",
                " the",
                " amount",
                " of",
                " injuries",
                " suffered",
                " by",
                " all",
                " road",
                " users",
                " by",
                " 20",
                "%.",
                " Only",
                " 35",
                " of",
                " the",
                " 960",
                " miles",
                " of",
                " bike",
                " lanes",
                " in",
                " the",
                " city",
                " are",
                " protected",
                ";",
                " 650",
                " are",
                " on",
                "-",
                "street",
                " lanes",
                ",",
                " and",
                " 310",
                " are",
                " on",
                " green",
                "ways",
                ",",
                " parks",
                ",",
                " and",
                " bridges",
                ".",
                "\n",
                "\n",
                "\"",
                "In",
                " Manhattan",
                ",",
                " [",
                "5",
                " miles",
                "]",
                " is",
                " the",
                " equivalent",
                " of",
                " about",
                " 100",
                " city",
                " blocks",
                ",\"",
                " Tro",
                "tt",
                "enberg",
                " said",
                " when",
                " Manhattan",
                " Council",
                "member",
                " Y",
                "dan",
                "is",
                " Rodriguez",
                " asked",
                " why",
                " the",
                " administration",
                " wasn",
                "'t",
                " building",
                " more",
                " protected",
                " lanes",
                ".",
                " \"",
                "There",
                "'s",
                " a",
                " fair",
                " amount",
                " of",
                " intensive",
                " work",
                " that",
                " goes",
                " into",
                " a",
                " safely",
                " designed",
                " protected",
                " bike",
                " lane",
                "\u00c2",
                "\u0139",
                "work",
                " with",
                " the"
            ],
            "dataIndex": null,
            "index": "11943",
            "layer": "8-res_fs12288-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "cljj57d3c000076ei38vwnv35",
            "createdAt": "2024-06-13T22:32:23.882Z",
            "lossValues": [],
            "logitContributions": "{\"pos\": [], \"neg\": []}",
            "binMin": 0,
            "binMax": 5.702,
            "binContains": 0.9995,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clymq1v8d106zj7a1jgvyhaje",
            "description": "phrases related to cognitive performance and memory",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}