{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "peer learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "56619",
            "description": "references to peer-to-peer relationships and interactions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5959881544113159,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "56619",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:44:13.768Z",
                "maxActApprox": 63.285,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    56619,
                    9241,
                    31563,
                    75683,
                    65276,
                    10387,
                    25596,
                    71061,
                    61963,
                    34785,
                    41687,
                    51022,
                    97965,
                    66600,
                    22566,
                    83184,
                    16881,
                    96185,
                    62118,
                    62794,
                    52195,
                    80749,
                    59876,
                    49931,
                    56168
                ],
                "topkCosSimValues": [
                    1,
                    0.4648,
                    0.4609,
                    0.4569,
                    0.4554,
                    0.4428,
                    0.419,
                    0.4028,
                    0.3976,
                    0.3894,
                    0.3852,
                    0.3836,
                    0.3835,
                    0.3783,
                    0.374,
                    0.3705,
                    0.3704,
                    0.3684,
                    0.3675,
                    0.3635,
                    0.3524,
                    0.3519,
                    0.3508,
                    0.3495,
                    0.3488
                ],
                "neuron_alignment_indices": [
                    429,
                    381,
                    408
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.103,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    429,
                    381,
                    323
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.008,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.008,
                    0.007
                ],
                "correlated_features_indices": [
                    56690,
                    56596,
                    56703
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "estones",
                    "stad",
                    "sbm",
                    "mist",
                    "IGHTS",
                    "arius",
                    "frey",
                    "kins",
                    "etta",
                    "OIL"
                ],
                "neg_values": [
                    -0.924,
                    -0.917,
                    -0.915,
                    -0.89,
                    -0.867,
                    -0.861,
                    -0.795,
                    -0.793,
                    -0.785,
                    -0.775
                ],
                "pos_str": [
                    " networking",
                    " connectivity",
                    " networks",
                    " network",
                    " lending",
                    " access",
                    " telecommunications",
                    " wireless",
                    " transmission",
                    " broadband"
                ],
                "pos_values": [
                    1.128,
                    1.089,
                    1.055,
                    0.998,
                    0.983,
                    0.945,
                    0.922,
                    0.912,
                    0.889,
                    0.887
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    132,
                    46,
                    22,
                    17,
                    14,
                    7,
                    4,
                    4,
                    4,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    3,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.633,
                    1.899,
                    3.164,
                    4.43,
                    5.696,
                    6.962,
                    8.227,
                    9.493,
                    10.759,
                    12.024,
                    13.29,
                    14.556,
                    15.821,
                    17.087,
                    18.353,
                    19.619,
                    20.884,
                    22.15,
                    23.416,
                    24.681,
                    25.947,
                    27.213,
                    28.478,
                    29.744,
                    31.01,
                    32.276,
                    33.541,
                    34.807,
                    36.073,
                    37.338,
                    38.604,
                    39.87,
                    41.135,
                    42.401,
                    43.667,
                    44.933,
                    46.198,
                    47.464,
                    48.73,
                    49.995,
                    51.261,
                    52.527,
                    53.792,
                    55.058,
                    56.324,
                    57.59,
                    58.855,
                    60.121,
                    61.387,
                    62.652
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    2,
                    0,
                    6,
                    13,
                    23,
                    36,
                    64,
                    103,
                    195,
                    307,
                    469,
                    696,
                    951,
                    1308,
                    1731,
                    2144,
                    2567,
                    2907,
                    3201,
                    3458,
                    3721,
                    3569,
                    3461,
                    3337,
                    3093,
                    2675,
                    2215,
                    1885,
                    1547,
                    1149,
                    928,
                    701,
                    535,
                    408,
                    273,
                    206,
                    117,
                    89,
                    64,
                    34,
                    28,
                    15,
                    11,
                    5,
                    1,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.903,
                    -0.862,
                    -0.821,
                    -0.78,
                    -0.739,
                    -0.698,
                    -0.657,
                    -0.616,
                    -0.575,
                    -0.534,
                    -0.493,
                    -0.452,
                    -0.411,
                    -0.37,
                    -0.329,
                    -0.288,
                    -0.247,
                    -0.206,
                    -0.164,
                    -0.123,
                    -0.082,
                    -0.041,
                    0,
                    0.041,
                    0.082,
                    0.123,
                    0.164,
                    0.205,
                    0.246,
                    0.287,
                    0.328,
                    0.369,
                    0.41,
                    0.451,
                    0.492,
                    0.533,
                    0.574,
                    0.615,
                    0.656,
                    0.697,
                    0.738,
                    0.779,
                    0.82,
                    0.861,
                    0.903,
                    0.944,
                    0.985,
                    1.026,
                    1.067,
                    1.108
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to peer-to-peer relationships and transactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to peer-to-peer relationships and interactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to peer-to-peer networks and transactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghlfd9i73v10exx888pmyl",
                        "tokens": [
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "pet",
                            "ertodd",
                            "bt",
                            "c",
                            "),",
                            " Applied",
                            " Crypt",
                            "ography",
                            " Consult",
                            "ant",
                            " (",
                            "what",
                            " the",
                            " cool",
                            " kids",
                            " call",
                            " '",
                            "block",
                            "chain",
                            " tech",
                            "')",
                            "\n",
                            "\n",
                            "Learn",
                            " about",
                            " how",
                            " he",
                            " first",
                            " got",
                            " into",
                            " bitcoin",
                            ",",
                            " if",
                            " he",
                            " thinks",
                            " bitcoin",
                            " is",
                            " becoming",
                            " too",
                            " centralized",
                            ",",
                            " his",
                            " thoughts",
                            " on",
                            " scal",
                            "ability",
                            " and",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "8",
                            ":",
                            "30",
                            "pm",
                            " (",
                            "30",
                            " minutes",
                            "):",
                            "\n",
                            "\n",
                            "Net",
                            "working",
                            "\n",
                            "\n",
                            "-------",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ",",
                            " the",
                            " first",
                            " application",
                            " of",
                            " blockchain",
                            " technology",
                            ",",
                            " is",
                            " an",
                            " innovative",
                            " payment",
                            " network",
                            " and",
                            " a",
                            " new",
                            " kind",
                            " of",
                            " money",
                            ".",
                            " It",
                            " uses",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " technology",
                            " to",
                            " operate",
                            " with",
                            " no",
                            " central",
                            " authority",
                            " or",
                            " banks",
                            ";",
                            " managing",
                            " transactions",
                            " and",
                            " the",
                            " issuing",
                            " of",
                            " bitcoins",
                            " is",
                            " carried",
                            " out",
                            " collectively",
                            " by",
                            " the",
                            " network",
                            ".",
                            " Bitcoin",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "56619",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 63.285,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.624,
                            1.497,
                            0,
                            0,
                            63.285,
                            0.13,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:17.373Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 63.285,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghlfdai74610exi1uuz2xe",
                        "tokens": [
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "pet",
                            "ertodd",
                            "bt",
                            "c",
                            "),",
                            " Applied",
                            " Crypt",
                            "ography",
                            " Consult",
                            "ant",
                            " (",
                            "what",
                            " the",
                            " cool",
                            " kids",
                            " call",
                            " '",
                            "block",
                            "chain",
                            " tech",
                            "')",
                            "\n",
                            "\n",
                            "Learn",
                            " about",
                            " how",
                            " he",
                            " first",
                            " got",
                            " into",
                            " bitcoin",
                            ",",
                            " if",
                            " he",
                            " thinks",
                            " bitcoin",
                            " is",
                            " becoming",
                            " too",
                            " centralized",
                            ",",
                            " his",
                            " thoughts",
                            " on",
                            " scal",
                            "ability",
                            " and",
                            " more",
                            ".",
                            "\n",
                            "\n",
                            "8",
                            ":",
                            "30",
                            "pm",
                            " (",
                            "30",
                            " minutes",
                            "):",
                            "\n",
                            "\n",
                            "Net",
                            "working",
                            "\n",
                            "\n",
                            "-------",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ",",
                            " the",
                            " first",
                            " application",
                            " of",
                            " blockchain",
                            " technology",
                            ",",
                            " is",
                            " an",
                            " innovative",
                            " payment",
                            " network",
                            " and",
                            " a",
                            " new",
                            " kind",
                            " of",
                            " money",
                            ".",
                            " It",
                            " uses",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " technology",
                            " to",
                            " operate",
                            " with",
                            " no",
                            " central",
                            " authority",
                            " or",
                            " banks",
                            ";",
                            " managing",
                            " transactions",
                            " and",
                            " the",
                            " issuing",
                            " of",
                            " bitcoins",
                            " is",
                            " carried",
                            " out",
                            " collectively",
                            " by",
                            " the",
                            " network",
                            ".",
                            " Bitcoin",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "56619",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 63.285,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.624,
                            1.497,
                            0,
                            0,
                            63.285,
                            0.13,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:17.373Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 63.285,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghlfd9i73w10ex8ai3mokp",
                        "tokens": [
                            "\u013f",
                            "\n",
                            "\n",
                            "Russia",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " has",
                            " been",
                            " hard",
                            " on",
                            " its",
                            " attitude",
                            " towards",
                            " bitcoin",
                            " but",
                            " the",
                            " same",
                            " has",
                            " seen",
                            " a",
                            " gradual",
                            " shift",
                            " from",
                            " a",
                            " time",
                            " when",
                            " the",
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if"
                        ],
                        "dataIndex": null,
                        "index": "56619",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.362,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.918,
                            5.04,
                            0,
                            3.723,
                            61.362,
                            6.956,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:17.373Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 63.285,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "40870",
            "description": "references to peer-to-peer interactions and systems",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.554222822189331,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "40870",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:11:58.681Z",
                "maxActApprox": 71.251,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    40870,
                    11368,
                    23758,
                    29934,
                    45838,
                    42570,
                    9095,
                    4734,
                    18323,
                    17875,
                    10813,
                    15659,
                    36197,
                    5935,
                    15672,
                    33323,
                    38364,
                    8706,
                    48952,
                    16277,
                    16824,
                    47062,
                    43313,
                    43620,
                    46764
                ],
                "topkCosSimValues": [
                    1,
                    0.4459,
                    0.4123,
                    0.3823,
                    0.3691,
                    0.3577,
                    0.3507,
                    0.3235,
                    0.3233,
                    0.3196,
                    0.3192,
                    0.3182,
                    0.3124,
                    0.3083,
                    0.3043,
                    0.303,
                    0.2979,
                    0.2974,
                    0.2968,
                    0.2941,
                    0.2918,
                    0.2907,
                    0.2894,
                    0.2864,
                    0.2853
                ],
                "neuron_alignment_indices": [
                    285,
                    420,
                    323
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.109,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    323,
                    285,
                    79
                ],
                "correlated_neurons_pearson": [
                    0.01,
                    0.009,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.008,
                    0.009
                ],
                "correlated_features_indices": [
                    40909,
                    40859,
                    40903
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0
                ],
                "neg_str": [
                    "enegger",
                    "obiles",
                    " ABE",
                    "mes",
                    "aurus",
                    " Parables",
                    "ktop",
                    "\u00c4\u0141",
                    " Liberties",
                    "mson"
                ],
                "neg_values": [
                    -0.833,
                    -0.797,
                    -0.781,
                    -0.776,
                    -0.768,
                    -0.722,
                    -0.703,
                    -0.701,
                    -0.688,
                    -0.673
                ],
                "pos_str": [
                    " peer",
                    " reviewed",
                    "Reviewed",
                    "reviewed",
                    "wise",
                    "less",
                    "age",
                    "hood",
                    "lessly",
                    "peer"
                ],
                "pos_values": [
                    0.884,
                    0.819,
                    0.811,
                    0.809,
                    0.805,
                    0.798,
                    0.786,
                    0.772,
                    0.733,
                    0.714
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    49,
                    21,
                    13,
                    8,
                    6,
                    4,
                    3,
                    2,
                    4,
                    1,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    2,
                    3,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    3,
                    3,
                    3,
                    6,
                    1,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.73,
                    2.154,
                    3.579,
                    5.004,
                    6.428,
                    7.853,
                    9.278,
                    10.702,
                    12.127,
                    13.552,
                    14.976,
                    16.401,
                    17.826,
                    19.25,
                    20.675,
                    22.1,
                    23.524,
                    24.949,
                    26.374,
                    27.798,
                    29.223,
                    30.648,
                    32.073,
                    33.497,
                    34.922,
                    36.347,
                    37.771,
                    39.196,
                    40.621,
                    42.045,
                    43.47,
                    44.895,
                    46.319,
                    47.744,
                    49.169,
                    50.593,
                    52.018,
                    53.443,
                    54.867,
                    56.292,
                    57.717,
                    59.141,
                    60.566,
                    61.991,
                    63.415,
                    64.84,
                    66.265,
                    67.689,
                    69.114,
                    70.539
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    0,
                    3,
                    7,
                    4,
                    14,
                    24,
                    38,
                    50,
                    105,
                    152,
                    234,
                    411,
                    513,
                    808,
                    1114,
                    1511,
                    1986,
                    2473,
                    2972,
                    3469,
                    3859,
                    3997,
                    4273,
                    4037,
                    3826,
                    3417,
                    2881,
                    2303,
                    1805,
                    1301,
                    854,
                    624,
                    437,
                    289,
                    176,
                    122,
                    67,
                    34,
                    17,
                    17,
                    13,
                    2,
                    3,
                    2,
                    1,
                    5,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.816,
                    -0.782,
                    -0.747,
                    -0.713,
                    -0.679,
                    -0.644,
                    -0.61,
                    -0.576,
                    -0.541,
                    -0.507,
                    -0.473,
                    -0.438,
                    -0.404,
                    -0.369,
                    -0.335,
                    -0.301,
                    -0.266,
                    -0.232,
                    -0.198,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.06,
                    -0.026,
                    0.008,
                    0.043,
                    0.077,
                    0.111,
                    0.146,
                    0.18,
                    0.214,
                    0.249,
                    0.283,
                    0.317,
                    0.352,
                    0.386,
                    0.42,
                    0.455,
                    0.489,
                    0.523,
                    0.558,
                    0.592,
                    0.626,
                    0.661,
                    0.695,
                    0.729,
                    0.764,
                    0.798,
                    0.833,
                    0.867
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to peer-to-peer interactions and systems",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6qxfkdbe6i666o3s6ihpy",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "40870",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.251,
                        "maxValueTokenIndex": 67,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.251,
                            0,
                            0,
                            0,
                            31.51,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:12:00.675Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 71.251,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6qxfkdbe7i666zrm4v0ab",
                        "tokens": [
                            " math",
                            " was",
                            " introduced",
                            ".",
                            " Who",
                            " knows",
                            " at",
                            " this",
                            " point",
                            "?",
                            " All",
                            " we",
                            " know",
                            " is",
                            " that",
                            " one",
                            " paper",
                            " is",
                            " not",
                            " like",
                            " the",
                            " other",
                            ",",
                            " and",
                            " one",
                            " produces",
                            " a",
                            " hockey",
                            " stick",
                            " and",
                            " the",
                            " other",
                            " does",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "Some",
                            " additional",
                            " detective",
                            " work",
                            " is",
                            " sorely",
                            " needed",
                            " to",
                            " determine",
                            " why",
                            " this",
                            " discrepancy",
                            " exists",
                            " and",
                            " if",
                            " anyone",
                            " in",
                            " the",
                            " peer",
                            " review",
                            " process",
                            " asked",
                            " any",
                            " similar",
                            " questions",
                            ".",
                            "\n",
                            "\n",
                            "Advertisements",
                            "\n",
                            "\n",
                            "Share",
                            " this",
                            ":",
                            " Print",
                            "\n",
                            "\n",
                            "Email",
                            "\n",
                            "\n",
                            "Twitter",
                            "\n",
                            "\n",
                            "Facebook",
                            "\n",
                            "\n",
                            "Pinterest",
                            "\n",
                            "\n",
                            "LinkedIn",
                            "\n",
                            "\n",
                            "Reddit",
                            "<|endoftext|>",
                            "L",
                            "AS",
                            " V",
                            "EG",
                            "AS",
                            " \u2013",
                            " Motorola",
                            " launched",
                            " its",
                            " third",
                            " Android",
                            " smartphone",
                            ",",
                            " an",
                            " attractive",
                            ",",
                            " compact",
                            " device",
                            " with",
                            " some",
                            " surprising",
                            " hardware",
                            " innovations",
                            " and",
                            " a",
                            " user",
                            " interface",
                            " that",
                            " aggreg",
                            "ates",
                            " social",
                            " networking",
                            " feeds",
                            ",",
                            " e",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "40870",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.195,
                        "maxValueTokenIndex": 55,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.195,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:12:00.675Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 71.251,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6qxfkdbe8i6669hybmw5s",
                        "tokens": [
                            " middle",
                            " of",
                            " the",
                            " room",
                            ".",
                            " <",
                            "br",
                            " />",
                            "\n",
                            "\n",
                            "Fif",
                            "teen",
                            " million",
                            " people",
                            " downloaded",
                            " Win",
                            "amp",
                            " in",
                            " a",
                            " little",
                            " over",
                            " a",
                            " year",
                            " after",
                            " its",
                            " release",
                            ".",
                            " It",
                            " allowed",
                            " users",
                            " to",
                            " not",
                            " only",
                            " easily",
                            " play",
                            " music",
                            " on",
                            " their",
                            " computers",
                            " complete",
                            " with",
                            " play",
                            "lists",
                            ",",
                            " an",
                            " equal",
                            "izer",
                            ",",
                            " and",
                            " Pink",
                            " Floyd",
                            " light",
                            "-",
                            "show",
                            "-",
                            "worthy",
                            " visual",
                            "izations",
                            ",",
                            " it",
                            " also",
                            " inspired",
                            " fans",
                            " to",
                            " make",
                            " their",
                            " own",
                            " player",
                            " skins",
                            " to",
                            " share",
                            " with",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " 1999",
                            ",",
                            " AOL",
                            " bought",
                            " Null",
                            "soft",
                            " and",
                            " everything",
                            " changed",
                            ".",
                            " While",
                            " working",
                            " under",
                            " AOL",
                            ",",
                            " Fran",
                            "kel",
                            " (",
                            "along",
                            " with",
                            " fellow",
                            " computer",
                            " programmer",
                            " and",
                            " Null",
                            "soft",
                            " co",
                            "-",
                            "founder",
                            " Tom",
                            " Pepper",
                            ")",
                            " released",
                            " G",
                            "nut",
                            "ella",
                            ",",
                            " an",
                            " open",
                            "-",
                            "source",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " file",
                            "-",
                            "sharing",
                            " network"
                        ],
                        "dataIndex": null,
                        "index": "40870",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 70.299,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            70.299,
                            0,
                            0,
                            0,
                            30.597,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:12:00.675Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 71.251,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "23758",
            "description": "mentions of \"peers\" in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.533187210559845,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "23758",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:41:21.805Z",
                "maxActApprox": 30.065,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23758,
                    8706,
                    38571,
                    25299,
                    38364,
                    19184,
                    13020,
                    40870,
                    15672,
                    38483,
                    5608,
                    33946,
                    36100,
                    13186,
                    43334,
                    28131,
                    42983,
                    9726,
                    12860,
                    47139,
                    1803,
                    13080,
                    7493,
                    24591,
                    28294
                ],
                "topkCosSimValues": [
                    1,
                    0.4995,
                    0.4706,
                    0.4536,
                    0.451,
                    0.4509,
                    0.4197,
                    0.4123,
                    0.4102,
                    0.404,
                    0.3955,
                    0.3832,
                    0.377,
                    0.3703,
                    0.3673,
                    0.3649,
                    0.3498,
                    0.347,
                    0.3392,
                    0.3374,
                    0.3341,
                    0.334,
                    0.3328,
                    0.3315,
                    0.3275
                ],
                "neuron_alignment_indices": [
                    445,
                    762,
                    481
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.108,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    506,
                    575,
                    762
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.01,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.011,
                    0.011
                ],
                "correlated_features_indices": [
                    23650,
                    23667,
                    23700
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Tycoon",
                    "ichick",
                    "ohyd",
                    " landfall",
                    "veyard",
                    "EVA",
                    "selage",
                    " Rohing",
                    "o\u00c4\u0141",
                    "asel"
                ],
                "neg_values": [
                    -0.741,
                    -0.676,
                    -0.664,
                    -0.658,
                    -0.641,
                    -0.627,
                    -0.612,
                    -0.596,
                    -0.594,
                    -0.59
                ],
                "pos_str": [
                    "iblings",
                    "mates",
                    " classmates",
                    " peers",
                    "inary",
                    "hips",
                    "hip",
                    "hall",
                    "peer",
                    " siblings"
                ],
                "pos_values": [
                    0.963,
                    0.947,
                    0.925,
                    0.873,
                    0.818,
                    0.815,
                    0.797,
                    0.778,
                    0.751,
                    0.748
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    59,
                    58,
                    34,
                    15,
                    30,
                    10,
                    6,
                    10,
                    8,
                    2,
                    5,
                    4,
                    3,
                    1,
                    7,
                    4,
                    3,
                    6,
                    1,
                    3,
                    1,
                    0,
                    5,
                    1,
                    2,
                    0,
                    1,
                    0,
                    2,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    2,
                    2,
                    4,
                    1,
                    0,
                    2,
                    2,
                    1,
                    0,
                    2,
                    1,
                    2,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.313,
                    0.914,
                    1.515,
                    2.116,
                    2.717,
                    3.318,
                    3.919,
                    4.52,
                    5.121,
                    5.722,
                    6.324,
                    6.925,
                    7.526,
                    8.127,
                    8.728,
                    9.329,
                    9.93,
                    10.531,
                    11.132,
                    11.733,
                    12.334,
                    12.935,
                    13.536,
                    14.137,
                    14.738,
                    15.339,
                    15.94,
                    16.541,
                    17.142,
                    17.744,
                    18.345,
                    18.946,
                    19.547,
                    20.148,
                    20.749,
                    21.35,
                    21.951,
                    22.552,
                    23.153,
                    23.754,
                    24.355,
                    24.956,
                    25.557,
                    26.158,
                    26.759,
                    27.36,
                    27.961,
                    28.562,
                    29.164,
                    29.765
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    2,
                    6,
                    10,
                    26,
                    34,
                    93,
                    113,
                    247,
                    383,
                    576,
                    946,
                    1232,
                    1782,
                    2329,
                    2869,
                    3379,
                    3955,
                    4250,
                    4350,
                    4249,
                    4096,
                    3540,
                    2935,
                    2352,
                    1873,
                    1332,
                    1063,
                    719,
                    504,
                    341,
                    206,
                    149,
                    87,
                    79,
                    55,
                    34,
                    20,
                    9,
                    8,
                    5,
                    6,
                    1,
                    3,
                    0,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.724,
                    -0.69,
                    -0.656,
                    -0.622,
                    -0.588,
                    -0.554,
                    -0.52,
                    -0.485,
                    -0.451,
                    -0.417,
                    -0.383,
                    -0.349,
                    -0.315,
                    -0.281,
                    -0.247,
                    -0.213,
                    -0.179,
                    -0.145,
                    -0.111,
                    -0.077,
                    -0.042,
                    -0.008,
                    0.026,
                    0.06,
                    0.094,
                    0.128,
                    0.162,
                    0.196,
                    0.23,
                    0.264,
                    0.298,
                    0.332,
                    0.366,
                    0.4,
                    0.435,
                    0.469,
                    0.503,
                    0.537,
                    0.571,
                    0.605,
                    0.639,
                    0.673,
                    0.707,
                    0.741,
                    0.775,
                    0.809,
                    0.843,
                    0.878,
                    0.912,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of \"peers\" in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5npjmxjh0i666yzt6958q",
                        "tokens": [
                            " to",
                            " seek",
                            " a",
                            " wide",
                            " range",
                            " of",
                            " legal",
                            " actions",
                            " when",
                            " they",
                            " perceive",
                            " laws",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " being",
                            " enforced",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ruling",
                            " allows",
                            " L",
                            "itz",
                            " to",
                            " have",
                            " what",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " wanted",
                            " all",
                            " along",
                            ":",
                            " a",
                            " chance",
                            " to",
                            " argue",
                            " her",
                            " case",
                            " to",
                            " a",
                            " jury",
                            " of",
                            " her",
                            " peers",
                            " in",
                            " Caroline",
                            " County",
                            ",",
                            " her",
                            " home",
                            " for",
                            " most",
                            " of",
                            " her",
                            " 67",
                            " years",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " exciting",
                            " thing",
                            " is",
                            " that",
                            " it",
                            " sets",
                            " a",
                            " precedent",
                            ",",
                            " so",
                            " people",
                            " all",
                            " over",
                            " \u00e2\u0122\u00a6",
                            " can",
                            " do",
                            " this",
                            " to",
                            " get",
                            " relief",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "When",
                            " the",
                            " state",
                            " says",
                            " they",
                            " are",
                            " going",
                            " to",
                            " do",
                            " something",
                            ",",
                            " they",
                            " need",
                            " to",
                            " do",
                            " it",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " court",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " majority",
                            " looked",
                            " at",
                            " laws",
                            " and",
                            " legal"
                        ],
                        "dataIndex": null,
                        "index": "23758",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.065,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.065,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:41:30.844Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5npjmxjh1i666olp41z4r",
                        "tokens": [
                            " native",
                            " Islamic",
                            " scholars",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " Of",
                            "sted",
                            " report",
                            " recommended",
                            " that",
                            " the",
                            " school",
                            " develop",
                            " \"",
                            "links",
                            " with",
                            " other",
                            " schools",
                            " to",
                            " provide",
                            " students",
                            " with",
                            " opportunities",
                            " to",
                            " social",
                            "ise",
                            " and",
                            " learn",
                            " with",
                            " their",
                            " peers",
                            " in",
                            " different",
                            " environments",
                            "\",",
                            " which",
                            " is",
                            " in",
                            " stark",
                            " contrast",
                            " to",
                            " the",
                            " rules",
                            " uncovered",
                            " by",
                            " Sky",
                            " News",
                            " which",
                            " prohibit",
                            " social",
                            " interactions",
                            " with",
                            " non",
                            "-",
                            "Muslims",
                            ".",
                            "\n",
                            "\n",
                            "Since",
                            " 2014",
                            ",",
                            " independent",
                            " schools",
                            " have",
                            " been",
                            " required",
                            " to",
                            " \"",
                            "actively",
                            " promote",
                            "\"",
                            " the",
                            " fundamental",
                            " values",
                            " \"",
                            "of",
                            " democracy",
                            ",",
                            " the",
                            " rule",
                            " of",
                            " law",
                            ",",
                            " individual",
                            " liberty",
                            ",",
                            " and",
                            " mutual",
                            " respect",
                            " and",
                            " tolerance",
                            " of",
                            " those",
                            " with",
                            " different",
                            " faiths",
                            " and",
                            " beliefs",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " National",
                            " Sec",
                            "ular",
                            " Society",
                            " has",
                            " written",
                            " to",
                            " the",
                            " Department",
                            " for",
                            " Education",
                            " and",
                            " Of",
                            "sted",
                            " calling",
                            " for",
                            " an",
                            " inspection",
                            " to",
                            " take",
                            " place",
                            " under",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "23758",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.837,
                        "maxValueTokenIndex": 32,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.837,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:41:30.844Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5npjmxjh2i666tndz7hzs",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " club",
                            " uses",
                            " an",
                            " established",
                            " player",
                            " vote",
                            " system",
                            " to",
                            " elect",
                            " its",
                            " captain",
                            " and",
                            " leadership",
                            " group",
                            " every",
                            " season",
                            ".",
                            "\n",
                            "\n",
                            "P",
                            "av",
                            "lich",
                            " said",
                            " the",
                            " large",
                            " number",
                            " of",
                            " players",
                            " who",
                            " gained",
                            " votes",
                            " from",
                            " their",
                            " peers",
                            " was",
                            " a",
                            " healthy",
                            " sign",
                            " for",
                            " Fre",
                            "o",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "That",
                            " shows",
                            " a",
                            " great",
                            " development",
                            " and",
                            " strength",
                            " in",
                            " our",
                            " leadership",
                            " throughout",
                            " the",
                            " whole",
                            " team",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " Jeffrey",
                            " Mine",
                            " in",
                            " Quebec",
                            "'s",
                            " Eastern",
                            " Town",
                            "ships",
                            " has",
                            " received",
                            " a",
                            " $",
                            "58",
                            "-",
                            "million",
                            " boost",
                            " from",
                            " the",
                            " province",
                            " to",
                            " help",
                            " revive",
                            " the",
                            " asbestos",
                            " industry",
                            ",",
                            " a",
                            " move",
                            " the",
                            " Canadian",
                            " Cancer",
                            " Society",
                            " is",
                            " urging",
                            " the",
                            " government",
                            " to",
                            " reconsider",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " asbestos",
                            " mine",
                            " in",
                            " Quebec",
                            "'s",
                            " Eastern",
                            " Town",
                            "ships",
                            " received",
                            " the",
                            " loan",
                            " from"
                        ],
                        "dataIndex": null,
                        "index": "23758",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.568,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.568,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:41:30.844Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5159588763689335,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "8385",
            "description": "phrases that depict learning from others and building upon shared knowledge",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5116685933869248,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "8385",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:55:28.122Z",
                "maxActApprox": 14.867,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8385,
                    3301,
                    16642,
                    11621,
                    4513,
                    17830,
                    12237,
                    9003,
                    9986,
                    18039,
                    3143,
                    21375,
                    1196,
                    8374,
                    21762,
                    9203,
                    1886,
                    13617,
                    15074,
                    14505,
                    12556,
                    17036,
                    21530,
                    18191,
                    16918
                ],
                "topkCosSimValues": [
                    1,
                    0.3621,
                    0.3287,
                    0.3267,
                    0.3252,
                    0.3199,
                    0.3045,
                    0.2834,
                    0.2798,
                    0.2784,
                    0.2778,
                    0.2777,
                    0.2705,
                    0.2614,
                    0.2599,
                    0.2493,
                    0.2471,
                    0.2436,
                    0.2423,
                    0.2393,
                    0.2384,
                    0.238,
                    0.2356,
                    0.2335,
                    0.2322
                ],
                "neuron_alignment_indices": [
                    760,
                    283,
                    382
                ],
                "neuron_alignment_values": [
                    0.102,
                    0.101,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    283,
                    382,
                    703
                ],
                "correlated_neurons_pearson": [
                    0.042,
                    0.035,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.032,
                    0.029
                ],
                "correlated_features_indices": [
                    8374,
                    8328,
                    8393
                ],
                "correlated_features_pearson": [
                    0.045,
                    0.018,
                    0.008
                ],
                "correlated_features_l1": [
                    0.047,
                    0.02,
                    0.015
                ],
                "neg_str": [
                    "BuyableInstoreAndOnline",
                    "portation",
                    "stead",
                    "pool",
                    "requ",
                    "................................",
                    " subsidy",
                    " redemption",
                    " cancell",
                    "................................................................"
                ],
                "neg_values": [
                    -0.749,
                    -0.679,
                    -0.667,
                    -0.643,
                    -0.611,
                    -0.608,
                    -0.607,
                    -0.603,
                    -0.6,
                    -0.598
                ],
                "pos_str": [
                    "\u00bb\u0134",
                    " glance",
                    " analys",
                    " analyzing",
                    " hindsight",
                    " studying",
                    " FAC",
                    " hier",
                    " subconscious",
                    " decipher"
                ],
                "pos_values": [
                    0.959,
                    0.916,
                    0.873,
                    0.852,
                    0.842,
                    0.809,
                    0.788,
                    0.781,
                    0.78,
                    0.765
                ],
                "frac_nonzero": 0.00485,
                "freq_hist_data_bar_heights": [
                    2952,
                    2361,
                    1854,
                    1507,
                    1241,
                    923,
                    772,
                    626,
                    512,
                    432,
                    368,
                    300,
                    211,
                    183,
                    150,
                    141,
                    127,
                    89,
                    96,
                    58,
                    50,
                    48,
                    36,
                    34,
                    27,
                    21,
                    21,
                    19,
                    13,
                    12,
                    8,
                    9,
                    9,
                    9,
                    4,
                    5,
                    2,
                    4,
                    5,
                    1,
                    1,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.149,
                    0.446,
                    0.743,
                    1.041,
                    1.338,
                    1.635,
                    1.933,
                    2.23,
                    2.527,
                    2.825,
                    3.122,
                    3.419,
                    3.717,
                    4.014,
                    4.312,
                    4.609,
                    4.906,
                    5.204,
                    5.501,
                    5.798,
                    6.096,
                    6.393,
                    6.69,
                    6.988,
                    7.285,
                    7.582,
                    7.88,
                    8.177,
                    8.474,
                    8.772,
                    9.069,
                    9.366,
                    9.664,
                    9.961,
                    10.258,
                    10.556,
                    10.853,
                    11.15,
                    11.448,
                    11.745,
                    12.042,
                    12.34,
                    12.637,
                    12.934,
                    13.232,
                    13.529,
                    13.826,
                    14.124,
                    14.421,
                    14.719
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    1,
                    13,
                    18,
                    33,
                    61,
                    83,
                    160,
                    261,
                    390,
                    638,
                    925,
                    1300,
                    1804,
                    2351,
                    2876,
                    3399,
                    3835,
                    4018,
                    4157,
                    4047,
                    3734,
                    3304,
                    2741,
                    2363,
                    1871,
                    1545,
                    1086,
                    935,
                    650,
                    475,
                    337,
                    252,
                    195,
                    125,
                    96,
                    55,
                    39,
                    31,
                    16,
                    13,
                    6,
                    8,
                    2,
                    2,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.732,
                    -0.698,
                    -0.664,
                    -0.63,
                    -0.596,
                    -0.562,
                    -0.527,
                    -0.493,
                    -0.459,
                    -0.425,
                    -0.391,
                    -0.357,
                    -0.322,
                    -0.288,
                    -0.254,
                    -0.22,
                    -0.186,
                    -0.152,
                    -0.117,
                    -0.083,
                    -0.049,
                    -0.015,
                    0.019,
                    0.054,
                    0.088,
                    0.122,
                    0.156,
                    0.19,
                    0.224,
                    0.259,
                    0.293,
                    0.327,
                    0.361,
                    0.395,
                    0.429,
                    0.464,
                    0.498,
                    0.532,
                    0.566,
                    0.6,
                    0.634,
                    0.669,
                    0.703,
                    0.737,
                    0.771,
                    0.805,
                    0.839,
                    0.874,
                    0.908,
                    0.942
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases that depict learning from others and building upon shared knowledge",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdme3px7ys5i6667niic835",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3pz7ysri666uzzv756q",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 11.894,
                        "binMax": 14.867,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3px7ys6i666o2p6pnx3",
                        "tokens": [
                            " before",
                            " coming",
                            " to",
                            " understand",
                            " its",
                            " limitations",
                            ".",
                            "\n",
                            "\n",
                            "Dec",
                            "on",
                            "struct",
                            "ive",
                            " post",
                            "modern",
                            "ism",
                            ",",
                            " their",
                            " critique",
                            " of",
                            " stage",
                            " 4",
                            " modern",
                            "ism",
                            "/",
                            "system",
                            "atic",
                            "ity",
                            "/",
                            "rational",
                            "ity",
                            ",",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " the",
                            " contemporary",
                            " university",
                            " humanities",
                            " curriculum",
                            ".",
                            " This",
                            " is",
                            " a",
                            " disaster",
                            ".",
                            " The",
                            " critique",
                            " is",
                            " largely",
                            " correct",
                            ";",
                            " but",
                            ",",
                            " as",
                            " Ke",
                            "gan",
                            " observed",
                            ",",
                            " to",
                            " teach",
                            " it",
                            " to",
                            " young",
                            " adults",
                            " is",
                            " harmful",
                            ".",
                            " Few",
                            " university",
                            " students",
                            " have",
                            " consolidated",
                            " rationality",
                            ".",
                            " Essentially",
                            " none",
                            " are",
                            " ready",
                            " to",
                            " move",
                            " beyond",
                            " it",
                            ".",
                            " Point",
                            "ing",
                            " out",
                            " its",
                            " defects",
                            " makes",
                            " their",
                            " developmental",
                            " task",
                            " more",
                            " difficult",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " cannot",
                            " understand",
                            " what",
                            " is",
                            " wrong",
                            " with",
                            " rational",
                            "ism",
                            " until",
                            " you",
                            " are",
                            " capable",
                            " of",
                            " being",
                            " rational",
                            ".",
                            " You",
                            " cannot",
                            " go",
                            " beyond",
                            " rationality",
                            " until",
                            " after",
                            " you",
                            " can",
                            " use",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.32,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.32,
                            10.238,
                            6.529,
                            3.316,
                            2.932,
                            1.183,
                            0,
                            0,
                            1.373,
                            0,
                            0,
                            0,
                            0,
                            1.877,
                            1.947,
                            0.137,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "23242",
            "description": "terms or phrases related to education and knowledge-sharing",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4866302158424325,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "23242",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:58:22.551Z",
                "maxActApprox": 5.808,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23242,
                    95491,
                    56642,
                    17073,
                    65827,
                    91459,
                    45812,
                    41118,
                    1065,
                    39866,
                    13457,
                    97784,
                    24073,
                    5120,
                    35629,
                    72583,
                    33632,
                    97185,
                    26317,
                    50837,
                    23345,
                    74039,
                    69847,
                    15826,
                    26771
                ],
                "topkCosSimValues": [
                    1,
                    0.3608,
                    0.3221,
                    0.3185,
                    0.3045,
                    0.3019,
                    0.2901,
                    0.288,
                    0.2829,
                    0.281,
                    0.2786,
                    0.2634,
                    0.2633,
                    0.2493,
                    0.2464,
                    0.2444,
                    0.2436,
                    0.2419,
                    0.2404,
                    0.2402,
                    0.24,
                    0.238,
                    0.2375,
                    0.237,
                    0.2359
                ],
                "neuron_alignment_indices": [
                    373,
                    13,
                    280
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.116,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    138,
                    447,
                    64
                ],
                "correlated_neurons_pearson": [
                    0.971,
                    0.97,
                    0.694
                ],
                "correlated_neurons_l1": [
                    0.971,
                    0.959,
                    -0.008
                ],
                "correlated_features_indices": [
                    23242,
                    23244,
                    23221
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "staking",
                    " calibr",
                    "obar",
                    "\u00d6\u00bc",
                    "querque",
                    "%%%%",
                    "DAQ",
                    " incent",
                    "inton",
                    " algorithm"
                ],
                "neg_values": [
                    -0.627,
                    -0.625,
                    -0.601,
                    -0.601,
                    -0.577,
                    -0.572,
                    -0.566,
                    -0.561,
                    -0.548,
                    -0.546
                ],
                "pos_str": [
                    "itars",
                    "ept",
                    "allowed",
                    "amins",
                    "jured",
                    "itarian",
                    " \u00e8\u00a3\u0131\u00e7",
                    "atural",
                    "Wiki",
                    "ppa"
                ],
                "pos_values": [
                    0.827,
                    0.688,
                    0.681,
                    0.67,
                    0.655,
                    0.651,
                    0.639,
                    0.632,
                    0.629,
                    0.626
                ],
                "frac_nonzero": 0.00793,
                "freq_hist_data_bar_heights": [
                    76,
                    51,
                    41,
                    41,
                    24606,
                    26,
                    18,
                    11,
                    12,
                    6,
                    8,
                    9,
                    3,
                    6,
                    2,
                    3,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    2,
                    3,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.062,
                    0.178,
                    0.294,
                    0.41,
                    0.526,
                    0.642,
                    0.759,
                    0.875,
                    0.991,
                    1.107,
                    1.223,
                    1.339,
                    1.455,
                    1.571,
                    1.687,
                    1.803,
                    1.919,
                    2.035,
                    2.152,
                    2.268,
                    2.384,
                    2.5,
                    2.616,
                    2.732,
                    2.848,
                    2.964,
                    3.08,
                    3.196,
                    3.312,
                    3.428,
                    3.545,
                    3.661,
                    3.777,
                    3.893,
                    4.009,
                    4.125,
                    4.241,
                    4.357,
                    4.473,
                    4.589,
                    4.705,
                    4.821,
                    4.938,
                    5.054,
                    5.17,
                    5.286,
                    5.402,
                    5.518,
                    5.634,
                    5.75
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    2,
                    5,
                    15,
                    31,
                    49,
                    88,
                    150,
                    189,
                    327,
                    460,
                    645,
                    914,
                    1263,
                    1576,
                    2062,
                    2388,
                    2843,
                    3119,
                    3478,
                    3687,
                    3636,
                    3651,
                    3364,
                    3108,
                    2840,
                    2378,
                    2036,
                    1532,
                    1243,
                    932,
                    663,
                    493,
                    392,
                    243,
                    172,
                    124,
                    55,
                    37,
                    30,
                    11,
                    5,
                    6,
                    6,
                    3,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.613,
                    -0.583,
                    -0.554,
                    -0.525,
                    -0.496,
                    -0.467,
                    -0.438,
                    -0.409,
                    -0.38,
                    -0.351,
                    -0.322,
                    -0.293,
                    -0.264,
                    -0.234,
                    -0.205,
                    -0.176,
                    -0.147,
                    -0.118,
                    -0.089,
                    -0.06,
                    -0.031,
                    -0.002,
                    0.027,
                    0.056,
                    0.086,
                    0.115,
                    0.144,
                    0.173,
                    0.202,
                    0.231,
                    0.26,
                    0.289,
                    0.318,
                    0.347,
                    0.376,
                    0.405,
                    0.435,
                    0.464,
                    0.493,
                    0.522,
                    0.551,
                    0.58,
                    0.609,
                    0.638,
                    0.667,
                    0.696,
                    0.725,
                    0.754,
                    0.784,
                    0.813
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases or references related to significant titles or positions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " textual references that denote specific subjects or entities, such as titles, terms, or names",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms or phrases related to education and knowledge-sharing",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfyhopsx9h10ext3zlckhx",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 5.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfyhopsx9j10exn44j4545",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 5.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfyhorsxa210ex6aww85l2",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 4.647,
                        "binMax": 5.808,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "43081",
            "description": " phrases or words associated with peer-to-peer interactions or transactions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48565971851348877,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "43081",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:15:48.223Z",
                "maxActApprox": 51.246,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43081,
                    11368,
                    4381,
                    22331,
                    40832,
                    26095,
                    45747,
                    35980,
                    40269,
                    48736,
                    42335,
                    1703,
                    7830,
                    5736,
                    36649,
                    26743,
                    48080,
                    7706,
                    38278,
                    30255,
                    13262,
                    705,
                    10415,
                    22809,
                    23290
                ],
                "topkCosSimValues": [
                    1,
                    0.5074,
                    0.4408,
                    0.4347,
                    0.4264,
                    0.415,
                    0.4132,
                    0.4096,
                    0.409,
                    0.3999,
                    0.3947,
                    0.3903,
                    0.3832,
                    0.3823,
                    0.3699,
                    0.3614,
                    0.3611,
                    0.3608,
                    0.3595,
                    0.3564,
                    0.3529,
                    0.3515,
                    0.3503,
                    0.3481,
                    0.3478
                ],
                "neuron_alignment_indices": [
                    213,
                    649,
                    469
                ],
                "neuron_alignment_values": [
                    0.107,
                    0.105,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    120,
                    202,
                    213
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.01,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.01,
                    0.009
                ],
                "correlated_features_indices": [
                    43159,
                    43150,
                    43140
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    "\u0123\u00ab",
                    "\u0143\u0136",
                    "tin",
                    "natureconservancy",
                    "pedia",
                    "MSN",
                    " disgu",
                    "hya",
                    "adelphia",
                    " brim"
                ],
                "neg_values": [
                    -0.864,
                    -0.64,
                    -0.634,
                    -0.629,
                    -0.607,
                    -0.603,
                    -0.598,
                    -0.593,
                    -0.587,
                    -0.583
                ],
                "pos_str": [
                    "ceptor",
                    "olescent",
                    "eus",
                    " peer",
                    " orbit",
                    "ledged",
                    " neighbour",
                    "oard",
                    " Princ",
                    " ancestor"
                ],
                "pos_values": [
                    0.783,
                    0.773,
                    0.729,
                    0.694,
                    0.664,
                    0.658,
                    0.647,
                    0.633,
                    0.633,
                    0.628
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    114,
                    73,
                    52,
                    24,
                    27,
                    10,
                    9,
                    6,
                    2,
                    4,
                    2,
                    4,
                    1,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.517,
                    1.541,
                    2.566,
                    3.591,
                    4.616,
                    5.641,
                    6.666,
                    7.69,
                    8.715,
                    9.74,
                    10.765,
                    11.79,
                    12.815,
                    13.839,
                    14.864,
                    15.889,
                    16.914,
                    17.939,
                    18.964,
                    19.988,
                    21.013,
                    22.038,
                    23.063,
                    24.088,
                    25.113,
                    26.137,
                    27.162,
                    28.187,
                    29.212,
                    30.237,
                    31.262,
                    32.286,
                    33.311,
                    34.336,
                    35.361,
                    36.386,
                    37.411,
                    38.435,
                    39.46,
                    40.485,
                    41.51,
                    42.535,
                    43.56,
                    44.584,
                    45.609,
                    46.634,
                    47.659,
                    48.684,
                    49.709,
                    50.733
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    3,
                    6,
                    12,
                    31,
                    32,
                    59,
                    114,
                    188,
                    303,
                    537,
                    743,
                    1085,
                    1497,
                    2066,
                    2647,
                    3279,
                    3656,
                    3943,
                    4314,
                    4173,
                    4123,
                    3719,
                    3191,
                    2696,
                    2151,
                    1707,
                    1274,
                    884,
                    640,
                    441,
                    301,
                    183,
                    94,
                    66,
                    39,
                    23,
                    17,
                    7,
                    4,
                    2,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.847,
                    -0.814,
                    -0.781,
                    -0.748,
                    -0.715,
                    -0.682,
                    -0.649,
                    -0.617,
                    -0.584,
                    -0.551,
                    -0.518,
                    -0.485,
                    -0.452,
                    -0.419,
                    -0.386,
                    -0.353,
                    -0.32,
                    -0.287,
                    -0.254,
                    -0.221,
                    -0.188,
                    -0.155,
                    -0.123,
                    -0.09,
                    -0.057,
                    -0.024,
                    0.009,
                    0.042,
                    0.075,
                    0.108,
                    0.141,
                    0.174,
                    0.207,
                    0.24,
                    0.273,
                    0.306,
                    0.339,
                    0.371,
                    0.404,
                    0.437,
                    0.47,
                    0.503,
                    0.536,
                    0.569,
                    0.602,
                    0.635,
                    0.668,
                    0.701,
                    0.734,
                    0.767
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases or words associated with peer-to-peer interactions or transactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6vvqlfcvti666bkgfeqsb",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "43081",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.246,
                        "maxValueTokenIndex": 69,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.445,
                            51.246,
                            47.637,
                            1.07,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:15:51.266Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 51.246,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6vvqmfcvxi666sk2tv931",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "43081",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.246,
                        "maxValueTokenIndex": 69,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.445,
                            51.246,
                            47.637,
                            1.07,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:15:51.266Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 51.246,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6vvqnfcwei666riakbiqu",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "43081",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.246,
                        "maxValueTokenIndex": 69,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.445,
                            51.246,
                            47.637,
                            1.07,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:15:51.266Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 40.997,
                        "binMax": 51.246,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "8677",
            "description": "terms related to sharing and collaborative activities",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46715110540390015,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "8677",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:13:21.390Z",
                "maxActApprox": 45.817,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8677,
                    27175,
                    44113,
                    39463,
                    29579,
                    6190,
                    3957,
                    15498,
                    30253,
                    33392,
                    39358,
                    30601,
                    24556,
                    4519,
                    37112,
                    31480,
                    11541,
                    5850,
                    46775,
                    22512,
                    47819,
                    31740,
                    5397,
                    15722,
                    37824
                ],
                "topkCosSimValues": [
                    1,
                    0.742,
                    0.7047,
                    0.6834,
                    0.6775,
                    0.5734,
                    0.5704,
                    0.5187,
                    0.4402,
                    0.4133,
                    0.4087,
                    0.4072,
                    0.4054,
                    0.3988,
                    0.3981,
                    0.368,
                    0.3643,
                    0.3626,
                    0.3578,
                    0.356,
                    0.3471,
                    0.3458,
                    0.3445,
                    0.344,
                    0.3438
                ],
                "neuron_alignment_indices": [
                    578,
                    656,
                    1
                ],
                "neuron_alignment_values": [
                    0.109,
                    0.103,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    1,
                    578,
                    639
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.018,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.015,
                    0.017
                ],
                "correlated_features_indices": [
                    8722,
                    8646,
                    8616
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.003,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.004,
                    0
                ],
                "neg_str": [
                    "paio",
                    "ichick",
                    "stad",
                    "annis",
                    "veyard",
                    "inez",
                    "herty",
                    " hur",
                    "ogie",
                    "\u012b"
                ],
                "neg_values": [
                    -0.762,
                    -0.731,
                    -0.708,
                    -0.693,
                    -0.689,
                    -0.676,
                    -0.67,
                    -0.666,
                    -0.664,
                    -0.66
                ],
                "pos_str": [
                    "itarian",
                    "hare",
                    "cro",
                    "ware",
                    "sheets",
                    "holders",
                    " networks",
                    " platforms",
                    "mates",
                    " algorithms"
                ],
                "pos_values": [
                    0.865,
                    0.864,
                    0.847,
                    0.836,
                    0.824,
                    0.778,
                    0.777,
                    0.77,
                    0.756,
                    0.749
                ],
                "frac_nonzero": 0.00019,
                "freq_hist_data_bar_heights": [
                    81,
                    71,
                    38,
                    44,
                    38,
                    31,
                    30,
                    22,
                    13,
                    16,
                    15,
                    18,
                    8,
                    11,
                    12,
                    8,
                    11,
                    13,
                    8,
                    7,
                    7,
                    4,
                    7,
                    6,
                    7,
                    0,
                    2,
                    5,
                    5,
                    5,
                    1,
                    7,
                    3,
                    3,
                    4,
                    6,
                    9,
                    4,
                    5,
                    5,
                    2,
                    5,
                    1,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.469,
                    1.386,
                    2.302,
                    3.218,
                    4.134,
                    5.05,
                    5.966,
                    6.882,
                    7.798,
                    8.714,
                    9.631,
                    10.547,
                    11.463,
                    12.379,
                    13.295,
                    14.211,
                    15.127,
                    16.043,
                    16.959,
                    17.876,
                    18.792,
                    19.708,
                    20.624,
                    21.54,
                    22.456,
                    23.372,
                    24.288,
                    25.204,
                    26.121,
                    27.037,
                    27.953,
                    28.869,
                    29.785,
                    30.701,
                    31.617,
                    32.533,
                    33.449,
                    34.366,
                    35.282,
                    36.198,
                    37.114,
                    38.03,
                    38.946,
                    39.862,
                    40.778,
                    41.694,
                    42.611,
                    43.527,
                    44.443,
                    45.359
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    5,
                    11,
                    7,
                    9,
                    16,
                    40,
                    66,
                    98,
                    145,
                    257,
                    341,
                    536,
                    813,
                    1108,
                    1526,
                    1847,
                    2524,
                    2917,
                    3549,
                    3816,
                    4066,
                    4154,
                    3910,
                    3655,
                    3292,
                    2734,
                    2227,
                    1809,
                    1359,
                    1062,
                    719,
                    528,
                    353,
                    247,
                    162,
                    110,
                    73,
                    48,
                    40,
                    30,
                    14,
                    7,
                    4,
                    6,
                    6,
                    3,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.746,
                    -0.713,
                    -0.681,
                    -0.648,
                    -0.616,
                    -0.583,
                    -0.55,
                    -0.518,
                    -0.485,
                    -0.453,
                    -0.42,
                    -0.388,
                    -0.355,
                    -0.323,
                    -0.29,
                    -0.258,
                    -0.225,
                    -0.192,
                    -0.16,
                    -0.127,
                    -0.095,
                    -0.062,
                    -0.03,
                    0.003,
                    0.035,
                    0.068,
                    0.1,
                    0.133,
                    0.166,
                    0.198,
                    0.231,
                    0.263,
                    0.296,
                    0.328,
                    0.361,
                    0.393,
                    0.426,
                    0.458,
                    0.491,
                    0.524,
                    0.556,
                    0.589,
                    0.621,
                    0.654,
                    0.686,
                    0.719,
                    0.751,
                    0.784,
                    0.816,
                    0.849
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to sharing and collaborative activities",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4nmqmjnczi666pd976z50",
                        "tokens": [
                            ",",
                            " are",
                            " scheduled",
                            " to",
                            " arrive",
                            " in",
                            " the",
                            " early",
                            " afternoon",
                            " of",
                            " Aug",
                            ".",
                            " 15",
                            " \u2014",
                            " a",
                            " day",
                            " that",
                            " marks",
                            " the",
                            " 67",
                            "th",
                            " anniversary",
                            " of",
                            " South",
                            " Korea",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " independence",
                            " from",
                            " Japanese",
                            " colonial",
                            " rule",
                            ".",
                            " Their",
                            " swim",
                            " follows",
                            " a",
                            " visit",
                            " last",
                            " Friday",
                            " by",
                            " South",
                            " Korean",
                            " President",
                            " Lee",
                            " My",
                            "ung",
                            "-",
                            "b",
                            "ak",
                            " \u2014",
                            " the",
                            " first",
                            " ever",
                            " by",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " top",
                            " leader",
                            " \u2014",
                            " which",
                            " prompted",
                            " Japan",
                            " to",
                            " summon",
                            " the",
                            " South",
                            " Korean",
                            " ambassador",
                            " in",
                            " Tokyo",
                            " and",
                            " to",
                            " recall",
                            " its",
                            " top",
                            " diplomat",
                            " from",
                            " Seoul",
                            ".",
                            " Japan",
                            " also",
                            " suggested",
                            " that",
                            " it",
                            " might",
                            " take",
                            " the",
                            " territorial",
                            " dispute",
                            " to",
                            " the",
                            " International",
                            " Court",
                            " of",
                            " Justice",
                            ".",
                            "\n",
                            "\n",
                            "(",
                            "MORE",
                            ":",
                            " Why",
                            " South",
                            " Korea",
                            " Is",
                            " in",
                            " an",
                            " U",
                            "pro",
                            "ar",
                            " over",
                            " Intelligence",
                            " Sharing",
                            " with",
                            " Japan",
                            ")",
                            "\n",
                            "\n",
                            "The",
                            " islands",
                            " are",
                            " located"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.817,
                        "maxValueTokenIndex": 117,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.817,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 45.817,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4nmqmjnd0i666gfz7m736",
                        "tokens": [
                            "Update",
                            ":",
                            " Oct",
                            ".",
                            " 12",
                            ":",
                            " Python",
                            " script",
                            " to",
                            " query",
                            " the",
                            " API",
                            "\n",
                            "\n",
                            "We",
                            " are",
                            " very",
                            " excited",
                            " to",
                            " announce",
                            " that",
                            " J",
                            "EB",
                            " 2",
                            ".",
                            "3",
                            ".",
                            "6",
                            " integrates",
                            " with",
                            " a",
                            " new",
                            " project",
                            " we",
                            " called",
                            " the",
                            " Mal",
                            "ware",
                            " Sharing",
                            " Network",
                            ".",
                            " It",
                            " allows",
                            " reverse",
                            " engineers",
                            " to",
                            " share",
                            " samples",
                            " anonymously",
                            ",",
                            " in",
                            " a",
                            " give",
                            "-",
                            "and",
                            "-",
                            "take",
                            " fashion",
                            ".",
                            " The",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " give",
                            ",",
                            " the",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " will",
                            " receive",
                            ".",
                            "\n",
                            "\n",
                            "Files",
                            " are",
                            " shared",
                            " with",
                            " P",
                            "NF",
                            " Software",
                            " (",
                            "they",
                            " are",
                            " not",
                            " shared",
                            " directly",
                            " with",
                            " other",
                            " users",
                            ");",
                            "\n",
                            "\n",
                            "Contribut",
                            "ions",
                            " and",
                            " users",
                            " are",
                            " algorithm",
                            "ically",
                            " ranked",
                            " and",
                            " scored",
                            ";",
                            "\n",
                            "\n",
                            "In",
                            " exchange",
                            " for",
                            " their",
                            " contributions",
                            ",",
                            " users",
                            " receive",
                            " more",
                            " files",
                            ",",
                            " based",
                            " on",
                            " their",
                            " score",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.853,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.436,
                            0,
                            0.69,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.082,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.323,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 45.817,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4nmqojndki666zp25jkzc",
                        "tokens": [
                            "Update",
                            ":",
                            " Oct",
                            ".",
                            " 12",
                            ":",
                            " Python",
                            " script",
                            " to",
                            " query",
                            " the",
                            " API",
                            "\n",
                            "\n",
                            "We",
                            " are",
                            " very",
                            " excited",
                            " to",
                            " announce",
                            " that",
                            " J",
                            "EB",
                            " 2",
                            ".",
                            "3",
                            ".",
                            "6",
                            " integrates",
                            " with",
                            " a",
                            " new",
                            " project",
                            " we",
                            " called",
                            " the",
                            " Mal",
                            "ware",
                            " Sharing",
                            " Network",
                            ".",
                            " It",
                            " allows",
                            " reverse",
                            " engineers",
                            " to",
                            " share",
                            " samples",
                            " anonymously",
                            ",",
                            " in",
                            " a",
                            " give",
                            "-",
                            "and",
                            "-",
                            "take",
                            " fashion",
                            ".",
                            " The",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " give",
                            ",",
                            " the",
                            " more",
                            " and",
                            " the",
                            " better",
                            " you",
                            " will",
                            " receive",
                            ".",
                            "\n",
                            "\n",
                            "Files",
                            " are",
                            " shared",
                            " with",
                            " P",
                            "NF",
                            " Software",
                            " (",
                            "they",
                            " are",
                            " not",
                            " shared",
                            " directly",
                            " with",
                            " other",
                            " users",
                            ");",
                            "\n",
                            "\n",
                            "Contribut",
                            "ions",
                            " and",
                            " users",
                            " are",
                            " algorithm",
                            "ically",
                            " ranked",
                            " and",
                            " scored",
                            ";",
                            "\n",
                            "\n",
                            "In",
                            " exchange",
                            " for",
                            " their",
                            " contributions",
                            ",",
                            " users",
                            " receive",
                            " more",
                            " files",
                            ",",
                            " based",
                            " on",
                            " their",
                            " score",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "8677",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.853,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.436,
                            0,
                            0.69,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.082,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.323,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:13:27.147Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 36.654,
                        "binMax": 45.817,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46391060733262424,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "5902",
            "description": "references to collaborative projects and educational initiatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4612895983841898,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "5902",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:08:27.998Z",
                "maxActApprox": 10.83,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5902,
                    14080,
                    34669,
                    17734,
                    6915,
                    22948,
                    4605,
                    48747,
                    17249,
                    17660,
                    42876,
                    1682,
                    20454,
                    11952,
                    16080,
                    44792,
                    23791,
                    42073,
                    37253,
                    18052,
                    21215,
                    14605,
                    44365,
                    12560,
                    19672
                ],
                "topkCosSimValues": [
                    1,
                    0.524,
                    0.4349,
                    0.4323,
                    0.4295,
                    0.4262,
                    0.4206,
                    0.4151,
                    0.4143,
                    0.3911,
                    0.3876,
                    0.3861,
                    0.3834,
                    0.3829,
                    0.3811,
                    0.3773,
                    0.373,
                    0.3679,
                    0.3651,
                    0.3634,
                    0.3619,
                    0.3608,
                    0.3575,
                    0.3571,
                    0.3563
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    626
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.149,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    558,
                    498,
                    220
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.034,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.037,
                    0.03
                ],
                "correlated_features_indices": [
                    5779,
                    5792,
                    5782
                ],
                "correlated_features_pearson": [
                    0.032,
                    0.025,
                    0.022
                ],
                "correlated_features_l1": [
                    0.033,
                    0.026,
                    0.024
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "fax",
                    "soType",
                    "enough",
                    "needs",
                    " Salary",
                    "mother",
                    "66666666",
                    "Smith",
                    "errors"
                ],
                "neg_values": [
                    -0.877,
                    -0.68,
                    -0.631,
                    -0.608,
                    -0.603,
                    -0.602,
                    -0.581,
                    -0.579,
                    -0.578,
                    -0.572
                ],
                "pos_str": [
                    " acronym",
                    " themed",
                    " combining",
                    " loosely",
                    " curated",
                    " reim",
                    " revamped",
                    " pioneering",
                    " collaborative",
                    " innovative"
                ],
                "pos_values": [
                    0.853,
                    0.839,
                    0.831,
                    0.83,
                    0.805,
                    0.796,
                    0.789,
                    0.749,
                    0.745,
                    0.744
                ],
                "frac_nonzero": 0.00293,
                "freq_hist_data_bar_heights": [
                    1226,
                    1100,
                    934,
                    764,
                    623,
                    592,
                    487,
                    500,
                    411,
                    356,
                    263,
                    287,
                    200,
                    192,
                    181,
                    147,
                    117,
                    111,
                    101,
                    91,
                    85,
                    58,
                    52,
                    49,
                    51,
                    40,
                    36,
                    26,
                    24,
                    18,
                    15,
                    14,
                    17,
                    8,
                    8,
                    6,
                    5,
                    5,
                    4,
                    5,
                    3,
                    3,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.108,
                    0.325,
                    0.542,
                    0.758,
                    0.975,
                    1.191,
                    1.408,
                    1.624,
                    1.841,
                    2.058,
                    2.274,
                    2.491,
                    2.707,
                    2.924,
                    3.141,
                    3.357,
                    3.574,
                    3.79,
                    4.007,
                    4.224,
                    4.44,
                    4.657,
                    4.873,
                    5.09,
                    5.307,
                    5.523,
                    5.74,
                    5.956,
                    6.173,
                    6.39,
                    6.606,
                    6.823,
                    7.039,
                    7.256,
                    7.473,
                    7.689,
                    7.906,
                    8.122,
                    8.339,
                    8.556,
                    8.772,
                    8.989,
                    9.205,
                    9.422,
                    9.639,
                    9.855,
                    10.072,
                    10.288,
                    10.505,
                    10.722
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    6,
                    11,
                    32,
                    42,
                    93,
                    133,
                    264,
                    437,
                    682,
                    1088,
                    1486,
                    2036,
                    2647,
                    3354,
                    3836,
                    4158,
                    4307,
                    4236,
                    3995,
                    3565,
                    3145,
                    2646,
                    2066,
                    1515,
                    1270,
                    953,
                    657,
                    465,
                    363,
                    250,
                    182,
                    119,
                    72,
                    60,
                    32,
                    15,
                    14,
                    5,
                    7,
                    0,
                    3,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.86,
                    -0.825,
                    -0.791,
                    -0.756,
                    -0.722,
                    -0.687,
                    -0.652,
                    -0.618,
                    -0.583,
                    -0.549,
                    -0.514,
                    -0.479,
                    -0.445,
                    -0.41,
                    -0.375,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.064,
                    -0.029,
                    0.005,
                    0.04,
                    0.074,
                    0.109,
                    0.144,
                    0.178,
                    0.213,
                    0.248,
                    0.282,
                    0.317,
                    0.351,
                    0.386,
                    0.421,
                    0.455,
                    0.49,
                    0.524,
                    0.559,
                    0.594,
                    0.628,
                    0.663,
                    0.698,
                    0.732,
                    0.767,
                    0.801,
                    0.836
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to collaborative projects and educational initiatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4heuqh37bi666m6l6lyza",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuuh388i666aew2pu4t",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 4.332,
                        "binMax": 6.498,
                        "binContains": 0.00014,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuqh37ci666gdc1fdp1",
                        "tokens": [
                            " space",
                            " and",
                            " a",
                            " three",
                            "-",
                            "day",
                            " sym",
                            "posium",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013a",
                            "I",
                            " have",
                            " written",
                            " a",
                            " wicked",
                            " book",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " said",
                            " Mel",
                            "ville",
                            " when",
                            " his",
                            " novel",
                            " was",
                            " first",
                            " published",
                            " in",
                            " 18",
                            "51",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "and",
                            " I",
                            " feel",
                            " as",
                            " spot",
                            "less",
                            " as",
                            " the",
                            " lamb",
                            "\u00e2\u0122",
                            "\u013b",
                            ".",
                            " Deep",
                            "ly",
                            " subversive",
                            ",",
                            " in",
                            " almost",
                            " every",
                            " way",
                            " imaginable",
                            ",",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " is",
                            " a",
                            " virtual",
                            ",",
                            " alternative",
                            " bible",
                            " \u2013",
                            " and",
                            " as",
                            " such",
                            ",",
                            " ripe",
                            " for",
                            " re",
                            "interpret",
                            "ation",
                            " in",
                            " this",
                            " new",
                            " world",
                            " of",
                            " new",
                            " media",
                            ".",
                            " Out",
                            " of",
                            " Dominion",
                            " was",
                            " born",
                            " its",
                            " bastard",
                            " child",
                            " \u2013",
                            " or",
                            " perhaps",
                            " its",
                            " imm",
                            "ac",
                            "ulate",
                            " conception",
                            " \u2013",
                            " the",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " Big",
                            " Read",
                            ":",
                            " an",
                            " online",
                            " version",
                            " of",
                            " Mel",
                            "ville",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mag",
                            "ister",
                            "ial",
                            " to",
                            "me",
                            ":"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.607,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.969,
                            10.607,
                            8.971,
                            3.062,
                            2.038,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            1.269,
                            0,
                            0,
                            2.09
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "87355",
            "description": "references to colleagues and peer relationships in professional contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.460862471487,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "87355",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:17:33.954Z",
                "maxActApprox": 34.645,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    87355,
                    50718,
                    94526,
                    67890,
                    3347,
                    48017,
                    18421,
                    88988,
                    81658,
                    62926,
                    2171,
                    310,
                    76127,
                    52230,
                    53636,
                    84499,
                    50613,
                    17397,
                    46700,
                    31193,
                    67909,
                    65642,
                    34243,
                    6578,
                    59679
                ],
                "topkCosSimValues": [
                    1,
                    0.5832,
                    0.5121,
                    0.5115,
                    0.4972,
                    0.4943,
                    0.487,
                    0.4643,
                    0.4611,
                    0.457,
                    0.4547,
                    0.4501,
                    0.4362,
                    0.4256,
                    0.4253,
                    0.4237,
                    0.4191,
                    0.4189,
                    0.4184,
                    0.4173,
                    0.4153,
                    0.4145,
                    0.4134,
                    0.4087,
                    0.4077
                ],
                "neuron_alignment_indices": [
                    420,
                    679,
                    488
                ],
                "neuron_alignment_values": [
                    0.16,
                    0.147,
                    0.122
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    420,
                    491,
                    722
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.015,
                    0.013,
                    0.013
                ],
                "correlated_features_indices": [
                    87389,
                    87273,
                    87355
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " Ukrain",
                    "itized",
                    "sole",
                    "skinned",
                    "clusively",
                    " cryst",
                    "aval",
                    "apor",
                    "icted",
                    "finger"
                ],
                "neg_values": [
                    -0.802,
                    -0.707,
                    -0.682,
                    -0.678,
                    -0.648,
                    -0.635,
                    -0.635,
                    -0.611,
                    -0.608,
                    -0.59
                ],
                "pos_str": [
                    " colleagues",
                    " colleague",
                    "ries",
                    " coworkers",
                    "ority",
                    "enary",
                    "tops",
                    " classmates",
                    "mates",
                    "opausal"
                ],
                "pos_values": [
                    1.136,
                    1.016,
                    0.895,
                    0.856,
                    0.748,
                    0.743,
                    0.738,
                    0.723,
                    0.691,
                    0.687
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    54,
                    34,
                    15,
                    16,
                    17,
                    6,
                    11,
                    10,
                    8,
                    14,
                    10,
                    6,
                    5,
                    10,
                    5,
                    5,
                    2,
                    3,
                    5,
                    2,
                    5,
                    7,
                    0,
                    1,
                    1,
                    2,
                    1,
                    1,
                    3,
                    2,
                    2,
                    3,
                    7,
                    1,
                    3,
                    7,
                    2,
                    7,
                    3,
                    7,
                    6,
                    8,
                    5,
                    6,
                    5,
                    2,
                    2,
                    1,
                    1,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.356,
                    1.049,
                    1.742,
                    2.434,
                    3.127,
                    3.82,
                    4.513,
                    5.205,
                    5.898,
                    6.591,
                    7.283,
                    7.976,
                    8.669,
                    9.361,
                    10.054,
                    10.747,
                    11.439,
                    12.132,
                    12.825,
                    13.518,
                    14.21,
                    14.903,
                    15.596,
                    16.288,
                    16.981,
                    17.674,
                    18.366,
                    19.059,
                    19.752,
                    20.444,
                    21.137,
                    21.83,
                    22.523,
                    23.215,
                    23.908,
                    24.601,
                    25.293,
                    25.986,
                    26.679,
                    27.371,
                    28.064,
                    28.757,
                    29.45,
                    30.142,
                    30.835,
                    31.528,
                    32.22,
                    32.913,
                    33.606,
                    34.298
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    3,
                    3,
                    6,
                    16,
                    33,
                    62,
                    112,
                    227,
                    394,
                    637,
                    993,
                    1508,
                    2204,
                    2928,
                    3695,
                    4331,
                    4889,
                    4893,
                    4781,
                    4439,
                    3696,
                    3090,
                    2333,
                    1733,
                    1196,
                    789,
                    491,
                    304,
                    207,
                    112,
                    55,
                    38,
                    21,
                    19,
                    5,
                    4,
                    4,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.783,
                    -0.744,
                    -0.705,
                    -0.667,
                    -0.628,
                    -0.589,
                    -0.55,
                    -0.512,
                    -0.473,
                    -0.434,
                    -0.395,
                    -0.357,
                    -0.318,
                    -0.279,
                    -0.24,
                    -0.202,
                    -0.163,
                    -0.124,
                    -0.085,
                    -0.047,
                    -0.008,
                    0.031,
                    0.07,
                    0.108,
                    0.147,
                    0.186,
                    0.225,
                    0.264,
                    0.302,
                    0.341,
                    0.38,
                    0.419,
                    0.457,
                    0.496,
                    0.535,
                    0.574,
                    0.612,
                    0.651,
                    0.69,
                    0.729,
                    0.767,
                    0.806,
                    0.845,
                    0.884,
                    0.922,
                    0.961,
                    1,
                    1.039,
                    1.077,
                    1.116
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " mentions of colleagues or references to teamwork and professional relationships",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to colleagues and peer relationships in professional contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygischr5jhi10exc6lq294v",
                        "tokens": [
                            " after",
                            " concluding",
                            " he",
                            " had",
                            " no",
                            " future",
                            " in",
                            " the",
                            " force",
                            " following",
                            " his",
                            " decision",
                            " to",
                            " expose",
                            " the",
                            " '",
                            "in",
                            "comp",
                            "et",
                            "ence",
                            "'",
                            " of",
                            " colleagues",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " launched",
                            " a",
                            " wider",
                            " attack",
                            " on",
                            " Mr",
                            " Watson",
                            " over",
                            " his",
                            " role",
                            " in",
                            " the",
                            " VIP",
                            " sex",
                            " and",
                            " paed",
                            "ophile",
                            " scandal",
                            ".",
                            "\n",
                            "\n",
                            "Mr",
                            " S",
                            "ettle",
                            " said",
                            " he",
                            " was",
                            " in",
                            " '",
                            "no",
                            " doubt",
                            "'",
                            " that",
                            " a",
                            " 2012",
                            " speech",
                            " by",
                            " Mr",
                            " Watson",
                            " in",
                            " the",
                            " House",
                            " of",
                            " Commons",
                            ",",
                            " which",
                            " alleged",
                            " the",
                            " existence",
                            " of",
                            " a",
                            " powerful",
                            " paed",
                            "ophile",
                            " ring",
                            " with",
                            " links",
                            " to",
                            " a",
                            " former",
                            " Prime",
                            " Minister",
                            "'s",
                            " advisor",
                            ",",
                            " was",
                            " '",
                            "cal",
                            "culated",
                            "'",
                            " to",
                            " damage",
                            " the",
                            " Conservative",
                            " Party",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " accused",
                            " the",
                            " deputy",
                            " leader",
                            " and",
                            " several",
                            " Labour",
                            " activists",
                            " of",
                            " being",
                            " '",
                            "polit",
                            "ically",
                            " motivated",
                            "'",
                            " when",
                            " they",
                            " made",
                            " allegations",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "87355",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.645,
                        "maxValueTokenIndex": 22,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.645,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.890Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 34.645,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygischt5ji410ex3u4iru8u",
                        "tokens": [
                            " after",
                            " concluding",
                            " he",
                            " had",
                            " no",
                            " future",
                            " in",
                            " the",
                            " force",
                            " following",
                            " his",
                            " decision",
                            " to",
                            " expose",
                            " the",
                            " '",
                            "in",
                            "comp",
                            "et",
                            "ence",
                            "'",
                            " of",
                            " colleagues",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " launched",
                            " a",
                            " wider",
                            " attack",
                            " on",
                            " Mr",
                            " Watson",
                            " over",
                            " his",
                            " role",
                            " in",
                            " the",
                            " VIP",
                            " sex",
                            " and",
                            " paed",
                            "ophile",
                            " scandal",
                            ".",
                            "\n",
                            "\n",
                            "Mr",
                            " S",
                            "ettle",
                            " said",
                            " he",
                            " was",
                            " in",
                            " '",
                            "no",
                            " doubt",
                            "'",
                            " that",
                            " a",
                            " 2012",
                            " speech",
                            " by",
                            " Mr",
                            " Watson",
                            " in",
                            " the",
                            " House",
                            " of",
                            " Commons",
                            ",",
                            " which",
                            " alleged",
                            " the",
                            " existence",
                            " of",
                            " a",
                            " powerful",
                            " paed",
                            "ophile",
                            " ring",
                            " with",
                            " links",
                            " to",
                            " a",
                            " former",
                            " Prime",
                            " Minister",
                            "'s",
                            " advisor",
                            ",",
                            " was",
                            " '",
                            "cal",
                            "culated",
                            "'",
                            " to",
                            " damage",
                            " the",
                            " Conservative",
                            " Party",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " accused",
                            " the",
                            " deputy",
                            " leader",
                            " and",
                            " several",
                            " Labour",
                            " activists",
                            " of",
                            " being",
                            " '",
                            "polit",
                            "ically",
                            " motivated",
                            "'",
                            " when",
                            " they",
                            " made",
                            " allegations",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "87355",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.645,
                        "maxValueTokenIndex": 22,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.645,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.890Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 27.716,
                        "binMax": 34.645,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygischr5jhj10exigmkl8pp",
                        "tokens": [
                            " 1",
                            ",",
                            "750",
                            " farmers",
                            "--",
                            "all",
                            " of",
                            " whom",
                            " had",
                            " purportedly",
                            " sold",
                            " their",
                            " land",
                            "--",
                            "st",
                            "ating",
                            " their",
                            " opposition",
                            " to",
                            " selling",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            "'s",
                            " nothing",
                            " subtle",
                            " about",
                            " the",
                            " threats",
                            ".",
                            " A",
                            " teacher",
                            ",",
                            " Ret",
                            "u",
                            " Ram",
                            ",",
                            " was",
                            " told",
                            " he",
                            "'d",
                            " be",
                            " transferred",
                            " to",
                            " another",
                            " district",
                            " if",
                            " he",
                            " didn",
                            "'t",
                            " sell",
                            ".",
                            " That",
                            "'s",
                            " what",
                            " happened",
                            " to",
                            " a",
                            " colleague",
                            ".",
                            " In",
                            " another",
                            " village",
                            ",",
                            " Bang",
                            "a",
                            " Pe",
                            "eta",
                            " A",
                            "ito",
                            ",",
                            " a",
                            " farmer",
                            " of",
                            " 60",
                            " or",
                            " so",
                            ",",
                            " had",
                            " been",
                            " in",
                            " prison",
                            " for",
                            " a",
                            " month",
                            " on",
                            " charges",
                            " of",
                            " disturbing",
                            " the",
                            " peace",
                            ".",
                            " His",
                            " sons",
                            " were",
                            " told",
                            " that",
                            " unless",
                            " they",
                            " agreed",
                            " to",
                            " take",
                            " the",
                            " check",
                            " from",
                            " Tata",
                            ",",
                            " their",
                            " father",
                            " would",
                            " rot",
                            " in",
                            " jail",
                            ".",
                            " They",
                            " finally",
                            " accepted",
                            " it",
                            "--",
                            "and",
                            " their",
                            " father",
                            " was",
                            " released",
                            " the",
                            " next"
                        ],
                        "dataIndex": null,
                        "index": "87355",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.459,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.459,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:39.890Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 34.645,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "3461",
            "description": "discussions about teamwork and collaboration",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.458542200413812,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "3461",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:04:10.185Z",
                "maxActApprox": 39.041,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3461,
                    47086,
                    17628,
                    13294,
                    33642,
                    1517,
                    5536,
                    38582,
                    1373,
                    14042,
                    12967,
                    15231,
                    29129,
                    15469,
                    31602,
                    44109,
                    29873,
                    43779,
                    35965,
                    16315,
                    15667,
                    35370,
                    4114,
                    38066,
                    46663
                ],
                "topkCosSimValues": [
                    1,
                    0.6695,
                    0.6662,
                    0.6313,
                    0.6286,
                    0.6238,
                    0.6173,
                    0.6142,
                    0.6096,
                    0.6005,
                    0.5973,
                    0.5948,
                    0.5942,
                    0.5934,
                    0.5836,
                    0.5801,
                    0.5799,
                    0.5775,
                    0.5756,
                    0.5728,
                    0.5643,
                    0.5595,
                    0.5527,
                    0.5514,
                    0.5442
                ],
                "neuron_alignment_indices": [
                    640,
                    618,
                    372
                ],
                "neuron_alignment_values": [
                    0.245,
                    0.102,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.011,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    640,
                    64,
                    143
                ],
                "correlated_neurons_pearson": [
                    0.083,
                    0.051,
                    0.047
                ],
                "correlated_neurons_l1": [
                    0.077,
                    -0.017,
                    0.045
                ],
                "correlated_features_indices": [
                    3374,
                    3451,
                    3461
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "ibrary",
                    "wart",
                    " estranged",
                    "warts",
                    " unin",
                    " extrad",
                    "antine",
                    " Reincarnated",
                    " centrally",
                    " inconvenient"
                ],
                "neg_values": [
                    -0.766,
                    -0.715,
                    -0.713,
                    -0.704,
                    -0.672,
                    -0.672,
                    -0.67,
                    -0.667,
                    -0.632,
                    -0.629
                ],
                "pos_str": [
                    "Interview",
                    "Narr",
                    "Posted",
                    "Anyway",
                    "Yeah",
                    "Were",
                    "MJ",
                    "Jones",
                    "Talking",
                    "JC"
                ],
                "pos_values": [
                    1.035,
                    0.948,
                    0.895,
                    0.89,
                    0.887,
                    0.863,
                    0.845,
                    0.844,
                    0.84,
                    0.833
                ],
                "frac_nonzero": 0.00148,
                "freq_hist_data_bar_heights": [
                    1071,
                    727,
                    518,
                    418,
                    308,
                    246,
                    220,
                    164,
                    145,
                    114,
                    73,
                    62,
                    71,
                    46,
                    47,
                    44,
                    35,
                    39,
                    25,
                    25,
                    19,
                    25,
                    20,
                    13,
                    18,
                    15,
                    16,
                    17,
                    15,
                    8,
                    12,
                    17,
                    9,
                    5,
                    6,
                    6,
                    5,
                    4,
                    5,
                    7,
                    5,
                    2,
                    8,
                    2,
                    4,
                    1,
                    1,
                    2,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.391,
                    1.171,
                    1.952,
                    2.733,
                    3.514,
                    4.295,
                    5.076,
                    5.856,
                    6.637,
                    7.418,
                    8.199,
                    8.98,
                    9.76,
                    10.541,
                    11.322,
                    12.103,
                    12.884,
                    13.664,
                    14.445,
                    15.226,
                    16.007,
                    16.788,
                    17.568,
                    18.349,
                    19.13,
                    19.911,
                    20.692,
                    21.472,
                    22.253,
                    23.034,
                    23.815,
                    24.596,
                    25.377,
                    26.157,
                    26.938,
                    27.719,
                    28.5,
                    29.281,
                    30.061,
                    30.842,
                    31.623,
                    32.404,
                    33.185,
                    33.965,
                    34.746,
                    35.527,
                    36.308,
                    37.089,
                    37.869,
                    38.65
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    4,
                    6,
                    18,
                    20,
                    46,
                    92,
                    173,
                    283,
                    435,
                    777,
                    1078,
                    1367,
                    1918,
                    2396,
                    2957,
                    3203,
                    3537,
                    3699,
                    3694,
                    3624,
                    3290,
                    3008,
                    2604,
                    2279,
                    1973,
                    1620,
                    1401,
                    1072,
                    900,
                    700,
                    550,
                    463,
                    312,
                    240,
                    169,
                    105,
                    84,
                    52,
                    35,
                    34,
                    15,
                    6,
                    8,
                    3,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.748,
                    -0.712,
                    -0.676,
                    -0.64,
                    -0.604,
                    -0.568,
                    -0.532,
                    -0.496,
                    -0.46,
                    -0.424,
                    -0.388,
                    -0.352,
                    -0.316,
                    -0.28,
                    -0.244,
                    -0.208,
                    -0.172,
                    -0.136,
                    -0.1,
                    -0.064,
                    -0.028,
                    0.008,
                    0.045,
                    0.081,
                    0.117,
                    0.153,
                    0.189,
                    0.225,
                    0.261,
                    0.297,
                    0.333,
                    0.369,
                    0.405,
                    0.441,
                    0.477,
                    0.513,
                    0.549,
                    0.585,
                    0.621,
                    0.657,
                    0.693,
                    0.729,
                    0.765,
                    0.801,
                    0.837,
                    0.873,
                    0.909,
                    0.945,
                    0.981,
                    1.017
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions about teamwork and collaboration",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4bxeqetwmi666dqpi3rmk",
                        "tokens": [
                            "re",
                            " doing",
                            " a",
                            " basic",
                            " cable",
                            " show",
                            " in",
                            " seven",
                            " days",
                            ",",
                            " and",
                            " I",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Tim",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " probably",
                            " gonna",
                            " be",
                            " able",
                            " to",
                            " just",
                            " shoot",
                            " one",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "Laughs",
                            ")",
                            " We",
                            " heard",
                            " about",
                            " all",
                            " these",
                            " other",
                            " things",
                            " that",
                            " Marsh",
                            "als",
                            " will",
                            " do",
                            ".",
                            " If",
                            " they",
                            " know",
                            " that",
                            " a",
                            " restaurant",
                            " is",
                            " owned",
                            " by",
                            " bad",
                            " guys",
                            ",",
                            " well",
                            ",",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " just",
                            " start",
                            " eating",
                            " there",
                            " and",
                            " have",
                            " cops",
                            " eating",
                            " there",
                            " all",
                            " the",
                            " time",
                            " to",
                            " dry",
                            " up",
                            " the",
                            " bad",
                            "-",
                            "guy",
                            " business",
                            ".",
                            " Obviously",
                            " pulling",
                            " licenses",
                            " and",
                            " doing",
                            " anything",
                            " that",
                            " they",
                            " can",
                            " in",
                            " terms",
                            " of",
                            " the",
                            " legal",
                            " status",
                            " of",
                            " an",
                            " operation",
                            " and",
                            " taking",
                            " it",
                            " down",
                            ".",
                            " We",
                            " thought",
                            ",",
                            " let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " just",
                            " tow",
                            " the",
                            " RV",
                            ".",
                            "\n",
                            "\n",
                            "Are",
                            " we"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.041,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.769,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.041,
                            8.616,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4bxeqetwni666uidowndc",
                        "tokens": [
                            " of",
                            " mis",
                            "fit",
                            " toys",
                            ".",
                            " And",
                            " I",
                            " think",
                            " the",
                            " world",
                            " is",
                            " full",
                            " of",
                            " more",
                            " mis",
                            "fits",
                            " than",
                            " the",
                            " people",
                            " that",
                            " have",
                            " it",
                            " together",
                            ".",
                            " I",
                            " was",
                            " a",
                            " mis",
                            "fit",
                            ".",
                            " You",
                            " know",
                            " I",
                            " was",
                            " an",
                            " underdog",
                            " in",
                            " life",
                            ".",
                            " And",
                            " I",
                            " feel",
                            " like",
                            " when",
                            " you",
                            " find",
                            " your",
                            " tribe",
                            " you",
                            " hold",
                            " on",
                            " to",
                            " them",
                            ",",
                            " and",
                            " so",
                            " I",
                            " think",
                            " the",
                            " mis",
                            "fits",
                            " of",
                            " the",
                            " world",
                            " really",
                            " found",
                            " someone",
                            " in",
                            " that",
                            " study",
                            " group",
                            " that",
                            " reminded",
                            " them",
                            " of",
                            " themselves",
                            ",",
                            " and",
                            " they",
                            " held",
                            " on",
                            ".",
                            "\n",
                            "\n",
                            "Larry",
                            " King",
                            ":",
                            " Do",
                            " you",
                            " miss",
                            " the",
                            " show",
                            "?",
                            "\n",
                            "\n",
                            "Y",
                            "vette",
                            " Nicole",
                            " Brown",
                            ":",
                            " I",
                            " do",
                            ".",
                            " I",
                            " was",
                            " going",
                            " to",
                            " say",
                            " I",
                            " miss",
                            " my",
                            " friends",
                            " in",
                            " the",
                            " cast",
                            " and",
                            " crew",
                            " but",
                            " I",
                            " actually",
                            " see",
                            " a",
                            " lot",
                            " of",
                            " them",
                            " so",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.974,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.974,
                            12.063,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.333,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4bxeretwoi666xgnpceo5",
                        "tokens": [
                            " element",
                            ".",
                            " I",
                            " was",
                            " playing",
                            " the",
                            " four",
                            " and",
                            " the",
                            " five",
                            " because",
                            " I",
                            " was",
                            " the",
                            " tallest",
                            " guy",
                            " on",
                            " my",
                            " team",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " somewhere",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " used",
                            " to",
                            " playing",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " used",
                            " to",
                            " playing",
                            " on",
                            " the",
                            " wing",
                            " or",
                            " the",
                            " one",
                            ",",
                            " two",
                            " or",
                            " three",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " learning",
                            " the",
                            " game",
                            " from",
                            " a",
                            " different",
                            " aspect",
                            " and",
                            " it",
                            " was",
                            " a",
                            " learning",
                            " process",
                            ".",
                            " So",
                            " I",
                            " had",
                            " to",
                            " deal",
                            " with",
                            " that",
                            ".",
                            " I",
                            " caught",
                            " a",
                            " rhythm",
                            " towards",
                            " the",
                            " middle",
                            " of",
                            " the",
                            " season",
                            " and",
                            " I",
                            " thought",
                            " I",
                            " played",
                            " pretty",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Develop",
                            "mental",
                            " wise",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " long",
                            " list",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " long",
                            " list",
                            " of",
                            " things",
                            " from",
                            " top",
                            " to",
                            " bottom",
                            ".",
                            " I",
                            " could",
                            " start"
                        ],
                        "dataIndex": null,
                        "index": "3461",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.537,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.537,
                            10.203,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:04:21.577Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.041,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4578067039136122,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67890",
            "description": " mentions of \"peers\" or references to social comparisons and relationships",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4572485685348511,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67890",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:56:25.947Z",
                "maxActApprox": 36.079,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67890,
                    9241,
                    88988,
                    87355,
                    46700,
                    55919,
                    52230,
                    73432,
                    31193,
                    50613,
                    3347,
                    76127,
                    2171,
                    34243,
                    92170,
                    50718,
                    1202,
                    94322,
                    43418,
                    89244,
                    28596,
                    61385,
                    31522,
                    43241,
                    51137
                ],
                "topkCosSimValues": [
                    1,
                    0.5826,
                    0.533,
                    0.5115,
                    0.483,
                    0.4547,
                    0.4485,
                    0.4469,
                    0.4387,
                    0.4356,
                    0.4307,
                    0.4304,
                    0.4296,
                    0.4115,
                    0.4101,
                    0.4094,
                    0.3982,
                    0.3707,
                    0.367,
                    0.3623,
                    0.3573,
                    0.3569,
                    0.3426,
                    0.3415,
                    0.3295
                ],
                "neuron_alignment_indices": [
                    383,
                    445,
                    349
                ],
                "neuron_alignment_values": [
                    0.108,
                    0.105,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    506,
                    743,
                    722
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.008,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.007,
                    0.008
                ],
                "correlated_features_indices": [
                    67813,
                    67785,
                    67844
                ],
                "correlated_features_pearson": [
                    0.014,
                    0.006,
                    0
                ],
                "correlated_features_l1": [
                    0.014,
                    0.006,
                    0.001
                ],
                "neg_str": [
                    "\u00e3\u0125\u013b",
                    "veyard",
                    " Tycoon",
                    " Ukrain",
                    "ohyd",
                    "ichick",
                    " coincidence",
                    "selage",
                    " Liberties",
                    " Rohing"
                ],
                "neg_values": [
                    -0.709,
                    -0.689,
                    -0.666,
                    -0.647,
                    -0.638,
                    -0.629,
                    -0.624,
                    -0.602,
                    -0.601,
                    -0.597
                ],
                "pos_str": [
                    " peers",
                    "peer",
                    "hip",
                    "iblings",
                    "folk",
                    "heimer",
                    "ystem",
                    "mates",
                    "enary",
                    "hall"
                ],
                "pos_values": [
                    0.883,
                    0.843,
                    0.818,
                    0.798,
                    0.785,
                    0.768,
                    0.748,
                    0.74,
                    0.736,
                    0.728
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    23,
                    16,
                    16,
                    8,
                    12,
                    6,
                    6,
                    4,
                    4,
                    1,
                    3,
                    2,
                    1,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1,
                    2,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    5,
                    3,
                    0,
                    0,
                    4,
                    2,
                    2,
                    3,
                    2,
                    4,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.38,
                    1.101,
                    1.823,
                    2.544,
                    3.265,
                    3.986,
                    4.707,
                    5.429,
                    6.15,
                    6.871,
                    7.592,
                    8.313,
                    9.034,
                    9.756,
                    10.477,
                    11.198,
                    11.919,
                    12.64,
                    13.362,
                    14.083,
                    14.804,
                    15.525,
                    16.246,
                    16.967,
                    17.689,
                    18.41,
                    19.131,
                    19.852,
                    20.573,
                    21.295,
                    22.016,
                    22.737,
                    23.458,
                    24.179,
                    24.9,
                    25.622,
                    26.343,
                    27.064,
                    27.785,
                    28.506,
                    29.228,
                    29.949,
                    30.67,
                    31.391,
                    32.112,
                    32.833,
                    33.555,
                    34.276,
                    34.997,
                    35.718
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    3,
                    5,
                    3,
                    11,
                    25,
                    36,
                    82,
                    118,
                    199,
                    361,
                    526,
                    802,
                    1088,
                    1598,
                    2114,
                    2738,
                    3145,
                    3569,
                    4000,
                    4161,
                    4039,
                    3938,
                    3655,
                    3155,
                    2572,
                    2131,
                    1723,
                    1277,
                    949,
                    678,
                    478,
                    349,
                    240,
                    163,
                    99,
                    80,
                    48,
                    29,
                    23,
                    15,
                    5,
                    10,
                    3,
                    4,
                    2,
                    2,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.693,
                    -0.661,
                    -0.63,
                    -0.598,
                    -0.566,
                    -0.534,
                    -0.502,
                    -0.47,
                    -0.438,
                    -0.407,
                    -0.375,
                    -0.343,
                    -0.311,
                    -0.279,
                    -0.247,
                    -0.216,
                    -0.184,
                    -0.152,
                    -0.12,
                    -0.088,
                    -0.056,
                    -0.025,
                    0.007,
                    0.039,
                    0.071,
                    0.103,
                    0.135,
                    0.166,
                    0.198,
                    0.23,
                    0.262,
                    0.294,
                    0.326,
                    0.357,
                    0.389,
                    0.421,
                    0.453,
                    0.485,
                    0.517,
                    0.548,
                    0.58,
                    0.612,
                    0.644,
                    0.676,
                    0.708,
                    0.739,
                    0.771,
                    0.803,
                    0.835,
                    0.867
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to social relationships among equals or colleagues",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " mentions of \"peers\" or references to social comparisons and relationships",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi177zqs1m10ex8lakjuv8",
                        "tokens": [
                            " draw",
                            " ahead",
                            " of",
                            " its",
                            " peers",
                            " on",
                            " both",
                            " the",
                            " design",
                            " and",
                            " technology",
                            " fronts",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " Mazda",
                            " says",
                            " the",
                            " interior",
                            " was",
                            " benchmark",
                            "ed",
                            " against",
                            " the",
                            " latest",
                            " BMW",
                            " 3",
                            " Series",
                            " .",
                            " They",
                            "'re",
                            " quick",
                            " to",
                            " say",
                            " that",
                            " they",
                            " don",
                            "'t",
                            " expect",
                            " the",
                            " Mazda",
                            "3",
                            " to",
                            " compete",
                            " with",
                            " the",
                            " 3",
                            " Series",
                            ",",
                            " but",
                            " that",
                            " it",
                            " was",
                            " seen",
                            " as",
                            " a",
                            " goal",
                            " of",
                            " sorts",
                            " worth",
                            " reaching",
                            " for",
                            ".",
                            " The",
                            " most",
                            " noticeable",
                            " new",
                            " element",
                            " is",
                            " the",
                            " seven",
                            "-",
                            "inch",
                            " display",
                            " perched",
                            " prominently",
                            " atop",
                            " the",
                            " dash",
                            ",",
                            " right",
                            " above",
                            " the",
                            " center",
                            " stack",
                            ".",
                            " The",
                            " other",
                            " new",
                            " and",
                            " noteworthy",
                            " bit",
                            " is",
                            " the",
                            " fighter",
                            "-",
                            "p",
                            "ilot",
                            "-",
                            "like",
                            " Active",
                            " Driving",
                            " Display",
                            ".",
                            "According",
                            " to",
                            " Mazda",
                            ",",
                            " after",
                            " benchmark",
                            "ing",
                            " the",
                            " inf",
                            "ot",
                            "ainment",
                            " systems",
                            " in",
                            " many",
                            " of",
                            " its",
                            " rival",
                            " automakers",
                            ",",
                            " they",
                            " didn",
                            "'t"
                        ],
                        "dataIndex": null,
                        "index": "67890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.079,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            36.079,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:33.327Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 36.079,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi177zqs1n10exxjw4ggjt",
                        "tokens": [
                            " deemed",
                            " to",
                            " be",
                            " acceptable",
                            " attention",
                            ".",
                            " Where",
                            " does",
                            " that",
                            " leave",
                            " the",
                            " woman",
                            "?",
                            " She",
                            " is",
                            " expected",
                            " to",
                            " smile",
                            " and",
                            " say",
                            " thank",
                            " you",
                            ",",
                            " even",
                            " if",
                            " she",
                            " feels",
                            " mildly",
                            " aff",
                            "ront",
                            "ed",
                            ",",
                            " even",
                            " if",
                            " she",
                            " finds",
                            " you",
                            " disgusting",
                            "\u2014",
                            "although",
                            " you",
                            " would",
                            " likely",
                            " never",
                            " detect",
                            " this",
                            " as",
                            " she",
                            " is",
                            " forced",
                            " to",
                            " suspend",
                            " these",
                            " opinions",
                            " at",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            ":",
                            "\n",
                            "\n",
                            "Imagine",
                            " you",
                            " have",
                            " a",
                            " boss",
                            " who",
                            " rep",
                            "uls",
                            "es",
                            " you",
                            ",",
                            " and",
                            " one",
                            " day",
                            ",",
                            " in",
                            " front",
                            " of",
                            " a",
                            " group",
                            " of",
                            " your",
                            " peers",
                            ",",
                            " he",
                            " presents",
                            " you",
                            " with",
                            " a",
                            " gift",
                            ".",
                            " It",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " your",
                            " birthday",
                            ",",
                            " but",
                            " you",
                            " have",
                            " been",
                            " singled",
                            " out",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Open",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " impl",
                            "ores",
                            ",",
                            " be",
                            "aming",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "67890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.322,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.322,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:33.327Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 36.079,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1781qs2910exbanlcm8t",
                        "tokens": [
                            " deemed",
                            " to",
                            " be",
                            " acceptable",
                            " attention",
                            ".",
                            " Where",
                            " does",
                            " that",
                            " leave",
                            " the",
                            " woman",
                            "?",
                            " She",
                            " is",
                            " expected",
                            " to",
                            " smile",
                            " and",
                            " say",
                            " thank",
                            " you",
                            ",",
                            " even",
                            " if",
                            " she",
                            " feels",
                            " mildly",
                            " aff",
                            "ront",
                            "ed",
                            ",",
                            " even",
                            " if",
                            " she",
                            " finds",
                            " you",
                            " disgusting",
                            "\u2014",
                            "although",
                            " you",
                            " would",
                            " likely",
                            " never",
                            " detect",
                            " this",
                            " as",
                            " she",
                            " is",
                            " forced",
                            " to",
                            " suspend",
                            " these",
                            " opinions",
                            " at",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            ":",
                            "\n",
                            "\n",
                            "Imagine",
                            " you",
                            " have",
                            " a",
                            " boss",
                            " who",
                            " rep",
                            "uls",
                            "es",
                            " you",
                            ",",
                            " and",
                            " one",
                            " day",
                            ",",
                            " in",
                            " front",
                            " of",
                            " a",
                            " group",
                            " of",
                            " your",
                            " peers",
                            ",",
                            " he",
                            " presents",
                            " you",
                            " with",
                            " a",
                            " gift",
                            ".",
                            " It",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " your",
                            " birthday",
                            ",",
                            " but",
                            " you",
                            " have",
                            " been",
                            " singled",
                            " out",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Open",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " impl",
                            "ores",
                            ",",
                            " be",
                            "aming",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "67890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.322,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.322,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:33.327Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 28.863,
                        "binMax": 36.079,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "44916",
            "description": "terms related to social interaction and collaboration",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.45435380935668945,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "44916",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:19:03.910Z",
                "maxActApprox": 7.676,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44916,
                    43332,
                    21529,
                    18840,
                    5814,
                    14670,
                    11045,
                    36358,
                    42499,
                    29674,
                    7874,
                    45219,
                    24312,
                    3535,
                    22789,
                    21377,
                    48566,
                    36138,
                    20408,
                    15381,
                    19185,
                    13824,
                    39735,
                    41295,
                    29013
                ],
                "topkCosSimValues": [
                    1,
                    0.4922,
                    0.4906,
                    0.487,
                    0.4813,
                    0.4703,
                    0.4527,
                    0.4514,
                    0.4431,
                    0.4417,
                    0.4324,
                    0.4308,
                    0.4277,
                    0.4246,
                    0.4246,
                    0.4216,
                    0.4178,
                    0.4174,
                    0.4173,
                    0.4172,
                    0.4167,
                    0.4128,
                    0.4124,
                    0.4094,
                    0.4048
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    459
                ],
                "neuron_alignment_values": [
                    0.329,
                    0.119,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.018,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    87,
                    756,
                    459
                ],
                "correlated_neurons_pearson": [
                    0.06,
                    0.051,
                    0.041
                ],
                "correlated_neurons_l1": [
                    -0.011,
                    -0.008,
                    0.043
                ],
                "correlated_features_indices": [
                    44866,
                    44839,
                    44896
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.008,
                    0.008
                ],
                "correlated_features_l1": [
                    0.018,
                    0.01,
                    0.009
                ],
                "neg_str": [
                    "iatus",
                    "Synopsis",
                    "ORN",
                    " Podesta",
                    "Developer",
                    " \u00c2\u00ab",
                    " Hogan",
                    "advertising",
                    " Watergate",
                    "risis"
                ],
                "neg_values": [
                    -0.515,
                    -0.499,
                    -0.489,
                    -0.458,
                    -0.456,
                    -0.453,
                    -0.451,
                    -0.444,
                    -0.442,
                    -0.439
                ],
                "pos_str": [
                    " respectively",
                    " ones",
                    " alike",
                    " theirs",
                    " them",
                    " thereof",
                    " themselves",
                    " accordingly",
                    " apiece",
                    " thereto"
                ],
                "pos_values": [
                    0.972,
                    0.888,
                    0.882,
                    0.838,
                    0.754,
                    0.746,
                    0.739,
                    0.715,
                    0.709,
                    0.687
                ],
                "frac_nonzero": 0.00517,
                "freq_hist_data_bar_heights": [
                    2405,
                    1975,
                    1700,
                    1509,
                    1316,
                    1106,
                    939,
                    798,
                    671,
                    624,
                    506,
                    451,
                    366,
                    304,
                    243,
                    227,
                    195,
                    163,
                    121,
                    103,
                    81,
                    80,
                    64,
                    50,
                    52,
                    35,
                    28,
                    32,
                    21,
                    18,
                    11,
                    8,
                    13,
                    7,
                    3,
                    2,
                    5,
                    7,
                    2,
                    6,
                    1,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.077,
                    0.23,
                    0.384,
                    0.537,
                    0.691,
                    0.844,
                    0.998,
                    1.151,
                    1.305,
                    1.458,
                    1.612,
                    1.765,
                    1.919,
                    2.072,
                    2.226,
                    2.38,
                    2.533,
                    2.687,
                    2.84,
                    2.994,
                    3.147,
                    3.301,
                    3.454,
                    3.608,
                    3.761,
                    3.915,
                    4.068,
                    4.222,
                    4.375,
                    4.529,
                    4.682,
                    4.836,
                    4.989,
                    5.143,
                    5.296,
                    5.45,
                    5.603,
                    5.757,
                    5.91,
                    6.064,
                    6.217,
                    6.371,
                    6.524,
                    6.678,
                    6.831,
                    6.985,
                    7.138,
                    7.292,
                    7.445,
                    7.599
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    2,
                    12,
                    17,
                    52,
                    95,
                    174,
                    391,
                    619,
                    938,
                    1365,
                    2073,
                    2699,
                    3369,
                    3945,
                    4358,
                    4611,
                    4505,
                    4074,
                    3605,
                    3214,
                    2579,
                    2060,
                    1586,
                    1243,
                    876,
                    627,
                    425,
                    276,
                    167,
                    112,
                    62,
                    40,
                    29,
                    16,
                    11,
                    2,
                    5,
                    4,
                    3,
                    4,
                    2,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.5,
                    -0.47,
                    -0.441,
                    -0.411,
                    -0.381,
                    -0.351,
                    -0.322,
                    -0.292,
                    -0.262,
                    -0.232,
                    -0.203,
                    -0.173,
                    -0.143,
                    -0.114,
                    -0.084,
                    -0.054,
                    -0.024,
                    0.005,
                    0.035,
                    0.065,
                    0.095,
                    0.124,
                    0.154,
                    0.184,
                    0.214,
                    0.243,
                    0.273,
                    0.303,
                    0.332,
                    0.362,
                    0.392,
                    0.422,
                    0.451,
                    0.481,
                    0.511,
                    0.541,
                    0.57,
                    0.6,
                    0.63,
                    0.659,
                    0.689,
                    0.719,
                    0.749,
                    0.778,
                    0.808,
                    0.838,
                    0.868,
                    0.897,
                    0.927,
                    0.957
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to social interaction and collaboration",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk7056mh1q4i6669lvr5lop",
                        "tokens": [
                            " your",
                            " Hub",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " enabled",
                            ",",
                            " players",
                            " will",
                            " have",
                            " the",
                            " ability",
                            " to",
                            " apply",
                            " to",
                            " join",
                            " your",
                            " Hub",
                            " with",
                            " the",
                            " requirements",
                            " you",
                            " set",
                            " out",
                            " to",
                            " have",
                            " in",
                            " free",
                            "-",
                            "text",
                            " form",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " an",
                            " application",
                            " is",
                            " submitted",
                            ",",
                            " a",
                            " hub",
                            " owner",
                            " or",
                            " admin",
                            " can",
                            " review",
                            " it",
                            " and",
                            " choose",
                            " if",
                            " a",
                            " player",
                            " should",
                            " be",
                            " allowed",
                            " in",
                            " to",
                            " the",
                            " Hub",
                            " or",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "Match",
                            " Management",
                            "\n",
                            "\n",
                            "Starting",
                            " this",
                            " week",
                            " we",
                            " are",
                            " introducing",
                            " our",
                            " admin",
                            " tool",
                            " into",
                            " the",
                            " hubs",
                            " admin",
                            " system",
                            ".",
                            " This",
                            " means",
                            " that",
                            " i",
                            ")",
                            " hub",
                            " owners",
                            " can",
                            " now",
                            " give",
                            " permissions",
                            " to",
                            " manage",
                            " live",
                            " and",
                            " old",
                            " matches",
                            " to",
                            " any",
                            " role",
                            " within",
                            " the",
                            " hub",
                            " and",
                            " ii",
                            ")",
                            " users",
                            " in",
                            " the",
                            " hub",
                            " can",
                            " have",
                            " a",
                            " direct",
                            " line",
                            " of",
                            " contact",
                            " to",
                            " the",
                            " hub",
                            "\u00e2\u0122",
                            "\u013b"
                        ],
                        "dataIndex": null,
                        "index": "44916",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.676,
                        "maxValueTokenIndex": 111,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.092,
                            0.415,
                            0,
                            0,
                            0.091,
                            0.05,
                            4.829,
                            7.676,
                            4.349,
                            3.885,
                            2.488,
                            4.36,
                            3.454,
                            1.863,
                            1.333,
                            0,
                            0,
                            0.292,
                            2.194,
                            0.984,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:19:10.591Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 7.676,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk7056oh1qpi666dez17rkd",
                        "tokens": [
                            " your",
                            " Hub",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " enabled",
                            ",",
                            " players",
                            " will",
                            " have",
                            " the",
                            " ability",
                            " to",
                            " apply",
                            " to",
                            " join",
                            " your",
                            " Hub",
                            " with",
                            " the",
                            " requirements",
                            " you",
                            " set",
                            " out",
                            " to",
                            " have",
                            " in",
                            " free",
                            "-",
                            "text",
                            " form",
                            ".",
                            "\n",
                            "\n",
                            "Once",
                            " an",
                            " application",
                            " is",
                            " submitted",
                            ",",
                            " a",
                            " hub",
                            " owner",
                            " or",
                            " admin",
                            " can",
                            " review",
                            " it",
                            " and",
                            " choose",
                            " if",
                            " a",
                            " player",
                            " should",
                            " be",
                            " allowed",
                            " in",
                            " to",
                            " the",
                            " Hub",
                            " or",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "Match",
                            " Management",
                            "\n",
                            "\n",
                            "Starting",
                            " this",
                            " week",
                            " we",
                            " are",
                            " introducing",
                            " our",
                            " admin",
                            " tool",
                            " into",
                            " the",
                            " hubs",
                            " admin",
                            " system",
                            ".",
                            " This",
                            " means",
                            " that",
                            " i",
                            ")",
                            " hub",
                            " owners",
                            " can",
                            " now",
                            " give",
                            " permissions",
                            " to",
                            " manage",
                            " live",
                            " and",
                            " old",
                            " matches",
                            " to",
                            " any",
                            " role",
                            " within",
                            " the",
                            " hub",
                            " and",
                            " ii",
                            ")",
                            " users",
                            " in",
                            " the",
                            " hub",
                            " can",
                            " have",
                            " a",
                            " direct",
                            " line",
                            " of",
                            " contact",
                            " to",
                            " the",
                            " hub",
                            "\u00e2\u0122",
                            "\u013b"
                        ],
                        "dataIndex": null,
                        "index": "44916",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.676,
                        "maxValueTokenIndex": 111,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.092,
                            0.415,
                            0,
                            0,
                            0.091,
                            0.05,
                            4.829,
                            7.676,
                            4.349,
                            3.885,
                            2.488,
                            4.36,
                            3.454,
                            1.863,
                            1.333,
                            0,
                            0,
                            0.292,
                            2.194,
                            0.984,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:19:10.591Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 6.141,
                        "binMax": 7.676,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk7056mh1q5i6666vqxdz8j",
                        "tokens": [
                            "ch",
                            " in",
                            " November",
                            " 2011",
                            " and",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " just",
                            " finished",
                            " shooting",
                            " Avengers",
                            ".",
                            " I",
                            " was",
                            " doing",
                            " press",
                            " for",
                            " War",
                            " Horse",
                            ",",
                            " and",
                            " was",
                            " about",
                            " to",
                            " start",
                            " The",
                            " Hollow",
                            " Crown",
                            " for",
                            " the",
                            " BBC",
                            " and",
                            " PBS",
                            ".",
                            " In",
                            " this",
                            " swirl",
                            " of",
                            " superheroes",
                            " and",
                            " soldiers",
                            " and",
                            " Shakespeare",
                            ",",
                            " here",
                            " was",
                            " one",
                            " of",
                            " the",
                            " great",
                            " American",
                            " indie",
                            " a",
                            "ute",
                            "urs",
                            ",",
                            " and",
                            " we",
                            " sat",
                            ",",
                            " and",
                            " he",
                            " pitched",
                            " it",
                            " to",
                            " me",
                            ".",
                            " He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "This",
                            " is",
                            " a",
                            " love",
                            " story",
                            " about",
                            " two",
                            " old",
                            " souls",
                            " who",
                            " are",
                            " refined",
                            ",",
                            " sophisticated",
                            ",",
                            " delicate",
                            ",",
                            " and",
                            " in",
                            " danger",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " very",
                            " poetic",
                            ",",
                            " and",
                            " it",
                            " will",
                            " be",
                            " you",
                            " and",
                            " T",
                            "ilda",
                            " Sw",
                            "inton",
                            ",",
                            " and",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " a",
                            " musician",
                            " and",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " bo"
                        ],
                        "dataIndex": null,
                        "index": "44916",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.835,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.562,
                            2.355,
                            6.835,
                            0,
                            0,
                            5.157,
                            3.565,
                            1.774,
                            0,
                            1.076,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:19:10.591Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 7.676,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "10588",
            "description": "mentions of peer review",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.452305945616607,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "10588",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:30:28.406Z",
                "maxActApprox": 71.508,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    10588,
                    9804,
                    3439,
                    663,
                    4281,
                    6386,
                    5066,
                    12030,
                    414,
                    5150,
                    6205,
                    10051,
                    7723,
                    11837,
                    9505,
                    674,
                    8598,
                    11859,
                    7284,
                    12160,
                    7296,
                    11929,
                    10633,
                    2008,
                    5367
                ],
                "topkCosSimValues": [
                    1,
                    0.3447,
                    0.3344,
                    0.3195,
                    0.3158,
                    0.2995,
                    0.2791,
                    0.2783,
                    0.2779,
                    0.2658,
                    0.2624,
                    0.2545,
                    0.2532,
                    0.2521,
                    0.2515,
                    0.2442,
                    0.244,
                    0.2434,
                    0.241,
                    0.2383,
                    0.2354,
                    0.235,
                    0.2337,
                    0.2329,
                    0.2324
                ],
                "neuron_alignment_indices": [
                    420,
                    285,
                    323
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.111,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    285,
                    555,
                    125
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.013,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.013
                ],
                "correlated_features_indices": [
                    10506,
                    10568,
                    10520
                ],
                "correlated_features_pearson": [
                    0.018,
                    0.006,
                    0.005
                ],
                "correlated_features_l1": [
                    0.018,
                    0.007,
                    0.005
                ],
                "neg_str": [
                    "obiles",
                    " ABE",
                    "mes",
                    "enegger",
                    " Liberties",
                    " Kodi",
                    "\u00c4\u0141",
                    "RANT",
                    "aurus",
                    " Maiden"
                ],
                "neg_values": [
                    -0.761,
                    -0.736,
                    -0.721,
                    -0.718,
                    -0.714,
                    -0.648,
                    -0.646,
                    -0.644,
                    -0.641,
                    -0.636
                ],
                "pos_str": [
                    "reviewed",
                    "Reviewed",
                    " peer",
                    " reviewed",
                    "peer",
                    "wise",
                    "review",
                    "flix",
                    "iless",
                    "hood"
                ],
                "pos_values": [
                    0.977,
                    0.94,
                    0.935,
                    0.888,
                    0.874,
                    0.806,
                    0.751,
                    0.726,
                    0.716,
                    0.713
                ],
                "frac_nonzero": 0.00077,
                "freq_hist_data_bar_heights": [
                    1273,
                    544,
                    264,
                    157,
                    81,
                    20,
                    12,
                    7,
                    5,
                    4,
                    0,
                    5,
                    4,
                    8,
                    5,
                    3,
                    2,
                    1,
                    0,
                    2,
                    4,
                    3,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    2,
                    0,
                    1,
                    0,
                    1,
                    3,
                    3,
                    3,
                    3,
                    3,
                    1,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.715,
                    2.145,
                    3.576,
                    5.006,
                    6.436,
                    7.866,
                    9.296,
                    10.726,
                    12.156,
                    13.587,
                    15.017,
                    16.447,
                    17.877,
                    19.307,
                    20.737,
                    22.168,
                    23.598,
                    25.028,
                    26.458,
                    27.888,
                    29.318,
                    30.748,
                    32.179,
                    33.609,
                    35.039,
                    36.469,
                    37.899,
                    39.329,
                    40.76,
                    42.19,
                    43.62,
                    45.05,
                    46.48,
                    47.91,
                    49.34,
                    50.771,
                    52.201,
                    53.631,
                    55.061,
                    56.491,
                    57.921,
                    59.352,
                    60.782,
                    62.212,
                    63.642,
                    65.072,
                    66.502,
                    67.932,
                    69.363,
                    70.793
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    0,
                    6,
                    12,
                    17,
                    27,
                    48,
                    94,
                    137,
                    250,
                    373,
                    581,
                    841,
                    1117,
                    1700,
                    2185,
                    2768,
                    3255,
                    3823,
                    4028,
                    4297,
                    4256,
                    4189,
                    3732,
                    3084,
                    2614,
                    2088,
                    1496,
                    1050,
                    785,
                    483,
                    333,
                    223,
                    150,
                    76,
                    51,
                    33,
                    20,
                    8,
                    4,
                    7,
                    4,
                    1,
                    0,
                    1,
                    0,
                    2,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.743,
                    -0.709,
                    -0.674,
                    -0.639,
                    -0.604,
                    -0.57,
                    -0.535,
                    -0.5,
                    -0.465,
                    -0.431,
                    -0.396,
                    -0.361,
                    -0.326,
                    -0.292,
                    -0.257,
                    -0.222,
                    -0.187,
                    -0.153,
                    -0.118,
                    -0.083,
                    -0.048,
                    -0.014,
                    0.021,
                    0.056,
                    0.091,
                    0.126,
                    0.16,
                    0.195,
                    0.23,
                    0.265,
                    0.299,
                    0.334,
                    0.369,
                    0.404,
                    0.438,
                    0.473,
                    0.508,
                    0.543,
                    0.577,
                    0.612,
                    0.647,
                    0.682,
                    0.716,
                    0.751,
                    0.786,
                    0.821,
                    0.855,
                    0.89,
                    0.925,
                    0.96
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of peer review",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu2oak8mcui666e3idahj9",
                        "tokens": [
                            " math",
                            " was",
                            " introduced",
                            ".",
                            " Who",
                            " knows",
                            " at",
                            " this",
                            " point",
                            "?",
                            " All",
                            " we",
                            " know",
                            " is",
                            " that",
                            " one",
                            " paper",
                            " is",
                            " not",
                            " like",
                            " the",
                            " other",
                            ",",
                            " and",
                            " one",
                            " produces",
                            " a",
                            " hockey",
                            " stick",
                            " and",
                            " the",
                            " other",
                            " does",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "Some",
                            " additional",
                            " detective",
                            " work",
                            " is",
                            " sorely",
                            " needed",
                            " to",
                            " determine",
                            " why",
                            " this",
                            " discrepancy",
                            " exists",
                            " and",
                            " if",
                            " anyone",
                            " in",
                            " the",
                            " peer",
                            " review",
                            " process",
                            " asked",
                            " any",
                            " similar",
                            " questions",
                            ".",
                            "\n",
                            "\n",
                            "Advertisements",
                            "\n",
                            "\n",
                            "Share",
                            " this",
                            ":",
                            " Print",
                            "\n",
                            "\n",
                            "Email",
                            "\n",
                            "\n",
                            "Twitter",
                            "\n",
                            "\n",
                            "Facebook",
                            "\n",
                            "\n",
                            "Pinterest",
                            "\n",
                            "\n",
                            "LinkedIn",
                            "\n",
                            "\n",
                            "Reddit",
                            "<|endoftext|>",
                            "L",
                            "AS",
                            " V",
                            "EG",
                            "AS",
                            " \u2013",
                            " Motorola",
                            " launched",
                            " its",
                            " third",
                            " Android",
                            " smartphone",
                            ",",
                            " an",
                            " attractive",
                            ",",
                            " compact",
                            " device",
                            " with",
                            " some",
                            " surprising",
                            " hardware",
                            " innovations",
                            " and",
                            " a",
                            " user",
                            " interface",
                            " that",
                            " aggreg",
                            "ates",
                            " social",
                            " networking",
                            " feeds",
                            ",",
                            " e",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "10588",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.508,
                        "maxValueTokenIndex": 55,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.508,
                            9.544,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.538,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:36.615Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 71.508,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu2oam8mdii666dmwwotzt",
                        "tokens": [
                            " math",
                            " was",
                            " introduced",
                            ".",
                            " Who",
                            " knows",
                            " at",
                            " this",
                            " point",
                            "?",
                            " All",
                            " we",
                            " know",
                            " is",
                            " that",
                            " one",
                            " paper",
                            " is",
                            " not",
                            " like",
                            " the",
                            " other",
                            ",",
                            " and",
                            " one",
                            " produces",
                            " a",
                            " hockey",
                            " stick",
                            " and",
                            " the",
                            " other",
                            " does",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "Some",
                            " additional",
                            " detective",
                            " work",
                            " is",
                            " sorely",
                            " needed",
                            " to",
                            " determine",
                            " why",
                            " this",
                            " discrepancy",
                            " exists",
                            " and",
                            " if",
                            " anyone",
                            " in",
                            " the",
                            " peer",
                            " review",
                            " process",
                            " asked",
                            " any",
                            " similar",
                            " questions",
                            ".",
                            "\n",
                            "\n",
                            "Advertisements",
                            "\n",
                            "\n",
                            "Share",
                            " this",
                            ":",
                            " Print",
                            "\n",
                            "\n",
                            "Email",
                            "\n",
                            "\n",
                            "Twitter",
                            "\n",
                            "\n",
                            "Facebook",
                            "\n",
                            "\n",
                            "Pinterest",
                            "\n",
                            "\n",
                            "LinkedIn",
                            "\n",
                            "\n",
                            "Reddit",
                            "<|endoftext|>",
                            "L",
                            "AS",
                            " V",
                            "EG",
                            "AS",
                            " \u2013",
                            " Motorola",
                            " launched",
                            " its",
                            " third",
                            " Android",
                            " smartphone",
                            ",",
                            " an",
                            " attractive",
                            ",",
                            " compact",
                            " device",
                            " with",
                            " some",
                            " surprising",
                            " hardware",
                            " innovations",
                            " and",
                            " a",
                            " user",
                            " interface",
                            " that",
                            " aggreg",
                            "ates",
                            " social",
                            " networking",
                            " feeds",
                            ",",
                            " e",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "10588",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.508,
                        "maxValueTokenIndex": 55,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.508,
                            9.544,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.538,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:36.615Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 57.206,
                        "binMax": 71.508,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu2oak8mcvi666mde1u7fm",
                        "tokens": [
                            " introduced",
                            " later",
                            ".",
                            "R",
                            "app",
                            "op",
                            "ort",
                            " says",
                            " that",
                            " the",
                            " \"",
                            "d",
                            "ud",
                            "\"",
                            " epidem",
                            "ics",
                            " that",
                            " we",
                            " are",
                            " frightened",
                            " with",
                            " every",
                            " few",
                            " years",
                            " are",
                            " nothing",
                            " more",
                            " than",
                            " the",
                            " medical",
                            " establishment",
                            "'s",
                            " brain",
                            "washing",
                            " efforts",
                            " to",
                            " convince",
                            " us",
                            " that",
                            " we",
                            " need",
                            " constant",
                            " medical",
                            " care",
                            " -",
                            " and",
                            " that",
                            " there",
                            " is",
                            " no",
                            " such",
                            " thing",
                            " as",
                            " natural",
                            " health",
                            ".",
                            "He",
                            " points",
                            " out",
                            " the",
                            " lack",
                            " of",
                            " research",
                            " conducted",
                            " on",
                            " healthy",
                            " children",
                            ":",
                            " \"",
                            "How",
                            " many",
                            " studies",
                            " in",
                            " peer",
                            " reviewed",
                            " journals",
                            " examine",
                            " large",
                            " groups",
                            " of",
                            " healthy",
                            " un",
                            "vacc",
                            "inated",
                            " children",
                            "?\"",
                            " he",
                            " asks",
                            ".",
                            "In",
                            " fact",
                            ",",
                            " there",
                            " have",
                            " been",
                            " studies",
                            " suggesting",
                            " that",
                            " children",
                            " who",
                            " grow",
                            " up",
                            " on",
                            " farms",
                            ",",
                            " for",
                            " example",
                            ",",
                            " have",
                            " as",
                            "im",
                            "ply",
                            " because",
                            " they",
                            " were",
                            " exposed",
                            " to",
                            " more",
                            " ger",
                            "ms",
                            " at",
                            " an",
                            " early",
                            " age",
                            ",",
                            " therefore",
                            " strengthening"
                        ],
                        "dataIndex": null,
                        "index": "10588",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.324,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.324,
                            13.043,
                            6.223,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:30:36.615Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 71.508,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "7493",
            "description": "references to mentorship and mentorship relationships",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.45154958963394165,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "7493",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:11:22.009Z",
                "maxActApprox": 46.844,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7493,
                    18303,
                    46531,
                    21978,
                    38347,
                    10248,
                    47879,
                    19085,
                    11033,
                    47724,
                    45441,
                    31730,
                    34302,
                    48558,
                    2677,
                    10975,
                    13649,
                    44042,
                    11474,
                    18342,
                    20235,
                    32839,
                    29574,
                    6722,
                    13522
                ],
                "topkCosSimValues": [
                    1,
                    0.4887,
                    0.4738,
                    0.4641,
                    0.4519,
                    0.4339,
                    0.4225,
                    0.4219,
                    0.4203,
                    0.4163,
                    0.4018,
                    0.394,
                    0.3835,
                    0.3831,
                    0.375,
                    0.3738,
                    0.3707,
                    0.3659,
                    0.3626,
                    0.3603,
                    0.3586,
                    0.3575,
                    0.3553,
                    0.3549,
                    0.351
                ],
                "neuron_alignment_indices": [
                    343,
                    575,
                    415
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.107,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    575,
                    415,
                    701
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.009,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.009,
                    0.008
                ],
                "correlated_features_indices": [
                    7554,
                    7453,
                    7468
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    "rencies",
                    "jriwal",
                    "itars",
                    "inyl",
                    "cision",
                    "tarians",
                    "sid",
                    "\u00d4",
                    "ldon",
                    "fixes"
                ],
                "neg_values": [
                    -0.753,
                    -0.705,
                    -0.7,
                    -0.67,
                    -0.595,
                    -0.585,
                    -0.585,
                    -0.584,
                    -0.583,
                    -0.577
                ],
                "pos_str": [
                    " mentor",
                    " mentors",
                    "hesis",
                    " ment",
                    "heses",
                    " tutor",
                    " Ment",
                    " tut",
                    "hip",
                    " counselor"
                ],
                "pos_values": [
                    1.259,
                    1.081,
                    0.977,
                    0.948,
                    0.917,
                    0.832,
                    0.8,
                    0.782,
                    0.775,
                    0.765
                ],
                "frac_nonzero": 0.00015,
                "freq_hist_data_bar_heights": [
                    157,
                    85,
                    49,
                    51,
                    31,
                    18,
                    13,
                    8,
                    2,
                    3,
                    6,
                    6,
                    1,
                    2,
                    4,
                    0,
                    3,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    4,
                    2,
                    3,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.472,
                    1.409,
                    2.346,
                    3.283,
                    4.22,
                    5.156,
                    6.093,
                    7.03,
                    7.967,
                    8.904,
                    9.84,
                    10.777,
                    11.714,
                    12.651,
                    13.588,
                    14.524,
                    15.461,
                    16.398,
                    17.335,
                    18.272,
                    19.208,
                    20.145,
                    21.082,
                    22.019,
                    22.956,
                    23.893,
                    24.829,
                    25.766,
                    26.703,
                    27.64,
                    28.577,
                    29.513,
                    30.45,
                    31.387,
                    32.324,
                    33.261,
                    34.197,
                    35.134,
                    36.071,
                    37.008,
                    37.945,
                    38.881,
                    39.818,
                    40.755,
                    41.692,
                    42.629,
                    43.565,
                    44.502,
                    45.439,
                    46.376
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    1,
                    1,
                    15,
                    31,
                    52,
                    119,
                    187,
                    337,
                    594,
                    988,
                    1549,
                    2133,
                    2969,
                    3711,
                    4303,
                    4863,
                    5096,
                    4866,
                    4505,
                    3725,
                    2926,
                    2364,
                    1748,
                    1169,
                    720,
                    497,
                    319,
                    179,
                    128,
                    64,
                    31,
                    28,
                    11,
                    9,
                    4,
                    4,
                    2,
                    1,
                    0,
                    1,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.733,
                    -0.693,
                    -0.653,
                    -0.613,
                    -0.572,
                    -0.532,
                    -0.492,
                    -0.452,
                    -0.411,
                    -0.371,
                    -0.331,
                    -0.291,
                    -0.25,
                    -0.21,
                    -0.17,
                    -0.129,
                    -0.089,
                    -0.049,
                    -0.009,
                    0.032,
                    0.072,
                    0.112,
                    0.152,
                    0.193,
                    0.233,
                    0.273,
                    0.313,
                    0.354,
                    0.394,
                    0.434,
                    0.474,
                    0.515,
                    0.555,
                    0.595,
                    0.635,
                    0.676,
                    0.716,
                    0.756,
                    0.796,
                    0.837,
                    0.877,
                    0.917,
                    0.957,
                    0.998,
                    1.038,
                    1.078,
                    1.118,
                    1.159,
                    1.199,
                    1.239
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to mentorship and mentorship relationships",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4l14jik20i66677m29uly",
                        "tokens": [
                            " two",
                            " stayed",
                            " in",
                            " contact",
                            " through",
                            " social",
                            " media",
                            " and",
                            " texting",
                            ",",
                            " police",
                            " say",
                            ",",
                            " and",
                            " began",
                            " sending",
                            " \"",
                            "in",
                            "appropriate",
                            "\"",
                            " and",
                            " \"",
                            "dis",
                            "g",
                            "usting",
                            "\"",
                            " messages",
                            ".",
                            " The",
                            " boy",
                            " told",
                            " investigators",
                            " the",
                            " explicit",
                            " conversations",
                            " confused",
                            " him",
                            " but",
                            " that",
                            " he",
                            " looked",
                            " up",
                            " to",
                            " Cook",
                            " as",
                            " a",
                            " mentor",
                            ".",
                            "\n",
                            "\n",
                            "Shortly",
                            " after",
                            " the",
                            " boy",
                            " turned",
                            " 16",
                            ",",
                            " Cook",
                            " allegedly",
                            " met",
                            " with",
                            " him",
                            " at",
                            " the",
                            " LDS",
                            " temple",
                            " in",
                            " B",
                            "ount",
                            "iful",
                            " to",
                            " \"",
                            "catch",
                            " up",
                            "\"",
                            " and",
                            " then",
                            " went",
                            " to",
                            " a",
                            " nearby",
                            " park",
                            ".",
                            "\n",
                            "\n",
                            "\"(",
                            "Cook",
                            ")",
                            " made",
                            " advances",
                            " toward",
                            " the",
                            " minor",
                            " male",
                            " in",
                            " the",
                            " minor",
                            " male",
                            "'s",
                            " car",
                            ",\"",
                            " the",
                            " charges",
                            " state",
                            ".",
                            " \"",
                            "The",
                            " minor",
                            " male",
                            " stated",
                            " to",
                            " law",
                            " enforcement",
                            " that",
                            " the",
                            " defendant",
                            " persuaded",
                            " him",
                            " that",
                            " the",
                            " contact",
                            " they",
                            " had",
                            " was",
                            " acceptable",
                            " and",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "7493",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.844,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.844,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:11:26.297Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.844,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4l14lik2ki66605ws1bv8",
                        "tokens": [
                            " two",
                            " stayed",
                            " in",
                            " contact",
                            " through",
                            " social",
                            " media",
                            " and",
                            " texting",
                            ",",
                            " police",
                            " say",
                            ",",
                            " and",
                            " began",
                            " sending",
                            " \"",
                            "in",
                            "appropriate",
                            "\"",
                            " and",
                            " \"",
                            "dis",
                            "g",
                            "usting",
                            "\"",
                            " messages",
                            ".",
                            " The",
                            " boy",
                            " told",
                            " investigators",
                            " the",
                            " explicit",
                            " conversations",
                            " confused",
                            " him",
                            " but",
                            " that",
                            " he",
                            " looked",
                            " up",
                            " to",
                            " Cook",
                            " as",
                            " a",
                            " mentor",
                            ".",
                            "\n",
                            "\n",
                            "Shortly",
                            " after",
                            " the",
                            " boy",
                            " turned",
                            " 16",
                            ",",
                            " Cook",
                            " allegedly",
                            " met",
                            " with",
                            " him",
                            " at",
                            " the",
                            " LDS",
                            " temple",
                            " in",
                            " B",
                            "ount",
                            "iful",
                            " to",
                            " \"",
                            "catch",
                            " up",
                            "\"",
                            " and",
                            " then",
                            " went",
                            " to",
                            " a",
                            " nearby",
                            " park",
                            ".",
                            "\n",
                            "\n",
                            "\"(",
                            "Cook",
                            ")",
                            " made",
                            " advances",
                            " toward",
                            " the",
                            " minor",
                            " male",
                            " in",
                            " the",
                            " minor",
                            " male",
                            "'s",
                            " car",
                            ",\"",
                            " the",
                            " charges",
                            " state",
                            ".",
                            " \"",
                            "The",
                            " minor",
                            " male",
                            " stated",
                            " to",
                            " law",
                            " enforcement",
                            " that",
                            " the",
                            " defendant",
                            " persuaded",
                            " him",
                            " that",
                            " the",
                            " contact",
                            " they",
                            " had",
                            " was",
                            " acceptable",
                            " and",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "7493",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.844,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.844,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:11:26.297Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 37.475,
                        "binMax": 46.844,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4l14jik21i666gj2eg2m4",
                        "tokens": [
                            " Texas",
                            " coaches",
                            ":",
                            "\n",
                            "\n",
                            "Story",
                            " continues",
                            "\n",
                            "\n",
                            "\"",
                            "Today",
                            " is",
                            " a",
                            " very",
                            " sad",
                            " day",
                            ".",
                            " I",
                            " lost",
                            " a",
                            " wonderful",
                            " friend",
                            ",",
                            " a",
                            " mentor",
                            ",",
                            " a",
                            " confid",
                            "ant",
                            " and",
                            " my",
                            " hero",
                            ".",
                            " College",
                            " football",
                            " lost",
                            " maybe",
                            " its",
                            " best",
                            " ever",
                            " and",
                            " the",
                            " world",
                            " lost",
                            " a",
                            " great",
                            " man",
                            ".",
                            " I",
                            " can",
                            " hardly",
                            " put",
                            " in",
                            " words",
                            " how",
                            " much",
                            " Coach",
                            " Royal",
                            " means",
                            " to",
                            " me",
                            " and",
                            " all",
                            " that",
                            " he",
                            " has",
                            " done",
                            " for",
                            " me",
                            " and",
                            " my",
                            " family",
                            ".",
                            " I",
                            " wouldn",
                            "'t",
                            " even",
                            " be",
                            " at",
                            " Texas",
                            " without",
                            " Coach",
                            ".",
                            " His",
                            " counsel",
                            " and",
                            " friendship",
                            " meant",
                            " a",
                            " lot",
                            " to",
                            " me",
                            " before",
                            " I",
                            " came",
                            " to",
                            " Texas",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " been",
                            " my",
                            " guiding",
                            " light",
                            " for",
                            " my",
                            " 15",
                            " years",
                            " here",
                            ".",
                            " \"",
                            "Coach",
                            " gave",
                            " so",
                            " much",
                            " more",
                            " to",
                            " the",
                            " State",
                            " of",
                            " Texas",
                            " and",
                            " college",
                            " football",
                            " than",
                            " he"
                        ],
                        "dataIndex": null,
                        "index": "7493",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.544,
                        "maxValueTokenIndex": 24,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.544,
                            0.57,
                            0.322,
                            2.228,
                            10.05,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.382,
                            0,
                            0.709,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.927,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:11:26.297Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.844,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67437",
            "description": " actions associated with sharing, learning, and creating",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4506492018699646,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67437",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:55:57.104Z",
                "maxActApprox": 16.775,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67437,
                    20344,
                    82960,
                    51723,
                    201,
                    30390,
                    66426,
                    34190,
                    2922,
                    72289,
                    53029,
                    66794,
                    94072,
                    32648,
                    3113,
                    10428,
                    53797,
                    91010,
                    41901,
                    93241,
                    16621,
                    65571,
                    91347,
                    46610,
                    68613
                ],
                "topkCosSimValues": [
                    1,
                    0.4554,
                    0.4545,
                    0.4386,
                    0.4101,
                    0.3909,
                    0.3885,
                    0.3818,
                    0.378,
                    0.3769,
                    0.376,
                    0.3759,
                    0.3638,
                    0.3622,
                    0.347,
                    0.3453,
                    0.3425,
                    0.3371,
                    0.3369,
                    0.3363,
                    0.3321,
                    0.3317,
                    0.3299,
                    0.3297,
                    0.3282
                ],
                "neuron_alignment_indices": [
                    602,
                    500,
                    570
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.093,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    604,
                    738,
                    25
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.026,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.021
                ],
                "correlated_features_indices": [
                    67317,
                    67332,
                    67335
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    " mishand",
                    " Historically",
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "COMPLE",
                    "currently",
                    "urnal",
                    "abama",
                    "\u0123\u0138",
                    "Eastern",
                    "ablished"
                ],
                "neg_values": [
                    -0.623,
                    -0.622,
                    -0.592,
                    -0.588,
                    -0.582,
                    -0.579,
                    -0.576,
                    -0.575,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    " yourself",
                    " yourselves",
                    " yours",
                    "anooga",
                    " your",
                    " Yourself",
                    " ya",
                    "!'",
                    " whatever",
                    "oice"
                ],
                "pos_values": [
                    1.079,
                    0.921,
                    0.898,
                    0.798,
                    0.775,
                    0.752,
                    0.751,
                    0.742,
                    0.723,
                    0.721
                ],
                "frac_nonzero": 0.00094,
                "freq_hist_data_bar_heights": [
                    628,
                    432,
                    367,
                    300,
                    227,
                    182,
                    123,
                    110,
                    97,
                    78,
                    71,
                    50,
                    42,
                    39,
                    22,
                    29,
                    23,
                    19,
                    18,
                    13,
                    10,
                    10,
                    8,
                    7,
                    2,
                    7,
                    3,
                    4,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.168,
                    0.504,
                    0.839,
                    1.175,
                    1.51,
                    1.846,
                    2.181,
                    2.517,
                    2.852,
                    3.188,
                    3.523,
                    3.859,
                    4.194,
                    4.53,
                    4.865,
                    5.201,
                    5.536,
                    5.872,
                    6.207,
                    6.542,
                    6.878,
                    7.213,
                    7.549,
                    7.884,
                    8.22,
                    8.555,
                    8.891,
                    9.226,
                    9.562,
                    9.897,
                    10.233,
                    10.568,
                    10.904,
                    11.239,
                    11.575,
                    11.91,
                    12.246,
                    12.581,
                    12.917,
                    13.252,
                    13.588,
                    13.923,
                    14.259,
                    14.594,
                    14.93,
                    15.265,
                    15.6,
                    15.936,
                    16.271,
                    16.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    8,
                    19,
                    18,
                    41,
                    87,
                    156,
                    290,
                    426,
                    647,
                    1098,
                    1493,
                    2095,
                    2523,
                    3182,
                    3691,
                    4000,
                    4423,
                    4377,
                    4098,
                    3841,
                    3321,
                    2787,
                    2187,
                    1700,
                    1204,
                    826,
                    598,
                    374,
                    270,
                    165,
                    123,
                    66,
                    43,
                    23,
                    20,
                    10,
                    5,
                    6,
                    5,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.606,
                    -0.572,
                    -0.537,
                    -0.503,
                    -0.469,
                    -0.435,
                    -0.401,
                    -0.367,
                    -0.333,
                    -0.299,
                    -0.265,
                    -0.231,
                    -0.197,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.061,
                    -0.027,
                    0.007,
                    0.041,
                    0.075,
                    0.109,
                    0.143,
                    0.177,
                    0.211,
                    0.245,
                    0.28,
                    0.314,
                    0.348,
                    0.382,
                    0.416,
                    0.45,
                    0.484,
                    0.518,
                    0.552,
                    0.586,
                    0.62,
                    0.654,
                    0.688,
                    0.722,
                    0.756,
                    0.79,
                    0.824,
                    0.858,
                    0.892,
                    0.926,
                    0.96,
                    0.994,
                    1.028,
                    1.062
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions associated with sharing, learning, and creating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "actions related to sharing and engaging with content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi0kzjqfos10ex9oe2q0k7",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzjqfoy10exm0wixfaq",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzlqfpe10exe96je5qi",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 13.42,
                        "binMax": 16.775,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "11368",
            "description": " references to academic peer review processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4483534066887749,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "11368",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:18:19.937Z",
                "maxActApprox": 67.216,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11368,
                    48172,
                    41217,
                    24211,
                    35080,
                    43081,
                    13971,
                    46564,
                    27672,
                    7805,
                    48433,
                    40578,
                    9437,
                    31222,
                    48277,
                    41371,
                    34475,
                    40870,
                    29872,
                    26896,
                    574,
                    40543,
                    18848,
                    13694,
                    26743
                ],
                "topkCosSimValues": [
                    1,
                    0.5655,
                    0.5445,
                    0.5247,
                    0.5081,
                    0.5074,
                    0.5002,
                    0.4926,
                    0.4911,
                    0.4843,
                    0.4778,
                    0.474,
                    0.4592,
                    0.4572,
                    0.4568,
                    0.4512,
                    0.4494,
                    0.4459,
                    0.4457,
                    0.442,
                    0.4417,
                    0.4399,
                    0.4393,
                    0.437,
                    0.4343
                ],
                "neuron_alignment_indices": [
                    314,
                    120,
                    525
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.097,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    120,
                    124,
                    754
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.009,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.009,
                    0.008
                ],
                "correlated_features_indices": [
                    11298,
                    11356,
                    11332
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " Bucket",
                    " Salvation",
                    " Klux",
                    " Territory",
                    " Desert",
                    " Hyde",
                    " Territories",
                    " Helic",
                    " Syl",
                    " EntityItem"
                ],
                "neg_values": [
                    -0.707,
                    -0.696,
                    -0.688,
                    -0.684,
                    -0.669,
                    -0.665,
                    -0.664,
                    -0.659,
                    -0.653,
                    -0.644
                ],
                "pos_str": [
                    "reviewed",
                    "Reviewed",
                    "review",
                    "sized",
                    "ordering",
                    "based",
                    "peer",
                    "favorite",
                    "forward",
                    "advertisement"
                ],
                "pos_values": [
                    1.615,
                    1.287,
                    1.213,
                    0.989,
                    0.988,
                    0.98,
                    0.965,
                    0.956,
                    0.943,
                    0.939
                ],
                "frac_nonzero": 6e-05,
                "freq_hist_data_bar_heights": [
                    84,
                    36,
                    22,
                    11,
                    11,
                    11,
                    4,
                    4,
                    1,
                    1,
                    1,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    3,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.68,
                    2.025,
                    3.369,
                    4.713,
                    6.057,
                    7.401,
                    8.745,
                    10.09,
                    11.434,
                    12.778,
                    14.122,
                    15.466,
                    16.81,
                    18.155,
                    19.499,
                    20.843,
                    22.187,
                    23.531,
                    24.875,
                    26.22,
                    27.564,
                    28.908,
                    30.252,
                    31.596,
                    32.94,
                    34.284,
                    35.629,
                    36.973,
                    38.317,
                    39.661,
                    41.005,
                    42.349,
                    43.694,
                    45.038,
                    46.382,
                    47.726,
                    49.07,
                    50.414,
                    51.759,
                    53.103,
                    54.447,
                    55.791,
                    57.135,
                    58.479,
                    59.824,
                    61.168,
                    62.512,
                    63.856,
                    65.2,
                    66.544
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    12,
                    25,
                    52,
                    129,
                    285,
                    548,
                    972,
                    1564,
                    2369,
                    3134,
                    3880,
                    4387,
                    4618,
                    4606,
                    4118,
                    3625,
                    3187,
                    2867,
                    2166,
                    1812,
                    1376,
                    1129,
                    878,
                    650,
                    520,
                    422,
                    308,
                    198,
                    148,
                    110,
                    64,
                    43,
                    22,
                    12,
                    7,
                    4,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.637,
                    -0.591,
                    -0.545,
                    -0.498,
                    -0.452,
                    -0.405,
                    -0.359,
                    -0.312,
                    -0.266,
                    -0.22,
                    -0.173,
                    -0.127,
                    -0.08,
                    -0.034,
                    0.013,
                    0.059,
                    0.105,
                    0.152,
                    0.198,
                    0.245,
                    0.291,
                    0.338,
                    0.384,
                    0.431,
                    0.477,
                    0.523,
                    0.57,
                    0.616,
                    0.663,
                    0.709,
                    0.756,
                    0.802,
                    0.848,
                    0.895,
                    0.941,
                    0.988,
                    1.034,
                    1.081,
                    1.127,
                    1.174,
                    1.22,
                    1.266,
                    1.313,
                    1.359,
                    1.406,
                    1.452,
                    1.499,
                    1.545,
                    1.591
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to academic peer review processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4u22em4ydi666vdltv1en",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "11368",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.216,
                        "maxValueTokenIndex": 68,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.216,
                            0,
                            16.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:27.426Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 67.216,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4u22fm4yqi666ind0bo1y",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "11368",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.216,
                        "maxValueTokenIndex": 68,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.216,
                            0,
                            16.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:27.426Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 67.216,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4u22gm4yzi666te0lccrs",
                        "tokens": [
                            " Finance",
                            " Ministry",
                            " prepared",
                            " a",
                            " draft",
                            " on",
                            " banning",
                            " all",
                            " forms",
                            " of",
                            " money",
                            " substitutes",
                            " in",
                            " Russia",
                            " which",
                            " includes",
                            " bitcoins",
                            ".",
                            " According",
                            " to",
                            " Andre",
                            "i",
                            " Lug",
                            "ovo",
                            "i",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "In",
                            " the",
                            " beginning",
                            " of",
                            " 2016",
                            " after",
                            " a",
                            " series",
                            " of",
                            " meetings",
                            " with",
                            " the",
                            " fiscal",
                            " authorities",
                            " and",
                            " businesses",
                            ",",
                            " it",
                            " was",
                            " stated",
                            " that",
                            " in",
                            " the",
                            " future",
                            " the",
                            " Central",
                            " Bank",
                            " could",
                            " begin",
                            " to",
                            " legalize",
                            " and",
                            " regulate",
                            " certain",
                            " transactions",
                            " with",
                            " Bitcoin",
                            ",",
                            " particularly",
                            " peer",
                            "-",
                            "to",
                            "-",
                            "peer",
                            " transactions",
                            " and",
                            " settlements",
                            " with",
                            " individuals",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Russia",
                            " currently",
                            " ranks",
                            " fifth",
                            " in",
                            " the",
                            " world",
                            " with",
                            " 200",
                            ",",
                            "000",
                            " users",
                            " of",
                            " cryptocurrency",
                            " users",
                            ",",
                            " and",
                            " thus",
                            " if",
                            " the",
                            " above",
                            " proposal",
                            " is",
                            " enforced",
                            ",",
                            " it",
                            " will",
                            " provide",
                            " a",
                            " big",
                            " boost",
                            " to",
                            " virtual",
                            " currencies",
                            ".",
                            "\n",
                            "\n",
                            "Bitcoin",
                            " Could",
                            " Be",
                            " \u00e2\u0122",
                            "\u013a",
                            "Real",
                            " Money",
                            "\u00e2\u0122",
                            "\u013b",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "11368",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 67.216,
                        "maxValueTokenIndex": 68,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            67.216,
                            0,
                            16.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:27.426Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 53.773,
                        "binMax": 67.216,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "88988",
            "description": " references to educational or professional peers and social relationships",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4421674311161041,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "88988",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:19:20.799Z",
                "maxActApprox": 30.137,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    88988,
                    67890,
                    19860,
                    23900,
                    50718,
                    43241,
                    46700,
                    9870,
                    64882,
                    87355,
                    19965,
                    55919,
                    10166,
                    84880,
                    79875,
                    18946,
                    74864,
                    87134,
                    94019,
                    30963,
                    54499,
                    95550,
                    31270,
                    69803,
                    13624
                ],
                "topkCosSimValues": [
                    1,
                    0.533,
                    0.53,
                    0.5129,
                    0.5061,
                    0.503,
                    0.5005,
                    0.4936,
                    0.4862,
                    0.4643,
                    0.4613,
                    0.4589,
                    0.4568,
                    0.4538,
                    0.4373,
                    0.4332,
                    0.4265,
                    0.4165,
                    0.412,
                    0.4107,
                    0.41,
                    0.4091,
                    0.4077,
                    0.4058,
                    0.4041
                ],
                "neuron_alignment_indices": [
                    445,
                    288,
                    103
                ],
                "neuron_alignment_values": [
                    0.135,
                    0.129,
                    0.117
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    506,
                    224,
                    575
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.007,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.007,
                    0.008
                ],
                "correlated_features_indices": [
                    89054,
                    89058,
                    88936
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "ocene",
                    "iture",
                    "iciary",
                    "rosis",
                    "itures",
                    "obin",
                    "romy",
                    "intensity",
                    "idium",
                    "lyak"
                ],
                "neg_values": [
                    -0.848,
                    -0.756,
                    -0.703,
                    -0.684,
                    -0.682,
                    -0.678,
                    -0.673,
                    -0.657,
                    -0.643,
                    -0.638
                ],
                "pos_str": [
                    " classmates",
                    " classmate",
                    "essors",
                    "mates",
                    "essor",
                    "uates",
                    " Parents",
                    " students",
                    " graduation",
                    "kids"
                ],
                "pos_values": [
                    1.29,
                    1.195,
                    1.006,
                    0.927,
                    0.88,
                    0.876,
                    0.868,
                    0.854,
                    0.845,
                    0.837
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    30,
                    37,
                    20,
                    23,
                    10,
                    9,
                    6,
                    3,
                    5,
                    4,
                    0,
                    1,
                    0,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    1,
                    4,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.331,
                    0.933,
                    1.535,
                    2.137,
                    2.739,
                    3.341,
                    3.943,
                    4.546,
                    5.148,
                    5.75,
                    6.352,
                    6.954,
                    7.556,
                    8.159,
                    8.761,
                    9.363,
                    9.965,
                    10.567,
                    11.169,
                    11.771,
                    12.374,
                    12.976,
                    13.578,
                    14.18,
                    14.782,
                    15.384,
                    15.987,
                    16.589,
                    17.191,
                    17.793,
                    18.395,
                    18.997,
                    19.599,
                    20.202,
                    20.804,
                    21.406,
                    22.008,
                    22.61,
                    23.212,
                    23.814,
                    24.417,
                    25.019,
                    25.621,
                    26.223,
                    26.825,
                    27.427,
                    28.03,
                    28.632,
                    29.234,
                    29.836
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    4,
                    5,
                    12,
                    26,
                    52,
                    108,
                    154,
                    313,
                    542,
                    868,
                    1389,
                    2044,
                    2787,
                    3602,
                    4243,
                    4902,
                    5143,
                    5106,
                    4722,
                    4001,
                    3030,
                    2371,
                    1694,
                    1100,
                    764,
                    464,
                    310,
                    186,
                    102,
                    80,
                    43,
                    31,
                    21,
                    8,
                    12,
                    5,
                    4,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.827,
                    -0.784,
                    -0.741,
                    -0.699,
                    -0.656,
                    -0.613,
                    -0.57,
                    -0.528,
                    -0.485,
                    -0.442,
                    -0.399,
                    -0.357,
                    -0.314,
                    -0.271,
                    -0.228,
                    -0.186,
                    -0.143,
                    -0.1,
                    -0.057,
                    -0.014,
                    0.028,
                    0.071,
                    0.114,
                    0.157,
                    0.199,
                    0.242,
                    0.285,
                    0.328,
                    0.37,
                    0.413,
                    0.456,
                    0.499,
                    0.541,
                    0.584,
                    0.627,
                    0.67,
                    0.712,
                    0.755,
                    0.798,
                    0.841,
                    0.883,
                    0.926,
                    0.969,
                    1.012,
                    1.054,
                    1.097,
                    1.14,
                    1.183,
                    1.225,
                    1.268
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to educational or professional peers and social relationships",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to various types of classmates and relationships formed during school or work",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiul8e6r8510exq4k186gc",
                        "tokens": [
                            " in",
                            " Ireland",
                            " so",
                            " he",
                            " moved",
                            " to",
                            " the",
                            " United",
                            " Kingdom",
                            ",",
                            " working",
                            " first",
                            " in",
                            " Wales",
                            ",",
                            " then",
                            " in",
                            " London",
                            ".",
                            " There",
                            ",",
                            " he",
                            " met",
                            " two",
                            " former",
                            " classmates",
                            " from",
                            " his",
                            " medical",
                            " school",
                            " and",
                            ",",
                            " after",
                            " a",
                            " night",
                            " of",
                            " drinking",
                            " with",
                            " them",
                            ",",
                            " decided",
                            " to",
                            " join",
                            " the",
                            " British",
                            " armed",
                            " forces",
                            " as",
                            " a",
                            " medical",
                            " officer",
                            ".",
                            " Which",
                            " service",
                            " (",
                            "the",
                            " Royal",
                            " Navy",
                            " or",
                            " the",
                            " Royal",
                            " Air",
                            " Force",
                            ")",
                            " was",
                            " decided",
                            " for",
                            " him",
                            " by",
                            " a",
                            " coin",
                            " toss",
                            " made",
                            " by",
                            " a",
                            " nightclub",
                            " host",
                            "ess",
                            " in",
                            " the",
                            " early",
                            " hours",
                            " of",
                            " the",
                            " morning",
                            ".[",
                            "1",
                            "]",
                            "\n",
                            "\n",
                            "RA",
                            "F",
                            " career",
                            " [",
                            " edit",
                            " ]",
                            "\n",
                            "\n",
                            "In",
                            " 1940",
                            ",",
                            " he",
                            " was",
                            " posted",
                            " to",
                            " France",
                            " and",
                            " was",
                            " evacuated",
                            " from",
                            " Dunk",
                            "irk",
                            " where",
                            " he",
                            " attended",
                            " wounded",
                            " Allied",
                            " soldiers",
                            " while",
                            " under",
                            " fire",
                            " from",
                            " German",
                            " aircraft",
                            ".",
                            " In",
                            " September"
                        ],
                        "dataIndex": null,
                        "index": "88988",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.137,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.137,
                            0.029,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:24.503Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.137,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiul8g6r8s10ex1zcginnx",
                        "tokens": [
                            " in",
                            " Ireland",
                            " so",
                            " he",
                            " moved",
                            " to",
                            " the",
                            " United",
                            " Kingdom",
                            ",",
                            " working",
                            " first",
                            " in",
                            " Wales",
                            ",",
                            " then",
                            " in",
                            " London",
                            ".",
                            " There",
                            ",",
                            " he",
                            " met",
                            " two",
                            " former",
                            " classmates",
                            " from",
                            " his",
                            " medical",
                            " school",
                            " and",
                            ",",
                            " after",
                            " a",
                            " night",
                            " of",
                            " drinking",
                            " with",
                            " them",
                            ",",
                            " decided",
                            " to",
                            " join",
                            " the",
                            " British",
                            " armed",
                            " forces",
                            " as",
                            " a",
                            " medical",
                            " officer",
                            ".",
                            " Which",
                            " service",
                            " (",
                            "the",
                            " Royal",
                            " Navy",
                            " or",
                            " the",
                            " Royal",
                            " Air",
                            " Force",
                            ")",
                            " was",
                            " decided",
                            " for",
                            " him",
                            " by",
                            " a",
                            " coin",
                            " toss",
                            " made",
                            " by",
                            " a",
                            " nightclub",
                            " host",
                            "ess",
                            " in",
                            " the",
                            " early",
                            " hours",
                            " of",
                            " the",
                            " morning",
                            ".[",
                            "1",
                            "]",
                            "\n",
                            "\n",
                            "RA",
                            "F",
                            " career",
                            " [",
                            " edit",
                            " ]",
                            "\n",
                            "\n",
                            "In",
                            " 1940",
                            ",",
                            " he",
                            " was",
                            " posted",
                            " to",
                            " France",
                            " and",
                            " was",
                            " evacuated",
                            " from",
                            " Dunk",
                            "irk",
                            " where",
                            " he",
                            " attended",
                            " wounded",
                            " Allied",
                            " soldiers",
                            " while",
                            " under",
                            " fire",
                            " from",
                            " German",
                            " aircraft",
                            ".",
                            " In",
                            " September"
                        ],
                        "dataIndex": null,
                        "index": "88988",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.137,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.137,
                            0.029,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:24.503Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 24.11,
                        "binMax": 30.137,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiul8e6r8610ex6ohu0xmz",
                        "tokens": [
                            ".",
                            " It",
                            " was",
                            " then",
                            " that",
                            " four",
                            " of",
                            " my",
                            " classmates",
                            " and",
                            " I",
                            " had",
                            " decided",
                            " to",
                            " go",
                            " on",
                            " an",
                            " all",
                            " women",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " trip",
                            " to",
                            " rel",
                            "ive",
                            " our",
                            " old",
                            " cam",
                            "ar",
                            "ader",
                            "ie",
                            " in",
                            " a",
                            " new",
                            " place",
                            ",",
                            " in",
                            " a",
                            " different",
                            " city",
                            ",",
                            " maybe",
                            " in",
                            " a",
                            " different",
                            " country",
                            ".",
                            "\n",
                            "\n",
                            "Thus",
                            ",",
                            " began",
                            " the",
                            " search",
                            " for",
                            " a",
                            " tour",
                            " company",
                            " and",
                            " we",
                            " got",
                            " in",
                            " touch",
                            " with",
                            " S",
                            "OT",
                            "C",
                            " holidays",
                            " for",
                            " their",
                            " World",
                            " Tour",
                            " Pack",
                            "ages",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " us",
                            " Indians",
                            ",",
                            " Russia",
                            " generally",
                            " does",
                            " not",
                            " come",
                            " across",
                            " as",
                            " a",
                            " top",
                            " destination",
                            " of",
                            " choice",
                            " for",
                            " tourism",
                            " as",
                            " it",
                            " is",
                            " perceived",
                            " as",
                            " a",
                            " cold",
                            " and",
                            " distant",
                            " place",
                            ",",
                            " off",
                            " the",
                            " radar",
                            ".",
                            " But",
                            ",",
                            " that",
                            " was",
                            " precisely",
                            " the",
                            " reason",
                            " why",
                            " we",
                            " chose",
                            " Russia",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " Ald"
                        ],
                        "dataIndex": null,
                        "index": "88988",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.585,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.585,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:24.503Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.137,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}