{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "project based learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5017099083489134,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "27807",
            "description": "discussions about projects and personal experiences related to the creative process",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47921493897260303,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "27807",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:05:14.770Z",
                "maxActApprox": 15.738,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    27807,
                    48444,
                    26120,
                    79565,
                    22971,
                    32252,
                    85347,
                    45222,
                    47920,
                    18508,
                    20286,
                    50769,
                    74616,
                    25001,
                    60579,
                    59738,
                    27068,
                    9981,
                    67152,
                    82938,
                    5862,
                    85073,
                    76184,
                    77689,
                    85444
                ],
                "topkCosSimValues": [
                    1,
                    0.6016,
                    0.4606,
                    0.4597,
                    0.4523,
                    0.4508,
                    0.4331,
                    0.4176,
                    0.4112,
                    0.402,
                    0.4018,
                    0.399,
                    0.3849,
                    0.3745,
                    0.366,
                    0.3643,
                    0.3455,
                    0.3375,
                    0.3319,
                    0.3317,
                    0.3309,
                    0.3305,
                    0.3277,
                    0.3182,
                    0.3179
                ],
                "neuron_alignment_indices": [
                    60,
                    378,
                    243
                ],
                "neuron_alignment_values": [
                    0.098,
                    0.093,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    408,
                    243
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.024,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.034,
                    0.028
                ],
                "correlated_features_indices": [
                    27759,
                    27791,
                    27727
                ],
                "correlated_features_pearson": [
                    0.025,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.025,
                    0.005,
                    0.003
                ],
                "neg_str": [
                    "'.\"",
                    ".'\"",
                    ".\")",
                    "Redditor",
                    "\"],\"",
                    "!\".",
                    "\u0143\u0136",
                    "\").",
                    " fixme",
                    "@@"
                ],
                "neg_values": [
                    -0.867,
                    -0.725,
                    -0.711,
                    -0.689,
                    -0.668,
                    -0.664,
                    -0.639,
                    -0.636,
                    -0.629,
                    -0.627
                ],
                "pos_str": [
                    "?:",
                    "?",
                    "?\u00e3\u0122\u012f",
                    "...?",
                    ")?",
                    " yourselves",
                    "?]",
                    "?'",
                    "Going",
                    " yourself"
                ],
                "pos_values": [
                    1.074,
                    0.858,
                    0.778,
                    0.777,
                    0.777,
                    0.709,
                    0.692,
                    0.691,
                    0.677,
                    0.675
                ],
                "frac_nonzero": 0.00177,
                "freq_hist_data_bar_heights": [
                    831,
                    687,
                    508,
                    476,
                    385,
                    297,
                    240,
                    221,
                    206,
                    178,
                    171,
                    159,
                    110,
                    99,
                    98,
                    87,
                    81,
                    89,
                    80,
                    69,
                    59,
                    43,
                    48,
                    47,
                    36,
                    20,
                    34,
                    30,
                    28,
                    19,
                    19,
                    16,
                    16,
                    7,
                    9,
                    8,
                    8,
                    3,
                    10,
                    4,
                    5,
                    2,
                    1,
                    3,
                    3,
                    4,
                    1,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.157,
                    0.472,
                    0.787,
                    1.102,
                    1.416,
                    1.731,
                    2.046,
                    2.361,
                    2.675,
                    2.99,
                    3.305,
                    3.62,
                    3.934,
                    4.249,
                    4.564,
                    4.879,
                    5.193,
                    5.508,
                    5.823,
                    6.138,
                    6.452,
                    6.767,
                    7.082,
                    7.397,
                    7.712,
                    8.026,
                    8.341,
                    8.656,
                    8.971,
                    9.285,
                    9.6,
                    9.915,
                    10.23,
                    10.544,
                    10.859,
                    11.174,
                    11.489,
                    11.803,
                    12.118,
                    12.433,
                    12.748,
                    13.062,
                    13.377,
                    13.692,
                    14.007,
                    14.321,
                    14.636,
                    14.951,
                    15.266,
                    15.58
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    2,
                    4,
                    5,
                    8,
                    13,
                    31,
                    54,
                    112,
                    220,
                    372,
                    613,
                    1061,
                    1673,
                    2396,
                    3243,
                    4078,
                    4682,
                    5144,
                    5093,
                    4933,
                    4373,
                    3513,
                    2738,
                    1978,
                    1448,
                    965,
                    612,
                    342,
                    219,
                    147,
                    79,
                    45,
                    25,
                    10,
                    11,
                    5,
                    3,
                    0,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.848,
                    -0.809,
                    -0.77,
                    -0.732,
                    -0.693,
                    -0.654,
                    -0.615,
                    -0.576,
                    -0.537,
                    -0.499,
                    -0.46,
                    -0.421,
                    -0.382,
                    -0.343,
                    -0.305,
                    -0.266,
                    -0.227,
                    -0.188,
                    -0.149,
                    -0.11,
                    -0.072,
                    -0.033,
                    0.006,
                    0.045,
                    0.084,
                    0.123,
                    0.161,
                    0.2,
                    0.239,
                    0.278,
                    0.317,
                    0.355,
                    0.394,
                    0.433,
                    0.472,
                    0.511,
                    0.55,
                    0.588,
                    0.627,
                    0.666,
                    0.705,
                    0.744,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.015,
                    1.054
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " content related to personal experiences and future plans",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about projects and personal experiences related to the creative process",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg7e63wd7n10ex8v1ity51",
                        "tokens": [
                            " read",
                            " Op",
                            "ie",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " answers",
                            " below",
                            ".",
                            " Come",
                            " back",
                            " April",
                            " 29",
                            "th",
                            " for",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " interview",
                            " discussing",
                            " Sub",
                            "lime",
                            " with",
                            " Rome",
                            ",",
                            " today",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " reg",
                            "gae",
                            "-",
                            "rock",
                            " music",
                            " and",
                            " what",
                            " he",
                            " has",
                            " planned",
                            " for",
                            " the",
                            " future",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "You",
                            " Can",
                            " Read",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " Interview",
                            " by",
                            " clicking",
                            " HERE",
                            "\n",
                            "\n",
                            "The",
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "27807",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.738,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.953,
                            0,
                            0,
                            1.592,
                            4.281,
                            3.574,
                            5.764,
                            2.268,
                            2.906,
                            3.601,
                            2.016,
                            2.892,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.283,
                            7.42,
                            15.738,
                            14.948,
                            10.297,
                            8.608,
                            9.208,
                            3.33,
                            7.743,
                            7.197,
                            7.207,
                            4.669,
                            7.168,
                            7.291,
                            6.29,
                            9.969,
                            12.005,
                            7.804,
                            0.513,
                            7.869,
                            0,
                            4.008,
                            12.823,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:23.013Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.738,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg7e64wd7p10ex2glbo8dd",
                        "tokens": [
                            " read",
                            " Op",
                            "ie",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " answers",
                            " below",
                            ".",
                            " Come",
                            " back",
                            " April",
                            " 29",
                            "th",
                            " for",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " interview",
                            " discussing",
                            " Sub",
                            "lime",
                            " with",
                            " Rome",
                            ",",
                            " today",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " reg",
                            "gae",
                            "-",
                            "rock",
                            " music",
                            " and",
                            " what",
                            " he",
                            " has",
                            " planned",
                            " for",
                            " the",
                            " future",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "You",
                            " Can",
                            " Read",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " Interview",
                            " by",
                            " clicking",
                            " HERE",
                            "\n",
                            "\n",
                            "The",
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "27807",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.738,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.953,
                            0,
                            0,
                            1.592,
                            4.281,
                            3.574,
                            5.764,
                            2.268,
                            2.906,
                            3.601,
                            2.016,
                            2.892,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.283,
                            7.42,
                            15.738,
                            14.948,
                            10.297,
                            8.608,
                            9.208,
                            3.33,
                            7.743,
                            7.197,
                            7.207,
                            4.669,
                            7.168,
                            7.291,
                            6.29,
                            9.969,
                            12.005,
                            7.804,
                            0.513,
                            7.869,
                            0,
                            4.008,
                            12.823,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:23.013Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.738,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg7e65wd8510exlc1d7f57",
                        "tokens": [
                            " read",
                            " Op",
                            "ie",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " answers",
                            " below",
                            ".",
                            " Come",
                            " back",
                            " April",
                            " 29",
                            "th",
                            " for",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " interview",
                            " discussing",
                            " Sub",
                            "lime",
                            " with",
                            " Rome",
                            ",",
                            " today",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " reg",
                            "gae",
                            "-",
                            "rock",
                            " music",
                            " and",
                            " what",
                            " he",
                            " has",
                            " planned",
                            " for",
                            " the",
                            " future",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "You",
                            " Can",
                            " Read",
                            " Part",
                            " 2",
                            " of",
                            " this",
                            " Interview",
                            " by",
                            " clicking",
                            " HERE",
                            "\n",
                            "\n",
                            "The",
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "27807",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.738,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.953,
                            0,
                            0,
                            1.592,
                            4.281,
                            3.574,
                            5.764,
                            2.268,
                            2.906,
                            3.601,
                            2.016,
                            2.892,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.283,
                            7.42,
                            15.738,
                            14.948,
                            10.297,
                            8.608,
                            9.208,
                            3.33,
                            7.743,
                            7.197,
                            7.207,
                            4.669,
                            7.168,
                            7.291,
                            6.29,
                            9.969,
                            12.005,
                            7.804,
                            0.513,
                            7.869,
                            0,
                            4.008,
                            12.823,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:23.013Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.738,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "93285",
            "description": "actions related to planning and execution of personal projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46677461464556447,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "93285",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:24:01.481Z",
                "maxActApprox": 7.375,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    93285,
                    50367,
                    95067,
                    65482,
                    54970,
                    26858,
                    42420,
                    95655,
                    29612,
                    31993,
                    85515,
                    41529,
                    31033,
                    5525,
                    55196,
                    43704,
                    48414,
                    9448,
                    61871,
                    50255,
                    1693,
                    40456,
                    42132,
                    77800,
                    28755
                ],
                "topkCosSimValues": [
                    1,
                    0.5809,
                    0.5779,
                    0.5565,
                    0.5349,
                    0.5348,
                    0.5252,
                    0.5227,
                    0.5145,
                    0.51,
                    0.5099,
                    0.5042,
                    0.5042,
                    0.5019,
                    0.4975,
                    0.496,
                    0.4956,
                    0.4929,
                    0.4904,
                    0.4815,
                    0.479,
                    0.4777,
                    0.477,
                    0.4758,
                    0.4754
                ],
                "neuron_alignment_indices": [
                    480,
                    481,
                    266
                ],
                "neuron_alignment_values": [
                    0.48,
                    0.178,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.024,
                    0.009,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    266,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.072,
                    0.06,
                    0.047
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.069,
                    0.057
                ],
                "correlated_features_indices": [
                    93286,
                    93292,
                    93284
                ],
                "correlated_features_pearson": [
                    0.015,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.016,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    "anwhile",
                    " undermines",
                    " concedes",
                    " depends",
                    " denies",
                    " cited",
                    " repud",
                    "hovah",
                    " thri",
                    " derives"
                ],
                "neg_values": [
                    -0.668,
                    -0.653,
                    -0.65,
                    -0.631,
                    -0.63,
                    -0.616,
                    -0.59,
                    -0.585,
                    -0.58,
                    -0.578
                ],
                "pos_str": [
                    " crochet",
                    " Patreon",
                    " myself",
                    " Hearthstone",
                    " Kickstarter",
                    "DCS",
                    " blogging",
                    " awesome",
                    " badass",
                    " Lovecraft"
                ],
                "pos_values": [
                    0.818,
                    0.807,
                    0.699,
                    0.698,
                    0.686,
                    0.686,
                    0.684,
                    0.682,
                    0.682,
                    0.674
                ],
                "frac_nonzero": 0.00577,
                "freq_hist_data_bar_heights": [
                    2355,
                    2196,
                    1853,
                    1651,
                    1392,
                    1204,
                    1089,
                    915,
                    842,
                    670,
                    605,
                    497,
                    426,
                    402,
                    351,
                    263,
                    237,
                    187,
                    163,
                    131,
                    109,
                    115,
                    76,
                    70,
                    53,
                    51,
                    35,
                    49,
                    27,
                    24,
                    24,
                    12,
                    11,
                    9,
                    10,
                    8,
                    4,
                    3,
                    6,
                    5,
                    1,
                    2,
                    1,
                    3,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.074,
                    0.221,
                    0.369,
                    0.516,
                    0.664,
                    0.811,
                    0.959,
                    1.106,
                    1.254,
                    1.401,
                    1.549,
                    1.696,
                    1.844,
                    1.991,
                    2.139,
                    2.286,
                    2.434,
                    2.581,
                    2.729,
                    2.876,
                    3.024,
                    3.171,
                    3.319,
                    3.466,
                    3.614,
                    3.761,
                    3.909,
                    4.056,
                    4.204,
                    4.351,
                    4.499,
                    4.646,
                    4.794,
                    4.941,
                    5.089,
                    5.236,
                    5.384,
                    5.531,
                    5.679,
                    5.826,
                    5.974,
                    6.121,
                    6.269,
                    6.416,
                    6.564,
                    6.711,
                    6.859,
                    7.006,
                    7.154,
                    7.301
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    3,
                    9,
                    15,
                    31,
                    45,
                    89,
                    148,
                    265,
                    377,
                    526,
                    763,
                    1028,
                    1350,
                    1738,
                    2127,
                    2590,
                    2889,
                    3236,
                    3365,
                    3455,
                    3419,
                    3395,
                    3192,
                    2827,
                    2643,
                    2383,
                    1985,
                    1540,
                    1240,
                    945,
                    706,
                    550,
                    399,
                    320,
                    221,
                    160,
                    105,
                    68,
                    35,
                    22,
                    15,
                    12,
                    8,
                    10,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.653,
                    -0.623,
                    -0.593,
                    -0.564,
                    -0.534,
                    -0.504,
                    -0.474,
                    -0.445,
                    -0.415,
                    -0.385,
                    -0.356,
                    -0.326,
                    -0.296,
                    -0.266,
                    -0.237,
                    -0.207,
                    -0.177,
                    -0.148,
                    -0.118,
                    -0.088,
                    -0.058,
                    -0.029,
                    0.001,
                    0.031,
                    0.06,
                    0.09,
                    0.12,
                    0.15,
                    0.179,
                    0.209,
                    0.239,
                    0.269,
                    0.298,
                    0.328,
                    0.358,
                    0.387,
                    0.417,
                    0.447,
                    0.477,
                    0.506,
                    0.536,
                    0.566,
                    0.595,
                    0.625,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.774,
                    0.803
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "expressions of aspiration and personal projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "actions related to planning and execution of personal projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "verbs associated with actions of creation, travel, and personal ambition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj0kmw9zyl10exkv52utp2",
                        "tokens": [
                            " Track",
                            " Classic",
                            " and",
                            " the",
                            " Fal",
                            "mouth",
                            " Mile",
                            ",",
                            " I",
                            " was",
                            " inspired",
                            " to",
                            " create",
                            " my",
                            " own",
                            " race",
                            ",",
                            " The",
                            " H",
                            "oka",
                            " One",
                            " One",
                            " Long",
                            " Island",
                            " Mile",
                            " this",
                            " September",
                            " 9",
                            "th",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " an",
                            " easy",
                            " formula",
                            " to",
                            " replicate",
                            ",",
                            " and",
                            " if",
                            " enough",
                            " individual",
                            " race",
                            " organizers",
                            " through",
                            " out",
                            " the",
                            " country",
                            " decided",
                            " to",
                            " put",
                            " one",
                            " of",
                            " their",
                            " own",
                            " on",
                            ",",
                            " we",
                            " could",
                            " have",
                            " a",
                            " competitive",
                            " domestic",
                            " circuit",
                            " in",
                            " our",
                            " own",
                            " backyard",
                            " during",
                            " the",
                            " summer",
                            " months",
                            " that",
                            " could",
                            " rival",
                            " Europe",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            ".",
                            " The",
                            " US",
                            " distance",
                            " scene",
                            " is",
                            " plenty",
                            " deep",
                            ",",
                            " and",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " be",
                            " a",
                            " great",
                            " boost",
                            " to",
                            " the",
                            " local",
                            " running",
                            " community",
                            " and",
                            " for",
                            " athletes",
                            " who",
                            " cannot",
                            " afford",
                            " to",
                            " spend",
                            " multiple",
                            " weeks",
                            " overseas",
                            ".",
                            "\n",
                            "\n",
                            "Just",
                            " food",
                            " for",
                            " thought",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " huge"
                        ],
                        "dataIndex": null,
                        "index": "93285",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.375,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.404,
                            6.948,
                            5.868,
                            7.375,
                            3.811,
                            5.65,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.736,
                            1.981,
                            2.66,
                            0.866,
                            0.573,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.229,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:03.668Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.375,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj0kmw9zym10ex8acsb3hv",
                        "tokens": [
                            " Track",
                            " Classic",
                            " and",
                            " the",
                            " Fal",
                            "mouth",
                            " Mile",
                            ",",
                            " I",
                            " was",
                            " inspired",
                            " to",
                            " create",
                            " my",
                            " own",
                            " race",
                            ",",
                            " The",
                            " H",
                            "oka",
                            " One",
                            " One",
                            " Long",
                            " Island",
                            " Mile",
                            " this",
                            " September",
                            " 9",
                            "th",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " an",
                            " easy",
                            " formula",
                            " to",
                            " replicate",
                            ",",
                            " and",
                            " if",
                            " enough",
                            " individual",
                            " race",
                            " organizers",
                            " through",
                            " out",
                            " the",
                            " country",
                            " decided",
                            " to",
                            " put",
                            " one",
                            " of",
                            " their",
                            " own",
                            " on",
                            ",",
                            " we",
                            " could",
                            " have",
                            " a",
                            " competitive",
                            " domestic",
                            " circuit",
                            " in",
                            " our",
                            " own",
                            " backyard",
                            " during",
                            " the",
                            " summer",
                            " months",
                            " that",
                            " could",
                            " rival",
                            " Europe",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            ".",
                            " The",
                            " US",
                            " distance",
                            " scene",
                            " is",
                            " plenty",
                            " deep",
                            ",",
                            " and",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " be",
                            " a",
                            " great",
                            " boost",
                            " to",
                            " the",
                            " local",
                            " running",
                            " community",
                            " and",
                            " for",
                            " athletes",
                            " who",
                            " cannot",
                            " afford",
                            " to",
                            " spend",
                            " multiple",
                            " weeks",
                            " overseas",
                            ".",
                            "\n",
                            "\n",
                            "Just",
                            " food",
                            " for",
                            " thought",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " huge"
                        ],
                        "dataIndex": null,
                        "index": "93285",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.375,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.404,
                            6.948,
                            5.868,
                            7.375,
                            3.811,
                            5.65,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.736,
                            1.981,
                            2.66,
                            0.866,
                            0.573,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.229,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:03.668Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.375,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj0kmx9zyx10exv0owftyp",
                        "tokens": [
                            " Track",
                            " Classic",
                            " and",
                            " the",
                            " Fal",
                            "mouth",
                            " Mile",
                            ",",
                            " I",
                            " was",
                            " inspired",
                            " to",
                            " create",
                            " my",
                            " own",
                            " race",
                            ",",
                            " The",
                            " H",
                            "oka",
                            " One",
                            " One",
                            " Long",
                            " Island",
                            " Mile",
                            " this",
                            " September",
                            " 9",
                            "th",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " an",
                            " easy",
                            " formula",
                            " to",
                            " replicate",
                            ",",
                            " and",
                            " if",
                            " enough",
                            " individual",
                            " race",
                            " organizers",
                            " through",
                            " out",
                            " the",
                            " country",
                            " decided",
                            " to",
                            " put",
                            " one",
                            " of",
                            " their",
                            " own",
                            " on",
                            ",",
                            " we",
                            " could",
                            " have",
                            " a",
                            " competitive",
                            " domestic",
                            " circuit",
                            " in",
                            " our",
                            " own",
                            " backyard",
                            " during",
                            " the",
                            " summer",
                            " months",
                            " that",
                            " could",
                            " rival",
                            " Europe",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            ".",
                            " The",
                            " US",
                            " distance",
                            " scene",
                            " is",
                            " plenty",
                            " deep",
                            ",",
                            " and",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " be",
                            " a",
                            " great",
                            " boost",
                            " to",
                            " the",
                            " local",
                            " running",
                            " community",
                            " and",
                            " for",
                            " athletes",
                            " who",
                            " cannot",
                            " afford",
                            " to",
                            " spend",
                            " multiple",
                            " weeks",
                            " overseas",
                            ".",
                            "\n",
                            "\n",
                            "Just",
                            " food",
                            " for",
                            " thought",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " huge"
                        ],
                        "dataIndex": null,
                        "index": "93285",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.375,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.404,
                            6.948,
                            5.868,
                            7.375,
                            3.811,
                            5.65,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.736,
                            1.981,
                            2.66,
                            0.866,
                            0.573,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.229,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:24:03.668Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.375,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "37298",
            "description": " statements related to teaching and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4648664316614617,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "37298",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:18:08.931Z",
                "maxActApprox": 9.544,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37298,
                    90447,
                    44148,
                    93599,
                    2714,
                    82087,
                    36307,
                    18136,
                    17278,
                    70016,
                    71300,
                    59012,
                    23643,
                    97518,
                    40768,
                    70808,
                    98181,
                    78615,
                    85101,
                    21925,
                    40309,
                    53445,
                    26319,
                    42245,
                    49591
                ],
                "topkCosSimValues": [
                    1,
                    0.5543,
                    0.5408,
                    0.5356,
                    0.517,
                    0.516,
                    0.5119,
                    0.5118,
                    0.4883,
                    0.4736,
                    0.4733,
                    0.4704,
                    0.4662,
                    0.4625,
                    0.4608,
                    0.4595,
                    0.4592,
                    0.4577,
                    0.4546,
                    0.4544,
                    0.4533,
                    0.4516,
                    0.4492,
                    0.448,
                    0.4464
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    218
                ],
                "neuron_alignment_values": [
                    0.264,
                    0.118,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    8,
                    566,
                    87
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.037,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.056,
                    0.039,
                    -0.014
                ],
                "correlated_features_indices": [
                    37301,
                    37309,
                    37397
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "rete",
                    "aucas",
                    "atile",
                    " Unique",
                    "ciating",
                    " oval",
                    " exceeds",
                    " ambul",
                    "nexus",
                    "yth"
                ],
                "neg_values": [
                    -0.555,
                    -0.545,
                    -0.534,
                    -0.529,
                    -0.502,
                    -0.495,
                    -0.492,
                    -0.474,
                    -0.474,
                    -0.474
                ],
                "pos_str": [
                    " nonetheless",
                    " nevertheless",
                    " apologies",
                    " caveats",
                    " caution",
                    "endix",
                    " doubtless",
                    " gladly",
                    "warning",
                    " caveat"
                ],
                "pos_values": [
                    0.872,
                    0.768,
                    0.758,
                    0.707,
                    0.683,
                    0.641,
                    0.638,
                    0.63,
                    0.624,
                    0.624
                ],
                "frac_nonzero": 0.00287,
                "freq_hist_data_bar_heights": [
                    1368,
                    1126,
                    971,
                    817,
                    720,
                    624,
                    563,
                    441,
                    389,
                    346,
                    262,
                    219,
                    176,
                    182,
                    137,
                    119,
                    96,
                    87,
                    54,
                    60,
                    58,
                    36,
                    34,
                    32,
                    21,
                    19,
                    13,
                    11,
                    12,
                    9,
                    6,
                    3,
                    7,
                    2,
                    6,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.286,
                    0.477,
                    0.668,
                    0.859,
                    1.05,
                    1.241,
                    1.432,
                    1.623,
                    1.813,
                    2.004,
                    2.195,
                    2.386,
                    2.577,
                    2.768,
                    2.959,
                    3.149,
                    3.34,
                    3.531,
                    3.722,
                    3.913,
                    4.104,
                    4.295,
                    4.486,
                    4.676,
                    4.867,
                    5.058,
                    5.249,
                    5.44,
                    5.631,
                    5.822,
                    6.012,
                    6.203,
                    6.394,
                    6.585,
                    6.776,
                    6.967,
                    7.158,
                    7.349,
                    7.539,
                    7.73,
                    7.921,
                    8.112,
                    8.303,
                    8.494,
                    8.685,
                    8.875,
                    9.066,
                    9.257,
                    9.448
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    7,
                    14,
                    28,
                    58,
                    117,
                    184,
                    319,
                    492,
                    788,
                    1177,
                    1627,
                    2113,
                    2641,
                    3121,
                    3628,
                    3919,
                    3956,
                    3942,
                    3876,
                    3556,
                    3014,
                    2683,
                    2153,
                    1739,
                    1406,
                    1057,
                    774,
                    568,
                    356,
                    295,
                    209,
                    159,
                    95,
                    63,
                    47,
                    20,
                    20,
                    13,
                    5,
                    8,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.541,
                    -0.512,
                    -0.484,
                    -0.455,
                    -0.426,
                    -0.398,
                    -0.369,
                    -0.341,
                    -0.312,
                    -0.284,
                    -0.255,
                    -0.227,
                    -0.198,
                    -0.17,
                    -0.141,
                    -0.113,
                    -0.084,
                    -0.055,
                    -0.027,
                    0.002,
                    0.03,
                    0.059,
                    0.087,
                    0.116,
                    0.144,
                    0.173,
                    0.201,
                    0.23,
                    0.259,
                    0.287,
                    0.316,
                    0.344,
                    0.373,
                    0.401,
                    0.43,
                    0.458,
                    0.487,
                    0.515,
                    0.544,
                    0.573,
                    0.601,
                    0.63,
                    0.658,
                    0.687,
                    0.715,
                    0.744,
                    0.772,
                    0.801,
                    0.829,
                    0.858
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements related to teaching and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases expressing advice or suggestions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggntmh3k9e10ex8zq32xmy",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmj3k9y10exc6tmgsm1",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.635,
                        "binMax": 9.543,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmh3k9f10exukem1fpm",
                        "tokens": [
                            " this",
                            " console",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "Now",
                            " N",
                            "aughty",
                            " Dog",
                            " returns",
                            " to",
                            " the",
                            " spotlight",
                            " with",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            ".",
                            " Both",
                            " expected",
                            "ly",
                            " and",
                            " amazingly",
                            ",",
                            " N",
                            "aughty",
                            " Dog",
                            " has",
                            " indeed",
                            " best",
                            "ed",
                            " Nate",
                            "'s",
                            " first",
                            " adventure",
                            " and",
                            " has",
                            " created",
                            " a",
                            " sequel",
                            " that",
                            " is",
                            " not",
                            " only",
                            " bigger",
                            " and",
                            " better",
                            " in",
                            " practically",
                            " every",
                            " way",
                            ",",
                            " but",
                            " also",
                            " packs",
                            " a",
                            " multiplayer",
                            " component",
                            " that",
                            " could",
                            " be",
                            " released",
                            " as",
                            " its",
                            " own",
                            " separate",
                            ",",
                            " full",
                            "-",
                            "priced",
                            " game",
                            " and",
                            " people",
                            " would",
                            " stand",
                            " in",
                            " line",
                            " to",
                            " hand",
                            " over",
                            " their",
                            " cash",
                            ".",
                            "\n",
                            "\n",
                            "Yes",
                            ",",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            " is",
                            " fantastic",
                            ".",
                            "\n",
                            "\n",
                            "Click",
                            " the",
                            " image",
                            " to",
                            " watch",
                            " our",
                            " in",
                            "-",
                            "depth",
                            " video",
                            " review",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "rying",
                            " to",
                            " remain",
                            " as",
                            " spoiler",
                            "-",
                            "free",
                            " as",
                            " possible",
                            ",",
                            " I",
                            "'ll"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.545,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.14,
                            7.545
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "20567",
            "description": "references to personal development and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4621673546929752,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "20567",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:54:11.913Z",
                "maxActApprox": 13.663,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    20567,
                    11746,
                    18388,
                    61507,
                    42981,
                    31131,
                    49269,
                    40044,
                    42150,
                    20106,
                    37165,
                    22691,
                    61884,
                    19456,
                    67738,
                    9357,
                    24408,
                    31790,
                    96914,
                    8357,
                    67543,
                    396,
                    92916,
                    79202,
                    70532
                ],
                "topkCosSimValues": [
                    1,
                    0.4025,
                    0.3819,
                    0.3779,
                    0.3716,
                    0.3632,
                    0.3532,
                    0.3286,
                    0.3205,
                    0.3108,
                    0.31,
                    0.302,
                    0.3013,
                    0.3,
                    0.299,
                    0.2969,
                    0.2968,
                    0.2959,
                    0.2934,
                    0.2932,
                    0.2869,
                    0.2864,
                    0.2861,
                    0.2855,
                    0.2808
                ],
                "neuron_alignment_indices": [
                    215,
                    760,
                    323
                ],
                "neuron_alignment_values": [
                    0.143,
                    0.099,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    362,
                    215,
                    572
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.028,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.025,
                    0.031
                ],
                "correlated_features_indices": [
                    20597,
                    20550,
                    20493
                ],
                "correlated_features_pearson": [
                    0.018,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.018,
                    0.008,
                    0.001
                ],
                "neg_str": [
                    "xit",
                    "cture",
                    "\u00e3\u0125\u012b\u00e3\u0125\u00a9",
                    "OTUS",
                    "\u00e5\u00b0\u0128",
                    " TRUMP",
                    "\u00e3\u0124\u00aa",
                    "\u00e3\u0124\u00ae",
                    "orem",
                    " exits"
                ],
                "neg_values": [
                    -0.77,
                    -0.718,
                    -0.716,
                    -0.706,
                    -0.679,
                    -0.678,
                    -0.675,
                    -0.671,
                    -0.667,
                    -0.665
                ],
                "pos_str": [
                    " summers",
                    " undergrad",
                    " semin",
                    "chool",
                    " college",
                    " youth",
                    " taught",
                    " Buenos",
                    " minors",
                    " school"
                ],
                "pos_values": [
                    0.859,
                    0.846,
                    0.83,
                    0.764,
                    0.759,
                    0.756,
                    0.75,
                    0.746,
                    0.746,
                    0.741
                ],
                "frac_nonzero": 0.00179,
                "freq_hist_data_bar_heights": [
                    1189,
                    897,
                    777,
                    554,
                    455,
                    364,
                    239,
                    225,
                    165,
                    148,
                    125,
                    83,
                    76,
                    58,
                    55,
                    45,
                    33,
                    35,
                    19,
                    15,
                    12,
                    10,
                    7,
                    10,
                    3,
                    7,
                    4,
                    2,
                    4,
                    5,
                    2,
                    3,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.137,
                    0.41,
                    0.683,
                    0.957,
                    1.23,
                    1.503,
                    1.776,
                    2.05,
                    2.323,
                    2.596,
                    2.869,
                    3.143,
                    3.416,
                    3.689,
                    3.962,
                    4.236,
                    4.509,
                    4.782,
                    5.056,
                    5.329,
                    5.602,
                    5.875,
                    6.149,
                    6.422,
                    6.695,
                    6.968,
                    7.242,
                    7.515,
                    7.788,
                    8.061,
                    8.335,
                    8.608,
                    8.881,
                    9.154,
                    9.428,
                    9.701,
                    9.974,
                    10.247,
                    10.521,
                    10.794,
                    11.067,
                    11.341,
                    11.614,
                    11.887,
                    12.16,
                    12.434,
                    12.707,
                    12.98,
                    13.253,
                    13.527
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    3,
                    9,
                    13,
                    20,
                    22,
                    52,
                    94,
                    125,
                    179,
                    322,
                    433,
                    681,
                    927,
                    1235,
                    1633,
                    1924,
                    2355,
                    2823,
                    3099,
                    3274,
                    3518,
                    3622,
                    3653,
                    3626,
                    3112,
                    2844,
                    2459,
                    2055,
                    1647,
                    1365,
                    950,
                    725,
                    474,
                    323,
                    206,
                    165,
                    97,
                    59,
                    48,
                    30,
                    17,
                    10,
                    8,
                    7,
                    6,
                    1,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.754,
                    -0.721,
                    -0.689,
                    -0.656,
                    -0.623,
                    -0.591,
                    -0.558,
                    -0.526,
                    -0.493,
                    -0.46,
                    -0.428,
                    -0.395,
                    -0.363,
                    -0.33,
                    -0.298,
                    -0.265,
                    -0.232,
                    -0.2,
                    -0.167,
                    -0.135,
                    -0.102,
                    -0.069,
                    -0.037,
                    -0.004,
                    0.028,
                    0.061,
                    0.093,
                    0.126,
                    0.159,
                    0.191,
                    0.224,
                    0.256,
                    0.289,
                    0.322,
                    0.354,
                    0.387,
                    0.419,
                    0.452,
                    0.485,
                    0.517,
                    0.55,
                    0.582,
                    0.615,
                    0.647,
                    0.68,
                    0.713,
                    0.745,
                    0.778,
                    0.81,
                    0.843
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases related to long-term experiences and timelines",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to personal development and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygft4dgqwd710ex4kyh7wc7",
                        "tokens": [
                            " motor",
                            "bike",
                            " in",
                            " 1956",
                            ".",
                            "\n",
                            "\n",
                            "Ol",
                            "iver",
                            " became",
                            " a",
                            " combination",
                            " of",
                            " an",
                            " intellectual",
                            " and",
                            " a",
                            " reneg",
                            "ade",
                            ".",
                            " He",
                            " studied",
                            " medicine",
                            " in",
                            " Britain",
                            " and",
                            " then",
                            " made",
                            " his",
                            " way",
                            " to",
                            " North",
                            " America",
                            ",",
                            " cr",
                            "iss",
                            "cross",
                            "ing",
                            " the",
                            " continent",
                            " on",
                            " a",
                            " motorcycle",
                            ",",
                            " and",
                            " getting",
                            " into",
                            " some",
                            " dangerous",
                            " accidents",
                            ".",
                            " He",
                            " briefly",
                            " spent",
                            " some",
                            " time",
                            " hanging",
                            " out",
                            " with",
                            " Hell",
                            "s",
                            " Angels",
                            ",",
                            " b",
                            "iked",
                            " across",
                            " Canada",
                            ",",
                            " and",
                            " tried",
                            " to",
                            " sign",
                            " up",
                            " as",
                            " a",
                            " pilot",
                            " with",
                            " the",
                            " Royal",
                            " Canadian",
                            " Air",
                            " Force",
                            ".",
                            " He",
                            " later",
                            " moved",
                            " to",
                            " California",
                            ",",
                            " where",
                            " he",
                            " set",
                            " a",
                            " state",
                            "-",
                            "wide",
                            " weight",
                            "lifting",
                            " record",
                            ",",
                            " and",
                            " also",
                            " began",
                            " a",
                            " medical",
                            " residency",
                            " in",
                            " neurolog",
                            "y",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " the",
                            " end",
                            " of",
                            " work",
                            " on",
                            " Friday",
                            ",",
                            " he",
                            "'d",
                            " exchange",
                            " his",
                            " white",
                            " coat",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "20567",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.663,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.663,
                            7.344,
                            2.181,
                            2.744,
                            0.54,
                            0.594,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            2.409,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.054,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.842,
                            0,
                            0,
                            0,
                            0.004,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.212,
                            3.26,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.044,
                            0,
                            0.668,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:17.128Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.931,
                        "binMax": 13.663,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft4deqwcn10exylqnbzqf",
                        "tokens": [
                            " motor",
                            "bike",
                            " in",
                            " 1956",
                            ".",
                            "\n",
                            "\n",
                            "Ol",
                            "iver",
                            " became",
                            " a",
                            " combination",
                            " of",
                            " an",
                            " intellectual",
                            " and",
                            " a",
                            " reneg",
                            "ade",
                            ".",
                            " He",
                            " studied",
                            " medicine",
                            " in",
                            " Britain",
                            " and",
                            " then",
                            " made",
                            " his",
                            " way",
                            " to",
                            " North",
                            " America",
                            ",",
                            " cr",
                            "iss",
                            "cross",
                            "ing",
                            " the",
                            " continent",
                            " on",
                            " a",
                            " motorcycle",
                            ",",
                            " and",
                            " getting",
                            " into",
                            " some",
                            " dangerous",
                            " accidents",
                            ".",
                            " He",
                            " briefly",
                            " spent",
                            " some",
                            " time",
                            " hanging",
                            " out",
                            " with",
                            " Hell",
                            "s",
                            " Angels",
                            ",",
                            " b",
                            "iked",
                            " across",
                            " Canada",
                            ",",
                            " and",
                            " tried",
                            " to",
                            " sign",
                            " up",
                            " as",
                            " a",
                            " pilot",
                            " with",
                            " the",
                            " Royal",
                            " Canadian",
                            " Air",
                            " Force",
                            ".",
                            " He",
                            " later",
                            " moved",
                            " to",
                            " California",
                            ",",
                            " where",
                            " he",
                            " set",
                            " a",
                            " state",
                            "-",
                            "wide",
                            " weight",
                            "lifting",
                            " record",
                            ",",
                            " and",
                            " also",
                            " began",
                            " a",
                            " medical",
                            " residency",
                            " in",
                            " neurolog",
                            "y",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " the",
                            " end",
                            " of",
                            " work",
                            " on",
                            " Friday",
                            ",",
                            " he",
                            "'d",
                            " exchange",
                            " his",
                            " white",
                            " coat",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "20567",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.663,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.663,
                            7.344,
                            2.181,
                            2.744,
                            0.54,
                            0.594,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            2.409,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.054,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.842,
                            0,
                            0,
                            0,
                            0.004,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.212,
                            3.26,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.044,
                            0,
                            0.668,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:17.128Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.663,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygft4dfqwco10ex5sj06wu0",
                        "tokens": [
                            " artist",
                            " Pand",
                            "it",
                            " R",
                            "avi",
                            " Shank",
                            "ar",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " ashes",
                            " were",
                            " immersed",
                            " in",
                            " the",
                            " holy",
                            " waters",
                            " of",
                            " Var",
                            "anas",
                            "i",
                            " by",
                            " his",
                            " daughters",
                            ",",
                            " An",
                            "ous",
                            "h",
                            "ka",
                            " and",
                            " Nor",
                            "ah",
                            " Jones",
                            " in",
                            " March",
                            " 2013",
                            ".",
                            " Celebr",
                            "ated",
                            " models",
                            " and",
                            " actors",
                            " Seal",
                            " and",
                            " Heidi",
                            " Kl",
                            "um",
                            ",",
                            " till",
                            " they",
                            " were",
                            " married",
                            ",",
                            " routinely",
                            " sought",
                            " priests",
                            " from",
                            " Var",
                            "anas",
                            "i",
                            " every",
                            " year",
                            " to",
                            " take",
                            " vows",
                            " as",
                            " per",
                            " Hindu",
                            " rites",
                            " because",
                            " they",
                            " were",
                            " mesmer",
                            "ised",
                            " by",
                            " the",
                            " city",
                            " and",
                            " its",
                            " culture",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "inger",
                            " Madonna",
                            " took",
                            " lessons",
                            " in",
                            " Sanskrit",
                            " over",
                            " the",
                            " phone",
                            " from",
                            " Vag",
                            "ish",
                            " Sh",
                            "ast",
                            "ri",
                            " of",
                            " Kund",
                            "al",
                            "ini",
                            " Yoga",
                            " Pe",
                            "eth",
                            " way",
                            " back",
                            " in",
                            " 1998",
                            ",",
                            " for",
                            " her",
                            " album",
                            " Ray",
                            " of",
                            " Light",
                            ",",
                            " Grammy",
                            " award",
                            " winner",
                            " Sting",
                            " spent",
                            " some",
                            " time",
                            " in",
                            " Var"
                        ],
                        "dataIndex": null,
                        "index": "20567",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.896,
                        "maxValueTokenIndex": 90,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.896,
                            5.953,
                            0.834,
                            2.769,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.304,
                            4.642,
                            0.462,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:54:17.128Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.663,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21856",
            "description": "descriptions of projects or activities related to personal interests and experiences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46088624000549316,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21856",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:12:43.977Z",
                "maxActApprox": 19.845,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21856,
                    6544,
                    6211,
                    11580,
                    17769,
                    19727,
                    18471,
                    5526,
                    6686,
                    3927,
                    5181,
                    15396,
                    1296,
                    17952,
                    10102,
                    12346,
                    13823,
                    17367,
                    8656,
                    8354,
                    1601,
                    7866,
                    2921,
                    17698,
                    6275
                ],
                "topkCosSimValues": [
                    1,
                    0.5633,
                    0.5359,
                    0.5345,
                    0.5169,
                    0.5156,
                    0.5048,
                    0.4943,
                    0.4911,
                    0.4891,
                    0.4618,
                    0.46,
                    0.4563,
                    0.4561,
                    0.4485,
                    0.4465,
                    0.4459,
                    0.4387,
                    0.4341,
                    0.4304,
                    0.4288,
                    0.4281,
                    0.4185,
                    0.4132,
                    0.4132
                ],
                "neuron_alignment_indices": [
                    640,
                    679,
                    280
                ],
                "neuron_alignment_values": [
                    0.157,
                    0.123,
                    0.119
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    6,
                    679,
                    145
                ],
                "correlated_neurons_pearson": [
                    0.113,
                    0.091,
                    0.086
                ],
                "correlated_neurons_l1": [
                    0.121,
                    0.102,
                    0.087
                ],
                "correlated_features_indices": [
                    21837,
                    21853,
                    21817
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.011,
                    0.003
                ],
                "correlated_features_l1": [
                    0.016,
                    0.012,
                    0.006
                ],
                "neg_str": [
                    " aven",
                    " cameo",
                    " disemb",
                    " utter",
                    "ozyg",
                    " repe",
                    " mysteriously",
                    "plet",
                    " redeemed",
                    " hears"
                ],
                "neg_values": [
                    -0.734,
                    -0.727,
                    -0.725,
                    -0.708,
                    -0.697,
                    -0.692,
                    -0.689,
                    -0.686,
                    -0.684,
                    -0.682
                ],
                "pos_str": [
                    " Ideally",
                    " Otherwise",
                    " Unfortunately",
                    " Fortunately",
                    " Luckily",
                    " Thankfully",
                    " Specifically",
                    " Especially",
                    " Doing",
                    " Instead"
                ],
                "pos_values": [
                    1.692,
                    1.564,
                    1.422,
                    1.416,
                    1.406,
                    1.36,
                    1.266,
                    1.248,
                    1.209,
                    1.207
                ],
                "frac_nonzero": 0.0044,
                "freq_hist_data_bar_heights": [
                    2309,
                    1896,
                    1523,
                    1244,
                    1150,
                    875,
                    743,
                    601,
                    520,
                    443,
                    421,
                    319,
                    272,
                    230,
                    200,
                    175,
                    120,
                    124,
                    97,
                    87,
                    81,
                    69,
                    42,
                    51,
                    25,
                    29,
                    36,
                    19,
                    23,
                    17,
                    14,
                    7,
                    16,
                    9,
                    13,
                    4,
                    8,
                    2,
                    1,
                    4,
                    3,
                    3,
                    1,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.199,
                    0.595,
                    0.992,
                    1.389,
                    1.786,
                    2.183,
                    2.58,
                    2.977,
                    3.374,
                    3.771,
                    4.168,
                    4.564,
                    4.961,
                    5.358,
                    5.755,
                    6.152,
                    6.549,
                    6.946,
                    7.343,
                    7.74,
                    8.136,
                    8.533,
                    8.93,
                    9.327,
                    9.724,
                    10.121,
                    10.518,
                    10.915,
                    11.312,
                    11.709,
                    12.105,
                    12.502,
                    12.899,
                    13.296,
                    13.693,
                    14.09,
                    14.487,
                    14.884,
                    15.281,
                    15.678,
                    16.074,
                    16.471,
                    16.868,
                    17.265,
                    17.662,
                    18.059,
                    18.456,
                    18.853,
                    19.25,
                    19.646
                ],
                "logits_hist_data_bar_heights": [
                    8,
                    13,
                    21,
                    85,
                    176,
                    359,
                    629,
                    1083,
                    1727,
                    2427,
                    3075,
                    3649,
                    4026,
                    4109,
                    4190,
                    4025,
                    3938,
                    3663,
                    3316,
                    2692,
                    2077,
                    1464,
                    1061,
                    734,
                    502,
                    341,
                    252,
                    182,
                    113,
                    65,
                    57,
                    53,
                    36,
                    32,
                    27,
                    16,
                    8,
                    6,
                    5,
                    5,
                    3,
                    1,
                    0,
                    1,
                    3,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.71,
                    -0.662,
                    -0.613,
                    -0.564,
                    -0.516,
                    -0.467,
                    -0.419,
                    -0.37,
                    -0.322,
                    -0.273,
                    -0.225,
                    -0.176,
                    -0.128,
                    -0.079,
                    -0.031,
                    0.018,
                    0.066,
                    0.115,
                    0.163,
                    0.212,
                    0.26,
                    0.309,
                    0.357,
                    0.406,
                    0.454,
                    0.503,
                    0.552,
                    0.6,
                    0.649,
                    0.697,
                    0.746,
                    0.794,
                    0.843,
                    0.891,
                    0.94,
                    0.988,
                    1.037,
                    1.085,
                    1.134,
                    1.182,
                    1.231,
                    1.279,
                    1.328,
                    1.376,
                    1.425,
                    1.473,
                    1.522,
                    1.57,
                    1.619,
                    1.668
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "descriptions of projects or activities related to personal interests and experiences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn0c2bkrvsi666044oqy6g",
                        "tokens": [
                            "As",
                            "he",
                            "ville",
                            " Scare",
                            "fest",
                            " started",
                            " out",
                            " as",
                            " a",
                            " little",
                            " mini",
                            "-",
                            "con",
                            " for",
                            " Pathfinder",
                            " Society",
                            ",",
                            " back",
                            " in",
                            " 2013",
                            ".",
                            " The",
                            " idea",
                            " was",
                            " to",
                            " find",
                            " a",
                            " way",
                            " to",
                            " combine",
                            " the",
                            " creep",
                            "iness",
                            " of",
                            " The",
                            " Best",
                            " Holiday",
                            " with",
                            " the",
                            " joy",
                            " of",
                            " our",
                            " favourite",
                            " hobby",
                            ",",
                            " and",
                            " it",
                            " worked",
                            "!",
                            " We",
                            " ran",
                            " and",
                            " played",
                            " a",
                            " lot",
                            " of",
                            " the",
                            " scar",
                            "ier",
                            " P",
                            "FS",
                            " games",
                            ",",
                            " had",
                            " some",
                            " pretty",
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once"
                        ],
                        "dataIndex": null,
                        "index": "21856",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.845,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.845,
                            3.634,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:50.130Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 19.845,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn0c2dkrwei666byt1yfnp",
                        "tokens": [
                            "As",
                            "he",
                            "ville",
                            " Scare",
                            "fest",
                            " started",
                            " out",
                            " as",
                            " a",
                            " little",
                            " mini",
                            "-",
                            "con",
                            " for",
                            " Pathfinder",
                            " Society",
                            ",",
                            " back",
                            " in",
                            " 2013",
                            ".",
                            " The",
                            " idea",
                            " was",
                            " to",
                            " find",
                            " a",
                            " way",
                            " to",
                            " combine",
                            " the",
                            " creep",
                            "iness",
                            " of",
                            " The",
                            " Best",
                            " Holiday",
                            " with",
                            " the",
                            " joy",
                            " of",
                            " our",
                            " favourite",
                            " hobby",
                            ",",
                            " and",
                            " it",
                            " worked",
                            "!",
                            " We",
                            " ran",
                            " and",
                            " played",
                            " a",
                            " lot",
                            " of",
                            " the",
                            " scar",
                            "ier",
                            " P",
                            "FS",
                            " games",
                            ",",
                            " had",
                            " some",
                            " pretty",
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once"
                        ],
                        "dataIndex": null,
                        "index": "21856",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.845,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.845,
                            3.634,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:50.130Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 15.876,
                        "binMax": 19.845,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn0c2bkrvti666qt6o24dx",
                        "tokens": [
                            "ra",
                            "fl",
                            "ops",
                            ").",
                            " A",
                            " standard",
                            " desktop",
                            " computer",
                            " requires",
                            " about",
                            " 40",
                            ",",
                            "000",
                            " times",
                            " more",
                            " power",
                            " to",
                            " run",
                            " and",
                            " operates",
                            " about",
                            " 9",
                            ",",
                            "000",
                            " times",
                            " slower",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            "\n",
                            "\n",
                            "The",
                            " goal",
                            ",",
                            " therefore",
                            ",",
                            " is",
                            " to",
                            " produce",
                            " information",
                            " technologies",
                            " with",
                            " the",
                            " power",
                            " of",
                            " the",
                            " human",
                            " brain",
                            ".",
                            " There",
                            " are",
                            " several",
                            " initiatives",
                            " underway",
                            " that",
                            " are",
                            " working",
                            " to",
                            " achieve",
                            " this",
                            " goal",
                            ",",
                            " including",
                            " IBM",
                            "'s",
                            " neuro",
                            "syn",
                            "aptic",
                            " chips",
                            " (",
                            "and",
                            " accompanying",
                            " programming",
                            " language",
                            "),",
                            " the",
                            " University",
                            " of",
                            " He",
                            "idel",
                            "berg",
                            "'s",
                            " H",
                            "IC",
                            "ANN",
                            " Chip",
                            ",",
                            " and",
                            " brain",
                            "-",
                            "m",
                            "apping",
                            " initiatives",
                            " like",
                            " the",
                            " European",
                            " Human",
                            " Brain",
                            " Project",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " can",
                            " now",
                            " add",
                            " another",
                            " project",
                            " to",
                            " the",
                            " list",
                            ":",
                            " Stanford",
                            "'s",
                            " Neuro",
                            "grid",
                            ".",
                            " But",
                            " unlike",
                            " other",
                            " current",
                            " efforts",
                            ",",
                            " this",
                            " \"",
                            "ne"
                        ],
                        "dataIndex": null,
                        "index": "21856",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.356,
                        "maxValueTokenIndex": 49,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.067,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.356,
                            2.624,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.178,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:50.130Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 19.845,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "5902",
            "description": "references to collaborative projects and educational initiatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4566897587981751,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "5902",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:08:27.998Z",
                "maxActApprox": 10.83,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5902,
                    14080,
                    34669,
                    17734,
                    6915,
                    22948,
                    4605,
                    48747,
                    17249,
                    17660,
                    42876,
                    1682,
                    20454,
                    11952,
                    16080,
                    44792,
                    23791,
                    42073,
                    37253,
                    18052,
                    21215,
                    14605,
                    44365,
                    12560,
                    19672
                ],
                "topkCosSimValues": [
                    1,
                    0.524,
                    0.4349,
                    0.4323,
                    0.4295,
                    0.4262,
                    0.4206,
                    0.4151,
                    0.4143,
                    0.3911,
                    0.3876,
                    0.3861,
                    0.3834,
                    0.3829,
                    0.3811,
                    0.3773,
                    0.373,
                    0.3679,
                    0.3651,
                    0.3634,
                    0.3619,
                    0.3608,
                    0.3575,
                    0.3571,
                    0.3563
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    626
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.149,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    558,
                    498,
                    220
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.034,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.037,
                    0.03
                ],
                "correlated_features_indices": [
                    5779,
                    5792,
                    5782
                ],
                "correlated_features_pearson": [
                    0.032,
                    0.025,
                    0.022
                ],
                "correlated_features_l1": [
                    0.033,
                    0.026,
                    0.024
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "fax",
                    "soType",
                    "enough",
                    "needs",
                    " Salary",
                    "mother",
                    "66666666",
                    "Smith",
                    "errors"
                ],
                "neg_values": [
                    -0.877,
                    -0.68,
                    -0.631,
                    -0.608,
                    -0.603,
                    -0.602,
                    -0.581,
                    -0.579,
                    -0.578,
                    -0.572
                ],
                "pos_str": [
                    " acronym",
                    " themed",
                    " combining",
                    " loosely",
                    " curated",
                    " reim",
                    " revamped",
                    " pioneering",
                    " collaborative",
                    " innovative"
                ],
                "pos_values": [
                    0.853,
                    0.839,
                    0.831,
                    0.83,
                    0.805,
                    0.796,
                    0.789,
                    0.749,
                    0.745,
                    0.744
                ],
                "frac_nonzero": 0.00293,
                "freq_hist_data_bar_heights": [
                    1226,
                    1100,
                    934,
                    764,
                    623,
                    592,
                    487,
                    500,
                    411,
                    356,
                    263,
                    287,
                    200,
                    192,
                    181,
                    147,
                    117,
                    111,
                    101,
                    91,
                    85,
                    58,
                    52,
                    49,
                    51,
                    40,
                    36,
                    26,
                    24,
                    18,
                    15,
                    14,
                    17,
                    8,
                    8,
                    6,
                    5,
                    5,
                    4,
                    5,
                    3,
                    3,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.108,
                    0.325,
                    0.542,
                    0.758,
                    0.975,
                    1.191,
                    1.408,
                    1.624,
                    1.841,
                    2.058,
                    2.274,
                    2.491,
                    2.707,
                    2.924,
                    3.141,
                    3.357,
                    3.574,
                    3.79,
                    4.007,
                    4.224,
                    4.44,
                    4.657,
                    4.873,
                    5.09,
                    5.307,
                    5.523,
                    5.74,
                    5.956,
                    6.173,
                    6.39,
                    6.606,
                    6.823,
                    7.039,
                    7.256,
                    7.473,
                    7.689,
                    7.906,
                    8.122,
                    8.339,
                    8.556,
                    8.772,
                    8.989,
                    9.205,
                    9.422,
                    9.639,
                    9.855,
                    10.072,
                    10.288,
                    10.505,
                    10.722
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    6,
                    11,
                    32,
                    42,
                    93,
                    133,
                    264,
                    437,
                    682,
                    1088,
                    1486,
                    2036,
                    2647,
                    3354,
                    3836,
                    4158,
                    4307,
                    4236,
                    3995,
                    3565,
                    3145,
                    2646,
                    2066,
                    1515,
                    1270,
                    953,
                    657,
                    465,
                    363,
                    250,
                    182,
                    119,
                    72,
                    60,
                    32,
                    15,
                    14,
                    5,
                    7,
                    0,
                    3,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.86,
                    -0.825,
                    -0.791,
                    -0.756,
                    -0.722,
                    -0.687,
                    -0.652,
                    -0.618,
                    -0.583,
                    -0.549,
                    -0.514,
                    -0.479,
                    -0.445,
                    -0.41,
                    -0.375,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.064,
                    -0.029,
                    0.005,
                    0.04,
                    0.074,
                    0.109,
                    0.144,
                    0.178,
                    0.213,
                    0.248,
                    0.282,
                    0.317,
                    0.351,
                    0.386,
                    0.421,
                    0.455,
                    0.49,
                    0.524,
                    0.559,
                    0.594,
                    0.628,
                    0.663,
                    0.698,
                    0.732,
                    0.767,
                    0.801,
                    0.836
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to collaborative projects and educational initiatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4heuqh37bi666m6l6lyza",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuuh388i666aew2pu4t",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 4.332,
                        "binMax": 6.498,
                        "binContains": 0.00014,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuqh37ci666gdc1fdp1",
                        "tokens": [
                            " space",
                            " and",
                            " a",
                            " three",
                            "-",
                            "day",
                            " sym",
                            "posium",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013a",
                            "I",
                            " have",
                            " written",
                            " a",
                            " wicked",
                            " book",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " said",
                            " Mel",
                            "ville",
                            " when",
                            " his",
                            " novel",
                            " was",
                            " first",
                            " published",
                            " in",
                            " 18",
                            "51",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "and",
                            " I",
                            " feel",
                            " as",
                            " spot",
                            "less",
                            " as",
                            " the",
                            " lamb",
                            "\u00e2\u0122",
                            "\u013b",
                            ".",
                            " Deep",
                            "ly",
                            " subversive",
                            ",",
                            " in",
                            " almost",
                            " every",
                            " way",
                            " imaginable",
                            ",",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " is",
                            " a",
                            " virtual",
                            ",",
                            " alternative",
                            " bible",
                            " \u2013",
                            " and",
                            " as",
                            " such",
                            ",",
                            " ripe",
                            " for",
                            " re",
                            "interpret",
                            "ation",
                            " in",
                            " this",
                            " new",
                            " world",
                            " of",
                            " new",
                            " media",
                            ".",
                            " Out",
                            " of",
                            " Dominion",
                            " was",
                            " born",
                            " its",
                            " bastard",
                            " child",
                            " \u2013",
                            " or",
                            " perhaps",
                            " its",
                            " imm",
                            "ac",
                            "ulate",
                            " conception",
                            " \u2013",
                            " the",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " Big",
                            " Read",
                            ":",
                            " an",
                            " online",
                            " version",
                            " of",
                            " Mel",
                            "ville",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mag",
                            "ister",
                            "ial",
                            " to",
                            "me",
                            ":"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.607,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.969,
                            10.607,
                            8.971,
                            3.062,
                            2.038,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            1.269,
                            0,
                            0,
                            2.09
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "26259",
            "description": " concepts related to collaborative projects and their structures",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4560442268848419,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "26259",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:02:31.264Z",
                "maxActApprox": 13.722,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    26259,
                    47068,
                    59033,
                    42985,
                    71977,
                    78473,
                    70724,
                    23342,
                    93941,
                    89463,
                    83813,
                    64396,
                    66882,
                    18435,
                    76755,
                    57613,
                    33691,
                    52087,
                    72515,
                    33170,
                    14498,
                    65445,
                    55791,
                    13396,
                    34286
                ],
                "topkCosSimValues": [
                    1,
                    0.679,
                    0.566,
                    0.5511,
                    0.5496,
                    0.549,
                    0.5349,
                    0.5232,
                    0.5017,
                    0.4796,
                    0.475,
                    0.455,
                    0.4497,
                    0.4463,
                    0.4461,
                    0.4428,
                    0.4335,
                    0.4272,
                    0.4242,
                    0.4198,
                    0.4133,
                    0.4077,
                    0.3987,
                    0.3984,
                    0.3922
                ],
                "neuron_alignment_indices": [
                    447,
                    481,
                    288
                ],
                "neuron_alignment_values": [
                    0.25,
                    0.106,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.012,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    575,
                    288,
                    435
                ],
                "correlated_neurons_pearson": [
                    0.058,
                    0.056,
                    0.042
                ],
                "correlated_neurons_l1": [
                    0.067,
                    0.066,
                    0.035
                ],
                "correlated_features_indices": [
                    26233,
                    26258,
                    26281
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.004,
                    0.004,
                    0.002
                ],
                "neg_str": [
                    "quickShipAvailable",
                    " heaviest",
                    " recent",
                    " Latest",
                    " setbacks",
                    "hani",
                    " insults",
                    " Portug",
                    "\u012a\u0134",
                    "ighed"
                ],
                "neg_values": [
                    -0.626,
                    -0.613,
                    -0.603,
                    -0.593,
                    -0.592,
                    -0.591,
                    -0.58,
                    -0.578,
                    -0.578,
                    -0.571
                ],
                "pos_str": [
                    " WITHOUT",
                    " anew",
                    " suitable",
                    " yourself",
                    "enstein",
                    " believable",
                    "onto",
                    " ourselves",
                    " capable",
                    " accordingly"
                ],
                "pos_values": [
                    0.916,
                    0.86,
                    0.782,
                    0.734,
                    0.732,
                    0.718,
                    0.7,
                    0.685,
                    0.677,
                    0.668
                ],
                "frac_nonzero": 0.00268,
                "freq_hist_data_bar_heights": [
                    1045,
                    868,
                    792,
                    686,
                    548,
                    481,
                    425,
                    335,
                    319,
                    302,
                    263,
                    214,
                    214,
                    188,
                    170,
                    168,
                    163,
                    150,
                    114,
                    117,
                    110,
                    106,
                    74,
                    76,
                    52,
                    57,
                    54,
                    53,
                    52,
                    49,
                    28,
                    31,
                    26,
                    20,
                    14,
                    13,
                    15,
                    15,
                    6,
                    5,
                    3,
                    2,
                    1,
                    2,
                    0,
                    4,
                    1,
                    3,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.138,
                    0.412,
                    0.687,
                    0.961,
                    1.236,
                    1.51,
                    1.784,
                    2.059,
                    2.333,
                    2.608,
                    2.882,
                    3.157,
                    3.431,
                    3.705,
                    3.98,
                    4.254,
                    4.529,
                    4.803,
                    5.077,
                    5.352,
                    5.626,
                    5.901,
                    6.175,
                    6.45,
                    6.724,
                    6.998,
                    7.273,
                    7.547,
                    7.822,
                    8.096,
                    8.371,
                    8.645,
                    8.919,
                    9.194,
                    9.468,
                    9.743,
                    10.017,
                    10.291,
                    10.566,
                    10.84,
                    11.115,
                    11.389,
                    11.664,
                    11.938,
                    12.212,
                    12.487,
                    12.761,
                    13.036,
                    13.31,
                    13.585
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    8,
                    12,
                    23,
                    30,
                    49,
                    81,
                    150,
                    236,
                    345,
                    494,
                    824,
                    1118,
                    1569,
                    1983,
                    2569,
                    3056,
                    3587,
                    3938,
                    4051,
                    4185,
                    4085,
                    3619,
                    3296,
                    2614,
                    2273,
                    1740,
                    1286,
                    910,
                    680,
                    460,
                    334,
                    237,
                    145,
                    88,
                    75,
                    37,
                    23,
                    14,
                    13,
                    5,
                    3,
                    3,
                    1,
                    2,
                    1,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.61,
                    -0.58,
                    -0.549,
                    -0.518,
                    -0.487,
                    -0.456,
                    -0.425,
                    -0.395,
                    -0.364,
                    -0.333,
                    -0.302,
                    -0.271,
                    -0.24,
                    -0.209,
                    -0.179,
                    -0.148,
                    -0.117,
                    -0.086,
                    -0.055,
                    -0.024,
                    0.006,
                    0.037,
                    0.068,
                    0.099,
                    0.13,
                    0.161,
                    0.192,
                    0.222,
                    0.253,
                    0.284,
                    0.315,
                    0.346,
                    0.377,
                    0.407,
                    0.438,
                    0.469,
                    0.5,
                    0.531,
                    0.562,
                    0.593,
                    0.623,
                    0.654,
                    0.685,
                    0.716,
                    0.747,
                    0.778,
                    0.808,
                    0.839,
                    0.87,
                    0.901
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to collaborative projects and their structures",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts related to technology, social structures, and fictional elements in storytelling",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg3tdvv6t910exotabddph",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Mot",
                            "iv",
                            "ations",
                            " to",
                            " Build",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " in",
                            " Panama",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ".",
                            "com",
                            " reached",
                            " out",
                            " to",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " of",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " (",
                            "and",
                            " Crypt",
                            "ob",
                            "uy",
                            "er",
                            "),",
                            " Jorge",
                            " F",
                            "ari",
                            "as",
                            ",",
                            " to",
                            " get",
                            " some",
                            " insight",
                            " on",
                            " the",
                            " motivations",
                            " behind",
                            " setting",
                            " up",
                            " the",
                            " embassy",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " created",
                            " the",
                            " embassy",
                            " because",
                            " we",
                            " were",
                            " motivated",
                            " by",
                            " the",
                            " need",
                            " to",
                            " educate",
                            " the",
                            " people",
                            " not",
                            " only",
                            " of",
                            " Panama",
                            ",",
                            " but",
                            " also",
                            " of",
                            " the",
                            " world",
                            ".",
                            " Panama",
                            " is",
                            " a",
                            " tourist",
                            " site",
                            ",",
                            " and",
                            " at",
                            " the",
                            " same",
                            " time",
                            ",",
                            " a",
                            " major",
                            " financial",
                            " and",
                            " log",
                            "istic",
                            " center",
                            ".",
                            " We",
                            " believe",
                            " that",
                            " it",
                            " is",
                            " an",
                            " ideal",
                            " place",
                            " to",
                            " show",
                            " the",
                            " power",
                            " of",
                            " technology",
                            " in",
                            " a",
                            " real",
                            ",",
                            " palpable",
                            " way"
                        ],
                        "dataIndex": null,
                        "index": "26259",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.722,
                        "maxValueTokenIndex": 64,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.871,
                            7.571,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.233,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.722,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:35.671Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.722,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg3tdvv6ta10ex6gbtgiks",
                        "tokens": [
                            " results",
                            " in",
                            " a",
                            " lower",
                            " return",
                            " frequency",
                            ".",
                            " The",
                            " difference",
                            " between",
                            " transmitted",
                            " and",
                            " received",
                            " frequencies",
                            " provides",
                            " a",
                            " measure",
                            " of",
                            " the",
                            " target",
                            " speed",
                            " relative",
                            " to",
                            " the",
                            " radar",
                            " antenna",
                            ".",
                            " That",
                            " difference",
                            " is",
                            " always",
                            " small",
                            ".",
                            " A",
                            " target",
                            " approaching",
                            " at",
                            " 100",
                            " kilometers",
                            " per",
                            " hour",
                            " raises",
                            " the",
                            " received",
                            " frequency",
                            " by",
                            " less",
                            " than",
                            " one",
                            " part",
                            " in",
                            " 5",
                            " million",
                            ",",
                            " for",
                            " example",
                            ".",
                            " Fortunately",
                            ",",
                            " engineers",
                            " have",
                            " long",
                            " known",
                            " how",
                            " to",
                            " create",
                            " circuits",
                            " that",
                            " can",
                            " precisely",
                            " compare",
                            " nearly",
                            " identical",
                            " frequencies",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " earliest",
                            " applications",
                            " of",
                            " Do",
                            "pp",
                            "ler",
                            " radar",
                            " simply",
                            " measured",
                            " raw",
                            " speed",
                            ",",
                            " like",
                            " the",
                            " police",
                            " radar",
                            " that",
                            " caught",
                            " Watson",
                            "-",
                            "W",
                            "att",
                            " in",
                            " the",
                            " 1950",
                            "s",
                            ".",
                            " It",
                            " would",
                            " be",
                            " another",
                            " 20",
                            " years",
                            " before",
                            " the",
                            " emergence",
                            " of",
                            " digital",
                            " micro",
                            "process",
                            "ors",
                            " made",
                            " possible",
                            " some",
                            " truly",
                            " amazing",
                            " improvements",
                            ".",
                            " For"
                        ],
                        "dataIndex": null,
                        "index": "26259",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.493,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.493,
                            2.948,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:35.671Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.722,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg3tdvv6tb10exzzape6xh",
                        "tokens": [
                            "Welcome",
                            " to",
                            " Gw",
                            "ai",
                            "h",
                            "ir",
                            ",",
                            " the",
                            " Lord",
                            " of",
                            " the",
                            " Eagles",
                            ",",
                            " and",
                            " all",
                            " his",
                            " kin",
                            " in",
                            " Ros",
                            "ro",
                            "val",
                            ",",
                            " the",
                            " \"",
                            "Pe",
                            "ak",
                            " of",
                            " the",
                            " Eagles",
                            "\".",
                            " The",
                            " Line",
                            " of",
                            " Golf",
                            "imb",
                            "ul",
                            " is",
                            " still",
                            " alive",
                            ",",
                            " and",
                            " Mount",
                            " Gram",
                            " can",
                            " prepar",
                            " to",
                            " war",
                            " once",
                            " again",
                            ".",
                            " All",
                            " E",
                            "ri",
                            "ador",
                            " fears",
                            " the",
                            " new",
                            " powers",
                            " of",
                            " the",
                            " orcs",
                            " of",
                            " the",
                            " North",
                            " now",
                            "!",
                            "\n",
                            "\n",
                            "Create",
                            " your",
                            " own",
                            " kingdom",
                            " of",
                            " middle",
                            "men",
                            " in",
                            " En",
                            "ed",
                            "w",
                            "aith",
                            ",",
                            " and",
                            " become",
                            " the",
                            " High",
                            " King",
                            " of",
                            " Is",
                            "env",
                            "ale",
                            ",",
                            " to",
                            " balance",
                            " the",
                            " power",
                            " of",
                            " both",
                            " Ar",
                            "nor",
                            " and",
                            " G",
                            "ond",
                            "or",
                            "!",
                            "\n",
                            "\n",
                            "Craft",
                            " your",
                            " own",
                            " objects",
                            " !",
                            "\n",
                            "\n",
                            "As",
                            " a",
                            " Dwarf",
                            " or",
                            " a",
                            " N",
                            "old",
                            "or",
                            " crafts",
                            "man",
                            ",",
                            " you",
                            "'re",
                            " now"
                        ],
                        "dataIndex": null,
                        "index": "26259",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.145,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.145,
                            0,
                            0,
                            2.635,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.391,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:35.671Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.722,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4523964495895185,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "4906",
            "description": "discussions about participation in projects or events",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44671443422350765,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "4906",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:06:49.069Z",
                "maxActApprox": 11.24,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4906,
                    10317,
                    27536,
                    18142,
                    27592,
                    30315,
                    10890,
                    11178,
                    47995,
                    31182,
                    41307,
                    1655,
                    36349,
                    37408,
                    4134,
                    4729,
                    33805,
                    27302,
                    4883,
                    16466,
                    8907,
                    4694,
                    43192,
                    7641,
                    16112
                ],
                "topkCosSimValues": [
                    1,
                    0.5242,
                    0.473,
                    0.4416,
                    0.4232,
                    0.4164,
                    0.4145,
                    0.412,
                    0.4015,
                    0.3917,
                    0.3843,
                    0.3811,
                    0.3801,
                    0.3762,
                    0.3759,
                    0.3754,
                    0.3704,
                    0.3698,
                    0.3683,
                    0.3642,
                    0.3588,
                    0.356,
                    0.3536,
                    0.3532,
                    0.3526
                ],
                "neuron_alignment_indices": [
                    480,
                    447,
                    266
                ],
                "neuron_alignment_values": [
                    0.395,
                    0.155,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.019,
                    0.008,
                    0.004
                ],
                "correlated_neurons_indices": [
                    480,
                    624,
                    105
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.039,
                    0.038
                ],
                "correlated_neurons_l1": [
                    -0.003,
                    0.031,
                    0.034
                ],
                "correlated_features_indices": [
                    4957,
                    4883,
                    4914
                ],
                "correlated_features_pearson": [
                    0.053,
                    0.023,
                    0.016
                ],
                "correlated_features_l1": [
                    0.055,
                    0.026,
                    0.017
                ],
                "neg_str": [
                    "utterstock",
                    "Liber",
                    " MSM",
                    " pathetic",
                    "\u00e0",
                    "carry",
                    "iberal",
                    "heid",
                    " worthless",
                    "equality"
                ],
                "neg_values": [
                    -0.704,
                    -0.661,
                    -0.638,
                    -0.635,
                    -0.623,
                    -0.623,
                    -0.612,
                    -0.609,
                    -0.608,
                    -0.608
                ],
                "pos_str": [
                    " brainstorm",
                    " designing",
                    " designers",
                    " collaborating",
                    " inspir",
                    " sketches",
                    " studio",
                    " collaboration",
                    " collaborate",
                    " design"
                ],
                "pos_values": [
                    1.093,
                    1.081,
                    1.055,
                    0.965,
                    0.959,
                    0.947,
                    0.923,
                    0.905,
                    0.883,
                    0.881
                ],
                "frac_nonzero": 0.008539999999999999,
                "freq_hist_data_bar_heights": [
                    4601,
                    3647,
                    3030,
                    2484,
                    2156,
                    1792,
                    1490,
                    1251,
                    1024,
                    844,
                    766,
                    645,
                    518,
                    425,
                    406,
                    323,
                    239,
                    232,
                    150,
                    140,
                    102,
                    117,
                    82,
                    84,
                    67,
                    50,
                    40,
                    28,
                    25,
                    24,
                    18,
                    15,
                    8,
                    8,
                    8,
                    9,
                    2,
                    5,
                    2,
                    3,
                    3,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.112,
                    0.337,
                    0.562,
                    0.787,
                    1.012,
                    1.236,
                    1.461,
                    1.686,
                    1.911,
                    2.136,
                    2.36,
                    2.585,
                    2.81,
                    3.035,
                    3.26,
                    3.484,
                    3.709,
                    3.934,
                    4.159,
                    4.384,
                    4.608,
                    4.833,
                    5.058,
                    5.283,
                    5.508,
                    5.732,
                    5.957,
                    6.182,
                    6.407,
                    6.632,
                    6.856,
                    7.081,
                    7.306,
                    7.531,
                    7.756,
                    7.98,
                    8.205,
                    8.43,
                    8.655,
                    8.88,
                    9.104,
                    9.329,
                    9.554,
                    9.779,
                    10.004,
                    10.228,
                    10.453,
                    10.678,
                    10.903,
                    11.127
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    10,
                    18,
                    27,
                    41,
                    112,
                    197,
                    290,
                    494,
                    708,
                    1004,
                    1360,
                    1949,
                    2436,
                    2991,
                    3553,
                    4102,
                    4178,
                    4235,
                    4057,
                    3694,
                    3227,
                    2665,
                    2209,
                    1755,
                    1297,
                    1018,
                    775,
                    510,
                    372,
                    290,
                    175,
                    141,
                    98,
                    72,
                    56,
                    42,
                    18,
                    19,
                    21,
                    11,
                    11,
                    5,
                    3,
                    2,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.686,
                    -0.65,
                    -0.614,
                    -0.578,
                    -0.542,
                    -0.507,
                    -0.471,
                    -0.435,
                    -0.399,
                    -0.363,
                    -0.327,
                    -0.291,
                    -0.255,
                    -0.219,
                    -0.183,
                    -0.147,
                    -0.111,
                    -0.075,
                    -0.039,
                    -0.003,
                    0.033,
                    0.069,
                    0.105,
                    0.14,
                    0.176,
                    0.212,
                    0.248,
                    0.284,
                    0.32,
                    0.356,
                    0.392,
                    0.428,
                    0.464,
                    0.5,
                    0.536,
                    0.572,
                    0.608,
                    0.644,
                    0.68,
                    0.716,
                    0.752,
                    0.787,
                    0.823,
                    0.859,
                    0.895,
                    0.931,
                    0.967,
                    1.003,
                    1.039,
                    1.075
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions about participation in projects or events",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4f75ag60ti666a8rqs8p7",
                        "tokens": [
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff",
                            " &",
                            " we",
                            " had",
                            " been",
                            " talking",
                            " about",
                            " doing",
                            " some",
                            " actual",
                            " shows",
                            " based",
                            " on",
                            " this",
                            " newer",
                            " material",
                            " we",
                            " have",
                            ".",
                            " It",
                            " was",
                            " weird",
                            " because",
                            " we",
                            " were",
                            " talking",
                            " about",
                            " something",
                            " similar",
                            " to",
                            " this",
                            " and",
                            " then",
                            " all",
                            " of",
                            " the",
                            " sudden",
                            " it",
                            " was",
                            " happening",
                            ".",
                            " What",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " bringing",
                            ",",
                            " is",
                            " I",
                            " have",
                            " 2",
                            " new",
                            " songs",
                            " that",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " written",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "4906",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.24,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.503,
                            4.492,
                            4.96,
                            6.419,
                            11.24,
                            8.061,
                            6.028,
                            3.95,
                            1.154,
                            3.309,
                            2.509,
                            0,
                            2.564,
                            2.1,
                            0,
                            3.218,
                            4.424,
                            2.321,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.845,
                            5.45,
                            3.209,
                            4.168,
                            1.247,
                            0,
                            0,
                            6.401,
                            8.496,
                            7.239,
                            4.339,
                            4.178,
                            2.664,
                            1.748,
                            2.704,
                            0.012,
                            0.666,
                            7.064,
                            6.982,
                            4.91,
                            3.866,
                            2.733,
                            3.366,
                            0.419,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.677,
                            0.418,
                            5.577,
                            1.232,
                            2.612,
                            3.088,
                            1.287,
                            1.511,
                            0.672,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.352,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:54.034Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 11.24,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4f75bg618i666r86hschk",
                        "tokens": [
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff",
                            " &",
                            " we",
                            " had",
                            " been",
                            " talking",
                            " about",
                            " doing",
                            " some",
                            " actual",
                            " shows",
                            " based",
                            " on",
                            " this",
                            " newer",
                            " material",
                            " we",
                            " have",
                            ".",
                            " It",
                            " was",
                            " weird",
                            " because",
                            " we",
                            " were",
                            " talking",
                            " about",
                            " something",
                            " similar",
                            " to",
                            " this",
                            " and",
                            " then",
                            " all",
                            " of",
                            " the",
                            " sudden",
                            " it",
                            " was",
                            " happening",
                            ".",
                            " What",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " bringing",
                            ",",
                            " is",
                            " I",
                            " have",
                            " 2",
                            " new",
                            " songs",
                            " that",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " written",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "4906",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.24,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.503,
                            4.492,
                            4.96,
                            6.419,
                            11.24,
                            8.061,
                            6.028,
                            3.95,
                            1.154,
                            3.309,
                            2.509,
                            0,
                            2.564,
                            2.1,
                            0,
                            3.218,
                            4.424,
                            2.321,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.845,
                            5.45,
                            3.209,
                            4.168,
                            1.247,
                            0,
                            0,
                            6.401,
                            8.496,
                            7.239,
                            4.339,
                            4.178,
                            2.664,
                            1.748,
                            2.704,
                            0.012,
                            0.666,
                            7.064,
                            6.982,
                            4.91,
                            3.866,
                            2.733,
                            3.366,
                            0.419,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.677,
                            0.418,
                            5.577,
                            1.232,
                            2.612,
                            3.088,
                            1.287,
                            1.511,
                            0.672,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.352,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:54.034Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 11.24,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4f75cg61hi66647ni0368",
                        "tokens": [
                            " Pier",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " lot",
                            " of",
                            " excitement",
                            " coming",
                            " up",
                            " for",
                            " the",
                            " Sk",
                            "unk",
                            " 25",
                            "th",
                            " Anniversary",
                            " Show",
                            " at",
                            " Cal",
                            "i",
                            "-",
                            "R",
                            "oots",
                            ".",
                            " How",
                            " were",
                            " you",
                            " personally",
                            " approached",
                            " to",
                            " be",
                            " a",
                            " part",
                            " of",
                            " this",
                            " &",
                            " is",
                            " there",
                            " anything",
                            " you",
                            " have",
                            " planned",
                            " for",
                            " Cal",
                            "i",
                            "-",
                            "roots",
                            " specifically",
                            "?",
                            "\n",
                            "\n",
                            "Op",
                            "ie",
                            " Ortiz",
                            ":",
                            " We",
                            " were",
                            " in",
                            " the",
                            " midst",
                            " of",
                            " recording",
                            " some",
                            " stuff",
                            " &",
                            " we",
                            " had",
                            " been",
                            " talking",
                            " about",
                            " doing",
                            " some",
                            " actual",
                            " shows",
                            " based",
                            " on",
                            " this",
                            " newer",
                            " material",
                            " we",
                            " have",
                            ".",
                            " It",
                            " was",
                            " weird",
                            " because",
                            " we",
                            " were",
                            " talking",
                            " about",
                            " something",
                            " similar",
                            " to",
                            " this",
                            " and",
                            " then",
                            " all",
                            " of",
                            " the",
                            " sudden",
                            " it",
                            " was",
                            " happening",
                            ".",
                            " What",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " bringing",
                            ",",
                            " is",
                            " I",
                            " have",
                            " 2",
                            " new",
                            " songs",
                            " that",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " written",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "4906",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.24,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.503,
                            4.492,
                            4.96,
                            6.419,
                            11.24,
                            8.061,
                            6.028,
                            3.95,
                            1.154,
                            3.309,
                            2.509,
                            0,
                            2.564,
                            2.1,
                            0,
                            3.218,
                            4.424,
                            2.321,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.845,
                            5.45,
                            3.209,
                            4.168,
                            1.247,
                            0,
                            0,
                            6.401,
                            8.496,
                            7.239,
                            4.339,
                            4.178,
                            2.664,
                            1.748,
                            2.704,
                            0.012,
                            0.666,
                            7.064,
                            6.982,
                            4.91,
                            3.866,
                            2.733,
                            3.366,
                            0.419,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.677,
                            0.418,
                            5.577,
                            1.232,
                            2.612,
                            3.088,
                            1.287,
                            1.511,
                            0.672,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.352,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:54.034Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 8.992,
                        "binMax": 11.24,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "68892",
            "description": "keywords related to projects and their associated challenges or developments",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4453558921813965,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "68892",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:57:35.470Z",
                "maxActApprox": 13.632,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    68892,
                    84620,
                    74797,
                    12247,
                    39473,
                    36328,
                    17501,
                    6569,
                    78272,
                    36596,
                    64401,
                    84767,
                    9840,
                    71174,
                    12820,
                    733,
                    41539,
                    25444,
                    61157,
                    70794,
                    2082,
                    92031,
                    87043,
                    93047,
                    10858
                ],
                "topkCosSimValues": [
                    1,
                    0.5166,
                    0.4778,
                    0.4741,
                    0.4723,
                    0.4685,
                    0.4543,
                    0.4533,
                    0.4392,
                    0.4356,
                    0.4341,
                    0.4274,
                    0.4268,
                    0.4266,
                    0.4119,
                    0.4043,
                    0.4041,
                    0.4007,
                    0.4001,
                    0.3918,
                    0.3914,
                    0.3908,
                    0.3877,
                    0.3866,
                    0.3846
                ],
                "neuron_alignment_indices": [
                    481,
                    408,
                    447
                ],
                "neuron_alignment_values": [
                    0.186,
                    0.113,
                    0.113
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    312,
                    679
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.036,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.046,
                    0.03,
                    0.042
                ],
                "correlated_features_indices": [
                    68958,
                    68878,
                    68929
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.02,
                    0.005,
                    0.004
                ],
                "neg_str": [
                    "maximum",
                    "ilk",
                    "\u00e5\u00a7\u00ab",
                    "otto",
                    "rocal",
                    "enting",
                    "estinal",
                    "utenberg",
                    "cair",
                    "aldo"
                ],
                "neg_values": [
                    -0.765,
                    -0.726,
                    -0.711,
                    -0.695,
                    -0.676,
                    -0.662,
                    -0.658,
                    -0.657,
                    -0.648,
                    -0.643
                ],
                "pos_str": [
                    " imaginable",
                    " ever",
                    " EVER",
                    " besides",
                    " roundup",
                    "ivals",
                    " dystop",
                    " hack",
                    " since",
                    " involving"
                ],
                "pos_values": [
                    0.96,
                    0.943,
                    0.906,
                    0.691,
                    0.661,
                    0.64,
                    0.634,
                    0.631,
                    0.623,
                    0.614
                ],
                "frac_nonzero": 0.0014,
                "freq_hist_data_bar_heights": [
                    733,
                    551,
                    470,
                    405,
                    344,
                    270,
                    245,
                    202,
                    182,
                    134,
                    121,
                    94,
                    98,
                    82,
                    50,
                    70,
                    44,
                    36,
                    37,
                    28,
                    29,
                    25,
                    24,
                    16,
                    21,
                    21,
                    13,
                    6,
                    13,
                    6,
                    9,
                    9,
                    3,
                    7,
                    1,
                    3,
                    2,
                    2,
                    0,
                    3,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.137,
                    0.409,
                    0.682,
                    0.955,
                    1.227,
                    1.5,
                    1.773,
                    2.045,
                    2.318,
                    2.59,
                    2.863,
                    3.136,
                    3.408,
                    3.681,
                    3.954,
                    4.226,
                    4.499,
                    4.771,
                    5.044,
                    5.317,
                    5.589,
                    5.862,
                    6.134,
                    6.407,
                    6.68,
                    6.952,
                    7.225,
                    7.498,
                    7.77,
                    8.043,
                    8.315,
                    8.588,
                    8.861,
                    9.133,
                    9.406,
                    9.679,
                    9.951,
                    10.224,
                    10.496,
                    10.769,
                    11.042,
                    11.314,
                    11.587,
                    11.86,
                    12.132,
                    12.405,
                    12.677,
                    12.95,
                    13.223,
                    13.495
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    3,
                    8,
                    17,
                    22,
                    22,
                    59,
                    105,
                    130,
                    239,
                    358,
                    494,
                    751,
                    1041,
                    1435,
                    1856,
                    2457,
                    3084,
                    3622,
                    3922,
                    4293,
                    4471,
                    4359,
                    4067,
                    3457,
                    2752,
                    2230,
                    1603,
                    1185,
                    793,
                    578,
                    309,
                    232,
                    116,
                    93,
                    38,
                    27,
                    8,
                    9,
                    4,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.748,
                    -0.713,
                    -0.679,
                    -0.644,
                    -0.61,
                    -0.575,
                    -0.541,
                    -0.506,
                    -0.472,
                    -0.437,
                    -0.403,
                    -0.368,
                    -0.334,
                    -0.299,
                    -0.264,
                    -0.23,
                    -0.195,
                    -0.161,
                    -0.126,
                    -0.092,
                    -0.057,
                    -0.023,
                    0.012,
                    0.046,
                    0.081,
                    0.115,
                    0.15,
                    0.184,
                    0.219,
                    0.253,
                    0.288,
                    0.322,
                    0.357,
                    0.391,
                    0.426,
                    0.46,
                    0.495,
                    0.529,
                    0.564,
                    0.598,
                    0.633,
                    0.667,
                    0.702,
                    0.736,
                    0.771,
                    0.805,
                    0.84,
                    0.874,
                    0.909,
                    0.943
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "keywords related to projects and their associated challenges or developments",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "topics related to projects and environmental issues",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi2mserjhl10exw3jkdjvt",
                        "tokens": [
                            " albums",
                            " or",
                            " what",
                            " he",
                            " did",
                            " with",
                            " the",
                            " existing",
                            " Bieber",
                            " records",
                            " on",
                            " store",
                            " shelves",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " think",
                            " legal",
                            " repercussions",
                            " are",
                            " always",
                            " a",
                            " possibility",
                            " when",
                            " you",
                            " do",
                            " performance",
                            " pieces",
                            ",\"",
                            " said",
                            " P",
                            "az",
                            ".",
                            " \"",
                            "Sometimes",
                            " you",
                            " have",
                            " to",
                            " take",
                            " risks",
                            " for",
                            " your",
                            " art",
                            ".\"",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " not",
                            " P",
                            "az",
                            "'s",
                            " first",
                            " music",
                            " industry",
                            " prank",
                            ".",
                            " Last",
                            " year",
                            ",",
                            " he",
                            " slipped",
                            " photos",
                            " of",
                            " himself",
                            " into",
                            " the",
                            " Grammy",
                            " Museum",
                            " in",
                            " downtown",
                            " Los",
                            " Angeles",
                            " and",
                            " hung",
                            " them",
                            " on",
                            " the",
                            " wall",
                            " next",
                            " to",
                            " the",
                            " likes",
                            " of",
                            " Grammy",
                            " winners",
                            " Cal",
                            "le",
                            " 13",
                            " and",
                            " Maria",
                            " Rita",
                            ".",
                            "\n",
                            "\n",
                            "___",
                            "\n",
                            "\n",
                            "Online",
                            ":",
                            "\n",
                            "\n",
                            "https",
                            "://",
                            "www",
                            ".",
                            "facebook",
                            ".",
                            "com",
                            "/",
                            "p",
                            "az",
                            "\n",
                            "\n",
                            "___",
                            "\n",
                            "\n",
                            "Follow",
                            " AP",
                            " Entertainment",
                            " Writer",
                            " Der",
                            "rik",
                            " J",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "68892",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.632,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.516,
                            13.632,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:40.141Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.632,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi2mshrji710exzijj4ut4",
                        "tokens": [
                            " albums",
                            " or",
                            " what",
                            " he",
                            " did",
                            " with",
                            " the",
                            " existing",
                            " Bieber",
                            " records",
                            " on",
                            " store",
                            " shelves",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " think",
                            " legal",
                            " repercussions",
                            " are",
                            " always",
                            " a",
                            " possibility",
                            " when",
                            " you",
                            " do",
                            " performance",
                            " pieces",
                            ",\"",
                            " said",
                            " P",
                            "az",
                            ".",
                            " \"",
                            "Sometimes",
                            " you",
                            " have",
                            " to",
                            " take",
                            " risks",
                            " for",
                            " your",
                            " art",
                            ".\"",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " not",
                            " P",
                            "az",
                            "'s",
                            " first",
                            " music",
                            " industry",
                            " prank",
                            ".",
                            " Last",
                            " year",
                            ",",
                            " he",
                            " slipped",
                            " photos",
                            " of",
                            " himself",
                            " into",
                            " the",
                            " Grammy",
                            " Museum",
                            " in",
                            " downtown",
                            " Los",
                            " Angeles",
                            " and",
                            " hung",
                            " them",
                            " on",
                            " the",
                            " wall",
                            " next",
                            " to",
                            " the",
                            " likes",
                            " of",
                            " Grammy",
                            " winners",
                            " Cal",
                            "le",
                            " 13",
                            " and",
                            " Maria",
                            " Rita",
                            ".",
                            "\n",
                            "\n",
                            "___",
                            "\n",
                            "\n",
                            "Online",
                            ":",
                            "\n",
                            "\n",
                            "https",
                            "://",
                            "www",
                            ".",
                            "facebook",
                            ".",
                            "com",
                            "/",
                            "p",
                            "az",
                            "\n",
                            "\n",
                            "___",
                            "\n",
                            "\n",
                            "Follow",
                            " AP",
                            " Entertainment",
                            " Writer",
                            " Der",
                            "rik",
                            " J",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "68892",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.632,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.516,
                            13.632,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:40.141Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.905,
                        "binMax": 13.632,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi2msfrjhm10ext2lvxcsy",
                        "tokens": [
                            " Seg",
                            "Net",
                            " 4",
                            ".",
                            " Russell",
                            " doubts",
                            " his",
                            " version",
                            " of",
                            " the",
                            " network",
                            " will",
                            " be",
                            " available",
                            " when",
                            " Se",
                            "greg",
                            "ated",
                            " Witness",
                            " and",
                            " other",
                            " protocol",
                            " changes",
                            " implemented",
                            " in",
                            " Seg",
                            "Net",
                            " 4",
                            " go",
                            " live",
                            " on",
                            " Bitcoin",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " main",
                            "net",
                            ".",
                            " In",
                            " terms",
                            " of",
                            " Seg",
                            "Net",
                            " 4",
                            ",",
                            " the",
                            " Block",
                            "stream",
                            " Core",
                            " Tech",
                            " Engineer",
                            " added",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " last",
                            " bitcoin",
                            " protocol",
                            " change",
                            " required",
                            " to",
                            " make",
                            " lightning",
                            " a",
                            " reality",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "<|endoftext|>",
                            "\"",
                            "Cre",
                            "ep",
                            "y",
                            " Uncle",
                            " Sam",
                            "\"",
                            " is",
                            " doubling",
                            " down",
                            "!",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " got",
                            " new",
                            " ads",
                            " out",
                            ",",
                            " and",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " using",
                            " the",
                            " image",
                            "-",
                            "sharing",
                            " site",
                            " Snapchat",
                            " in",
                            " his",
                            " campaign",
                            " to",
                            " scare",
                            " young",
                            " Americans",
                            " away",
                            " from",
                            " Obamacare",
                            ".",
                            "\n",
                            "\n",
                            "Will",
                            " he",
                            " and",
                            " his",
                            " creator",
                            ",",
                            " the",
                            " conservative"
                        ],
                        "dataIndex": null,
                        "index": "68892",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.201,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.698,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.509,
                            13.201,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:40.141Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.632,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "89258",
            "description": "expressions of creativity and innovative thinking",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.42997992038726807,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "89258",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:19:39.991Z",
                "maxActApprox": 37.448,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    89258,
                    29302,
                    153,
                    37782,
                    8761,
                    16256,
                    14432,
                    46920,
                    14936,
                    49967,
                    42828,
                    88716,
                    16107,
                    54923,
                    15475,
                    58337,
                    62096,
                    19777,
                    15956,
                    27104,
                    4241,
                    22806,
                    74211,
                    7986,
                    28366
                ],
                "topkCosSimValues": [
                    1,
                    0.8033,
                    0.5877,
                    0.5567,
                    0.5218,
                    0.4965,
                    0.4898,
                    0.4716,
                    0.4592,
                    0.4454,
                    0.4374,
                    0.4342,
                    0.4332,
                    0.4313,
                    0.4254,
                    0.4252,
                    0.4175,
                    0.4102,
                    0.4098,
                    0.4087,
                    0.4014,
                    0.3971,
                    0.3853,
                    0.3812,
                    0.3778
                ],
                "neuron_alignment_indices": [
                    339,
                    523,
                    151
                ],
                "neuron_alignment_values": [
                    0.121,
                    0.109,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    151,
                    18,
                    271
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.015,
                    0.014
                ],
                "correlated_features_indices": [
                    89297,
                    89348,
                    89289
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.006,
                    0,
                    0
                ],
                "neg_str": [
                    "atched",
                    "ighed",
                    " Adin",
                    "ovan",
                    "pta",
                    "BuyableInstoreAndOnline",
                    "roy",
                    "phia",
                    "uked",
                    "atch"
                ],
                "neg_values": [
                    -0.768,
                    -0.75,
                    -0.744,
                    -0.741,
                    -0.71,
                    -0.71,
                    -0.687,
                    -0.677,
                    -0.673,
                    -0.672
                ],
                "pos_str": [
                    " juices",
                    " commons",
                    " arts",
                    "smanship",
                    " genius",
                    " improvis",
                    " imagination",
                    " flair",
                    " creatively",
                    " creative"
                ],
                "pos_values": [
                    1.008,
                    0.945,
                    0.896,
                    0.893,
                    0.889,
                    0.85,
                    0.835,
                    0.826,
                    0.795,
                    0.792
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    74,
                    60,
                    38,
                    20,
                    17,
                    18,
                    5,
                    8,
                    7,
                    8,
                    5,
                    4,
                    2,
                    0,
                    4,
                    4,
                    4,
                    4,
                    3,
                    6,
                    8,
                    13,
                    3,
                    3,
                    2,
                    1,
                    2,
                    3,
                    1,
                    2,
                    1,
                    4,
                    2,
                    1,
                    2,
                    5,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.379,
                    1.127,
                    1.876,
                    2.625,
                    3.374,
                    4.123,
                    4.872,
                    5.621,
                    6.37,
                    7.119,
                    7.867,
                    8.616,
                    9.365,
                    10.114,
                    10.863,
                    11.612,
                    12.361,
                    13.11,
                    13.858,
                    14.607,
                    15.356,
                    16.105,
                    16.854,
                    17.603,
                    18.352,
                    19.101,
                    19.85,
                    20.598,
                    21.347,
                    22.096,
                    22.845,
                    23.594,
                    24.343,
                    25.092,
                    25.841,
                    26.589,
                    27.338,
                    28.087,
                    28.836,
                    29.585,
                    30.334,
                    31.083,
                    31.832,
                    32.58,
                    33.329,
                    34.078,
                    34.827,
                    35.576,
                    36.325,
                    37.074
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    2,
                    8,
                    7,
                    17,
                    33,
                    52,
                    75,
                    127,
                    227,
                    306,
                    472,
                    710,
                    960,
                    1318,
                    1775,
                    2346,
                    2998,
                    3426,
                    3729,
                    4141,
                    4326,
                    4128,
                    3848,
                    3384,
                    2842,
                    2320,
                    1799,
                    1436,
                    1012,
                    733,
                    555,
                    379,
                    260,
                    166,
                    114,
                    82,
                    50,
                    27,
                    19,
                    16,
                    10,
                    3,
                    6,
                    2,
                    2,
                    3,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.75,
                    -0.714,
                    -0.679,
                    -0.643,
                    -0.608,
                    -0.572,
                    -0.537,
                    -0.501,
                    -0.466,
                    -0.43,
                    -0.395,
                    -0.359,
                    -0.324,
                    -0.288,
                    -0.253,
                    -0.217,
                    -0.182,
                    -0.146,
                    -0.111,
                    -0.075,
                    -0.04,
                    -0.004,
                    0.031,
                    0.067,
                    0.102,
                    0.138,
                    0.174,
                    0.209,
                    0.245,
                    0.28,
                    0.316,
                    0.351,
                    0.387,
                    0.422,
                    0.458,
                    0.493,
                    0.529,
                    0.564,
                    0.6,
                    0.635,
                    0.671,
                    0.706,
                    0.742,
                    0.777,
                    0.813,
                    0.848,
                    0.884,
                    0.919,
                    0.955,
                    0.99
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "expressions of creativity and innovative thinking",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "instances of the word \"creative\" and its related forms, indicating a focus on creativity and innovative thinking",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiuyw06yhv10exaftoc1w3",
                        "tokens": [
                            "-",
                            "by",
                            "-",
                            "four",
                            " equipment",
                            " trunk",
                            " onto",
                            " the",
                            " field",
                            " and",
                            " worked",
                            " alone",
                            ";",
                            " now",
                            ",",
                            " the",
                            " Super",
                            " Bowl",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " grounds",
                            "keeping",
                            " crew",
                            " is",
                            " 32",
                            " strong",
                            " and",
                            " pulling",
                            " expensive",
                            " equipment",
                            " from",
                            " three",
                            " tractor",
                            " trailers",
                            "\n",
                            "\n",
                            "T",
                            "oma",
                            " began",
                            " working",
                            " on",
                            " playing",
                            " fields",
                            " as",
                            " a",
                            " teenager",
                            ".",
                            " When",
                            " he",
                            " was",
                            " a",
                            " senior",
                            " in",
                            " high",
                            " school",
                            ",",
                            " he",
                            " was",
                            " named",
                            " head",
                            " grounds",
                            "keeper",
                            " for",
                            " the",
                            " Cleveland",
                            " Indians",
                            "\u00e2\u0122",
                            "\u013b",
                            " Class",
                            " A",
                            " affiliate",
                            " in",
                            " Wil",
                            "kes",
                            "-",
                            "B",
                            "arre",
                            ",",
                            " Pa",
                            ".,",
                            " and",
                            " began",
                            " experimenting",
                            " with",
                            " seeds",
                            " and",
                            " sod",
                            ",",
                            " sunlight",
                            " and",
                            " shadows",
                            ",",
                            " learning",
                            " about",
                            " the",
                            " right",
                            " amount",
                            " of",
                            " watering",
                            " and",
                            " when",
                            " to",
                            " get",
                            " creative",
                            ".",
                            " Eventually",
                            " he",
                            " became",
                            " head",
                            " grounds",
                            "keeper",
                            " of",
                            " the",
                            " Kansas",
                            " City",
                            " Athletics",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " where",
                            " then",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "89258",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.448,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.448,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:42.214Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 29.959,
                        "binMax": 37.448,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiuyvy6yh810exoz8o9kv3",
                        "tokens": [
                            "-",
                            "by",
                            "-",
                            "four",
                            " equipment",
                            " trunk",
                            " onto",
                            " the",
                            " field",
                            " and",
                            " worked",
                            " alone",
                            ";",
                            " now",
                            ",",
                            " the",
                            " Super",
                            " Bowl",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " grounds",
                            "keeping",
                            " crew",
                            " is",
                            " 32",
                            " strong",
                            " and",
                            " pulling",
                            " expensive",
                            " equipment",
                            " from",
                            " three",
                            " tractor",
                            " trailers",
                            "\n",
                            "\n",
                            "T",
                            "oma",
                            " began",
                            " working",
                            " on",
                            " playing",
                            " fields",
                            " as",
                            " a",
                            " teenager",
                            ".",
                            " When",
                            " he",
                            " was",
                            " a",
                            " senior",
                            " in",
                            " high",
                            " school",
                            ",",
                            " he",
                            " was",
                            " named",
                            " head",
                            " grounds",
                            "keeper",
                            " for",
                            " the",
                            " Cleveland",
                            " Indians",
                            "\u00e2\u0122",
                            "\u013b",
                            " Class",
                            " A",
                            " affiliate",
                            " in",
                            " Wil",
                            "kes",
                            "-",
                            "B",
                            "arre",
                            ",",
                            " Pa",
                            ".,",
                            " and",
                            " began",
                            " experimenting",
                            " with",
                            " seeds",
                            " and",
                            " sod",
                            ",",
                            " sunlight",
                            " and",
                            " shadows",
                            ",",
                            " learning",
                            " about",
                            " the",
                            " right",
                            " amount",
                            " of",
                            " watering",
                            " and",
                            " when",
                            " to",
                            " get",
                            " creative",
                            ".",
                            " Eventually",
                            " he",
                            " became",
                            " head",
                            " grounds",
                            "keeper",
                            " of",
                            " the",
                            " Kansas",
                            " City",
                            " Athletics",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " where",
                            " then",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "89258",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.448,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.448,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:42.214Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.448,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiuyvy6yh910exe5h4l5ht",
                        "tokens": [
                            " obscure",
                            " \u2013",
                            " l",
                            "up",
                            "in",
                            " seeds",
                            ",",
                            " for",
                            " example",
                            " \u2013",
                            " but",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " of",
                            " many",
                            " dishes",
                            " that",
                            " require",
                            " those",
                            " as",
                            " an",
                            " essential",
                            " ingredient",
                            ".",
                            " Is",
                            " it",
                            " really",
                            " that",
                            " hard",
                            " to",
                            " put",
                            " a",
                            " few",
                            " letters",
                            " on",
                            " a",
                            " menu",
                            "?",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " shame",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " not",
                            " embracing",
                            " it",
                            " as",
                            " an",
                            " opportunity",
                            " to",
                            " be",
                            " more",
                            " creative",
                            ".",
                            " When",
                            " I",
                            " was",
                            " diagnosed",
                            ",",
                            " I",
                            " suddenly",
                            " had",
                            " to",
                            " change",
                            " the",
                            " way",
                            " I",
                            " cooked",
                            " and",
                            " baked",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " now",
                            " more",
                            " adventurous",
                            " in",
                            " the",
                            " kitchen",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " had",
                            " to",
                            " experiment",
                            " with",
                            " recipes",
                            " to",
                            " make",
                            " gluten",
                            "-",
                            "free",
                            " versions",
                            " of",
                            " my",
                            " favourite",
                            " foods",
                            ",",
                            " and",
                            " dairy",
                            "-",
                            "free",
                            " creations",
                            " for",
                            " my",
                            " dad",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " wife",
                            ",",
                            " who",
                            " suffers",
                            " from"
                        ],
                        "dataIndex": null,
                        "index": "89258",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.31,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.31,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.833,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.774,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:19:42.214Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 37.448,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "71445",
            "description": "references to the number and variety of projects and experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4269699156284332,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "71445",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:00:20.682Z",
                "maxActApprox": 18.148,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    71445,
                    18979,
                    65425,
                    6073,
                    2037,
                    59566,
                    56143,
                    58558,
                    83893,
                    21823,
                    52589,
                    74430,
                    98057,
                    36200,
                    28863,
                    63285,
                    17951,
                    9890,
                    35659,
                    89269,
                    56046,
                    49577,
                    55672,
                    9024,
                    66756
                ],
                "topkCosSimValues": [
                    1,
                    0.4799,
                    0.457,
                    0.4516,
                    0.4462,
                    0.4374,
                    0.4287,
                    0.422,
                    0.4037,
                    0.3992,
                    0.399,
                    0.3935,
                    0.393,
                    0.3838,
                    0.3789,
                    0.3769,
                    0.3737,
                    0.3714,
                    0.3684,
                    0.3675,
                    0.362,
                    0.3617,
                    0.3589,
                    0.358,
                    0.3488
                ],
                "neuron_alignment_indices": [
                    71,
                    689,
                    49
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.12,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    71,
                    689,
                    344
                ],
                "correlated_neurons_pearson": [
                    0.051,
                    0.039,
                    0.038
                ],
                "correlated_neurons_l1": [
                    0.044,
                    0.039,
                    0.042
                ],
                "correlated_features_indices": [
                    71393,
                    71370,
                    71380
                ],
                "correlated_features_pearson": [
                    0.012,
                    0.007,
                    0.003
                ],
                "correlated_features_l1": [
                    0.012,
                    0.007,
                    0.004
                ],
                "neg_str": [
                    "efficiency",
                    "isk",
                    "urden",
                    "isky",
                    "racuse",
                    "anwhile",
                    "aurus",
                    "APE",
                    "OIL",
                    " fumes"
                ],
                "neg_values": [
                    -0.764,
                    -0.753,
                    -0.741,
                    -0.685,
                    -0.685,
                    -0.664,
                    -0.646,
                    -0.619,
                    -0.614,
                    -0.606
                ],
                "pos_str": [
                    " civilizations",
                    " unsuccessful",
                    " iterations",
                    " incarn",
                    " successful",
                    " administrations",
                    " occasions",
                    " dozen",
                    " Presidents",
                    " presidents"
                ],
                "pos_values": [
                    0.933,
                    0.908,
                    0.871,
                    0.867,
                    0.84,
                    0.824,
                    0.813,
                    0.812,
                    0.787,
                    0.732
                ],
                "frac_nonzero": 0.00122,
                "freq_hist_data_bar_heights": [
                    683,
                    566,
                    437,
                    351,
                    274,
                    231,
                    191,
                    137,
                    128,
                    117,
                    97,
                    71,
                    72,
                    66,
                    54,
                    43,
                    30,
                    45,
                    33,
                    32,
                    17,
                    22,
                    23,
                    19,
                    13,
                    12,
                    13,
                    9,
                    9,
                    7,
                    6,
                    2,
                    3,
                    5,
                    2,
                    1,
                    4,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.182,
                    0.545,
                    0.908,
                    1.271,
                    1.634,
                    1.997,
                    2.36,
                    2.723,
                    3.086,
                    3.449,
                    3.812,
                    4.175,
                    4.538,
                    4.9,
                    5.263,
                    5.626,
                    5.989,
                    6.352,
                    6.715,
                    7.078,
                    7.441,
                    7.804,
                    8.167,
                    8.53,
                    8.893,
                    9.256,
                    9.619,
                    9.982,
                    10.345,
                    10.708,
                    11.071,
                    11.434,
                    11.796,
                    12.159,
                    12.522,
                    12.885,
                    13.248,
                    13.611,
                    13.974,
                    14.337,
                    14.7,
                    15.063,
                    15.426,
                    15.789,
                    16.152,
                    16.515,
                    16.878,
                    17.241,
                    17.604,
                    17.967
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    1,
                    5,
                    14,
                    17,
                    50,
                    69,
                    123,
                    178,
                    301,
                    489,
                    697,
                    1093,
                    1448,
                    1899,
                    2507,
                    2939,
                    3494,
                    3804,
                    4115,
                    4210,
                    4107,
                    3763,
                    3337,
                    2768,
                    2385,
                    1857,
                    1421,
                    953,
                    713,
                    507,
                    355,
                    222,
                    175,
                    75,
                    62,
                    34,
                    17,
                    16,
                    12,
                    7,
                    2,
                    1,
                    1,
                    3,
                    1,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.747,
                    -0.713,
                    -0.679,
                    -0.645,
                    -0.611,
                    -0.577,
                    -0.543,
                    -0.509,
                    -0.475,
                    -0.441,
                    -0.407,
                    -0.373,
                    -0.339,
                    -0.305,
                    -0.272,
                    -0.238,
                    -0.204,
                    -0.17,
                    -0.136,
                    -0.102,
                    -0.068,
                    -0.034,
                    0,
                    0.034,
                    0.068,
                    0.102,
                    0.136,
                    0.17,
                    0.204,
                    0.238,
                    0.272,
                    0.306,
                    0.339,
                    0.373,
                    0.407,
                    0.441,
                    0.475,
                    0.509,
                    0.543,
                    0.577,
                    0.611,
                    0.645,
                    0.679,
                    0.713,
                    0.747,
                    0.781,
                    0.815,
                    0.849,
                    0.883,
                    0.916
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to counts, quantities, or numerical values",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to the number and variety of projects and experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi677ithn310exwosikav5",
                        "tokens": [
                            "hate",
                            " relationship",
                            " with",
                            " video",
                            " games",
                            " so",
                            " much",
                            " as",
                            " a",
                            " love",
                            "/",
                            "ind",
                            "ifference",
                            " one",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " worked",
                            " on",
                            " several",
                            " game",
                            " projects",
                            " that",
                            " never",
                            " made",
                            " it",
                            " to",
                            " market",
                            ",",
                            " wrote",
                            " a",
                            " tie",
                            "-",
                            "in",
                            " novel",
                            " for",
                            " a",
                            " game",
                            " that",
                            " did",
                            ".",
                            " Occasionally",
                            " my",
                            " work",
                            " has",
                            " inspired",
                            " games",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " had",
                            " nothing",
                            " to",
                            " do",
                            " with",
                            ";",
                            " the",
                            " creators",
                            " of",
                            " Bi",
                            "osh",
                            "ock",
                            " 2",
                            " and",
                            " Torment",
                            ":",
                            " T",
                            "ides",
                            " of",
                            " N",
                            "uman",
                            "era",
                            " cite",
                            " me",
                            " as",
                            " an",
                            " influence",
                            ",",
                            " for",
                            " example",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " vampire",
                            " in",
                            " The",
                            " Witcher",
                            " 3",
                            " named",
                            " Sar",
                            "ast",
                            "i",
                            ".",
                            " Eclipse",
                            " Phase",
                            ",",
                            " the",
                            " paper",
                            "-",
                            "based",
                            " open",
                            "-",
                            "source",
                            " role",
                            "-",
                            "playing",
                            " game",
                            ",",
                            " names",
                            " me",
                            " in",
                            " their",
                            " references",
                            ".",
                            " And",
                            " so",
                            " on",
                            ".",
                            "\n",
                            "\n",
                            "For"
                        ],
                        "dataIndex": null,
                        "index": "71445",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.148,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.148,
                            2.322,
                            3.19,
                            2.517,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.436,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:00:26.585Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.148,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi677kthnn10ex8995wm5n",
                        "tokens": [
                            "hate",
                            " relationship",
                            " with",
                            " video",
                            " games",
                            " so",
                            " much",
                            " as",
                            " a",
                            " love",
                            "/",
                            "ind",
                            "ifference",
                            " one",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " worked",
                            " on",
                            " several",
                            " game",
                            " projects",
                            " that",
                            " never",
                            " made",
                            " it",
                            " to",
                            " market",
                            ",",
                            " wrote",
                            " a",
                            " tie",
                            "-",
                            "in",
                            " novel",
                            " for",
                            " a",
                            " game",
                            " that",
                            " did",
                            ".",
                            " Occasionally",
                            " my",
                            " work",
                            " has",
                            " inspired",
                            " games",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " had",
                            " nothing",
                            " to",
                            " do",
                            " with",
                            ";",
                            " the",
                            " creators",
                            " of",
                            " Bi",
                            "osh",
                            "ock",
                            " 2",
                            " and",
                            " Torment",
                            ":",
                            " T",
                            "ides",
                            " of",
                            " N",
                            "uman",
                            "era",
                            " cite",
                            " me",
                            " as",
                            " an",
                            " influence",
                            ",",
                            " for",
                            " example",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " vampire",
                            " in",
                            " The",
                            " Witcher",
                            " 3",
                            " named",
                            " Sar",
                            "ast",
                            "i",
                            ".",
                            " Eclipse",
                            " Phase",
                            ",",
                            " the",
                            " paper",
                            "-",
                            "based",
                            " open",
                            "-",
                            "source",
                            " role",
                            "-",
                            "playing",
                            " game",
                            ",",
                            " names",
                            " me",
                            " in",
                            " their",
                            " references",
                            ".",
                            " And",
                            " so",
                            " on",
                            ".",
                            "\n",
                            "\n",
                            "For"
                        ],
                        "dataIndex": null,
                        "index": "71445",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.148,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.148,
                            2.322,
                            3.19,
                            2.517,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.436,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:00:26.585Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.518,
                        "binMax": 18.148,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi677ithn410exrq4aj0ua",
                        "tokens": [
                            ".",
                            " A",
                            " 18",
                            "th",
                            " century",
                            " court",
                            " dress",
                            " may",
                            " look",
                            " authentic",
                            " on",
                            " stage",
                            ",",
                            " but",
                            " it",
                            " can",
                            " be",
                            " constructed",
                            " on",
                            " modern",
                            " fabrics",
                            " with",
                            " invisible",
                            " z",
                            "ippers",
                            " to",
                            " allow",
                            " the",
                            " actor",
                            " to",
                            " change",
                            " quickly",
                            " between",
                            " scenes",
                            ".",
                            " Stage",
                            " costumes",
                            " are",
                            " they",
                            " are",
                            " kept",
                            " in",
                            " storage",
                            " and",
                            "/",
                            "or",
                            " recycled",
                            " into",
                            " new",
                            " costumes",
                            ".",
                            " The",
                            " Strat",
                            "ford",
                            " Festival",
                            " in",
                            " Canada",
                            " re",
                            "-",
                            "uses",
                            " costumes",
                            ",",
                            " l",
                            "aces",
                            ",",
                            " tr",
                            "ims",
                            ",",
                            " shoes",
                            ",",
                            " w",
                            "igs",
                            " etc",
                            ".",
                            " There",
                            " are",
                            " a",
                            " few",
                            " important",
                            " costumes",
                            " that",
                            " are",
                            " kept",
                            " for",
                            " publicity",
                            ".",
                            " Every",
                            " few",
                            " years",
                            " the",
                            " costume",
                            " department",
                            " hold",
                            " a",
                            " garage",
                            " sale",
                            " of",
                            " costumes",
                            ",",
                            " l",
                            "aces",
                            ",",
                            " shoes",
                            ",",
                            " and",
                            " grab",
                            " bags",
                            " of",
                            " leftover",
                            " supplies",
                            ".",
                            " I",
                            " have",
                            " been",
                            " to",
                            " several",
                            " of",
                            " these",
                            " sales",
                            " and",
                            " know",
                            " people",
                            " who",
                            " work",
                            " in",
                            " the",
                            " costume"
                        ],
                        "dataIndex": null,
                        "index": "71445",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.932,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.932,
                            7.329,
                            3.378,
                            0.593,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:00:26.585Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.148,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "30517",
            "description": "questions about the origin and development of projects or ideas",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.42281786067379423,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "30517",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:09:14.826Z",
                "maxActApprox": 32.729,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30517,
                    10636,
                    28787,
                    80332,
                    77821,
                    27516,
                    67472,
                    37723,
                    19276,
                    48997,
                    6466,
                    7904,
                    10308,
                    79697,
                    41089,
                    22293,
                    1857,
                    58950,
                    45403,
                    54738,
                    6174,
                    45021,
                    20743,
                    32883,
                    31669
                ],
                "topkCosSimValues": [
                    1,
                    0.5751,
                    0.4981,
                    0.4551,
                    0.4413,
                    0.4352,
                    0.4284,
                    0.4202,
                    0.4157,
                    0.4153,
                    0.4121,
                    0.4076,
                    0.3919,
                    0.3866,
                    0.3825,
                    0.3786,
                    0.3744,
                    0.3635,
                    0.3579,
                    0.3575,
                    0.355,
                    0.3497,
                    0.349,
                    0.3463,
                    0.3404
                ],
                "neuron_alignment_indices": [
                    368,
                    665,
                    197
                ],
                "neuron_alignment_values": [
                    0.107,
                    0.086,
                    0.084
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    665,
                    368,
                    504
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.028,
                    0.02
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.03,
                    0.019
                ],
                "correlated_features_indices": [
                    30406,
                    30452,
                    30429
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "illation",
                    "rored",
                    " Bei",
                    " balcon",
                    " fixme",
                    "elli",
                    "illin",
                    "inder",
                    "lator",
                    "cour"
                ],
                "neg_values": [
                    -0.738,
                    -0.656,
                    -0.656,
                    -0.639,
                    -0.631,
                    -0.605,
                    -0.599,
                    -0.59,
                    -0.589,
                    -0.584
                ],
                "pos_str": [
                    " conception",
                    " fixation",
                    " existence",
                    " genesis",
                    "agascar",
                    "omon",
                    "zsche",
                    "oslov",
                    " fateful",
                    " evolve"
                ],
                "pos_values": [
                    0.679,
                    0.678,
                    0.676,
                    0.675,
                    0.644,
                    0.627,
                    0.604,
                    0.6,
                    0.596,
                    0.596
                ],
                "frac_nonzero": 0.00101,
                "freq_hist_data_bar_heights": [
                    950,
                    574,
                    378,
                    264,
                    203,
                    154,
                    116,
                    75,
                    72,
                    49,
                    33,
                    28,
                    24,
                    25,
                    28,
                    26,
                    19,
                    13,
                    9,
                    20,
                    18,
                    8,
                    9,
                    11,
                    5,
                    6,
                    7,
                    5,
                    12,
                    3,
                    4,
                    3,
                    0,
                    5,
                    3,
                    1,
                    4,
                    0,
                    2,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.327,
                    0.982,
                    1.637,
                    2.291,
                    2.946,
                    3.6,
                    4.255,
                    4.909,
                    5.564,
                    6.219,
                    6.873,
                    7.528,
                    8.182,
                    8.837,
                    9.491,
                    10.146,
                    10.801,
                    11.455,
                    12.11,
                    12.764,
                    13.419,
                    14.073,
                    14.728,
                    15.383,
                    16.037,
                    16.692,
                    17.346,
                    18.001,
                    18.655,
                    19.31,
                    19.965,
                    20.619,
                    21.274,
                    21.928,
                    22.583,
                    23.237,
                    23.892,
                    24.547,
                    25.201,
                    25.856,
                    26.51,
                    27.165,
                    27.819,
                    28.474,
                    29.129,
                    29.783,
                    30.438,
                    31.092,
                    31.747,
                    32.401
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    2,
                    10,
                    12,
                    11,
                    36,
                    70,
                    76,
                    118,
                    162,
                    240,
                    374,
                    571,
                    743,
                    1076,
                    1353,
                    1796,
                    2198,
                    2553,
                    3169,
                    3351,
                    3450,
                    3658,
                    3658,
                    3615,
                    3301,
                    3021,
                    2581,
                    2097,
                    1795,
                    1377,
                    1087,
                    817,
                    578,
                    422,
                    286,
                    214,
                    143,
                    88,
                    52,
                    36,
                    20,
                    17,
                    7,
                    5,
                    2,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.724,
                    -0.696,
                    -0.667,
                    -0.639,
                    -0.611,
                    -0.582,
                    -0.554,
                    -0.526,
                    -0.497,
                    -0.469,
                    -0.441,
                    -0.412,
                    -0.384,
                    -0.356,
                    -0.327,
                    -0.299,
                    -0.271,
                    -0.242,
                    -0.214,
                    -0.186,
                    -0.157,
                    -0.129,
                    -0.101,
                    -0.072,
                    -0.044,
                    -0.016,
                    0.013,
                    0.041,
                    0.069,
                    0.098,
                    0.126,
                    0.154,
                    0.183,
                    0.211,
                    0.239,
                    0.268,
                    0.296,
                    0.324,
                    0.353,
                    0.381,
                    0.409,
                    0.438,
                    0.466,
                    0.494,
                    0.523,
                    0.551,
                    0.579,
                    0.608,
                    0.636,
                    0.664
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " questions regarding origins and processes of events or projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "questions about the origin and development of projects or ideas",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggckriyf8910exut8kuv8f",
                        "tokens": [
                            " said",
                            ".",
                            " \"",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " as",
                            " good",
                            " a",
                            " motto",
                            " for",
                            " a",
                            " software",
                            " company",
                            " as",
                            " any",
                            ".\"",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "What",
                            " I",
                            " hope",
                            " people",
                            " pick",
                            " up",
                            " on",
                            " is",
                            " that",
                            " in",
                            " this",
                            " scenario",
                            ",",
                            " we",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " Bond",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " W",
                            "isk",
                            "us",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " the",
                            " people",
                            " who",
                            " make",
                            " all",
                            " the",
                            " great",
                            " tools",
                            " for",
                            " the",
                            " agents",
                            " to",
                            " use",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " look",
                            " at",
                            " the",
                            " formation",
                            " of",
                            " Q",
                            " Branch",
                            " and",
                            " the",
                            " creation",
                            " of",
                            " Ves",
                            "per",
                            " in",
                            " the",
                            " words",
                            " of",
                            " its",
                            " three",
                            " creators",
                            ".",
                            "\n",
                            "\n",
                            "Mac",
                            "world",
                            ":",
                            " How",
                            " did",
                            " this",
                            " project",
                            " come",
                            " about",
                            "?",
                            " When",
                            " did",
                            " you",
                            " decide",
                            " to",
                            " work",
                            " together",
                            "?",
                            " Did",
                            " the",
                            " idea",
                            " for",
                            " Ves",
                            "per",
                            " appear",
                            " first"
                        ],
                        "dataIndex": null,
                        "index": "30517",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.729,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.496,
                            0.631,
                            0,
                            0,
                            0,
                            0.029,
                            3.03,
                            0.037,
                            0,
                            0,
                            0.246,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.437,
                            11.002,
                            9.379,
                            30.1,
                            32.729,
                            4.015,
                            2.575,
                            2.045,
                            9.208,
                            12.12,
                            2.921,
                            0,
                            0.702,
                            0.049,
                            0,
                            0,
                            3.791,
                            0.115,
                            0,
                            0,
                            0.225,
                            2.609
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:09:24.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 32.729,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggckriyf8a10exl6m22u8f",
                        "tokens": [
                            " said",
                            ".",
                            " \"",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " as",
                            " good",
                            " a",
                            " motto",
                            " for",
                            " a",
                            " software",
                            " company",
                            " as",
                            " any",
                            ".\"",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "What",
                            " I",
                            " hope",
                            " people",
                            " pick",
                            " up",
                            " on",
                            " is",
                            " that",
                            " in",
                            " this",
                            " scenario",
                            ",",
                            " we",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " Bond",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " W",
                            "isk",
                            "us",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " the",
                            " people",
                            " who",
                            " make",
                            " all",
                            " the",
                            " great",
                            " tools",
                            " for",
                            " the",
                            " agents",
                            " to",
                            " use",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " look",
                            " at",
                            " the",
                            " formation",
                            " of",
                            " Q",
                            " Branch",
                            " and",
                            " the",
                            " creation",
                            " of",
                            " Ves",
                            "per",
                            " in",
                            " the",
                            " words",
                            " of",
                            " its",
                            " three",
                            " creators",
                            ".",
                            "\n",
                            "\n",
                            "Mac",
                            "world",
                            ":",
                            " How",
                            " did",
                            " this",
                            " project",
                            " come",
                            " about",
                            "?",
                            " When",
                            " did",
                            " you",
                            " decide",
                            " to",
                            " work",
                            " together",
                            "?",
                            " Did",
                            " the",
                            " idea",
                            " for",
                            " Ves",
                            "per",
                            " appear",
                            " first"
                        ],
                        "dataIndex": null,
                        "index": "30517",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.729,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.496,
                            0.631,
                            0,
                            0,
                            0,
                            0.029,
                            3.03,
                            0.037,
                            0,
                            0,
                            0.246,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.437,
                            11.002,
                            9.379,
                            30.1,
                            32.729,
                            4.015,
                            2.575,
                            2.045,
                            9.208,
                            12.12,
                            2.921,
                            0,
                            0.702,
                            0.049,
                            0,
                            0,
                            3.791,
                            0.115,
                            0,
                            0,
                            0.225,
                            2.609
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:09:24.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 32.729,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggckrkyf8u10exd526acay",
                        "tokens": [
                            " said",
                            ".",
                            " \"",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " as",
                            " good",
                            " a",
                            " motto",
                            " for",
                            " a",
                            " software",
                            " company",
                            " as",
                            " any",
                            ".\"",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "What",
                            " I",
                            " hope",
                            " people",
                            " pick",
                            " up",
                            " on",
                            " is",
                            " that",
                            " in",
                            " this",
                            " scenario",
                            ",",
                            " we",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " Bond",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " W",
                            "isk",
                            "us",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " the",
                            " people",
                            " who",
                            " make",
                            " all",
                            " the",
                            " great",
                            " tools",
                            " for",
                            " the",
                            " agents",
                            " to",
                            " use",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " look",
                            " at",
                            " the",
                            " formation",
                            " of",
                            " Q",
                            " Branch",
                            " and",
                            " the",
                            " creation",
                            " of",
                            " Ves",
                            "per",
                            " in",
                            " the",
                            " words",
                            " of",
                            " its",
                            " three",
                            " creators",
                            ".",
                            "\n",
                            "\n",
                            "Mac",
                            "world",
                            ":",
                            " How",
                            " did",
                            " this",
                            " project",
                            " come",
                            " about",
                            "?",
                            " When",
                            " did",
                            " you",
                            " decide",
                            " to",
                            " work",
                            " together",
                            "?",
                            " Did",
                            " the",
                            " idea",
                            " for",
                            " Ves",
                            "per",
                            " appear",
                            " first"
                        ],
                        "dataIndex": null,
                        "index": "30517",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.729,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.496,
                            0.631,
                            0,
                            0,
                            0,
                            0.029,
                            3.03,
                            0.037,
                            0,
                            0,
                            0.246,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.437,
                            11.002,
                            9.379,
                            30.1,
                            32.729,
                            4.015,
                            2.575,
                            2.045,
                            9.208,
                            12.12,
                            2.921,
                            0,
                            0.702,
                            0.049,
                            0,
                            0,
                            3.791,
                            0.115,
                            0,
                            0,
                            0.225,
                            2.609
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:09:24.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 26.183,
                        "binMax": 32.729,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.42211973667144775,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "24144",
            "description": " activities related to practical skills or tasks",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4089222550392151,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "24144",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:42:05.035Z",
                "maxActApprox": 16.154,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24144,
                    28025,
                    37774,
                    39148,
                    16232,
                    14135,
                    9445,
                    31299,
                    33929,
                    9355,
                    34418,
                    15343,
                    7136,
                    38404,
                    18111,
                    22557,
                    18693,
                    8529,
                    13683,
                    43282,
                    43612,
                    7460,
                    36658,
                    41555,
                    7271
                ],
                "topkCosSimValues": [
                    1,
                    0.7273,
                    0.691,
                    0.6308,
                    0.6214,
                    0.619,
                    0.609,
                    0.6027,
                    0.5776,
                    0.5692,
                    0.569,
                    0.5689,
                    0.5674,
                    0.5642,
                    0.5528,
                    0.5433,
                    0.5398,
                    0.5334,
                    0.5333,
                    0.5242,
                    0.5124,
                    0.5082,
                    0.4997,
                    0.4988,
                    0.4823
                ],
                "neuron_alignment_indices": [
                    216,
                    481,
                    17
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.107,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    216,
                    288,
                    524
                ],
                "correlated_neurons_pearson": [
                    0.047,
                    0.046,
                    0.039
                ],
                "correlated_neurons_l1": [
                    0.048,
                    0.052,
                    0.041
                ],
                "correlated_features_indices": [
                    24032,
                    24119,
                    24027
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "ivic",
                    "uate",
                    "ifies",
                    "zynski",
                    "udos",
                    "ridges",
                    "ighed",
                    "rition",
                    "mented",
                    "iosis"
                ],
                "neg_values": [
                    -0.793,
                    -0.776,
                    -0.765,
                    -0.747,
                    -0.747,
                    -0.747,
                    -0.737,
                    -0.719,
                    -0.714,
                    -0.704
                ],
                "pos_str": [
                    " prowess",
                    " spree",
                    " apparatus",
                    " process",
                    " mechanism",
                    " habits",
                    " technique",
                    " ability",
                    " regimen",
                    " experience"
                ],
                "pos_values": [
                    1.148,
                    1.091,
                    1.075,
                    1.056,
                    1.028,
                    1.014,
                    1.011,
                    0.971,
                    0.95,
                    0.94
                ],
                "frac_nonzero": 0.00148,
                "freq_hist_data_bar_heights": [
                    463,
                    377,
                    355,
                    308,
                    271,
                    244,
                    219,
                    204,
                    170,
                    171,
                    144,
                    116,
                    115,
                    106,
                    114,
                    131,
                    94,
                    84,
                    88,
                    83,
                    79,
                    71,
                    61,
                    55,
                    50,
                    50,
                    57,
                    48,
                    43,
                    40,
                    34,
                    20,
                    23,
                    24,
                    28,
                    18,
                    11,
                    16,
                    15,
                    11,
                    6,
                    5,
                    3,
                    7,
                    6,
                    3,
                    2,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.163,
                    0.486,
                    0.809,
                    1.132,
                    1.455,
                    1.778,
                    2.101,
                    2.424,
                    2.747,
                    3.07,
                    3.393,
                    3.716,
                    4.039,
                    4.362,
                    4.685,
                    5.008,
                    5.331,
                    5.654,
                    5.978,
                    6.301,
                    6.624,
                    6.947,
                    7.27,
                    7.593,
                    7.916,
                    8.239,
                    8.562,
                    8.885,
                    9.208,
                    9.531,
                    9.854,
                    10.177,
                    10.5,
                    10.823,
                    11.146,
                    11.469,
                    11.792,
                    12.115,
                    12.438,
                    12.761,
                    13.085,
                    13.408,
                    13.731,
                    14.054,
                    14.377,
                    14.7,
                    15.023,
                    15.346,
                    15.669,
                    15.992
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    16,
                    22,
                    39,
                    67,
                    128,
                    164,
                    277,
                    414,
                    527,
                    770,
                    1068,
                    1470,
                    1945,
                    2709,
                    3145,
                    3717,
                    4045,
                    4238,
                    4107,
                    3775,
                    3388,
                    2812,
                    2378,
                    1889,
                    1528,
                    1272,
                    1085,
                    813,
                    635,
                    483,
                    362,
                    264,
                    180,
                    166,
                    112,
                    78,
                    55,
                    32,
                    25,
                    19,
                    10,
                    10,
                    2,
                    1,
                    3,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.774,
                    -0.735,
                    -0.696,
                    -0.657,
                    -0.618,
                    -0.58,
                    -0.541,
                    -0.502,
                    -0.463,
                    -0.424,
                    -0.385,
                    -0.347,
                    -0.308,
                    -0.269,
                    -0.23,
                    -0.191,
                    -0.152,
                    -0.114,
                    -0.075,
                    -0.036,
                    0.003,
                    0.042,
                    0.081,
                    0.119,
                    0.158,
                    0.197,
                    0.236,
                    0.275,
                    0.314,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.585,
                    0.624,
                    0.663,
                    0.702,
                    0.741,
                    0.779,
                    0.818,
                    0.857,
                    0.896,
                    0.935,
                    0.974,
                    1.012,
                    1.051,
                    1.09,
                    1.129
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " activities related to practical skills or tasks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5omozxw96i6663x2wv8mt",
                        "tokens": [
                            " misses",
                            " the",
                            " point",
                            " utterly",
                            " and",
                            " completely",
                            ".",
                            " Psychological",
                            " research",
                            " like",
                            " this",
                            " first",
                            " becomes",
                            " really",
                            " value",
                            "able",
                            " when",
                            " you",
                            " stop",
                            " thinking",
                            " about",
                            " yourself",
                            " and",
                            " start",
                            " asking",
                            " how",
                            " this",
                            " can",
                            " help",
                            " you",
                            " understand",
                            " other",
                            " people",
                            ".",
                            " If",
                            " you",
                            " design",
                            " API",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " and",
                            " base",
                            " your",
                            " design",
                            " on",
                            " what",
                            " makes",
                            " most",
                            " sense",
                            " to",
                            " your",
                            " own",
                            " coding",
                            " style",
                            ",",
                            " you",
                            " will",
                            " create",
                            " something",
                            " that",
                            " two",
                            " thirds",
                            " of",
                            " your",
                            " audience",
                            " will",
                            " find",
                            " difficult",
                            " to",
                            " use",
                            ".",
                            " Even",
                            " if",
                            " you",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " like",
                            " or",
                            " agree",
                            " with",
                            " their",
                            " style",
                            ".",
                            "\n",
                            "\n",
                            "Gr",
                            "anted",
                            ",",
                            " that",
                            " makes",
                            " the",
                            " assumption",
                            " that",
                            " programmers",
                            " are",
                            " always",
                            " equally",
                            " distributed",
                            " among",
                            " styles",
                            ",",
                            " which",
                            " is",
                            " a",
                            " pretty",
                            " wild",
                            " assumption",
                            ".",
                            " The",
                            " point",
                            " is",
                            " that",
                            " other",
                            " people",
                            " are",
                            " more",
                            " likely",
                            " to",
                            " think",
                            " differently",
                            " than",
                            " similarly",
                            " to",
                            " you"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.154,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5omozxw97i666i7pgkm7w",
                        "tokens": [
                            " A",
                            " fantastic",
                            " collection",
                            " of",
                            " punk",
                            " music",
                            ",",
                            " ranging",
                            " from",
                            " scream",
                            "o",
                            " to",
                            " post",
                            "-",
                            "hard",
                            "core",
                            " to",
                            " pop",
                            "-",
                            "punk",
                            " along",
                            " with",
                            " any",
                            " other",
                            " notable",
                            " releases",
                            " that",
                            " can",
                            " somehow",
                            " shoe",
                            "horn",
                            " themselves",
                            " into",
                            " the",
                            " canon",
                            ".",
                            " If",
                            " this",
                            " blog",
                            " appeals",
                            " to",
                            " your",
                            " listening",
                            " tastes",
                            " then",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " make",
                            " no",
                            " qual",
                            "ms",
                            " as",
                            " to",
                            " how",
                            " Death",
                            " Gri",
                            "ps",
                            " are",
                            " on",
                            " there",
                            " or",
                            " how",
                            " Sunny",
                            " Day",
                            " Real",
                            " Estate",
                            " or",
                            " Texas",
                            " Is",
                            " the",
                            " Reason",
                            " belong",
                            " next",
                            " to",
                            " entries",
                            " about",
                            " Jaw",
                            "breaker",
                            " and",
                            " Touch",
                            "\u00c3\u00a9",
                            " Am",
                            "or",
                            "\u00c3\u00a9",
                            ".",
                            " It",
                            " just",
                            " makes",
                            " sense",
                            ".",
                            "\n",
                            "\n",
                            "Why",
                            ":",
                            " What",
                            " Sophie",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Floor",
                            "boards",
                            " excel",
                            " at",
                            " is",
                            " providing",
                            " a",
                            " fantastic",
                            " point",
                            " of",
                            " reference",
                            " for",
                            " people",
                            " looking",
                            " to",
                            " get",
                            " themselves",
                            " started",
                            " along",
                            " with",
                            " shining",
                            " a",
                            " light",
                            " on",
                            " lesser",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.803,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.803,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5omozxw98i6668l1l8vwl",
                        "tokens": [
                            " at",
                            " Bore",
                            "fts",
                            " had",
                            " met",
                            " the",
                            " challenge",
                            " by",
                            " taking",
                            " a",
                            " non",
                            "-",
                            "rad",
                            "ler",
                            " and",
                            " call",
                            " it",
                            " their",
                            " rad",
                            "ler",
                            ".",
                            " There",
                            " were",
                            " a",
                            " few",
                            " interesting",
                            " and",
                            " tasty",
                            " fruit",
                            " beers",
                            " among",
                            " them",
                            ",",
                            " but",
                            " they",
                            " had",
                            " very",
                            " little",
                            " in",
                            " common",
                            ".",
                            " I",
                            " really",
                            " hope",
                            " that",
                            " the",
                            " challenge",
                            " next",
                            " year",
                            " is",
                            " something",
                            " that",
                            " challenges",
                            " the",
                            " brewers",
                            " on",
                            " their",
                            " brewing",
                            " skills",
                            " and",
                            " not",
                            " their",
                            " imagination",
                            ".",
                            " Like",
                            " a",
                            " single",
                            " hop",
                            " pale",
                            " ale",
                            ",",
                            " a",
                            " crisp",
                            ",",
                            " clean",
                            " p",
                            "ils",
                            "ner",
                            ",",
                            " or",
                            " a",
                            " 5",
                            "%",
                            " p",
                            "orter",
                            ".",
                            " That",
                            " would",
                            " be",
                            " much",
                            " more",
                            " interesting",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " food",
                            " served",
                            " at",
                            " the",
                            " Bore",
                            "fts",
                            " Beer",
                            " Festival",
                            " has",
                            " definitely",
                            " also",
                            " evolved",
                            ",",
                            " from",
                            " a",
                            " choice",
                            " of",
                            " two",
                            " different",
                            " sandwiches",
                            " (",
                            "if",
                            " memory",
                            " serves",
                            " me",
                            " right",
                            "),",
                            " to",
                            " several",
                            " food",
                            " stalls"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.677,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.221,
                            0,
                            0,
                            15.677,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "54328",
            "description": " references to various types of projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4081685543060303,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "54328",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:41:47.851Z",
                "maxActApprox": 31.294,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    54328,
                    12105,
                    33904,
                    91699,
                    43512,
                    41802,
                    94316,
                    28323,
                    8306,
                    92359,
                    2288,
                    52492,
                    80903,
                    60953,
                    85392,
                    16150,
                    95555,
                    25165,
                    57909,
                    43656,
                    39306,
                    91773,
                    49967,
                    47582,
                    83963
                ],
                "topkCosSimValues": [
                    1,
                    0.7182,
                    0.6621,
                    0.5936,
                    0.5569,
                    0.5222,
                    0.4908,
                    0.489,
                    0.4883,
                    0.4744,
                    0.4546,
                    0.4531,
                    0.45,
                    0.4466,
                    0.4461,
                    0.4423,
                    0.4397,
                    0.437,
                    0.4342,
                    0.4287,
                    0.4273,
                    0.4271,
                    0.4262,
                    0.4246,
                    0.4161
                ],
                "neuron_alignment_indices": [
                    459,
                    679,
                    447
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.11,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    459,
                    651,
                    670
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.019,
                    0.017
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.02,
                    0.017
                ],
                "correlated_features_indices": [
                    54290,
                    54301,
                    54317
                ],
                "correlated_features_pearson": [
                    0.017,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.017,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "osate",
                    "\u00e3\u0124\u00a6\u00e3\u0124\u00b9",
                    "DOS",
                    "lua",
                    "asus",
                    "gel",
                    "Ul",
                    "phia",
                    "\u00e3\u0123\u0126",
                    "las"
                ],
                "neg_values": [
                    -1.003,
                    -0.854,
                    -0.777,
                    -0.722,
                    -0.663,
                    -0.658,
                    -0.654,
                    -0.645,
                    -0.637,
                    -0.609
                ],
                "pos_str": [
                    " undertaken",
                    " projects",
                    " underway",
                    " involving",
                    "projects",
                    " abroad",
                    " Projects",
                    " funded",
                    " Gutenberg",
                    "afety"
                ],
                "pos_values": [
                    1.11,
                    1.069,
                    0.935,
                    0.93,
                    0.894,
                    0.883,
                    0.869,
                    0.855,
                    0.824,
                    0.799
                ],
                "frac_nonzero": 0.00023,
                "freq_hist_data_bar_heights": [
                    111,
                    88,
                    59,
                    47,
                    29,
                    32,
                    22,
                    21,
                    21,
                    18,
                    14,
                    7,
                    11,
                    10,
                    8,
                    3,
                    8,
                    5,
                    3,
                    4,
                    3,
                    1,
                    3,
                    3,
                    2,
                    0,
                    1,
                    9,
                    8,
                    4,
                    6,
                    5,
                    11,
                    13,
                    11,
                    13,
                    4,
                    12,
                    12,
                    16,
                    9,
                    15,
                    9,
                    10,
                    9,
                    4,
                    1,
                    2,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.314,
                    0.939,
                    1.565,
                    2.191,
                    2.817,
                    3.443,
                    4.069,
                    4.695,
                    5.32,
                    5.946,
                    6.572,
                    7.198,
                    7.824,
                    8.45,
                    9.076,
                    9.702,
                    10.327,
                    10.953,
                    11.579,
                    12.205,
                    12.831,
                    13.457,
                    14.083,
                    14.708,
                    15.334,
                    15.96,
                    16.586,
                    17.212,
                    17.838,
                    18.464,
                    19.09,
                    19.715,
                    20.341,
                    20.967,
                    21.593,
                    22.219,
                    22.845,
                    23.471,
                    24.097,
                    24.722,
                    25.348,
                    25.974,
                    26.6,
                    27.226,
                    27.852,
                    28.478,
                    29.103,
                    29.729,
                    30.355,
                    30.981
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    5,
                    10,
                    24,
                    65,
                    78,
                    181,
                    297,
                    573,
                    848,
                    1429,
                    1996,
                    2886,
                    3629,
                    4447,
                    5067,
                    5412,
                    5165,
                    4656,
                    3770,
                    3025,
                    2199,
                    1570,
                    1029,
                    727,
                    435,
                    290,
                    176,
                    102,
                    60,
                    34,
                    22,
                    18,
                    10,
                    7,
                    2,
                    2,
                    3,
                    2,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.982,
                    -0.939,
                    -0.897,
                    -0.855,
                    -0.812,
                    -0.77,
                    -0.728,
                    -0.686,
                    -0.643,
                    -0.601,
                    -0.559,
                    -0.517,
                    -0.474,
                    -0.432,
                    -0.39,
                    -0.348,
                    -0.305,
                    -0.263,
                    -0.221,
                    -0.179,
                    -0.136,
                    -0.094,
                    -0.052,
                    -0.01,
                    0.033,
                    0.075,
                    0.117,
                    0.159,
                    0.202,
                    0.244,
                    0.286,
                    0.328,
                    0.371,
                    0.413,
                    0.455,
                    0.497,
                    0.54,
                    0.582,
                    0.624,
                    0.667,
                    0.709,
                    0.751,
                    0.793,
                    0.836,
                    0.878,
                    0.92,
                    0.962,
                    1.005,
                    1.047,
                    1.089
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to various projects and developments",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to various types of projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghiabugh5x10exkdz015kr",
                        "tokens": [
                            "-",
                            "s",
                            "ought",
                            " rail",
                            " connection",
                            " to",
                            " LA",
                            "X",
                            " gets",
                            " closer",
                            " to",
                            " reality",
                            ",",
                            " Metro",
                            " is",
                            " already",
                            " considering",
                            " ways",
                            " to",
                            " speed",
                            " up",
                            " the",
                            " trip",
                            " from",
                            " the",
                            " airport",
                            " to",
                            " Downtown",
                            " Los",
                            " Angeles",
                            ".",
                            "\n",
                            "\n",
                            "During",
                            " a",
                            " panel",
                            " discussion",
                            " at",
                            " Urban",
                            " Land",
                            " Institute",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Future",
                            " Build",
                            " conference",
                            ",",
                            " Metro",
                            " CEO",
                            " Phil",
                            " Washington",
                            " revealed",
                            " the",
                            " transit",
                            " agency",
                            " might",
                            " explore",
                            " adding",
                            " an",
                            " express",
                            " train",
                            " that",
                            " would",
                            " shuttle",
                            " passengers",
                            " between",
                            " LA",
                            "X",
                            " and",
                            " Union",
                            " Station",
                            ".",
                            "\n",
                            "\n",
                            "Metro",
                            " spokesperson",
                            " Dave",
                            " S",
                            "ot",
                            "ero",
                            " tells",
                            " Cur",
                            "bed",
                            " that",
                            " studies",
                            " of",
                            " the",
                            " project",
                            " could",
                            " be",
                            " funded",
                            " through",
                            " Measure",
                            " M",
                            ",",
                            " which",
                            " sets",
                            " aside",
                            " $",
                            "20",
                            " million",
                            " in",
                            " seed",
                            " money",
                            " for",
                            " research",
                            " into",
                            " \u00e2\u0122",
                            "\u013e",
                            "vision",
                            "ary",
                            " projects",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Measure",
                            " M",
                            " seed",
                            " money",
                            " will",
                            " allow",
                            " @",
                            "met",
                            "rol"
                        ],
                        "dataIndex": null,
                        "index": "54328",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.294,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.294,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:50.866Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.294,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghiabwgh6l10exipz2fr9x",
                        "tokens": [
                            "-",
                            "s",
                            "ought",
                            " rail",
                            " connection",
                            " to",
                            " LA",
                            "X",
                            " gets",
                            " closer",
                            " to",
                            " reality",
                            ",",
                            " Metro",
                            " is",
                            " already",
                            " considering",
                            " ways",
                            " to",
                            " speed",
                            " up",
                            " the",
                            " trip",
                            " from",
                            " the",
                            " airport",
                            " to",
                            " Downtown",
                            " Los",
                            " Angeles",
                            ".",
                            "\n",
                            "\n",
                            "During",
                            " a",
                            " panel",
                            " discussion",
                            " at",
                            " Urban",
                            " Land",
                            " Institute",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Future",
                            " Build",
                            " conference",
                            ",",
                            " Metro",
                            " CEO",
                            " Phil",
                            " Washington",
                            " revealed",
                            " the",
                            " transit",
                            " agency",
                            " might",
                            " explore",
                            " adding",
                            " an",
                            " express",
                            " train",
                            " that",
                            " would",
                            " shuttle",
                            " passengers",
                            " between",
                            " LA",
                            "X",
                            " and",
                            " Union",
                            " Station",
                            ".",
                            "\n",
                            "\n",
                            "Metro",
                            " spokesperson",
                            " Dave",
                            " S",
                            "ot",
                            "ero",
                            " tells",
                            " Cur",
                            "bed",
                            " that",
                            " studies",
                            " of",
                            " the",
                            " project",
                            " could",
                            " be",
                            " funded",
                            " through",
                            " Measure",
                            " M",
                            ",",
                            " which",
                            " sets",
                            " aside",
                            " $",
                            "20",
                            " million",
                            " in",
                            " seed",
                            " money",
                            " for",
                            " research",
                            " into",
                            " \u00e2\u0122",
                            "\u013e",
                            "vision",
                            "ary",
                            " projects",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Measure",
                            " M",
                            " seed",
                            " money",
                            " will",
                            " allow",
                            " @",
                            "met",
                            "rol"
                        ],
                        "dataIndex": null,
                        "index": "54328",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.294,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.294,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:50.866Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 25.035,
                        "binMax": 31.294,
                        "binContains": 2e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghiabugh5y10ex5jnnckse",
                        "tokens": [
                            " Solutions",
                            ",",
                            " an",
                            " information",
                            " technology",
                            " company",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " A",
                            ".",
                            "D",
                            ".",
                            " Morgan",
                            " Corporation",
                            " employs",
                            " 50",
                            " people",
                            " and",
                            " has",
                            " annual",
                            " revenues",
                            " of",
                            " about",
                            " $",
                            "80",
                            " million",
                            ",",
                            " according",
                            " to",
                            " its",
                            " website",
                            ".",
                            " The",
                            " company",
                            " lists",
                            " more",
                            " than",
                            " 130",
                            " projects",
                            " and",
                            " developments",
                            ".",
                            " Imp",
                            "ressive",
                            ",",
                            " no",
                            " doubt",
                            ".",
                            " But",
                            " the",
                            " list",
                            " is",
                            " nearly",
                            " all",
                            " government",
                            " projects",
                            ".",
                            " [...]",
                            " \"",
                            "We",
                            "'re",
                            " not",
                            " going",
                            " to",
                            " have",
                            " an",
                            " opportunity",
                            " in",
                            " the",
                            " private",
                            " sector",
                            ",",
                            " they",
                            " have",
                            " a",
                            " tendency",
                            " to",
                            " use",
                            " lump",
                            " sum",
                            ",",
                            " low",
                            " bid",
                            ",\"",
                            " Smith",
                            " said",
                            ",",
                            " explaining",
                            " how",
                            " government",
                            " bids",
                            " work",
                            ".",
                            " \"",
                            "So",
                            " by",
                            " virtue",
                            " of",
                            " what",
                            " it",
                            " is",
                            " that",
                            " we",
                            " do",
                            ",",
                            " we",
                            " go",
                            " to",
                            " the",
                            " client",
                            " base",
                            " that",
                            " purchases",
                            " construction",
                            " services",
                            " that",
                            " way",
                            ".\"",
                            "\n",
                            "\n",
                            "As",
                            " for",
                            " Ramos",
                            ",",
                            " his"
                        ],
                        "dataIndex": null,
                        "index": "54328",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.928,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.602,
                            0,
                            4.749,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.928,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:50.866Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.294,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21740",
            "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4024740813687999,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21740",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:12:34.087Z",
                "maxActApprox": 36.416,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21740,
                    3088,
                    21487,
                    12947,
                    16697,
                    2946,
                    20433,
                    251,
                    4001,
                    17235,
                    4407,
                    4717,
                    23503,
                    14215,
                    6124,
                    13657,
                    2197,
                    12026,
                    13434,
                    12886,
                    7963,
                    17224,
                    6857,
                    13339,
                    10095
                ],
                "topkCosSimValues": [
                    1,
                    0.5718,
                    0.5358,
                    0.419,
                    0.4171,
                    0.4083,
                    0.3814,
                    0.3811,
                    0.37,
                    0.3452,
                    0.3149,
                    0.3122,
                    0.3097,
                    0.3061,
                    0.3036,
                    0.2992,
                    0.298,
                    0.295,
                    0.2895,
                    0.2846,
                    0.2834,
                    0.283,
                    0.2741,
                    0.2639,
                    0.2629
                ],
                "neuron_alignment_indices": [
                    502,
                    363,
                    741
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.109,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    502,
                    566,
                    718
                ],
                "correlated_neurons_pearson": [
                    0.06,
                    0.05,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.058,
                    0.051,
                    0.041
                ],
                "correlated_features_indices": [
                    21711,
                    21727,
                    21757
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.009,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "umption",
                    " completion",
                    " Proced",
                    " Squid",
                    " sorcery",
                    " summary",
                    "allo",
                    " Volcano",
                    " Spur",
                    " Biology"
                ],
                "neg_values": [
                    -0.638,
                    -0.622,
                    -0.612,
                    -0.611,
                    -0.607,
                    -0.6,
                    -0.596,
                    -0.584,
                    -0.584,
                    -0.582
                ],
                "pos_str": [
                    " adore",
                    " admire",
                    " trusts",
                    " trusted",
                    " sidx",
                    " affection",
                    " befriend",
                    "igl",
                    "assadors",
                    " interviewed"
                ],
                "pos_values": [
                    0.954,
                    0.9,
                    0.865,
                    0.854,
                    0.8,
                    0.797,
                    0.796,
                    0.789,
                    0.779,
                    0.778
                ],
                "frac_nonzero": 0.00222,
                "freq_hist_data_bar_heights": [
                    1873,
                    1215,
                    804,
                    548,
                    393,
                    305,
                    251,
                    190,
                    178,
                    120,
                    116,
                    96,
                    84,
                    68,
                    67,
                    58,
                    59,
                    45,
                    49,
                    47,
                    27,
                    30,
                    25,
                    25,
                    21,
                    26,
                    20,
                    20,
                    19,
                    23,
                    12,
                    21,
                    13,
                    21,
                    16,
                    14,
                    15,
                    7,
                    9,
                    9,
                    12,
                    9,
                    9,
                    1,
                    3,
                    3,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.364,
                    1.093,
                    1.821,
                    2.549,
                    3.278,
                    4.006,
                    4.734,
                    5.463,
                    6.191,
                    6.919,
                    7.648,
                    8.376,
                    9.104,
                    9.833,
                    10.561,
                    11.289,
                    12.018,
                    12.746,
                    13.474,
                    14.203,
                    14.931,
                    15.659,
                    16.388,
                    17.116,
                    17.844,
                    18.572,
                    19.301,
                    20.029,
                    20.757,
                    21.486,
                    22.214,
                    22.942,
                    23.671,
                    24.399,
                    25.127,
                    25.856,
                    26.584,
                    27.312,
                    28.041,
                    28.769,
                    29.497,
                    30.226,
                    30.954,
                    31.682,
                    32.411,
                    33.139,
                    33.867,
                    34.596,
                    35.324,
                    36.052
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    13,
                    15,
                    32,
                    79,
                    124,
                    226,
                    344,
                    526,
                    743,
                    1006,
                    1395,
                    1826,
                    2448,
                    2769,
                    3259,
                    3635,
                    3664,
                    3840,
                    3742,
                    3509,
                    3114,
                    2826,
                    2268,
                    1971,
                    1604,
                    1381,
                    1003,
                    819,
                    556,
                    424,
                    284,
                    218,
                    176,
                    129,
                    84,
                    61,
                    50,
                    26,
                    13,
                    14,
                    9,
                    7,
                    6,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.622,
                    -0.59,
                    -0.558,
                    -0.526,
                    -0.494,
                    -0.463,
                    -0.431,
                    -0.399,
                    -0.367,
                    -0.335,
                    -0.303,
                    -0.272,
                    -0.24,
                    -0.208,
                    -0.176,
                    -0.144,
                    -0.112,
                    -0.081,
                    -0.049,
                    -0.017,
                    0.015,
                    0.047,
                    0.078,
                    0.11,
                    0.142,
                    0.174,
                    0.206,
                    0.238,
                    0.269,
                    0.301,
                    0.333,
                    0.365,
                    0.397,
                    0.429,
                    0.46,
                    0.492,
                    0.524,
                    0.556,
                    0.588,
                    0.62,
                    0.651,
                    0.683,
                    0.715,
                    0.747,
                    0.779,
                    0.811,
                    0.842,
                    0.874,
                    0.906,
                    0.938
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn050nknwui666bug7k88o",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050pknxhi6668it3dmdq",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 29.133,
                        "binMax": 36.416,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050nknwvi666w5dxgs5u",
                        "tokens": [
                            "'s",
                            " just",
                            " b",
                            "oll",
                            "ocks",
                            ".",
                            " Its",
                            " not",
                            " a",
                            " lot",
                            " of",
                            " sugar",
                            " in",
                            " the",
                            " scheme",
                            " of",
                            " things",
                            " at",
                            " all",
                            ",",
                            " and",
                            " the",
                            " stuff",
                            " about",
                            " processed",
                            " meat",
                            " is",
                            " badly",
                            " reported",
                            " and",
                            " misunderstood",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " and",
                            " everyone",
                            " I",
                            " know",
                            " was",
                            " raised",
                            " on",
                            " beans",
                            " on",
                            " toast",
                            " and",
                            " the",
                            " kind",
                            " of",
                            " food",
                            " people",
                            " sne",
                            "er",
                            " about",
                            " on",
                            " here",
                            ".",
                            " Never",
                            " did",
                            " any",
                            " of",
                            " us",
                            " any",
                            " harm",
                            ".",
                            " In",
                            " fact",
                            " its",
                            " now",
                            " that",
                            " everything",
                            " is",
                            " reduced",
                            " sugar",
                            " this",
                            " and",
                            " reduced",
                            " fat",
                            " that",
                            " that",
                            " the",
                            " kids",
                            " are",
                            " all",
                            " getting",
                            " obese",
                            " and",
                            " diabetes",
                            ".",
                            " Everyone",
                            " talks",
                            " about",
                            " kale",
                            " and",
                            " qu",
                            "inoa",
                            " but",
                            " they",
                            " are",
                            " less",
                            " healthy",
                            " than",
                            " those",
                            " of",
                            " us",
                            " raised",
                            " on",
                            " beans",
                            " and",
                            " turkey",
                            " drum",
                            "mers",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " fine",
                            " OP",
                            ",",
                            " its",
                            " food",
                            ".",
                            " Nothing",
                            " even",
                            " slightly",
                            " wrong"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.455,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.455,
                            0.145,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36759",
            "description": " actions related to learning and practicing skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.40200042724609375,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 13.291,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36759,
                    80530,
                    6057,
                    64733,
                    34954,
                    14052,
                    96770,
                    33115,
                    29063,
                    11105,
                    55382,
                    59850,
                    97527,
                    84712,
                    15165,
                    57852,
                    52248,
                    22083,
                    50986,
                    6850,
                    76062,
                    26071,
                    49673,
                    7364,
                    10485
                ],
                "topkCosSimValues": [
                    1,
                    0.5951,
                    0.5934,
                    0.5701,
                    0.5328,
                    0.4929,
                    0.4908,
                    0.4778,
                    0.4684,
                    0.4549,
                    0.4378,
                    0.4362,
                    0.4357,
                    0.4286,
                    0.428,
                    0.4258,
                    0.4207,
                    0.4182,
                    0.4174,
                    0.417,
                    0.4154,
                    0.4034,
                    0.4003,
                    0.3977,
                    0.396
                ],
                "neuron_alignment_indices": [
                    756,
                    393,
                    447
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.137,
                    0.131
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.061,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.07,
                    0.034
                ],
                "correlated_features_indices": [
                    36790,
                    36840,
                    36787
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.021,
                    0.006,
                    0.003
                ],
                "neg_str": [
                    "ortment",
                    "aran",
                    "emonic",
                    "advertising",
                    "oris",
                    "rin",
                    "hon",
                    "odon",
                    "grad",
                    "arty"
                ],
                "neg_values": [
                    -0.622,
                    -0.585,
                    -0.584,
                    -0.573,
                    -0.57,
                    -0.555,
                    -0.553,
                    -0.553,
                    -0.55,
                    -0.545
                ],
                "pos_str": [
                    " differently",
                    " freely",
                    " separately",
                    " excessively",
                    " directly",
                    " continuously",
                    " blindly",
                    " extensively",
                    " elsewhere",
                    " anyway"
                ],
                "pos_values": [
                    0.846,
                    0.829,
                    0.822,
                    0.779,
                    0.767,
                    0.766,
                    0.765,
                    0.764,
                    0.763,
                    0.759
                ],
                "frac_nonzero": 0.00365,
                "freq_hist_data_bar_heights": [
                    1695,
                    1427,
                    1185,
                    1012,
                    832,
                    711,
                    617,
                    515,
                    484,
                    401,
                    352,
                    293,
                    274,
                    220,
                    195,
                    180,
                    157,
                    135,
                    112,
                    104,
                    75,
                    73,
                    67,
                    54,
                    53,
                    48,
                    34,
                    21,
                    26,
                    21,
                    18,
                    18,
                    15,
                    9,
                    10,
                    4,
                    6,
                    8,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.93,
                    1.196,
                    1.462,
                    1.728,
                    1.994,
                    2.26,
                    2.525,
                    2.791,
                    3.057,
                    3.323,
                    3.589,
                    3.854,
                    4.12,
                    4.386,
                    4.652,
                    4.918,
                    5.184,
                    5.449,
                    5.715,
                    5.981,
                    6.247,
                    6.513,
                    6.779,
                    7.044,
                    7.31,
                    7.576,
                    7.842,
                    8.108,
                    8.373,
                    8.639,
                    8.905,
                    9.171,
                    9.437,
                    9.703,
                    9.968,
                    10.234,
                    10.5,
                    10.766,
                    11.032,
                    11.297,
                    11.563,
                    11.829,
                    12.095,
                    12.361,
                    12.627,
                    12.892,
                    13.158
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    14,
                    18,
                    19,
                    42,
                    76,
                    97,
                    180,
                    250,
                    398,
                    595,
                    849,
                    1222,
                    1681,
                    2166,
                    2679,
                    3186,
                    3622,
                    4005,
                    4027,
                    4002,
                    3965,
                    3469,
                    3043,
                    2447,
                    1988,
                    1546,
                    1160,
                    930,
                    685,
                    499,
                    360,
                    264,
                    190,
                    138,
                    101,
                    80,
                    54,
                    64,
                    28,
                    36,
                    24,
                    17,
                    12,
                    6,
                    8,
                    7,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.608,
                    -0.578,
                    -0.549,
                    -0.519,
                    -0.49,
                    -0.461,
                    -0.431,
                    -0.402,
                    -0.373,
                    -0.343,
                    -0.314,
                    -0.284,
                    -0.255,
                    -0.226,
                    -0.196,
                    -0.167,
                    -0.138,
                    -0.108,
                    -0.079,
                    -0.049,
                    -0.02,
                    0.009,
                    0.039,
                    0.068,
                    0.097,
                    0.127,
                    0.156,
                    0.186,
                    0.215,
                    0.244,
                    0.274,
                    0.303,
                    0.332,
                    0.362,
                    0.391,
                    0.42,
                    0.45,
                    0.479,
                    0.509,
                    0.538,
                    0.567,
                    0.597,
                    0.626,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.773,
                    0.802,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions related to learning and practicing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and typing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmwa335lx10exco67ax55",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa335m610exgnqozkf4",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa535mk10exsw1a50vs",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.633,
                        "binMax": 13.291,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "72585",
            "description": " instances of technical or scientific details related to personal projects or experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.3983460725339615,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "72585",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:01:37.146Z",
                "maxActApprox": 21.057,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    72585,
                    82542,
                    96955,
                    4815,
                    87426,
                    57518,
                    91085,
                    74258,
                    47575,
                    60326,
                    38443,
                    11850,
                    10104,
                    20055,
                    41732,
                    71161,
                    24930,
                    37520,
                    97664,
                    63370,
                    60007,
                    34234,
                    28110,
                    6533,
                    5017
                ],
                "topkCosSimValues": [
                    1,
                    0.6943,
                    0.6875,
                    0.6866,
                    0.6747,
                    0.6713,
                    0.6709,
                    0.6643,
                    0.6564,
                    0.654,
                    0.6447,
                    0.6386,
                    0.6347,
                    0.6261,
                    0.6136,
                    0.6109,
                    0.6106,
                    0.6083,
                    0.607,
                    0.6062,
                    0.6049,
                    0.6018,
                    0.5979,
                    0.5932,
                    0.5892
                ],
                "neuron_alignment_indices": [
                    640,
                    658,
                    615
                ],
                "neuron_alignment_values": [
                    0.348,
                    0.095,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.017,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    640,
                    94,
                    143
                ],
                "correlated_neurons_pearson": [
                    0.117,
                    0.067,
                    0.063
                ],
                "correlated_neurons_l1": [
                    0.108,
                    0.07,
                    0.061
                ],
                "correlated_features_indices": [
                    72585,
                    72671,
                    72609
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    " antit",
                    " estranged",
                    " intended",
                    " ideal",
                    " mistaken",
                    " withdraw",
                    " unexpl",
                    " alleged",
                    " advis",
                    " operative"
                ],
                "neg_values": [
                    -0.757,
                    -0.701,
                    -0.689,
                    -0.68,
                    -0.65,
                    -0.648,
                    -0.644,
                    -0.63,
                    -0.629,
                    -0.627
                ],
                "pos_str": [
                    "Anyway",
                    "\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142",
                    "\u00c2\u0142\u00c2\u0142\u00c2\u0142",
                    "\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142",
                    " Anyway",
                    "\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142\u00c2\u0142",
                    "Eventually",
                    "\u00c2\u0142\u00c2\u0142",
                    "Honestly",
                    "My"
                ],
                "pos_values": [
                    1.463,
                    1.19,
                    1.182,
                    1.146,
                    1.112,
                    1.103,
                    1.077,
                    1.07,
                    1.048,
                    1.042
                ],
                "frac_nonzero": 0.00189,
                "freq_hist_data_bar_heights": [
                    769,
                    655,
                    569,
                    503,
                    429,
                    376,
                    314,
                    282,
                    261,
                    198,
                    164,
                    167,
                    140,
                    115,
                    97,
                    99,
                    85,
                    87,
                    64,
                    70,
                    64,
                    55,
                    44,
                    41,
                    37,
                    39,
                    35,
                    29,
                    22,
                    20,
                    18,
                    22,
                    18,
                    7,
                    15,
                    10,
                    2,
                    8,
                    1,
                    3,
                    0,
                    4,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.211,
                    0.632,
                    1.053,
                    1.474,
                    1.895,
                    2.316,
                    2.737,
                    3.159,
                    3.58,
                    4.001,
                    4.422,
                    4.843,
                    5.264,
                    5.685,
                    6.106,
                    6.528,
                    6.949,
                    7.37,
                    7.791,
                    8.212,
                    8.633,
                    9.054,
                    9.476,
                    9.897,
                    10.318,
                    10.739,
                    11.16,
                    11.581,
                    12.002,
                    12.423,
                    12.845,
                    13.266,
                    13.687,
                    14.108,
                    14.529,
                    14.95,
                    15.371,
                    15.793,
                    16.214,
                    16.635,
                    17.056,
                    17.477,
                    17.898,
                    18.319,
                    18.74,
                    19.162,
                    19.583,
                    20.004,
                    20.425,
                    20.846
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    7,
                    25,
                    77,
                    125,
                    262,
                    427,
                    788,
                    1235,
                    1723,
                    2566,
                    3081,
                    3732,
                    4091,
                    4321,
                    4312,
                    4084,
                    3610,
                    3145,
                    2627,
                    2224,
                    1782,
                    1432,
                    1147,
                    943,
                    721,
                    529,
                    363,
                    297,
                    178,
                    140,
                    92,
                    58,
                    44,
                    31,
                    14,
                    6,
                    2,
                    1,
                    3,
                    3,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.691,
                    -0.646,
                    -0.602,
                    -0.558,
                    -0.513,
                    -0.469,
                    -0.424,
                    -0.38,
                    -0.335,
                    -0.291,
                    -0.247,
                    -0.202,
                    -0.158,
                    -0.113,
                    -0.069,
                    -0.025,
                    0.02,
                    0.064,
                    0.109,
                    0.153,
                    0.198,
                    0.242,
                    0.286,
                    0.331,
                    0.375,
                    0.42,
                    0.464,
                    0.508,
                    0.553,
                    0.597,
                    0.642,
                    0.686,
                    0.73,
                    0.775,
                    0.819,
                    0.864,
                    0.908,
                    0.953,
                    0.997,
                    1.041,
                    1.086,
                    1.13,
                    1.175,
                    1.219,
                    1.263,
                    1.308,
                    1.352,
                    1.397,
                    1.441
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " instances of technical or scientific details related to personal projects or experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to personal experiences and reflections",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi7rlfucjt10exfsonq67r",
                        "tokens": [
                            " my",
                            " own",
                            " perspective",
                            ".",
                            " I",
                            " was",
                            " doing",
                            " more",
                            " video",
                            " myself",
                            ".",
                            " Camera",
                            " and",
                            " storage",
                            " costs",
                            " had",
                            " come",
                            " way",
                            " down",
                            ",",
                            " getting",
                            " to",
                            " the",
                            " point",
                            " where",
                            " you",
                            " could",
                            " do",
                            " everything",
                            " on",
                            " a",
                            " laptop",
                            ".",
                            " It",
                            " was",
                            " becoming",
                            " very",
                            " personal",
                            ",",
                            " so",
                            " I",
                            " spent",
                            " working",
                            " on",
                            " versions",
                            " of",
                            " i",
                            "Movie",
                            " for",
                            " the",
                            " Mac",
                            " and",
                            " on",
                            " the",
                            " phone",
                            " with",
                            " some",
                            " great",
                            " teams",
                            ".",
                            "\n",
                            "\n",
                            "2011",
                            " \u2013",
                            " Final",
                            " Cut",
                            " Pro",
                            " X",
                            "\n",
                            "\n",
                            "As",
                            " Apple",
                            " seemed",
                            " to",
                            " \u00e2\u0122",
                            "\u013a",
                            "get",
                            " away",
                            " with",
                            "\u00e2\u0122",
                            "\u013b",
                            " that",
                            " painful",
                            " rel",
                            "aunch",
                            " of",
                            " i",
                            "Movie",
                            ",",
                            " did",
                            " that",
                            " help",
                            " them",
                            " make",
                            " the",
                            " decision",
                            " about",
                            " doing",
                            " the",
                            " same",
                            " for",
                            " Final",
                            " Cut",
                            " Pro",
                            "?",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " things",
                            " I",
                            " like",
                            " about",
                            " working",
                            " at",
                            " Apple",
                            " was",
                            " that",
                            " Apple",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " a",
                            " problem"
                        ],
                        "dataIndex": null,
                        "index": "72585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 21.057,
                        "maxValueTokenIndex": 60,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.208,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.905,
                            21.057,
                            6.003,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:39.662Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 21.057,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi7rlhuckh10exe4c1pztn",
                        "tokens": [
                            " my",
                            " own",
                            " perspective",
                            ".",
                            " I",
                            " was",
                            " doing",
                            " more",
                            " video",
                            " myself",
                            ".",
                            " Camera",
                            " and",
                            " storage",
                            " costs",
                            " had",
                            " come",
                            " way",
                            " down",
                            ",",
                            " getting",
                            " to",
                            " the",
                            " point",
                            " where",
                            " you",
                            " could",
                            " do",
                            " everything",
                            " on",
                            " a",
                            " laptop",
                            ".",
                            " It",
                            " was",
                            " becoming",
                            " very",
                            " personal",
                            ",",
                            " so",
                            " I",
                            " spent",
                            " working",
                            " on",
                            " versions",
                            " of",
                            " i",
                            "Movie",
                            " for",
                            " the",
                            " Mac",
                            " and",
                            " on",
                            " the",
                            " phone",
                            " with",
                            " some",
                            " great",
                            " teams",
                            ".",
                            "\n",
                            "\n",
                            "2011",
                            " \u2013",
                            " Final",
                            " Cut",
                            " Pro",
                            " X",
                            "\n",
                            "\n",
                            "As",
                            " Apple",
                            " seemed",
                            " to",
                            " \u00e2\u0122",
                            "\u013a",
                            "get",
                            " away",
                            " with",
                            "\u00e2\u0122",
                            "\u013b",
                            " that",
                            " painful",
                            " rel",
                            "aunch",
                            " of",
                            " i",
                            "Movie",
                            ",",
                            " did",
                            " that",
                            " help",
                            " them",
                            " make",
                            " the",
                            " decision",
                            " about",
                            " doing",
                            " the",
                            " same",
                            " for",
                            " Final",
                            " Cut",
                            " Pro",
                            "?",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " things",
                            " I",
                            " like",
                            " about",
                            " working",
                            " at",
                            " Apple",
                            " was",
                            " that",
                            " Apple",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " a",
                            " problem"
                        ],
                        "dataIndex": null,
                        "index": "72585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 21.057,
                        "maxValueTokenIndex": 60,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.208,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.905,
                            21.057,
                            6.003,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:39.662Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 16.845,
                        "binMax": 21.057,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi7rlfucju10exc9o62kgi",
                        "tokens": [
                            " barely",
                            " understood",
                            "<|endoftext|>",
                            "L",
                            "unch",
                            ",",
                            " my",
                            " leftover",
                            " meal",
                            " from",
                            " the",
                            " night",
                            " before",
                            "\u00e2\u0122\u00a6",
                            "usually",
                            ".",
                            " Not",
                            " this",
                            " time",
                            ".",
                            " I",
                            " went",
                            " with",
                            " a",
                            " classic",
                            " soup",
                            " and",
                            " salad",
                            " for",
                            " lunch",
                            ".",
                            " G",
                            "umbo",
                            " soup",
                            " (",
                            "which",
                            " is",
                            " really",
                            " where",
                            " I",
                            " put",
                            " the",
                            " work",
                            ")",
                            " and",
                            " the",
                            " spring",
                            " salad",
                            " (",
                            "I",
                            " just",
                            " bought",
                            " a",
                            " bag",
                            ")",
                            " to",
                            " be",
                            " exact",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " decided",
                            " to",
                            " make",
                            " the",
                            " gum",
                            "bo",
                            " from",
                            " scratch",
                            ",",
                            " so",
                            " that",
                            " means",
                            " pe",
                            "eling",
                            " some",
                            " raw",
                            " shrimp",
                            " and",
                            " making",
                            " a",
                            " stock",
                            " first",
                            ".",
                            "\n",
                            "\n",
                            "Then",
                            " carefully",
                            " making",
                            " a",
                            " rou",
                            "x",
                            " and",
                            " putting",
                            " it",
                            " all",
                            " together",
                            ".",
                            " I",
                            " think",
                            " the",
                            " stock",
                            " really",
                            " gives",
                            " it",
                            " the",
                            " extra",
                            " flavor",
                            ",",
                            " if",
                            " you",
                            " have",
                            " the",
                            " time",
                            " and",
                            " patience",
                            " to",
                            " peel",
                            " lots",
                            " of",
                            " shrimp",
                            ",",
                            " I",
                            " suggest",
                            " doing",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "72585",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.712,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.712,
                            4.469,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.634,
                            2.271,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:39.662Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 21.057,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}