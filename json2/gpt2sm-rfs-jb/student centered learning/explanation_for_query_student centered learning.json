{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "student centered learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5836511006147336,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12849",
            "description": "content related to educational psychology and learning experiences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5339375138282776,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12849",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:01:13.921Z",
                "maxActApprox": 49.117,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12849,
                    20008,
                    13240,
                    8581,
                    7804,
                    3969,
                    9365,
                    7187,
                    9709,
                    7511,
                    8895,
                    2951,
                    4849,
                    1353,
                    4375,
                    2878,
                    15591,
                    19680,
                    10990,
                    8921,
                    15005,
                    1833,
                    12980,
                    19318,
                    14797
                ],
                "topkCosSimValues": [
                    1,
                    0.7413,
                    0.5438,
                    0.4984,
                    0.4831,
                    0.4655,
                    0.4593,
                    0.4568,
                    0.4064,
                    0.3952,
                    0.3851,
                    0.3757,
                    0.3671,
                    0.3625,
                    0.3492,
                    0.3279,
                    0.3268,
                    0.322,
                    0.322,
                    0.3211,
                    0.319,
                    0.3172,
                    0.3168,
                    0.3154,
                    0.311
                ],
                "neuron_alignment_indices": [
                    271,
                    62,
                    575
                ],
                "neuron_alignment_values": [
                    0.16,
                    0.119,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.019,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.018,
                    0.015
                ],
                "correlated_features_indices": [
                    12860,
                    12818,
                    12899
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "zzi",
                    "pard",
                    "\u0124\u00aa",
                    "vati",
                    " Shipping",
                    "swick",
                    "senal",
                    "een",
                    " spraying",
                    "tar"
                ],
                "neg_values": [
                    -0.754,
                    -0.694,
                    -0.691,
                    -0.688,
                    -0.684,
                    -0.641,
                    -0.64,
                    -0.636,
                    -0.628,
                    -0.619
                ],
                "pos_str": [
                    " disabilities",
                    " Curve",
                    " curve",
                    " disability",
                    "icult",
                    " aids",
                    "learn",
                    " lessons",
                    " Clicker",
                    " disabled"
                ],
                "pos_values": [
                    1.068,
                    0.925,
                    0.915,
                    0.866,
                    0.768,
                    0.762,
                    0.754,
                    0.738,
                    0.737,
                    0.731
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    115,
                    76,
                    57,
                    36,
                    28,
                    20,
                    12,
                    15,
                    12,
                    11,
                    11,
                    9,
                    12,
                    8,
                    3,
                    5,
                    3,
                    4,
                    6,
                    4,
                    6,
                    13,
                    3,
                    2,
                    3,
                    3,
                    0,
                    4,
                    2,
                    3,
                    1,
                    3,
                    3,
                    3,
                    3,
                    1,
                    3,
                    6,
                    4,
                    1,
                    3,
                    5,
                    5,
                    0,
                    5,
                    1,
                    2,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.5,
                    1.483,
                    2.465,
                    3.447,
                    4.429,
                    5.411,
                    6.393,
                    7.376,
                    8.358,
                    9.34,
                    10.322,
                    11.304,
                    12.286,
                    13.268,
                    14.251,
                    15.233,
                    16.215,
                    17.197,
                    18.179,
                    19.161,
                    20.144,
                    21.126,
                    22.108,
                    23.09,
                    24.072,
                    25.054,
                    26.036,
                    27.019,
                    28.001,
                    28.983,
                    29.965,
                    30.947,
                    31.929,
                    32.912,
                    33.894,
                    34.876,
                    35.858,
                    36.84,
                    37.822,
                    38.804,
                    39.787,
                    40.769,
                    41.751,
                    42.733,
                    43.715,
                    44.697,
                    45.68,
                    46.662,
                    47.644,
                    48.626
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    0,
                    11,
                    21,
                    13,
                    37,
                    71,
                    116,
                    209,
                    346,
                    499,
                    780,
                    1207,
                    1642,
                    2322,
                    2971,
                    3658,
                    4074,
                    4494,
                    4561,
                    4454,
                    4010,
                    3528,
                    2942,
                    2309,
                    1782,
                    1323,
                    892,
                    664,
                    474,
                    313,
                    184,
                    107,
                    88,
                    50,
                    28,
                    24,
                    16,
                    15,
                    10,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.699,
                    -0.662,
                    -0.626,
                    -0.59,
                    -0.553,
                    -0.517,
                    -0.48,
                    -0.444,
                    -0.408,
                    -0.371,
                    -0.335,
                    -0.298,
                    -0.262,
                    -0.225,
                    -0.189,
                    -0.153,
                    -0.116,
                    -0.08,
                    -0.043,
                    -0.007,
                    0.03,
                    0.066,
                    0.102,
                    0.139,
                    0.175,
                    0.212,
                    0.248,
                    0.285,
                    0.321,
                    0.357,
                    0.394,
                    0.43,
                    0.467,
                    0.503,
                    0.539,
                    0.576,
                    0.612,
                    0.649,
                    0.685,
                    0.722,
                    0.758,
                    0.794,
                    0.831,
                    0.867,
                    0.904,
                    0.94,
                    0.977,
                    1.013,
                    1.049
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "content related to educational psychology and learning experiences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmlhmzc7l2i666fxbcpcsw",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhn0c7l6i666zbaenjoe",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhmzc7l3i66681yibbcr",
                        "tokens": [
                            " on",
                            " comparative",
                            " psychology",
                            " and",
                            " the",
                            " learning",
                            " process",
                            " led",
                            " to",
                            " the",
                            " theory",
                            " of",
                            " connection",
                            "ism",
                            " and",
                            " helped",
                            " lay",
                            " the",
                            " scientific",
                            " foundation",
                            " for",
                            " educational",
                            " psychology",
                            ".",
                            " He",
                            " also",
                            " worked",
                            " on",
                            " solving",
                            " industrial",
                            " problems",
                            ",",
                            " such",
                            " as",
                            " employee",
                            " exams",
                            " and",
                            " testing",
                            ".",
                            " He",
                            " was",
                            " a",
                            " member",
                            " of",
                            " the",
                            " board",
                            " of",
                            " the",
                            " Psychological",
                            " Corporation",
                            " and",
                            " served",
                            " as",
                            " president",
                            " of",
                            " the",
                            " American",
                            " Psychological",
                            " Association",
                            " in",
                            " 1912",
                            ".[",
                            "1",
                            "][",
                            "2",
                            "]",
                            " A",
                            " Review",
                            " of",
                            " General",
                            " Psychology",
                            " survey",
                            ",",
                            " published",
                            " in",
                            " 2002",
                            ",",
                            " ranked",
                            " Thor",
                            "nd",
                            "ike",
                            " as",
                            " the",
                            " ninth",
                            "-",
                            "most",
                            " cited",
                            " psychologist",
                            " of",
                            " the",
                            " 20",
                            "th",
                            " century",
                            ".[",
                            "3",
                            "]",
                            " Edward",
                            " Thor",
                            "nd",
                            "ike",
                            " had",
                            " a",
                            " powerful",
                            " impact",
                            " on",
                            " reinforcement",
                            " theory",
                            " and",
                            " behavior",
                            " analysis",
                            ",",
                            " providing",
                            " the",
                            " basic",
                            " framework",
                            " for",
                            " empirical",
                            " laws",
                            " in",
                            " behavior",
                            " psychology",
                            " with",
                            " his",
                            " law",
                            " of",
                            " effect",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.626,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.626,
                            2.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3427",
            "description": "concepts related to teaching and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5264544486999512,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3427",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:27.928Z",
                "maxActApprox": 15.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3427,
                    77561,
                    60325,
                    73728,
                    50077,
                    33640,
                    55572,
                    46187,
                    52346,
                    44237,
                    71908,
                    41600,
                    11,
                    70412,
                    53181,
                    83314,
                    42965,
                    79098,
                    21161,
                    23492,
                    28490,
                    42202,
                    93440,
                    42300,
                    59028
                ],
                "topkCosSimValues": [
                    1,
                    0.5752,
                    0.5313,
                    0.518,
                    0.4759,
                    0.4686,
                    0.4422,
                    0.3923,
                    0.391,
                    0.3864,
                    0.3785,
                    0.3768,
                    0.3757,
                    0.3679,
                    0.367,
                    0.367,
                    0.3629,
                    0.3589,
                    0.3481,
                    0.3475,
                    0.3419,
                    0.3416,
                    0.3379,
                    0.3346,
                    0.3338
                ],
                "neuron_alignment_indices": [
                    635,
                    603,
                    263
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.094,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    263,
                    236,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    3457,
                    3415,
                    3391
                ],
                "correlated_features_pearson": [
                    0.054,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.054,
                    0.009,
                    0.001
                ],
                "neg_str": [
                    "Rum",
                    "storm",
                    "inqu",
                    " Inqu",
                    "estate",
                    "luster",
                    " inquiries",
                    " Noel",
                    " Bellev",
                    " Graves"
                ],
                "neg_values": [
                    -0.653,
                    -0.639,
                    -0.636,
                    -0.612,
                    -0.604,
                    -0.598,
                    -0.595,
                    -0.589,
                    -0.588,
                    -0.586
                ],
                "pos_str": [
                    " versatility",
                    " ropes",
                    " prowess",
                    "agy",
                    " horizont",
                    " ingenuity",
                    "alore",
                    "emade",
                    " vectors",
                    " flexibility"
                ],
                "pos_values": [
                    0.9,
                    0.817,
                    0.79,
                    0.753,
                    0.746,
                    0.734,
                    0.699,
                    0.698,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00055,
                "freq_hist_data_bar_heights": [
                    266,
                    194,
                    153,
                    123,
                    145,
                    105,
                    91,
                    85,
                    57,
                    50,
                    46,
                    43,
                    51,
                    29,
                    23,
                    30,
                    31,
                    15,
                    26,
                    22,
                    20,
                    8,
                    9,
                    10,
                    12,
                    7,
                    6,
                    6,
                    6,
                    6,
                    7,
                    8,
                    4,
                    6,
                    0,
                    3,
                    2,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.164,
                    0.483,
                    0.802,
                    1.121,
                    1.439,
                    1.758,
                    2.077,
                    2.396,
                    2.715,
                    3.033,
                    3.352,
                    3.671,
                    3.99,
                    4.308,
                    4.627,
                    4.946,
                    5.265,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.858,
                    7.177,
                    7.496,
                    7.815,
                    8.133,
                    8.452,
                    8.771,
                    9.09,
                    9.408,
                    9.727,
                    10.046,
                    10.365,
                    10.683,
                    11.002,
                    11.321,
                    11.64,
                    11.958,
                    12.277,
                    12.596,
                    12.915,
                    13.233,
                    13.552,
                    13.871,
                    14.19,
                    14.508,
                    14.827,
                    15.146,
                    15.465,
                    15.784
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    6,
                    21,
                    29,
                    57,
                    67,
                    144,
                    219,
                    332,
                    505,
                    720,
                    983,
                    1366,
                    1739,
                    2245,
                    2684,
                    3097,
                    3501,
                    3914,
                    3820,
                    3809,
                    3646,
                    3331,
                    2951,
                    2520,
                    2074,
                    1696,
                    1302,
                    1023,
                    739,
                    528,
                    402,
                    246,
                    194,
                    117,
                    80,
                    50,
                    29,
                    18,
                    14,
                    10,
                    10,
                    6,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.638,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.203,
                    -0.172,
                    -0.141,
                    -0.11,
                    -0.079,
                    -0.048,
                    -0.016,
                    0.015,
                    0.046,
                    0.077,
                    0.108,
                    0.139,
                    0.17,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.418,
                    0.449,
                    0.48,
                    0.511,
                    0.542,
                    0.574,
                    0.605,
                    0.636,
                    0.667,
                    0.698,
                    0.729,
                    0.76,
                    0.791,
                    0.822,
                    0.853,
                    0.884
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and instructions related to methods and processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to teaching and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf154kdwgm10ex7gzz8956",
                        "tokens": [
                            " Al",
                            "inea",
                            " outside",
                            " Chicago",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " chance",
                            " to",
                            " present",
                            " their",
                            " cooking",
                            " in",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " disc",
                            "erning",
                            " food",
                            " city",
                            " without",
                            " the",
                            " full",
                            "-",
                            "time",
                            " commitment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " can",
                            "'t",
                            " tell",
                            " you",
                            " how",
                            " many",
                            " chefs",
                            " have",
                            " said",
                            " to",
                            " me",
                            ",",
                            " '",
                            "Yeah",
                            ",",
                            " you",
                            "'re",
                            " a",
                            " big",
                            " fish",
                            " in",
                            " a",
                            " small",
                            " pond",
                            ".",
                            " The",
                            " only",
                            " reason",
                            " you",
                            "'re",
                            " so",
                            " popular",
                            " is",
                            " because",
                            " you",
                            "'re",
                            " in",
                            " the",
                            " Midwest",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " In",
                            " a",
                            " way",
                            ",",
                            " we",
                            "'re",
                            " am",
                            "ped",
                            " up",
                            ",\"",
                            " A",
                            "chat",
                            "z",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " want",
                            " to",
                            " introduce",
                            " Al",
                            "inea",
                            " food",
                            " to",
                            " the",
                            " j",
                            "aded",
                            " New",
                            " Yorker",
                            ".",
                            " We",
                            "'re",
                            " going",
                            " to",
                            " show",
                            " New",
                            " Yorkers",
                            " what",
                            " Chicago",
                            " food",
                            " is",
                            " all",
                            " about",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " collaboration"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.943,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            1.683,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.943,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgn10exy3t5v2tt",
                        "tokens": [
                            " has",
                            " come",
                            " to",
                            " this",
                            " particular",
                            " point",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Load",
                            " third",
                            " party",
                            " embed",
                            "\n",
                            "\n",
                            "As",
                            " an",
                            " avid",
                            " bike",
                            ",",
                            " parks",
                            " and",
                            " neighborhood",
                            " advocate",
                            ",",
                            " Ford",
                            " has",
                            " been",
                            " fighting",
                            " the",
                            " decline",
                            " of",
                            " Detroit",
                            " for",
                            " years",
                            ".",
                            " To",
                            " see",
                            " his",
                            " hometown",
                            " become",
                            " trendy",
                            " with",
                            " everyone",
                            " from",
                            " tech",
                            " developers",
                            " to",
                            " hip",
                            "ster",
                            " craft",
                            "-",
                            "l",
                            "iqu",
                            "or",
                            " dist",
                            "ill",
                            "ers",
                            " makes",
                            " him",
                            " laugh",
                            " with",
                            " joy",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Being",
                            " a",
                            " unique",
                            " individual",
                            " showcasing",
                            " your",
                            " talent",
                            " is",
                            " like",
                            " the",
                            " new",
                            " hot",
                            " thing",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Everybody",
                            " wants",
                            " to",
                            " show",
                            " us",
                            " what",
                            " they",
                            " can",
                            " do",
                            ".",
                            " People",
                            " are",
                            " coming",
                            " here",
                            " from",
                            " all",
                            " over",
                            " the",
                            " country",
                            ",",
                            " because",
                            " of",
                            " the",
                            " access",
                            " to",
                            " material",
                            ",",
                            " talent",
                            " and",
                            " overall",
                            " attitude",
                            " to",
                            " get"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.881,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.746,
                            1.82,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.881,
                            4.034,
                            4.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgo10exkj0oeyt1",
                        "tokens": [
                            " I",
                            " would",
                            " love",
                            " to",
                            " show",
                            " how",
                            " the",
                            " card",
                            " handle",
                            " but",
                            " I",
                            "'m",
                            " not",
                            " really",
                            " good",
                            " a",
                            " that",
                            ",",
                            " this",
                            " video",
                            " is",
                            " the",
                            " best",
                            " i",
                            " could",
                            " do",
                            "...",
                            " Sorry",
                            " :(",
                            " https",
                            "://",
                            "www",
                            ".",
                            "youtube",
                            ".",
                            "com",
                            "/",
                            "watch",
                            "?",
                            "v",
                            "=",
                            "U",
                            "An",
                            "8",
                            "g",
                            "U",
                            "5",
                            "r",
                            "61",
                            "s",
                            " ***",
                            " #",
                            "Le",
                            " Website",
                            " To",
                            " make",
                            " all",
                            " this",
                            " a",
                            " little",
                            " less",
                            " complicated",
                            " i",
                            " set",
                            " up",
                            " a",
                            " website",
                            " with",
                            " the",
                            " very",
                            " original",
                            " and",
                            " thought",
                            "-",
                            "through",
                            " name",
                            " [",
                            "L",
                            "OL",
                            "Playing",
                            "C",
                            "ards",
                            ".",
                            "com",
                            "](",
                            "http",
                            "://",
                            "www",
                            ".",
                            "lol",
                            "playing",
                            "cards",
                            ".",
                            "com",
                            "/",
                            ").",
                            " here",
                            " are",
                            " some",
                            " screenshots",
                            ":",
                            " Front",
                            " page",
                            " with",
                            " the",
                            " story",
                            " and",
                            " stuff",
                            "s",
                            ":",
                            " http",
                            "://",
                            "i",
                            ".",
                            "imgur",
                            ".",
                            "com",
                            "/",
                            "q",
                            "fy",
                            "B",
                            "10",
                            "Z",
                            ".",
                            "png",
                            " A",
                            " page"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.408,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.408,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "37298",
            "description": " statements related to teaching and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5211292790693484,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "37298",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:18:08.931Z",
                "maxActApprox": 9.544,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37298,
                    90447,
                    44148,
                    93599,
                    2714,
                    82087,
                    36307,
                    18136,
                    17278,
                    70016,
                    71300,
                    59012,
                    23643,
                    97518,
                    40768,
                    70808,
                    98181,
                    78615,
                    85101,
                    21925,
                    40309,
                    53445,
                    26319,
                    42245,
                    49591
                ],
                "topkCosSimValues": [
                    1,
                    0.5543,
                    0.5408,
                    0.5356,
                    0.517,
                    0.516,
                    0.5119,
                    0.5118,
                    0.4883,
                    0.4736,
                    0.4733,
                    0.4704,
                    0.4662,
                    0.4625,
                    0.4608,
                    0.4595,
                    0.4592,
                    0.4577,
                    0.4546,
                    0.4544,
                    0.4533,
                    0.4516,
                    0.4492,
                    0.448,
                    0.4464
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    218
                ],
                "neuron_alignment_values": [
                    0.264,
                    0.118,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    8,
                    566,
                    87
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.037,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.056,
                    0.039,
                    -0.014
                ],
                "correlated_features_indices": [
                    37301,
                    37309,
                    37397
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "rete",
                    "aucas",
                    "atile",
                    " Unique",
                    "ciating",
                    " oval",
                    " exceeds",
                    " ambul",
                    "nexus",
                    "yth"
                ],
                "neg_values": [
                    -0.555,
                    -0.545,
                    -0.534,
                    -0.529,
                    -0.502,
                    -0.495,
                    -0.492,
                    -0.474,
                    -0.474,
                    -0.474
                ],
                "pos_str": [
                    " nonetheless",
                    " nevertheless",
                    " apologies",
                    " caveats",
                    " caution",
                    "endix",
                    " doubtless",
                    " gladly",
                    "warning",
                    " caveat"
                ],
                "pos_values": [
                    0.872,
                    0.768,
                    0.758,
                    0.707,
                    0.683,
                    0.641,
                    0.638,
                    0.63,
                    0.624,
                    0.624
                ],
                "frac_nonzero": 0.00287,
                "freq_hist_data_bar_heights": [
                    1368,
                    1126,
                    971,
                    817,
                    720,
                    624,
                    563,
                    441,
                    389,
                    346,
                    262,
                    219,
                    176,
                    182,
                    137,
                    119,
                    96,
                    87,
                    54,
                    60,
                    58,
                    36,
                    34,
                    32,
                    21,
                    19,
                    13,
                    11,
                    12,
                    9,
                    6,
                    3,
                    7,
                    2,
                    6,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.286,
                    0.477,
                    0.668,
                    0.859,
                    1.05,
                    1.241,
                    1.432,
                    1.623,
                    1.813,
                    2.004,
                    2.195,
                    2.386,
                    2.577,
                    2.768,
                    2.959,
                    3.149,
                    3.34,
                    3.531,
                    3.722,
                    3.913,
                    4.104,
                    4.295,
                    4.486,
                    4.676,
                    4.867,
                    5.058,
                    5.249,
                    5.44,
                    5.631,
                    5.822,
                    6.012,
                    6.203,
                    6.394,
                    6.585,
                    6.776,
                    6.967,
                    7.158,
                    7.349,
                    7.539,
                    7.73,
                    7.921,
                    8.112,
                    8.303,
                    8.494,
                    8.685,
                    8.875,
                    9.066,
                    9.257,
                    9.448
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    7,
                    14,
                    28,
                    58,
                    117,
                    184,
                    319,
                    492,
                    788,
                    1177,
                    1627,
                    2113,
                    2641,
                    3121,
                    3628,
                    3919,
                    3956,
                    3942,
                    3876,
                    3556,
                    3014,
                    2683,
                    2153,
                    1739,
                    1406,
                    1057,
                    774,
                    568,
                    356,
                    295,
                    209,
                    159,
                    95,
                    63,
                    47,
                    20,
                    20,
                    13,
                    5,
                    8,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.541,
                    -0.512,
                    -0.484,
                    -0.455,
                    -0.426,
                    -0.398,
                    -0.369,
                    -0.341,
                    -0.312,
                    -0.284,
                    -0.255,
                    -0.227,
                    -0.198,
                    -0.17,
                    -0.141,
                    -0.113,
                    -0.084,
                    -0.055,
                    -0.027,
                    0.002,
                    0.03,
                    0.059,
                    0.087,
                    0.116,
                    0.144,
                    0.173,
                    0.201,
                    0.23,
                    0.259,
                    0.287,
                    0.316,
                    0.344,
                    0.373,
                    0.401,
                    0.43,
                    0.458,
                    0.487,
                    0.515,
                    0.544,
                    0.573,
                    0.601,
                    0.63,
                    0.658,
                    0.687,
                    0.715,
                    0.744,
                    0.772,
                    0.801,
                    0.829,
                    0.858
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements related to teaching and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases expressing advice or suggestions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggntmh3k9e10ex8zq32xmy",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmj3k9y10exc6tmgsm1",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.635,
                        "binMax": 9.543,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmh3k9f10exukem1fpm",
                        "tokens": [
                            " this",
                            " console",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "Now",
                            " N",
                            "aughty",
                            " Dog",
                            " returns",
                            " to",
                            " the",
                            " spotlight",
                            " with",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            ".",
                            " Both",
                            " expected",
                            "ly",
                            " and",
                            " amazingly",
                            ",",
                            " N",
                            "aughty",
                            " Dog",
                            " has",
                            " indeed",
                            " best",
                            "ed",
                            " Nate",
                            "'s",
                            " first",
                            " adventure",
                            " and",
                            " has",
                            " created",
                            " a",
                            " sequel",
                            " that",
                            " is",
                            " not",
                            " only",
                            " bigger",
                            " and",
                            " better",
                            " in",
                            " practically",
                            " every",
                            " way",
                            ",",
                            " but",
                            " also",
                            " packs",
                            " a",
                            " multiplayer",
                            " component",
                            " that",
                            " could",
                            " be",
                            " released",
                            " as",
                            " its",
                            " own",
                            " separate",
                            ",",
                            " full",
                            "-",
                            "priced",
                            " game",
                            " and",
                            " people",
                            " would",
                            " stand",
                            " in",
                            " line",
                            " to",
                            " hand",
                            " over",
                            " their",
                            " cash",
                            ".",
                            "\n",
                            "\n",
                            "Yes",
                            ",",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            " is",
                            " fantastic",
                            ".",
                            "\n",
                            "\n",
                            "Click",
                            " the",
                            " image",
                            " to",
                            " watch",
                            " our",
                            " in",
                            "-",
                            "depth",
                            " video",
                            " review",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "rying",
                            " to",
                            " remain",
                            " as",
                            " spoiler",
                            "-",
                            "free",
                            " as",
                            " possible",
                            ",",
                            " I",
                            "'ll"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.545,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.14,
                            7.545
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "14559",
            "description": "discussions related to educational achievement and challenges faced by students, particularly boys",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5205090641975403,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "14559",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:06.235Z",
                "maxActApprox": 10.489,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14559,
                    79875,
                    36119,
                    20928,
                    75739,
                    64264,
                    26789,
                    18105,
                    61837,
                    14066,
                    4065,
                    94660,
                    58881,
                    14825,
                    85431,
                    51711,
                    5909,
                    78790,
                    37808,
                    42150,
                    88366,
                    78467,
                    74433,
                    57450,
                    79364
                ],
                "topkCosSimValues": [
                    1,
                    0.4831,
                    0.4476,
                    0.4124,
                    0.4114,
                    0.4032,
                    0.4024,
                    0.382,
                    0.3789,
                    0.3778,
                    0.365,
                    0.3647,
                    0.3543,
                    0.3502,
                    0.3419,
                    0.3391,
                    0.334,
                    0.3306,
                    0.3295,
                    0.3257,
                    0.3203,
                    0.32,
                    0.3186,
                    0.3178,
                    0.3176
                ],
                "neuron_alignment_indices": [
                    738,
                    215,
                    235
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.109,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    738,
                    252,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.026,
                    0.034,
                    0.036
                ],
                "correlated_features_indices": [
                    14583,
                    14556,
                    14533
                ],
                "correlated_features_pearson": [
                    0.028,
                    0.009,
                    0.009
                ],
                "correlated_features_l1": [
                    0.028,
                    0.012,
                    0.01
                ],
                "neg_str": [
                    " eBay",
                    " Shipping",
                    " Canary",
                    " shipping",
                    "soType",
                    " hiber",
                    " Carnage",
                    "NetMessage",
                    " Hydra",
                    " franch"
                ],
                "neg_values": [
                    -0.805,
                    -0.783,
                    -0.753,
                    -0.721,
                    -0.718,
                    -0.708,
                    -0.697,
                    -0.687,
                    -0.685,
                    -0.684
                ],
                "pos_str": [
                    " literacy",
                    " classroom",
                    " curriculum",
                    " curric",
                    " proficiency",
                    " learners",
                    " homework",
                    " exams",
                    " vocational",
                    " kindergarten"
                ],
                "pos_values": [
                    1.505,
                    1.378,
                    1.367,
                    1.329,
                    1.322,
                    1.27,
                    1.268,
                    1.191,
                    1.138,
                    1.137
                ],
                "frac_nonzero": 0.00333,
                "freq_hist_data_bar_heights": [
                    1577,
                    1394,
                    1160,
                    998,
                    835,
                    687,
                    578,
                    467,
                    396,
                    374,
                    315,
                    248,
                    203,
                    184,
                    158,
                    126,
                    109,
                    95,
                    77,
                    69,
                    60,
                    72,
                    34,
                    47,
                    31,
                    28,
                    26,
                    23,
                    22,
                    10,
                    14,
                    12,
                    8,
                    5,
                    4,
                    5,
                    6,
                    5,
                    7,
                    1,
                    1,
                    2,
                    3,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.105,
                    0.315,
                    0.525,
                    0.734,
                    0.944,
                    1.154,
                    1.364,
                    1.573,
                    1.783,
                    1.993,
                    2.203,
                    2.413,
                    2.622,
                    2.832,
                    3.042,
                    3.252,
                    3.462,
                    3.671,
                    3.881,
                    4.091,
                    4.301,
                    4.51,
                    4.72,
                    4.93,
                    5.14,
                    5.35,
                    5.559,
                    5.769,
                    5.979,
                    6.189,
                    6.399,
                    6.608,
                    6.818,
                    7.028,
                    7.238,
                    7.447,
                    7.657,
                    7.867,
                    8.077,
                    8.287,
                    8.496,
                    8.706,
                    8.916,
                    9.126,
                    9.336,
                    9.545,
                    9.755,
                    9.965,
                    10.175,
                    10.384
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    9,
                    27,
                    53,
                    99,
                    154,
                    272,
                    468,
                    745,
                    1246,
                    1772,
                    2354,
                    3147,
                    4039,
                    4723,
                    5027,
                    5090,
                    4501,
                    4138,
                    3153,
                    2538,
                    1883,
                    1326,
                    991,
                    722,
                    516,
                    344,
                    234,
                    188,
                    118,
                    83,
                    69,
                    56,
                    34,
                    33,
                    22,
                    15,
                    20,
                    11,
                    10,
                    10,
                    4,
                    1,
                    2,
                    0,
                    2,
                    2,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.782,
                    -0.736,
                    -0.689,
                    -0.643,
                    -0.597,
                    -0.551,
                    -0.505,
                    -0.458,
                    -0.412,
                    -0.366,
                    -0.32,
                    -0.274,
                    -0.227,
                    -0.181,
                    -0.135,
                    -0.089,
                    -0.042,
                    0.004,
                    0.05,
                    0.096,
                    0.142,
                    0.189,
                    0.235,
                    0.281,
                    0.327,
                    0.373,
                    0.42,
                    0.466,
                    0.512,
                    0.558,
                    0.604,
                    0.651,
                    0.697,
                    0.743,
                    0.789,
                    0.835,
                    0.882,
                    0.928,
                    0.974,
                    1.02,
                    1.067,
                    1.113,
                    1.159,
                    1.205,
                    1.251,
                    1.298,
                    1.344,
                    1.39,
                    1.436,
                    1.482
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions related to educational achievement and challenges faced by students, particularly boys",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfipfkmc3910exq7nl1603",
                        "tokens": [
                            " said",
                            " universities",
                            " were",
                            " working",
                            " \"",
                            "hell",
                            " for",
                            " leather",
                            "\"",
                            " to",
                            " rect",
                            "ify",
                            " the",
                            " situation",
                            " in",
                            " terms",
                            " of",
                            " places",
                            " for",
                            " students",
                            " from",
                            " disadvantaged",
                            " backgrounds",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " told",
                            " BBC",
                            " Radio",
                            " Scotland",
                            " many",
                            " of",
                            " the",
                            " inequalities",
                            " in",
                            " education",
                            " begin",
                            " much",
                            " earlier",
                            ",",
                            " in",
                            " school",
                            " or",
                            " even",
                            " pre",
                            "-",
                            "school",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " \"",
                            "If",
                            " you",
                            " look",
                            " at",
                            " the",
                            " attainment",
                            " of",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            ",",
                            " you",
                            " find",
                            " some",
                            " absolutely",
                            " shocking",
                            " differences",
                            " according",
                            " to",
                            " whether",
                            " they",
                            "'re",
                            " from",
                            " a",
                            " challenged",
                            " background",
                            " of",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "There",
                            "'s",
                            " an",
                            " 18",
                            " month",
                            " attainment",
                            " gap",
                            " in",
                            " verbal",
                            " skills",
                            " between",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            " from",
                            " the",
                            " most",
                            " privileged",
                            " backgrounds",
                            " and",
                            " the",
                            " most",
                            " challenged",
                            " backgrounds",
                            ",",
                            " so",
                            " there",
                            "'s",
                            " a",
                            " huge",
                            " systemic",
                            " issue",
                            " for",
                            " Scotland",
                            " about",
                            " making"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.489,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.265,
                            0,
                            2.403,
                            3.438,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.616,
                            1.676,
                            2.849,
                            1.458,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.183,
                            3.543,
                            0,
                            0.358,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.343,
                            10.489,
                            5.592,
                            4.355,
                            2.994,
                            5.517,
                            2.602,
                            0.935,
                            1.258,
                            0,
                            3.796,
                            1.634,
                            0,
                            0,
                            0,
                            1.9,
                            0,
                            0.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 8.392,
                        "binMax": 10.489,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfipfhmc2n10exj5gcpbn6",
                        "tokens": [
                            " said",
                            " universities",
                            " were",
                            " working",
                            " \"",
                            "hell",
                            " for",
                            " leather",
                            "\"",
                            " to",
                            " rect",
                            "ify",
                            " the",
                            " situation",
                            " in",
                            " terms",
                            " of",
                            " places",
                            " for",
                            " students",
                            " from",
                            " disadvantaged",
                            " backgrounds",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " told",
                            " BBC",
                            " Radio",
                            " Scotland",
                            " many",
                            " of",
                            " the",
                            " inequalities",
                            " in",
                            " education",
                            " begin",
                            " much",
                            " earlier",
                            ",",
                            " in",
                            " school",
                            " or",
                            " even",
                            " pre",
                            "-",
                            "school",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " \"",
                            "If",
                            " you",
                            " look",
                            " at",
                            " the",
                            " attainment",
                            " of",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            ",",
                            " you",
                            " find",
                            " some",
                            " absolutely",
                            " shocking",
                            " differences",
                            " according",
                            " to",
                            " whether",
                            " they",
                            "'re",
                            " from",
                            " a",
                            " challenged",
                            " background",
                            " of",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "There",
                            "'s",
                            " an",
                            " 18",
                            " month",
                            " attainment",
                            " gap",
                            " in",
                            " verbal",
                            " skills",
                            " between",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            " from",
                            " the",
                            " most",
                            " privileged",
                            " backgrounds",
                            " and",
                            " the",
                            " most",
                            " challenged",
                            " backgrounds",
                            ",",
                            " so",
                            " there",
                            "'s",
                            " a",
                            " huge",
                            " systemic",
                            " issue",
                            " for",
                            " Scotland",
                            " about",
                            " making"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.489,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.265,
                            0,
                            2.403,
                            3.438,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.616,
                            1.676,
                            2.849,
                            1.458,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.183,
                            3.543,
                            0,
                            0.358,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.343,
                            10.489,
                            5.592,
                            4.355,
                            2.994,
                            5.517,
                            2.602,
                            0.935,
                            1.258,
                            0,
                            3.796,
                            1.634,
                            0,
                            0,
                            0,
                            1.9,
                            0,
                            0.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.489,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfipfhmc2o10exc7emu0os",
                        "tokens": [
                            " out",
                            ".",
                            " Steve",
                            " Compar",
                            "ato",
                            ",",
                            " the",
                            " principal",
                            " of",
                            " Com",
                            "bee",
                            " Elementary",
                            " School",
                            ",",
                            " worried",
                            " at",
                            " how",
                            " he",
                            " was",
                            " going",
                            " to",
                            " provide",
                            " essential",
                            " supplies",
                            " for",
                            " his",
                            " students",
                            " when",
                            " his",
                            " budget",
                            " was",
                            " cut",
                            " by",
                            " a",
                            " third",
                            " this",
                            " year",
                            ",",
                            " was",
                            " delighted",
                            " when",
                            " the",
                            " First",
                            " Baptist",
                            " Church",
                            " at",
                            " the",
                            " Mall",
                            " \u00e2\u0122",
                            "\u013e",
                            "ad",
                            "opted",
                            "\u00e2\u0122",
                            "\u013f",
                            " his",
                            " school",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " result",
                            "?",
                            " The",
                            " church",
                            " filled",
                            " the",
                            " school",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " resource",
                            " room",
                            " with",
                            " $",
                            "5000",
                            " worth",
                            " of",
                            " supplies",
                            ";",
                            " it",
                            " also",
                            " c",
                            "atered",
                            " spaghetti",
                            " dinners",
                            " at",
                            " evening",
                            " school",
                            " events",
                            ",",
                            " bought",
                            " sneakers",
                            " for",
                            " needy",
                            " kids",
                            ",",
                            " and",
                            " provided",
                            " math",
                            " and",
                            " English",
                            " tut",
                            "ors",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " exchange",
                            "?",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " have",
                            " in",
                            "roads",
                            " into",
                            " public",
                            " schools",
                            " that",
                            " we",
                            " had",
                            " not",
                            " had",
                            " before",
                            ",",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.369,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.62,
                            10.369,
                            5.965,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.489,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17577",
            "description": "text related to children, students, and educational activities",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5145671060939377,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17577",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:20.758Z",
                "maxActApprox": 59.885,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17577,
                    7030,
                    2777,
                    11321,
                    12445,
                    4506,
                    23116,
                    7779,
                    15591,
                    246,
                    5493,
                    3514,
                    4799,
                    21916,
                    11072,
                    277,
                    4375,
                    20861,
                    7511,
                    23144,
                    8285,
                    13240,
                    23885,
                    11293,
                    8686
                ],
                "topkCosSimValues": [
                    1,
                    0.7913,
                    0.7509,
                    0.6205,
                    0.6038,
                    0.571,
                    0.5541,
                    0.5371,
                    0.5336,
                    0.5221,
                    0.5168,
                    0.5141,
                    0.4887,
                    0.4743,
                    0.4683,
                    0.4669,
                    0.466,
                    0.4603,
                    0.4576,
                    0.4148,
                    0.4073,
                    0.407,
                    0.4059,
                    0.4031,
                    0.3953
                ],
                "neuron_alignment_indices": [
                    575,
                    481,
                    383
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.099,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    575,
                    281,
                    657
                ],
                "correlated_neurons_pearson": [
                    0.037,
                    0.032,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.041,
                    0.03,
                    0.031
                ],
                "correlated_features_indices": [
                    17628,
                    17603,
                    17539
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.008,
                    0.003
                ],
                "correlated_features_l1": [
                    0.014,
                    0.009,
                    0.004
                ],
                "neg_str": [
                    "\u00e2\u0138\u00ac",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "ventory",
                    "PROV",
                    "ENCE",
                    "ATIVE",
                    "PORT",
                    "ATION",
                    " myster",
                    "Client"
                ],
                "neg_values": [
                    -0.675,
                    -0.659,
                    -0.653,
                    -0.649,
                    -0.642,
                    -0.629,
                    -0.617,
                    -0.615,
                    -0.609,
                    -0.608
                ],
                "pos_str": [
                    "children",
                    "ishly",
                    " ages",
                    "child",
                    "girls",
                    " born",
                    " aged",
                    "riages",
                    " orphan",
                    "sle"
                ],
                "pos_values": [
                    0.99,
                    0.984,
                    0.947,
                    0.9,
                    0.88,
                    0.88,
                    0.879,
                    0.875,
                    0.864,
                    0.861
                ],
                "frac_nonzero": 0.0005899999999999999,
                "freq_hist_data_bar_heights": [
                    266,
                    181,
                    111,
                    112,
                    82,
                    84,
                    64,
                    53,
                    51,
                    57,
                    37,
                    31,
                    31,
                    21,
                    15,
                    18,
                    18,
                    20,
                    15,
                    19,
                    16,
                    11,
                    13,
                    15,
                    13,
                    24,
                    19,
                    19,
                    26,
                    37,
                    28,
                    19,
                    27,
                    33,
                    36,
                    39,
                    37,
                    34,
                    31,
                    29,
                    17,
                    19,
                    16,
                    6,
                    2,
                    4,
                    1,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.604,
                    1.802,
                    2.999,
                    4.197,
                    5.394,
                    6.592,
                    7.79,
                    8.987,
                    10.185,
                    11.382,
                    12.58,
                    13.777,
                    14.975,
                    16.173,
                    17.37,
                    18.568,
                    19.765,
                    20.963,
                    22.161,
                    23.358,
                    24.556,
                    25.753,
                    26.951,
                    28.149,
                    29.346,
                    30.544,
                    31.741,
                    32.939,
                    34.136,
                    35.334,
                    36.532,
                    37.729,
                    38.927,
                    40.124,
                    41.322,
                    42.52,
                    43.717,
                    44.915,
                    46.112,
                    47.31,
                    48.508,
                    49.705,
                    50.903,
                    52.1,
                    53.298,
                    54.495,
                    55.693,
                    56.891,
                    58.088,
                    59.286
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    4,
                    10,
                    9,
                    21,
                    27,
                    73,
                    111,
                    203,
                    347,
                    514,
                    804,
                    1136,
                    1587,
                    2143,
                    2678,
                    3238,
                    3694,
                    4037,
                    4220,
                    4171,
                    3846,
                    3501,
                    3084,
                    2543,
                    2095,
                    1580,
                    1285,
                    949,
                    654,
                    521,
                    357,
                    232,
                    181,
                    129,
                    84,
                    63,
                    40,
                    19,
                    10,
                    14,
                    8,
                    9,
                    2,
                    5,
                    4,
                    6,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.658,
                    -0.625,
                    -0.592,
                    -0.558,
                    -0.525,
                    -0.492,
                    -0.458,
                    -0.425,
                    -0.392,
                    -0.359,
                    -0.325,
                    -0.292,
                    -0.259,
                    -0.225,
                    -0.192,
                    -0.159,
                    -0.125,
                    -0.092,
                    -0.059,
                    -0.026,
                    0.008,
                    0.041,
                    0.074,
                    0.108,
                    0.141,
                    0.174,
                    0.208,
                    0.241,
                    0.274,
                    0.308,
                    0.341,
                    0.374,
                    0.407,
                    0.441,
                    0.474,
                    0.507,
                    0.541,
                    0.574,
                    0.607,
                    0.641,
                    0.674,
                    0.707,
                    0.74,
                    0.774,
                    0.807,
                    0.84,
                    0.874,
                    0.907,
                    0.94,
                    0.974
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "text related to children, students, and educational activities",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmtc7fgpf5i666iqgea7ww",
                        "tokens": [
                            ",",
                            " which",
                            " includes",
                            " the",
                            " three",
                            " biggest",
                            " camps",
                            " in",
                            " the",
                            " world",
                            ",",
                            " was",
                            " constructed",
                            " in",
                            " the",
                            " early",
                            " 1990",
                            "s",
                            ".",
                            " The",
                            " largest",
                            " of",
                            " the",
                            " three",
                            ",",
                            " Hag",
                            "ader",
                            "a",
                            ",",
                            " houses",
                            " 138",
                            ",",
                            "102",
                            " refugees",
                            ",",
                            " which",
                            " is",
                            " equivalent",
                            " to",
                            " the",
                            " population",
                            " of",
                            " Pasadena",
                            ",",
                            " California",
                            ".",
                            " For",
                            " each",
                            " camp",
                            " on",
                            " the",
                            " map",
                            ",",
                            " a",
                            " comparable",
                            " American",
                            " city",
                            " is",
                            " listed",
                            " to",
                            " convey",
                            " size",
                            ".",
                            "\n",
                            "\n",
                            "World",
                            " Refugee",
                            " Day",
                            ",",
                            " recognized",
                            " each",
                            " year",
                            " on",
                            " June",
                            " 20",
                            ",",
                            " honors",
                            " the",
                            " millions",
                            " of",
                            " displaced",
                            " men",
                            ",",
                            " women",
                            " and",
                            " children",
                            " across",
                            " the",
                            " globe",
                            ".",
                            "<|endoftext|>",
                            "Children",
                            " in",
                            " lower",
                            "-",
                            "income",
                            " families",
                            " spend",
                            " more",
                            " time",
                            " watching",
                            " TV",
                            " and",
                            " using",
                            " electronic",
                            " devices",
                            " than",
                            " kids",
                            " in",
                            " more",
                            " affluent",
                            " homes",
                            ",",
                            " according",
                            " to",
                            " a",
                            " survey",
                            " released",
                            " Thursday",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " report",
                            " by",
                            " the",
                            " nonprofit"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.885,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.502,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtc7fgpf6i666xbwixhno",
                        "tokens": [
                            "\u2014",
                            "a",
                            " two",
                            "-",
                            "foot",
                            "-",
                            "tall",
                            " gu",
                            "ill",
                            "otine",
                            " was",
                            " popular",
                            " among",
                            " children",
                            ",",
                            " some",
                            " of",
                            " whom",
                            " used",
                            " it",
                            " to",
                            " decap",
                            "itate",
                            " rodents",
                            "\u2014",
                            "there",
                            " was",
                            " some",
                            " minor",
                            " fur",
                            "or",
                            " from",
                            " parents",
                            ",",
                            " and",
                            " Aurora",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " pursue",
                            " the",
                            " line",
                            ".",
                            "\n",
                            "\n",
                            "Six",
                            " years",
                            " later",
                            ",",
                            " the",
                            " company",
                            " felt",
                            " the",
                            " cultural",
                            " climate",
                            " was",
                            " ready",
                            " for",
                            " something",
                            " more",
                            " provocative",
                            ":",
                            " They",
                            " began",
                            " developing",
                            " a",
                            " line",
                            " dubbed",
                            " Monster",
                            " Scenes",
                            ".",
                            " Using",
                            " generic",
                            " characters",
                            " like",
                            " the",
                            " Victim",
                            ",",
                            " designers",
                            " concoct",
                            "ed",
                            " elaborate",
                            " scenarios",
                            " that",
                            " put",
                            " the",
                            " unfortunate",
                            " captives",
                            " in",
                            " mortal",
                            " peril",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " scenario",
                            " had",
                            " a",
                            " mad",
                            " scientist",
                            " hovering",
                            " over",
                            " his",
                            " captive",
                            " with",
                            " a",
                            " tray",
                            " full",
                            " of",
                            " hot",
                            " co",
                            "als",
                            " and",
                            " a",
                            " set",
                            " of",
                            " tong",
                            "s",
                            ";",
                            " another",
                            " designed",
                            " after",
                            " Edgar",
                            " Allan",
                            " Poe",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.886,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.886,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtc7fgpf7i666ihziey9y",
                        "tokens": [
                            " hundreds",
                            " of",
                            " restraints",
                            ",",
                            " which",
                            " can",
                            " include",
                            " anything",
                            " from",
                            " pin",
                            "ning",
                            " un",
                            "co",
                            "operative",
                            " children",
                            " face",
                            " down",
                            " on",
                            " the",
                            " floor",
                            " to",
                            " tying",
                            " them",
                            " up",
                            " with",
                            " straps",
                            ",",
                            " handcuffs",
                            " or",
                            " even",
                            " duct",
                            " tape",
                            ".",
                            " Three",
                            "-",
                            "quarters",
                            " of",
                            " students",
                            " who",
                            " were",
                            " restrained",
                            " had",
                            " physical",
                            ",",
                            " emotional",
                            " or",
                            " intellectual",
                            " disabilities",
                            ".",
                            "\n",
                            "\n",
                            "Children",
                            " have",
                            " suffered",
                            " countless",
                            " injuries",
                            " from",
                            " restraints",
                            ",",
                            " including",
                            " broken",
                            " bones",
                            ".",
                            " A",
                            " government",
                            " report",
                            " a",
                            " few",
                            " years",
                            " ago",
                            " detailed",
                            " hundreds",
                            " of",
                            " instances",
                            " of",
                            " abuse",
                            " and",
                            " several",
                            " deaths",
                            " over",
                            " two",
                            " decades",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " that",
                            " report",
                            ",",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " Department",
                            " of",
                            " Education",
                            "'s",
                            " Office",
                            " for",
                            " Civil",
                            " Rights",
                            " made",
                            " it",
                            " mandatory",
                            " for",
                            " school",
                            " districts",
                            " to",
                            " tell",
                            " to",
                            " the",
                            " government",
                            " how",
                            " many",
                            " times",
                            " they",
                            " have",
                            " used",
                            " restraints",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Department",
                            " of",
                            " Education"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.875,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.636,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.402,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.875,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4947418865407647,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21740",
            "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4843260059162383,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21740",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:12:34.087Z",
                "maxActApprox": 36.416,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21740,
                    3088,
                    21487,
                    12947,
                    16697,
                    2946,
                    20433,
                    251,
                    4001,
                    17235,
                    4407,
                    4717,
                    23503,
                    14215,
                    6124,
                    13657,
                    2197,
                    12026,
                    13434,
                    12886,
                    7963,
                    17224,
                    6857,
                    13339,
                    10095
                ],
                "topkCosSimValues": [
                    1,
                    0.5718,
                    0.5358,
                    0.419,
                    0.4171,
                    0.4083,
                    0.3814,
                    0.3811,
                    0.37,
                    0.3452,
                    0.3149,
                    0.3122,
                    0.3097,
                    0.3061,
                    0.3036,
                    0.2992,
                    0.298,
                    0.295,
                    0.2895,
                    0.2846,
                    0.2834,
                    0.283,
                    0.2741,
                    0.2639,
                    0.2629
                ],
                "neuron_alignment_indices": [
                    502,
                    363,
                    741
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.109,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    502,
                    566,
                    718
                ],
                "correlated_neurons_pearson": [
                    0.06,
                    0.05,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.058,
                    0.051,
                    0.041
                ],
                "correlated_features_indices": [
                    21711,
                    21727,
                    21757
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.009,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "umption",
                    " completion",
                    " Proced",
                    " Squid",
                    " sorcery",
                    " summary",
                    "allo",
                    " Volcano",
                    " Spur",
                    " Biology"
                ],
                "neg_values": [
                    -0.638,
                    -0.622,
                    -0.612,
                    -0.611,
                    -0.607,
                    -0.6,
                    -0.596,
                    -0.584,
                    -0.584,
                    -0.582
                ],
                "pos_str": [
                    " adore",
                    " admire",
                    " trusts",
                    " trusted",
                    " sidx",
                    " affection",
                    " befriend",
                    "igl",
                    "assadors",
                    " interviewed"
                ],
                "pos_values": [
                    0.954,
                    0.9,
                    0.865,
                    0.854,
                    0.8,
                    0.797,
                    0.796,
                    0.789,
                    0.779,
                    0.778
                ],
                "frac_nonzero": 0.00222,
                "freq_hist_data_bar_heights": [
                    1873,
                    1215,
                    804,
                    548,
                    393,
                    305,
                    251,
                    190,
                    178,
                    120,
                    116,
                    96,
                    84,
                    68,
                    67,
                    58,
                    59,
                    45,
                    49,
                    47,
                    27,
                    30,
                    25,
                    25,
                    21,
                    26,
                    20,
                    20,
                    19,
                    23,
                    12,
                    21,
                    13,
                    21,
                    16,
                    14,
                    15,
                    7,
                    9,
                    9,
                    12,
                    9,
                    9,
                    1,
                    3,
                    3,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.364,
                    1.093,
                    1.821,
                    2.549,
                    3.278,
                    4.006,
                    4.734,
                    5.463,
                    6.191,
                    6.919,
                    7.648,
                    8.376,
                    9.104,
                    9.833,
                    10.561,
                    11.289,
                    12.018,
                    12.746,
                    13.474,
                    14.203,
                    14.931,
                    15.659,
                    16.388,
                    17.116,
                    17.844,
                    18.572,
                    19.301,
                    20.029,
                    20.757,
                    21.486,
                    22.214,
                    22.942,
                    23.671,
                    24.399,
                    25.127,
                    25.856,
                    26.584,
                    27.312,
                    28.041,
                    28.769,
                    29.497,
                    30.226,
                    30.954,
                    31.682,
                    32.411,
                    33.139,
                    33.867,
                    34.596,
                    35.324,
                    36.052
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    13,
                    15,
                    32,
                    79,
                    124,
                    226,
                    344,
                    526,
                    743,
                    1006,
                    1395,
                    1826,
                    2448,
                    2769,
                    3259,
                    3635,
                    3664,
                    3840,
                    3742,
                    3509,
                    3114,
                    2826,
                    2268,
                    1971,
                    1604,
                    1381,
                    1003,
                    819,
                    556,
                    424,
                    284,
                    218,
                    176,
                    129,
                    84,
                    61,
                    50,
                    26,
                    13,
                    14,
                    9,
                    7,
                    6,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.622,
                    -0.59,
                    -0.558,
                    -0.526,
                    -0.494,
                    -0.463,
                    -0.431,
                    -0.399,
                    -0.367,
                    -0.335,
                    -0.303,
                    -0.272,
                    -0.24,
                    -0.208,
                    -0.176,
                    -0.144,
                    -0.112,
                    -0.081,
                    -0.049,
                    -0.017,
                    0.015,
                    0.047,
                    0.078,
                    0.11,
                    0.142,
                    0.174,
                    0.206,
                    0.238,
                    0.269,
                    0.301,
                    0.333,
                    0.365,
                    0.397,
                    0.429,
                    0.46,
                    0.492,
                    0.524,
                    0.556,
                    0.588,
                    0.62,
                    0.651,
                    0.683,
                    0.715,
                    0.747,
                    0.779,
                    0.811,
                    0.842,
                    0.874,
                    0.906,
                    0.938
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn050nknwui666bug7k88o",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050pknxhi6668it3dmdq",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 29.133,
                        "binMax": 36.416,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050nknwvi666w5dxgs5u",
                        "tokens": [
                            "'s",
                            " just",
                            " b",
                            "oll",
                            "ocks",
                            ".",
                            " Its",
                            " not",
                            " a",
                            " lot",
                            " of",
                            " sugar",
                            " in",
                            " the",
                            " scheme",
                            " of",
                            " things",
                            " at",
                            " all",
                            ",",
                            " and",
                            " the",
                            " stuff",
                            " about",
                            " processed",
                            " meat",
                            " is",
                            " badly",
                            " reported",
                            " and",
                            " misunderstood",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " and",
                            " everyone",
                            " I",
                            " know",
                            " was",
                            " raised",
                            " on",
                            " beans",
                            " on",
                            " toast",
                            " and",
                            " the",
                            " kind",
                            " of",
                            " food",
                            " people",
                            " sne",
                            "er",
                            " about",
                            " on",
                            " here",
                            ".",
                            " Never",
                            " did",
                            " any",
                            " of",
                            " us",
                            " any",
                            " harm",
                            ".",
                            " In",
                            " fact",
                            " its",
                            " now",
                            " that",
                            " everything",
                            " is",
                            " reduced",
                            " sugar",
                            " this",
                            " and",
                            " reduced",
                            " fat",
                            " that",
                            " that",
                            " the",
                            " kids",
                            " are",
                            " all",
                            " getting",
                            " obese",
                            " and",
                            " diabetes",
                            ".",
                            " Everyone",
                            " talks",
                            " about",
                            " kale",
                            " and",
                            " qu",
                            "inoa",
                            " but",
                            " they",
                            " are",
                            " less",
                            " healthy",
                            " than",
                            " those",
                            " of",
                            " us",
                            " raised",
                            " on",
                            " beans",
                            " and",
                            " turkey",
                            " drum",
                            "mers",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " fine",
                            " OP",
                            ",",
                            " its",
                            " food",
                            ".",
                            " Nothing",
                            " even",
                            " slightly",
                            " wrong"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.455,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.455,
                            0.145,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "4793",
            "description": "educational content related to school standards, teaching practices, and testing protocols",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4824590097392204,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "4793",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:22:19.242Z",
                "maxActApprox": 25.127,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4793,
                    3687,
                    11843,
                    11039,
                    11242,
                    10299,
                    11922,
                    10862,
                    1207,
                    3582,
                    3047,
                    5946,
                    11933,
                    2878,
                    7880,
                    645,
                    133,
                    8051,
                    2706,
                    6653,
                    9278,
                    944,
                    10197,
                    10995,
                    8176
                ],
                "topkCosSimValues": [
                    1,
                    0.508,
                    0.4371,
                    0.3982,
                    0.398,
                    0.3846,
                    0.378,
                    0.3757,
                    0.3541,
                    0.3404,
                    0.3222,
                    0.3182,
                    0.3086,
                    0.304,
                    0.3006,
                    0.29,
                    0.29,
                    0.2829,
                    0.2805,
                    0.2781,
                    0.2773,
                    0.2761,
                    0.2758,
                    0.2754,
                    0.2719
                ],
                "neuron_alignment_indices": [
                    481,
                    547,
                    720
                ],
                "neuron_alignment_values": [
                    0.183,
                    0.105,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    393,
                    384,
                    547
                ],
                "correlated_neurons_pearson": [
                    0.068,
                    0.066,
                    0.061
                ],
                "correlated_neurons_l1": [
                    0.079,
                    0.058,
                    0.05
                ],
                "correlated_features_indices": [
                    4820,
                    4833,
                    4739
                ],
                "correlated_features_pearson": [
                    0.012,
                    0.011,
                    0.008
                ],
                "correlated_features_l1": [
                    0.014,
                    0.012,
                    0.014
                ],
                "neg_str": [
                    "ocrat",
                    "UID",
                    "usterity",
                    "addafi",
                    "idae",
                    "ict",
                    "resa",
                    "usha",
                    " Centauri",
                    "rek"
                ],
                "neg_values": [
                    -0.723,
                    -0.64,
                    -0.622,
                    -0.619,
                    -0.597,
                    -0.593,
                    -0.59,
                    -0.59,
                    -0.562,
                    -0.559
                ],
                "pos_str": [
                    " elsewhere",
                    " beyond",
                    " workplaces",
                    " anywhere",
                    " classrooms",
                    " classroom",
                    " wherever",
                    " thereafter",
                    " throughout",
                    " periphery"
                ],
                "pos_values": [
                    1.387,
                    0.917,
                    0.89,
                    0.868,
                    0.858,
                    0.853,
                    0.852,
                    0.851,
                    0.842,
                    0.834
                ],
                "frac_nonzero": 0.00567,
                "freq_hist_data_bar_heights": [
                    3730,
                    2780,
                    2145,
                    1680,
                    1331,
                    1054,
                    841,
                    688,
                    603,
                    495,
                    408,
                    355,
                    284,
                    257,
                    189,
                    161,
                    135,
                    114,
                    75,
                    80,
                    58,
                    60,
                    54,
                    40,
                    35,
                    31,
                    21,
                    23,
                    13,
                    17,
                    10,
                    7,
                    9,
                    6,
                    7,
                    4,
                    8,
                    5,
                    2,
                    2,
                    0,
                    6,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.251,
                    0.754,
                    1.257,
                    1.759,
                    2.262,
                    2.764,
                    3.267,
                    3.769,
                    4.272,
                    4.774,
                    5.277,
                    5.779,
                    6.282,
                    6.785,
                    7.287,
                    7.79,
                    8.292,
                    8.795,
                    9.297,
                    9.8,
                    10.302,
                    10.805,
                    11.307,
                    11.81,
                    12.312,
                    12.815,
                    13.318,
                    13.82,
                    14.323,
                    14.825,
                    15.328,
                    15.83,
                    16.333,
                    16.835,
                    17.338,
                    17.84,
                    18.343,
                    18.846,
                    19.348,
                    19.851,
                    20.353,
                    20.856,
                    21.358,
                    21.861,
                    22.363,
                    22.866,
                    23.368,
                    23.871,
                    24.373,
                    24.876
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    7,
                    28,
                    53,
                    124,
                    199,
                    448,
                    777,
                    1277,
                    1977,
                    2753,
                    3674,
                    4503,
                    4854,
                    4953,
                    4871,
                    4378,
                    3795,
                    3042,
                    2404,
                    1912,
                    1389,
                    965,
                    642,
                    464,
                    287,
                    186,
                    125,
                    62,
                    39,
                    26,
                    14,
                    7,
                    4,
                    4,
                    6,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.702,
                    -0.659,
                    -0.617,
                    -0.575,
                    -0.533,
                    -0.491,
                    -0.448,
                    -0.406,
                    -0.364,
                    -0.322,
                    -0.28,
                    -0.237,
                    -0.195,
                    -0.153,
                    -0.111,
                    -0.069,
                    -0.026,
                    0.016,
                    0.058,
                    0.1,
                    0.142,
                    0.185,
                    0.227,
                    0.269,
                    0.311,
                    0.353,
                    0.396,
                    0.438,
                    0.48,
                    0.522,
                    0.564,
                    0.607,
                    0.649,
                    0.691,
                    0.733,
                    0.775,
                    0.818,
                    0.86,
                    0.902,
                    0.944,
                    0.986,
                    1.028,
                    1.071,
                    1.113,
                    1.155,
                    1.197,
                    1.239,
                    1.282,
                    1.324,
                    1.366
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "educational content related to school standards, teaching practices, and testing protocols",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdts3l7322gi666cv8tws9a",
                        "tokens": [
                            " strong",
                            ",",
                            " motivated",
                            " learners",
                            " for",
                            " their",
                            " whole",
                            " lives",
                            "\u2014",
                            "in",
                            " school",
                            " and",
                            " beyond",
                            ".",
                            " That",
                            " strength",
                            " begins",
                            " with",
                            " active",
                            " hands",
                            "-",
                            "on",
                            " learning",
                            ".",
                            " Current",
                            " state",
                            " standards",
                            " have",
                            " already",
                            " led",
                            " to",
                            " long",
                            " hours",
                            " of",
                            " did",
                            "actic",
                            " instruction",
                            ",",
                            " scripted",
                            " teaching",
                            ",",
                            " a",
                            " narrowing",
                            " of",
                            " the",
                            " curriculum",
                            ",",
                            " and",
                            " over",
                            "use",
                            " of",
                            " standardized",
                            " tests",
                            " with",
                            " young",
                            " children",
                            ".",
                            " The",
                            " new",
                            " standards",
                            " will",
                            " almost",
                            " certainly",
                            " intensify",
                            " those",
                            " inappropriate",
                            " practices",
                            ".",
                            " (",
                            "See",
                            " Crisis",
                            " in",
                            " the",
                            " Kinder",
                            "g",
                            "arten",
                            " for",
                            " data",
                            " on",
                            " current",
                            " practices",
                            " in",
                            " public",
                            " kindergarten",
                            " education",
                            ".)",
                            "\n",
                            "\n",
                            "The",
                            " new",
                            " standards",
                            " call",
                            " for",
                            " kindergarten",
                            " children",
                            " to",
                            " master",
                            " over",
                            " 90",
                            " skills",
                            " related",
                            " to",
                            " literacy",
                            " and",
                            " math",
                            "mat",
                            "ics",
                            ".",
                            " Is",
                            " this",
                            " necessary",
                            " for",
                            " children",
                            " to",
                            " succeed",
                            " in",
                            " school",
                            "?",
                            " Experts",
                            " know",
                            " of",
                            " no",
                            " research",
                            " showing",
                            " that",
                            " children",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "4793",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.127,
                        "maxValueTokenIndex": 11,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.127,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:23.217Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 25.127,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdts3l7322hi666zlalxcka",
                        "tokens": [
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " objective",
                            " and",
                            " comprehensive",
                            " testing",
                            " in",
                            " the",
                            " industry",
                            ".",
                            " We",
                            " feel",
                            " the",
                            " best",
                            " reviews",
                            " are",
                            " those",
                            " that",
                            " help",
                            " you",
                            " make",
                            " the",
                            " right",
                            " choices",
                            " and",
                            " help",
                            " you",
                            " get",
                            " the",
                            " most",
                            " out",
                            " of",
                            " your",
                            " time",
                            " and",
                            " money",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " key",
                            " to",
                            " our",
                            " testing",
                            " protocols",
                            " is",
                            " testing",
                            " products",
                            " head",
                            "-",
                            "to",
                            "-",
                            "head",
                            ".",
                            " We",
                            " select",
                            " the",
                            " top",
                            " products",
                            " from",
                            " each",
                            " category",
                            " and",
                            " put",
                            " the",
                            " products",
                            " through",
                            " detailed",
                            " head",
                            "-",
                            "to",
                            "-",
                            "head",
                            " testing",
                            ".",
                            " We",
                            " test",
                            " both",
                            " in",
                            " the",
                            " lab",
                            " and",
                            " in",
                            " the",
                            " field",
                            ".",
                            " We",
                            " score",
                            " each",
                            " product",
                            " across",
                            " a",
                            " range",
                            " of",
                            " weighted",
                            " categories",
                            ".",
                            " We",
                            " then",
                            " rank",
                            " the",
                            " products",
                            " and",
                            " explain",
                            " why",
                            ",",
                            " and",
                            " give",
                            " awards",
                            " to",
                            " the",
                            " best",
                            " performing",
                            " products",
                            " in",
                            " the",
                            " category",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " year",
                            " we",
                            " approached"
                        ],
                        "dataIndex": null,
                        "index": "4793",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.527,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.077,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.527,
                            0,
                            0.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:23.217Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 25.127,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdts3la3234i666xoqvk9m5",
                        "tokens": [
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " objective",
                            " and",
                            " comprehensive",
                            " testing",
                            " in",
                            " the",
                            " industry",
                            ".",
                            " We",
                            " feel",
                            " the",
                            " best",
                            " reviews",
                            " are",
                            " those",
                            " that",
                            " help",
                            " you",
                            " make",
                            " the",
                            " right",
                            " choices",
                            " and",
                            " help",
                            " you",
                            " get",
                            " the",
                            " most",
                            " out",
                            " of",
                            " your",
                            " time",
                            " and",
                            " money",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " key",
                            " to",
                            " our",
                            " testing",
                            " protocols",
                            " is",
                            " testing",
                            " products",
                            " head",
                            "-",
                            "to",
                            "-",
                            "head",
                            ".",
                            " We",
                            " select",
                            " the",
                            " top",
                            " products",
                            " from",
                            " each",
                            " category",
                            " and",
                            " put",
                            " the",
                            " products",
                            " through",
                            " detailed",
                            " head",
                            "-",
                            "to",
                            "-",
                            "head",
                            " testing",
                            ".",
                            " We",
                            " test",
                            " both",
                            " in",
                            " the",
                            " lab",
                            " and",
                            " in",
                            " the",
                            " field",
                            ".",
                            " We",
                            " score",
                            " each",
                            " product",
                            " across",
                            " a",
                            " range",
                            " of",
                            " weighted",
                            " categories",
                            ".",
                            " We",
                            " then",
                            " rank",
                            " the",
                            " products",
                            " and",
                            " explain",
                            " why",
                            ",",
                            " and",
                            " give",
                            " awards",
                            " to",
                            " the",
                            " best",
                            " performing",
                            " products",
                            " in",
                            " the",
                            " category",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " year",
                            " we",
                            " approached"
                        ],
                        "dataIndex": null,
                        "index": "4793",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.527,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.077,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.527,
                            0,
                            0.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:22:23.217Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 20.102,
                        "binMax": 25.127,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4658578634262085,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "44382",
            "description": " discussion about educational curriculums and standards",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46555501222610474,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "44382",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:18:05.949Z",
                "maxActApprox": 54.023,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44382,
                    24835,
                    5768,
                    7269,
                    28235,
                    14407,
                    27830,
                    46531,
                    47724,
                    44019,
                    34244,
                    272,
                    12106,
                    13820,
                    11474,
                    42983,
                    33291,
                    18922,
                    8181,
                    14863,
                    5198,
                    8748,
                    36846,
                    1263,
                    33946
                ],
                "topkCosSimValues": [
                    1,
                    0.544,
                    0.5171,
                    0.5,
                    0.4898,
                    0.4878,
                    0.4831,
                    0.4826,
                    0.4718,
                    0.4652,
                    0.4497,
                    0.4428,
                    0.4334,
                    0.4198,
                    0.4138,
                    0.4131,
                    0.4107,
                    0.4074,
                    0.407,
                    0.405,
                    0.4013,
                    0.3981,
                    0.3973,
                    0.3969,
                    0.3955
                ],
                "neuron_alignment_indices": [
                    288,
                    481,
                    72
                ],
                "neuron_alignment_values": [
                    0.174,
                    0.152,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.007,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    72,
                    575
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.012
                ],
                "correlated_features_indices": [
                    44393,
                    44343,
                    44335
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "conn",
                    "ulf",
                    "axy",
                    "erie",
                    "joy",
                    "ourke",
                    "hao",
                    "near",
                    "holes",
                    " fry"
                ],
                "neg_values": [
                    -0.698,
                    -0.687,
                    -0.62,
                    -0.618,
                    -0.601,
                    -0.592,
                    -0.585,
                    -0.577,
                    -0.576,
                    -0.575
                ],
                "pos_str": [
                    " vit",
                    " curriculum",
                    " syll",
                    " curric",
                    " textbooks",
                    " taught",
                    "ussion",
                    " refres",
                    "ourses",
                    " textbook"
                ],
                "pos_values": [
                    1.461,
                    1.141,
                    0.955,
                    0.937,
                    0.844,
                    0.81,
                    0.801,
                    0.784,
                    0.769,
                    0.768
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    183,
                    97,
                    72,
                    40,
                    23,
                    15,
                    14,
                    7,
                    5,
                    1,
                    2,
                    3,
                    4,
                    2,
                    1,
                    3,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    1,
                    3,
                    0,
                    2,
                    3,
                    0,
                    4,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.551,
                    1.631,
                    2.711,
                    3.791,
                    4.872,
                    5.952,
                    7.032,
                    8.112,
                    9.193,
                    10.273,
                    11.353,
                    12.433,
                    13.514,
                    14.594,
                    15.674,
                    16.754,
                    17.834,
                    18.915,
                    19.995,
                    21.075,
                    22.155,
                    23.236,
                    24.316,
                    25.396,
                    26.476,
                    27.557,
                    28.637,
                    29.717,
                    30.797,
                    31.878,
                    32.958,
                    34.038,
                    35.118,
                    36.199,
                    37.279,
                    38.359,
                    39.439,
                    40.52,
                    41.6,
                    42.68,
                    43.76,
                    44.841,
                    45.921,
                    47.001,
                    48.081,
                    49.162,
                    50.242,
                    51.322,
                    52.402,
                    53.482
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    7,
                    27,
                    31,
                    81,
                    158,
                    334,
                    551,
                    1017,
                    1595,
                    2494,
                    3501,
                    4306,
                    4982,
                    5647,
                    5529,
                    4975,
                    4259,
                    3362,
                    2543,
                    1709,
                    1162,
                    818,
                    462,
                    293,
                    169,
                    113,
                    50,
                    34,
                    22,
                    7,
                    3,
                    4,
                    3,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.677,
                    -0.634,
                    -0.59,
                    -0.547,
                    -0.504,
                    -0.461,
                    -0.418,
                    -0.374,
                    -0.331,
                    -0.288,
                    -0.245,
                    -0.202,
                    -0.159,
                    -0.115,
                    -0.072,
                    -0.029,
                    0.014,
                    0.057,
                    0.101,
                    0.144,
                    0.187,
                    0.23,
                    0.273,
                    0.316,
                    0.36,
                    0.403,
                    0.446,
                    0.489,
                    0.532,
                    0.576,
                    0.619,
                    0.662,
                    0.705,
                    0.748,
                    0.791,
                    0.835,
                    0.878,
                    0.921,
                    0.964,
                    1.007,
                    1.051,
                    1.094,
                    1.137,
                    1.18,
                    1.223,
                    1.266,
                    1.31,
                    1.353,
                    1.396,
                    1.439
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " discussion about educational curriculums and standards",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6yw1sgk05i666dq6b96vk",
                        "tokens": [
                            " you",
                            " why",
                            ":",
                            " Even",
                            " in",
                            " IT",
                            ",",
                            " an",
                            " IT",
                            " degree",
                            " is",
                            " useless",
                            ".",
                            " Unless",
                            " you",
                            " are",
                            " graduating",
                            " from",
                            " MIT",
                            ",",
                            " or",
                            " Stanford",
                            ",",
                            " or",
                            " some",
                            " other",
                            " school",
                            " of",
                            " similar",
                            " stature",
                            " then",
                            " get",
                            " a",
                            " degree",
                            " in",
                            " anything",
                            " but",
                            " IT",
                            ".",
                            " Get",
                            " a",
                            " degree",
                            " in",
                            " business",
                            " or",
                            " education",
                            " or",
                            " some",
                            " other",
                            " engineering",
                            " discipline",
                            "\u00e2\u0122\u00a6",
                            " anything",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " very",
                            " best",
                            " folks",
                            " in",
                            " IT",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " strictly",
                            " need",
                            " cert",
                            "ifications",
                            " or",
                            " degrees",
                            " because",
                            ",",
                            " as",
                            " a",
                            " matter",
                            " of",
                            " fact",
                            ",",
                            " the",
                            " curriculum",
                            " for",
                            " these",
                            " things",
                            " in",
                            " most",
                            " cases",
                            " is",
                            " never",
                            " really",
                            " current",
                            " and",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " really",
                            " teach",
                            " you",
                            " all",
                            " the",
                            " things",
                            " you",
                            " need",
                            " to",
                            " know",
                            " to",
                            " succeed",
                            ".",
                            " Cert",
                            "ifications",
                            " are",
                            " slightly",
                            " more",
                            " useful",
                            " than",
                            " degrees",
                            " I",
                            " think",
                            ",",
                            " they",
                            " can",
                            " help",
                            " you",
                            " get",
                            " started"
                        ],
                        "dataIndex": null,
                        "index": "44382",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.023,
                        "maxValueTokenIndex": 81,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.023,
                            4.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:18:11.802Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.023,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6yw1vgk12i666tw61gacq",
                        "tokens": [
                            " taught",
                            " about",
                            " evolution",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " the",
                            " curriculum",
                            " only",
                            " applies",
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "44382",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.22,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            1.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.03,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.73,
                            0.972,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:18:11.802Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 10.805,
                        "binMax": 21.609,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6yw1sgk06i666pe18s3ph",
                        "tokens": [
                            " taught",
                            " about",
                            " evolution",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " the",
                            " curriculum",
                            " only",
                            " applies",
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "44382",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.22,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            1.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.03,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.73,
                            0.972,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:18:11.802Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.023,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "52826",
            "description": "elements related to knowledge and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.46364688873291016,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "52826",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:40:09.008Z",
                "maxActApprox": 15.789,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    52826,
                    96686,
                    40863,
                    97899,
                    71247,
                    24561,
                    48130,
                    55567,
                    8808,
                    71698,
                    35618,
                    28127,
                    92040,
                    57404,
                    84959,
                    81141,
                    50650,
                    6393,
                    35398,
                    60541,
                    43498,
                    33284,
                    6516,
                    4039,
                    90574
                ],
                "topkCosSimValues": [
                    1,
                    0.5445,
                    0.5429,
                    0.4984,
                    0.4932,
                    0.4931,
                    0.4881,
                    0.4847,
                    0.4611,
                    0.4355,
                    0.435,
                    0.4342,
                    0.4316,
                    0.4176,
                    0.4173,
                    0.4145,
                    0.4073,
                    0.4068,
                    0.3996,
                    0.396,
                    0.3915,
                    0.3866,
                    0.3857,
                    0.3852,
                    0.3835
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    621
                ],
                "neuron_alignment_values": [
                    0.163,
                    0.109,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    594,
                    288,
                    459
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.046,
                    0.044
                ],
                "correlated_neurons_l1": [
                    0.046,
                    0.07,
                    0.047
                ],
                "correlated_features_indices": [
                    52914,
                    52866,
                    52812
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.009,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " contagious",
                    " Antar",
                    " embassies",
                    " Stard",
                    " Kazakh",
                    " hay",
                    " Canter",
                    " pseudonym",
                    " Kush",
                    " NEO"
                ],
                "neg_values": [
                    -0.581,
                    -0.564,
                    -0.547,
                    -0.541,
                    -0.541,
                    -0.534,
                    -0.531,
                    -0.524,
                    -0.519,
                    -0.516
                ],
                "pos_str": [
                    " thereof",
                    " counterpart",
                    " meanwhile",
                    " versa",
                    "SPONSORED",
                    "ogy",
                    " likewise",
                    "JV",
                    "OPE",
                    " ones"
                ],
                "pos_values": [
                    0.797,
                    0.767,
                    0.76,
                    0.735,
                    0.693,
                    0.691,
                    0.679,
                    0.677,
                    0.664,
                    0.661
                ],
                "frac_nonzero": 0.006059999999999999,
                "freq_hist_data_bar_heights": [
                    4184,
                    3244,
                    2529,
                    1903,
                    1535,
                    1102,
                    911,
                    727,
                    590,
                    455,
                    339,
                    307,
                    239,
                    190,
                    151,
                    95,
                    84,
                    98,
                    64,
                    62,
                    50,
                    38,
                    36,
                    34,
                    19,
                    14,
                    14,
                    10,
                    8,
                    12,
                    4,
                    7,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    3,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.158,
                    0.474,
                    0.79,
                    1.105,
                    1.421,
                    1.737,
                    2.053,
                    2.368,
                    2.684,
                    3,
                    3.316,
                    3.632,
                    3.947,
                    4.263,
                    4.579,
                    4.895,
                    5.21,
                    5.526,
                    5.842,
                    6.158,
                    6.474,
                    6.789,
                    7.105,
                    7.421,
                    7.737,
                    8.052,
                    8.368,
                    8.684,
                    9,
                    9.315,
                    9.631,
                    9.947,
                    10.263,
                    10.579,
                    10.894,
                    11.21,
                    11.526,
                    11.842,
                    12.157,
                    12.473,
                    12.789,
                    13.105,
                    13.421,
                    13.736,
                    14.052,
                    14.368,
                    14.684,
                    14.999,
                    15.315,
                    15.631
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    8,
                    12,
                    32,
                    71,
                    99,
                    159,
                    283,
                    418,
                    608,
                    824,
                    1265,
                    1646,
                    2052,
                    2465,
                    2834,
                    3124,
                    3399,
                    3510,
                    3403,
                    3327,
                    3074,
                    2771,
                    2408,
                    2225,
                    1945,
                    1750,
                    1422,
                    1192,
                    993,
                    793,
                    622,
                    482,
                    339,
                    249,
                    173,
                    104,
                    63,
                    50,
                    16,
                    11,
                    8,
                    5,
                    5,
                    5,
                    2,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.567,
                    -0.539,
                    -0.512,
                    -0.484,
                    -0.457,
                    -0.429,
                    -0.402,
                    -0.374,
                    -0.347,
                    -0.319,
                    -0.291,
                    -0.264,
                    -0.236,
                    -0.209,
                    -0.181,
                    -0.154,
                    -0.126,
                    -0.099,
                    -0.071,
                    -0.043,
                    -0.016,
                    0.012,
                    0.039,
                    0.067,
                    0.094,
                    0.122,
                    0.149,
                    0.177,
                    0.205,
                    0.232,
                    0.26,
                    0.287,
                    0.315,
                    0.342,
                    0.37,
                    0.397,
                    0.425,
                    0.453,
                    0.48,
                    0.508,
                    0.535,
                    0.563,
                    0.59,
                    0.618,
                    0.645,
                    0.673,
                    0.701,
                    0.728,
                    0.756,
                    0.783
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to advanced cognitive stages and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements related to knowledge and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghg5xgfbje10exspp02x14",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xgfbjl10expd7x9tbo",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.789,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghg5xifbk010exgakbmy4t",
                        "tokens": [
                            ".",
                            " Such",
                            " particles",
                            ",",
                            " called",
                            " tet",
                            "ra",
                            "qu",
                            "arks",
                            ",",
                            " or",
                            " their",
                            " close",
                            " relatives",
                            ",",
                            " the",
                            " pent",
                            "aqu",
                            "arks",
                            ",",
                            " would",
                            " be",
                            " exotic",
                            " states",
                            " forming",
                            " a",
                            " new",
                            " particle",
                            " species",
                            " paralle",
                            "ling",
                            " the",
                            " ordinary",
                            " mes",
                            "ons",
                            " and",
                            " b",
                            "ary",
                            "ons",
                            ".",
                            "\n",
                            "\n",
                            "D",
                            "Zero",
                            " searched",
                            " for",
                            " new",
                            " exotic",
                            " states",
                            " decaying",
                            " into",
                            " a",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " and",
                            " a",
                            " pi",
                            " mes",
                            "on",
                            ".",
                            " Both",
                            " of",
                            " these",
                            " are",
                            " well",
                            "-",
                            "known",
                            " mes",
                            "ons",
                            ",",
                            " which",
                            " travel",
                            " finite",
                            " distances",
                            " before",
                            " decaying",
                            " via",
                            " the",
                            " weak",
                            " nuclear",
                            " interaction",
                            ".",
                            " The",
                            " B",
                            " s",
                            " mes",
                            "on",
                            " is",
                            " composed",
                            " of",
                            " a",
                            " qu",
                            "ark",
                            " and",
                            " an",
                            " antiqu",
                            "ark",
                            " of",
                            " bottom",
                            " and",
                            " strange",
                            " types",
                            ",",
                            " and",
                            " the",
                            " pi",
                            " mes",
                            "on",
                            " has",
                            " an",
                            " up",
                            " and",
                            " down",
                            " qu",
                            "ark",
                            " and",
                            " antiqu",
                            "ark",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            ",",
                            " using"
                        ],
                        "dataIndex": null,
                        "index": "52826",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.789,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.877,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.772,
                            0,
                            0,
                            2.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.789,
                            12.665,
                            7.56,
                            2.002,
                            0,
                            0,
                            0,
                            0.594,
                            0,
                            0,
                            0,
                            0.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:40:11.878Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.631,
                        "binMax": 15.789,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "9965",
            "description": "questions or topics related to learning or being curious about a specific subject",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4613291323184967,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "9965",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:29:39.026Z",
                "maxActApprox": 46.528,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9965,
                    1397,
                    6983,
                    3824,
                    5476,
                    7623,
                    10267,
                    4161,
                    5753,
                    3508,
                    4988,
                    2082,
                    138,
                    7353,
                    10494,
                    2608,
                    2769,
                    3585,
                    10700,
                    7671,
                    620,
                    3796,
                    6317,
                    4491,
                    6724
                ],
                "topkCosSimValues": [
                    1,
                    0.6912,
                    0.6698,
                    0.64,
                    0.6037,
                    0.5688,
                    0.5677,
                    0.5594,
                    0.5315,
                    0.5275,
                    0.5239,
                    0.5052,
                    0.5035,
                    0.5032,
                    0.4992,
                    0.4811,
                    0.4699,
                    0.4601,
                    0.456,
                    0.4535,
                    0.4529,
                    0.4519,
                    0.4464,
                    0.4368,
                    0.4341
                ],
                "neuron_alignment_indices": [
                    665,
                    105,
                    718
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.114,
                    0.112
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    665,
                    105
                ],
                "correlated_neurons_pearson": [
                    0.074,
                    0.07,
                    0.057
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.075,
                    0.055
                ],
                "correlated_features_indices": [
                    9860,
                    9877,
                    9943
                ],
                "correlated_features_pearson": [
                    0.009,
                    0.007,
                    0.003
                ],
                "correlated_features_l1": [
                    0.012,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "rising",
                    " Kinnikuman",
                    "soDeliveryDate",
                    "soever",
                    " Lag",
                    " Stru",
                    " Rising",
                    "packing",
                    "ById",
                    " Returning"
                ],
                "neg_values": [
                    -0.755,
                    -0.681,
                    -0.663,
                    -0.662,
                    -0.639,
                    -0.621,
                    -0.614,
                    -0.61,
                    -0.599,
                    -0.599
                ],
                "pos_str": [
                    " emulate",
                    " hear",
                    " maximize",
                    " keep",
                    " recreate",
                    " avoid",
                    " know",
                    " replicate",
                    " see",
                    " pursue"
                ],
                "pos_values": [
                    1.323,
                    1.205,
                    1.161,
                    1.095,
                    1.082,
                    1.081,
                    1.076,
                    1.071,
                    1.069,
                    1.05
                ],
                "frac_nonzero": 0.00174,
                "freq_hist_data_bar_heights": [
                    879,
                    590,
                    480,
                    333,
                    289,
                    183,
                    187,
                    164,
                    137,
                    101,
                    79,
                    55,
                    70,
                    49,
                    69,
                    54,
                    63,
                    57,
                    61,
                    67,
                    78,
                    87,
                    56,
                    70,
                    61,
                    75,
                    54,
                    63,
                    51,
                    62,
                    56,
                    51,
                    54,
                    65,
                    78,
                    71,
                    67,
                    53,
                    57,
                    56,
                    62,
                    47,
                    37,
                    28,
                    23,
                    12,
                    6,
                    5,
                    2,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.465,
                    1.396,
                    2.327,
                    3.257,
                    4.188,
                    5.118,
                    6.049,
                    6.979,
                    7.91,
                    8.84,
                    9.771,
                    10.702,
                    11.632,
                    12.563,
                    13.493,
                    14.424,
                    15.354,
                    16.285,
                    17.216,
                    18.146,
                    19.077,
                    20.007,
                    20.938,
                    21.868,
                    22.799,
                    23.73,
                    24.66,
                    25.591,
                    26.521,
                    27.452,
                    28.382,
                    29.313,
                    30.244,
                    31.174,
                    32.105,
                    33.035,
                    33.966,
                    34.896,
                    35.827,
                    36.758,
                    37.688,
                    38.619,
                    39.549,
                    40.48,
                    41.41,
                    42.341,
                    43.271,
                    44.202,
                    45.133,
                    46.063
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    10,
                    19,
                    29,
                    71,
                    132,
                    263,
                    506,
                    861,
                    1411,
                    2106,
                    3091,
                    3961,
                    4560,
                    4932,
                    4944,
                    4614,
                    4093,
                    3321,
                    2716,
                    2023,
                    1607,
                    1152,
                    895,
                    638,
                    441,
                    358,
                    289,
                    227,
                    191,
                    167,
                    137,
                    113,
                    89,
                    84,
                    59,
                    50,
                    34,
                    18,
                    17,
                    11,
                    5,
                    4,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.734,
                    -0.692,
                    -0.651,
                    -0.609,
                    -0.568,
                    -0.526,
                    -0.485,
                    -0.443,
                    -0.402,
                    -0.36,
                    -0.318,
                    -0.277,
                    -0.235,
                    -0.194,
                    -0.152,
                    -0.111,
                    -0.069,
                    -0.028,
                    0.014,
                    0.056,
                    0.097,
                    0.139,
                    0.18,
                    0.222,
                    0.263,
                    0.305,
                    0.346,
                    0.388,
                    0.43,
                    0.471,
                    0.513,
                    0.554,
                    0.596,
                    0.637,
                    0.679,
                    0.72,
                    0.762,
                    0.804,
                    0.845,
                    0.887,
                    0.928,
                    0.97,
                    1.011,
                    1.053,
                    1.094,
                    1.136,
                    1.178,
                    1.219,
                    1.261,
                    1.302
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions or topics related to learning or being curious about a specific subject",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu1mfh80uri666ulbypfae",
                        "tokens": [
                            "umbledore",
                            " had",
                            " wanted",
                            " to",
                            " discuss",
                            " more",
                            " with",
                            " him",
                            ",",
                            " if",
                            " he",
                            " had",
                            " nothing",
                            " better",
                            " to",
                            " do",
                            ".",
                            "\n",
                            "\n",
                            "List",
                            " of",
                            " things",
                            " to",
                            " ask",
                            " Dumbledore",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " How",
                            " are",
                            " spells",
                            " really",
                            " made",
                            "?",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " How",
                            " does",
                            " magical",
                            " power",
                            " work",
                            "?",
                            " Why",
                            " aren",
                            "'t",
                            " I",
                            " as",
                            " powerful",
                            " as",
                            " Voldemort",
                            " was",
                            "?",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Where",
                            " does",
                            " magic",
                            " come",
                            " from",
                            "?",
                            "\n",
                            "\n",
                            "He",
                            " needed",
                            " to",
                            " contact",
                            " Professor",
                            " Qu",
                            "ir",
                            "rell",
                            ",",
                            " as",
                            " soon",
                            " as",
                            " possible",
                            ".",
                            " They",
                            " needed",
                            " the",
                            " Stone",
                            ".",
                            " Harry",
                            " reached",
                            " for",
                            " his",
                            " wand",
                            "-",
                            "\n",
                            "\n",
                            "\"",
                            "Hello",
                            " again",
                            ",",
                            " Mr",
                            ".",
                            " Potter",
                            ".\"",
                            "\n",
                            "\n",
                            "Harry",
                            " spun",
                            " around",
                            ",",
                            " almost",
                            " falling",
                            " off",
                            " his",
                            " chair",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Qu",
                            "ir",
                            "rell",
                            " was",
                            " not",
                            " leaning",
                            " against",
                            " a",
                            " wall"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.528,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            46.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.411,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu1mfh80usi666ktgkncrn",
                        "tokens": [
                            "'s",
                            " hard",
                            " to",
                            " see",
                            " how",
                            " the",
                            " Republicans",
                            " would",
                            " ever",
                            " win",
                            " another",
                            " presidential",
                            " election",
                            " .\"",
                            "Everything",
                            " we",
                            " know",
                            " about",
                            " the",
                            " political",
                            " opinions",
                            " of",
                            " new",
                            " immigrants",
                            ",",
                            " including",
                            " Hispanics",
                            " and",
                            " non",
                            "-",
                            "His",
                            "pan",
                            "ics",
                            ",",
                            " are",
                            " that",
                            " they",
                            " tend",
                            " to",
                            " favor",
                            " the",
                            " Democratic",
                            " Party",
                            " because",
                            " the",
                            " Democrats",
                            " favor",
                            " expansive",
                            " government",
                            ",",
                            " and",
                            " immigrants",
                            " are",
                            " in",
                            " favor",
                            " of",
                            " that",
                            ".\"",
                            "Cam",
                            "ar",
                            "ota",
                            " \u2014",
                            " whose",
                            " nonpartisan",
                            ",",
                            " research",
                            " group",
                            " advocates",
                            " immigration",
                            " reduction",
                            " \u2014",
                            " said",
                            " a",
                            " \"",
                            "very",
                            " large",
                            " fraction",
                            "\"",
                            " of",
                            " Republicans",
                            " feel",
                            " they",
                            " must",
                            " support",
                            " the",
                            " bill",
                            ",",
                            " a",
                            " bipartisan",
                            " effort",
                            " of",
                            " four",
                            " Republican",
                            " and",
                            " four",
                            " Democratic",
                            " lawmakers",
                            " known",
                            " as",
                            " the",
                            " \"",
                            "G",
                            "ang",
                            " of",
                            " Eight",
                            ".\"",
                            "\"[",
                            "They",
                            "]",
                            " want",
                            " to",
                            " vote",
                            " for",
                            " something",
                            " so",
                            " that",
                            " they",
                            " can",
                            " say",
                            " they",
                            " did",
                            " something",
                            ".",
                            " Whether",
                            " the",
                            " bill",
                            " has"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.501,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.501,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu1mfh80uti66680m63wgs",
                        "tokens": [
                            " Bl",
                            "of",
                            "e",
                            "ld",
                            " starts",
                            " closing",
                            " in",
                            " on",
                            " them",
                            ".",
                            " Not",
                            " only",
                            " do",
                            " the",
                            " bad",
                            " guys",
                            " want",
                            " to",
                            " manipulate",
                            " M",
                            "iki",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " rage",
                            " for",
                            " their",
                            " own",
                            " benefit",
                            ",",
                            " they",
                            " hope",
                            " to",
                            " extract",
                            " the",
                            " wolf",
                            " guy",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " blood",
                            " to",
                            " create",
                            " a",
                            " wolf",
                            " guy",
                            " of",
                            " their",
                            " own",
                            " (",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " received",
                            " a",
                            " transf",
                            "usion",
                            " of",
                            " your",
                            " blood",
                            " and",
                            " became",
                            " a",
                            " wolf",
                            " man",
                            ",",
                            " too",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " one",
                            " of",
                            " my",
                            " favorite",
                            " lines",
                            " of",
                            " the",
                            " script",
                            ").",
                            "\n",
                            "\n",
                            "Ak",
                            "ira",
                            " encounters",
                            " many",
                            " other",
                            " women",
                            " in",
                            " his",
                            " attempts",
                            " to",
                            " rescue",
                            " M",
                            "iki",
                            " from",
                            " her",
                            " strange",
                            " fate",
                            ".",
                            " And",
                            " all",
                            " of",
                            " these",
                            " women",
                            " want",
                            " to",
                            " get",
                            " naked",
                            " with",
                            " him",
                            " almost",
                            " immediately",
                            ".",
                            " At",
                            " first",
                            ",",
                            " it",
                            " just",
                            " seems",
                            " like",
                            " the",
                            " film",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " attempt"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.348,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.862,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.348,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "9709",
            "description": "information related to teachers, classrooms, and educational settings",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4596025371788428,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "9709",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:57:06.133Z",
                "maxActApprox": 49.125,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9709,
                    7804,
                    4375,
                    19632,
                    13240,
                    8895,
                    17375,
                    23827,
                    7511,
                    16034,
                    8698,
                    10891,
                    11745,
                    8285,
                    12849,
                    9803,
                    1017,
                    10445,
                    2114,
                    19680,
                    4616,
                    22012,
                    8592,
                    17577,
                    9365
                ],
                "topkCosSimValues": [
                    1,
                    0.5934,
                    0.5782,
                    0.5404,
                    0.5284,
                    0.5009,
                    0.4992,
                    0.4952,
                    0.4701,
                    0.445,
                    0.4389,
                    0.4324,
                    0.4303,
                    0.4203,
                    0.4064,
                    0.3767,
                    0.3751,
                    0.3702,
                    0.3651,
                    0.3633,
                    0.3607,
                    0.3601,
                    0.3572,
                    0.3482,
                    0.3455
                ],
                "neuron_alignment_indices": [
                    167,
                    575,
                    354
                ],
                "neuron_alignment_values": [
                    0.122,
                    0.118,
                    0.118
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    224,
                    575,
                    354
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.025,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.029,
                    0.027,
                    0.024
                ],
                "correlated_features_indices": [
                    9691,
                    9654,
                    9645
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.004,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    " launchers",
                    "rils",
                    "axy",
                    "\u00d8\u00a7\u00d9\u0126",
                    "00200000",
                    "obin",
                    "hawks",
                    " Launcher",
                    " Ports",
                    " launcher"
                ],
                "neg_values": [
                    -0.726,
                    -0.707,
                    -0.674,
                    -0.665,
                    -0.662,
                    -0.659,
                    -0.657,
                    -0.655,
                    -0.655,
                    -0.652
                ],
                "pos_str": [
                    "girls",
                    "student",
                    " Teachers",
                    " teacher",
                    " Teacher",
                    " unions",
                    "girl",
                    " teachers",
                    " teaching",
                    "education"
                ],
                "pos_values": [
                    0.936,
                    0.918,
                    0.9,
                    0.851,
                    0.842,
                    0.837,
                    0.798,
                    0.796,
                    0.776,
                    0.76
                ],
                "frac_nonzero": 0.00046,
                "freq_hist_data_bar_heights": [
                    361,
                    227,
                    148,
                    100,
                    91,
                    63,
                    49,
                    29,
                    36,
                    29,
                    27,
                    31,
                    24,
                    13,
                    13,
                    10,
                    0,
                    1,
                    3,
                    1,
                    2,
                    2,
                    5,
                    3,
                    2,
                    2,
                    1,
                    0,
                    3,
                    1,
                    1,
                    5,
                    2,
                    7,
                    2,
                    6,
                    10,
                    17,
                    20,
                    10,
                    8,
                    16,
                    9,
                    13,
                    9,
                    15,
                    7,
                    1,
                    6,
                    5
                ],
                "freq_hist_data_bar_values": [
                    0.492,
                    1.474,
                    2.457,
                    3.439,
                    4.422,
                    5.404,
                    6.387,
                    7.369,
                    8.352,
                    9.334,
                    10.317,
                    11.299,
                    12.282,
                    13.264,
                    14.247,
                    15.229,
                    16.212,
                    17.194,
                    18.177,
                    19.159,
                    20.142,
                    21.124,
                    22.107,
                    23.089,
                    24.072,
                    25.054,
                    26.037,
                    27.019,
                    28.002,
                    28.984,
                    29.967,
                    30.949,
                    31.932,
                    32.914,
                    33.897,
                    34.879,
                    35.862,
                    36.844,
                    37.827,
                    38.809,
                    39.792,
                    40.774,
                    41.757,
                    42.739,
                    43.722,
                    44.704,
                    45.687,
                    46.669,
                    47.652,
                    48.634
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    11,
                    7,
                    15,
                    18,
                    36,
                    49,
                    92,
                    163,
                    264,
                    399,
                    546,
                    884,
                    1183,
                    1730,
                    2270,
                    2781,
                    3443,
                    3873,
                    4239,
                    4341,
                    4180,
                    3917,
                    3458,
                    2985,
                    2392,
                    1951,
                    1471,
                    1063,
                    739,
                    554,
                    389,
                    250,
                    186,
                    106,
                    71,
                    52,
                    46,
                    34,
                    22,
                    9,
                    11,
                    6,
                    7,
                    3,
                    0,
                    3,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.709,
                    -0.676,
                    -0.643,
                    -0.609,
                    -0.576,
                    -0.543,
                    -0.51,
                    -0.477,
                    -0.443,
                    -0.41,
                    -0.377,
                    -0.344,
                    -0.31,
                    -0.277,
                    -0.244,
                    -0.211,
                    -0.177,
                    -0.144,
                    -0.111,
                    -0.078,
                    -0.045,
                    -0.011,
                    0.022,
                    0.055,
                    0.088,
                    0.122,
                    0.155,
                    0.188,
                    0.221,
                    0.254,
                    0.288,
                    0.321,
                    0.354,
                    0.387,
                    0.421,
                    0.454,
                    0.487,
                    0.52,
                    0.554,
                    0.587,
                    0.62,
                    0.653,
                    0.686,
                    0.72,
                    0.753,
                    0.786,
                    0.819,
                    0.853,
                    0.886,
                    0.919
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "information related to teachers, classrooms, and educational settings",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmg9am985oi66660ox4ic3",
                        "tokens": [
                            " church",
                            " shooting",
                            " in",
                            " Aurora",
                            ",",
                            " Colo",
                            ".,",
                            " was",
                            " stopped",
                            " by",
                            " a",
                            " member",
                            " of",
                            " the",
                            " congregation",
                            " carrying",
                            " a",
                            " gun",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " the",
                            " recent",
                            " mall",
                            " shooting",
                            " in",
                            " Portland",
                            ",",
                            " Ore",
                            ".,",
                            " the",
                            " gunman",
                            " took",
                            " his",
                            " own",
                            " life",
                            " minutes",
                            " after",
                            " being",
                            " confronted",
                            " by",
                            " a",
                            " sho",
                            "pper",
                            " carrying",
                            " a",
                            " concealed",
                            " weapon",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " several",
                            " years",
                            " after",
                            " the",
                            " terrorist",
                            " attacks",
                            " on",
                            " Sept",
                            ".",
                            " 11",
                            ",",
                            " 2001",
                            ",",
                            " gun",
                            " prohibition",
                            "ists",
                            " blocked",
                            " pilots",
                            " from",
                            " carrying",
                            " firearms",
                            ".",
                            " But",
                            " after",
                            " it",
                            " became",
                            " undeniable",
                            " that",
                            " guns",
                            " are",
                            " an",
                            " essential",
                            " line",
                            " of",
                            " defense",
                            " against",
                            " hij",
                            "ackers",
                            " and",
                            " other",
                            " terrorists",
                            " when",
                            " the",
                            " lives",
                            " of",
                            " innocent",
                            " passengers",
                            " are",
                            " at",
                            " stake",
                            ",",
                            " Congress",
                            " finally",
                            " passed",
                            " legislation",
                            " allowing",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " time",
                            " to",
                            " take",
                            " the",
                            " same",
                            " approach",
                            " with",
                            " teachers",
                            ",",
                            " school"
                        ],
                        "dataIndex": null,
                        "index": "9709",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.125,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.125,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:13.466Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.125,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmg9am985pi666fmr4mxao",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            "For",
                            " The",
                            " Capital",
                            "'s",
                            " three",
                            "-",
                            "part",
                            " series",
                            ",",
                            " education",
                            " reporter",
                            " Cindy",
                            " Huang",
                            " examined",
                            " teacher",
                            " experience",
                            " levels",
                            " across",
                            " 12",
                            " public",
                            " high",
                            " schools",
                            " provided",
                            " by",
                            " a",
                            " 2016",
                            " database",
                            " of",
                            " school",
                            " employees",
                            ",",
                            " their",
                            " salaries",
                            ",",
                            " years",
                            " of",
                            " experience",
                            " and",
                            " obtained",
                            " through",
                            " a",
                            " public",
                            " information",
                            " request",
                            ".",
                            " Also",
                            " examined",
                            " was",
                            " data",
                            " of",
                            " classroom",
                            " teachers",
                            ",",
                            " including",
                            " department",
                            " chairs",
                            " to",
                            " determine",
                            " how",
                            " many",
                            " teachers",
                            " at",
                            " each",
                            " high",
                            " school",
                            " began",
                            " the",
                            " year",
                            " with",
                            " three",
                            " years",
                            " or",
                            " less",
                            " of",
                            " experience",
                            ".",
                            " The",
                            " school",
                            " system",
                            " provided",
                            " the",
                            " turnover",
                            " rates",
                            " for",
                            " teachers",
                            ".",
                            " The",
                            " data",
                            " includes",
                            " all",
                            " employees",
                            " in",
                            " the",
                            " Unit",
                            " I",
                            " employee",
                            " union",
                            ",",
                            " which",
                            " is",
                            " represented",
                            " by",
                            " the",
                            " Teachers",
                            " Association",
                            " of",
                            " Anne",
                            " A",
                            "ru",
                            "nd",
                            "el",
                            " County",
                            ".",
                            "\n",
                            "\n",
                            "Among",
                            " those",
                            " interviewed",
                            " over",
                            " four",
                            " months",
                            ";",
                            " teachers",
                            " and",
                            " former"
                        ],
                        "dataIndex": null,
                        "index": "9709",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.976,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.976,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.833,
                            42.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.43,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.973,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.258,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:13.466Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.125,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmg9ao9868i666h0qkklgd",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            "For",
                            " The",
                            " Capital",
                            "'s",
                            " three",
                            "-",
                            "part",
                            " series",
                            ",",
                            " education",
                            " reporter",
                            " Cindy",
                            " Huang",
                            " examined",
                            " teacher",
                            " experience",
                            " levels",
                            " across",
                            " 12",
                            " public",
                            " high",
                            " schools",
                            " provided",
                            " by",
                            " a",
                            " 2016",
                            " database",
                            " of",
                            " school",
                            " employees",
                            ",",
                            " their",
                            " salaries",
                            ",",
                            " years",
                            " of",
                            " experience",
                            " and",
                            " obtained",
                            " through",
                            " a",
                            " public",
                            " information",
                            " request",
                            ".",
                            " Also",
                            " examined",
                            " was",
                            " data",
                            " of",
                            " classroom",
                            " teachers",
                            ",",
                            " including",
                            " department",
                            " chairs",
                            " to",
                            " determine",
                            " how",
                            " many",
                            " teachers",
                            " at",
                            " each",
                            " high",
                            " school",
                            " began",
                            " the",
                            " year",
                            " with",
                            " three",
                            " years",
                            " or",
                            " less",
                            " of",
                            " experience",
                            ".",
                            " The",
                            " school",
                            " system",
                            " provided",
                            " the",
                            " turnover",
                            " rates",
                            " for",
                            " teachers",
                            ".",
                            " The",
                            " data",
                            " includes",
                            " all",
                            " employees",
                            " in",
                            " the",
                            " Unit",
                            " I",
                            " employee",
                            " union",
                            ",",
                            " which",
                            " is",
                            " represented",
                            " by",
                            " the",
                            " Teachers",
                            " Association",
                            " of",
                            " Anne",
                            " A",
                            "ru",
                            "nd",
                            "el",
                            " County",
                            ".",
                            "\n",
                            "\n",
                            "Among",
                            " those",
                            " interviewed",
                            " over",
                            " four",
                            " months",
                            ";",
                            " teachers",
                            " and",
                            " former"
                        ],
                        "dataIndex": null,
                        "index": "9709",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.976,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.976,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.833,
                            42.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.676,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.43,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.973,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.258,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:13.466Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 39.3,
                        "binMax": 49.125,
                        "binContains": 3e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5368",
            "description": "statements related to education and teaching methods",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4590795772993441,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5368",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:26.905Z",
                "maxActApprox": 40.572,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5368,
                    5681,
                    4191,
                    3878,
                    4574,
                    723,
                    407,
                    3647,
                    2419,
                    1460,
                    2278,
                    2769,
                    3848,
                    3311,
                    1370,
                    1154,
                    2255,
                    4728,
                    4634,
                    2208,
                    3651,
                    24,
                    4188,
                    5488,
                    1073
                ],
                "topkCosSimValues": [
                    1,
                    0.4779,
                    0.4544,
                    0.4237,
                    0.4202,
                    0.3907,
                    0.3893,
                    0.375,
                    0.3556,
                    0.3397,
                    0.3274,
                    0.3194,
                    0.3128,
                    0.3117,
                    0.3048,
                    0.293,
                    0.2913,
                    0.2848,
                    0.2829,
                    0.2712,
                    0.2708,
                    0.2705,
                    0.2698,
                    0.2661,
                    0.2601
                ],
                "neuron_alignment_indices": [
                    546,
                    698,
                    765
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.112,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    546,
                    765,
                    43
                ],
                "correlated_neurons_pearson": [
                    0.147,
                    0.117,
                    0.116
                ],
                "correlated_neurons_l1": [
                    0.146,
                    0.121,
                    0.105
                ],
                "correlated_features_indices": [
                    5286,
                    5324,
                    5358
                ],
                "correlated_features_pearson": [
                    0.115,
                    0.035,
                    0.016
                ],
                "correlated_features_l1": [
                    0.119,
                    0.04,
                    0.02
                ],
                "neg_str": [
                    "uta",
                    "itol",
                    " Zeal",
                    "\u00e3\u0123\u0142",
                    "cast",
                    "thora",
                    "venth",
                    "chnology",
                    "uther",
                    " GG"
                ],
                "neg_values": [
                    -0.677,
                    -0.584,
                    -0.577,
                    -0.576,
                    -0.566,
                    -0.559,
                    -0.556,
                    -0.551,
                    -0.544,
                    -0.541
                ],
                "pos_str": [
                    " according",
                    " says",
                    "according",
                    " said",
                    " writes",
                    " experts",
                    "said",
                    " analysts",
                    " observes",
                    " explained"
                ],
                "pos_values": [
                    1.418,
                    1.113,
                    1.1,
                    1.079,
                    0.911,
                    0.904,
                    0.886,
                    0.884,
                    0.829,
                    0.828
                ],
                "frac_nonzero": 0.01185,
                "freq_hist_data_bar_heights": [
                    7376,
                    5300,
                    3830,
                    3039,
                    2342,
                    1933,
                    1697,
                    1450,
                    1190,
                    1033,
                    868,
                    833,
                    636,
                    653,
                    534,
                    506,
                    423,
                    416,
                    302,
                    330,
                    286,
                    271,
                    251,
                    202,
                    189,
                    182,
                    141,
                    156,
                    119,
                    118,
                    102,
                    85,
                    91,
                    63,
                    57,
                    45,
                    36,
                    35,
                    36,
                    17,
                    27,
                    22,
                    19,
                    13,
                    11,
                    8,
                    3,
                    4,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.406,
                    1.217,
                    2.029,
                    2.84,
                    3.651,
                    4.463,
                    5.274,
                    6.086,
                    6.897,
                    7.709,
                    8.52,
                    9.331,
                    10.143,
                    10.954,
                    11.766,
                    12.577,
                    13.389,
                    14.2,
                    15.011,
                    15.823,
                    16.634,
                    17.446,
                    18.257,
                    19.069,
                    19.88,
                    20.691,
                    21.503,
                    22.314,
                    23.126,
                    23.937,
                    24.749,
                    25.56,
                    26.371,
                    27.183,
                    27.994,
                    28.806,
                    29.617,
                    30.429,
                    31.24,
                    32.051,
                    32.863,
                    33.674,
                    34.486,
                    35.297,
                    36.109,
                    36.92,
                    37.731,
                    38.543,
                    39.354,
                    40.166
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    7,
                    24,
                    31,
                    65,
                    154,
                    313,
                    558,
                    990,
                    1568,
                    2592,
                    3493,
                    4521,
                    5249,
                    5643,
                    5445,
                    4876,
                    4117,
                    3263,
                    2374,
                    1716,
                    1189,
                    772,
                    516,
                    296,
                    178,
                    105,
                    69,
                    45,
                    25,
                    23,
                    9,
                    10,
                    4,
                    8,
                    0,
                    4,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.656,
                    -0.614,
                    -0.572,
                    -0.53,
                    -0.488,
                    -0.446,
                    -0.404,
                    -0.363,
                    -0.321,
                    -0.279,
                    -0.237,
                    -0.195,
                    -0.153,
                    -0.111,
                    -0.069,
                    -0.027,
                    0.014,
                    0.056,
                    0.098,
                    0.14,
                    0.182,
                    0.224,
                    0.266,
                    0.308,
                    0.35,
                    0.391,
                    0.433,
                    0.475,
                    0.517,
                    0.559,
                    0.601,
                    0.643,
                    0.685,
                    0.727,
                    0.768,
                    0.81,
                    0.852,
                    0.894,
                    0.936,
                    0.978,
                    1.02,
                    1.062,
                    1.104,
                    1.145,
                    1.187,
                    1.229,
                    1.271,
                    1.313,
                    1.355,
                    1.397
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "statements related to education and teaching methods",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtgs65xpjwi6667wv6k8da",
                        "tokens": [
                            " It",
                            " also",
                            " could",
                            " mean",
                            " that",
                            " schools",
                            " are",
                            " missing",
                            " the",
                            " right",
                            " time",
                            " to",
                            " teach",
                            " those",
                            " subjects",
                            ".",
                            "\n",
                            "\n",
                            "School",
                            "s",
                            " ought",
                            " to",
                            " consider",
                            " some",
                            " gender",
                            "-",
                            "based",
                            " curric",
                            "ula",
                            ",",
                            " Jensen",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " beyond",
                            " gender",
                            " differences",
                            ",",
                            " if",
                            " every",
                            " student",
                            " were",
                            " given",
                            " a",
                            " neurological",
                            " evaluation",
                            ",",
                            " educators",
                            " would",
                            " have",
                            " powerful",
                            " clues",
                            " as",
                            " to",
                            " the",
                            " best",
                            " way",
                            " to",
                            " personal",
                            "ize",
                            " learning",
                            ",",
                            " she",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Br",
                            "ains",
                            " are",
                            " in",
                            " such",
                            " a",
                            " different",
                            " state",
                            " from",
                            " person",
                            " to",
                            " person",
                            ",",
                            " they",
                            " should",
                            " be",
                            " taught",
                            " differently",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "<|endoftext|>",
                            "Why",
                            " has",
                            " the",
                            " BBC",
                            " become",
                            " the",
                            " official",
                            " propaganda",
                            " arm",
                            " of",
                            " the",
                            " Vatican",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " Vatican",
                            " is",
                            " desperate",
                            " to",
                            " rehabilit",
                            "ate",
                            " its",
                            " reputation",
                            ".",
                            " And",
                            " well",
                            " it",
                            " might",
                            " be",
                            ".",
                            " The",
                            " past"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.572,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.621,
                            0,
                            5.03,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.4,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.66,
                            0.712,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.572,
                            2.983,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.879,
                            11.477,
                            5.085,
                            0,
                            0,
                            6.51,
                            33.86,
                            3.338,
                            10.238,
                            1.222,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjxi666fvxm0wp4",
                        "tokens": [
                            " and",
                            " run",
                            " east",
                            "bound",
                            " on",
                            " Roosevelt",
                            " Street",
                            ",",
                            " said",
                            " Deputy",
                            " Jo",
                            "aquin",
                            " En",
                            "ri",
                            "quez",
                            ",",
                            " a",
                            " sheriff",
                            "'s",
                            " spokesman",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " detention",
                            " officers",
                            " secured",
                            " the",
                            " other",
                            " two",
                            " inmates",
                            ",",
                            " and",
                            " the",
                            " second",
                            " detention",
                            " officer",
                            " hopped",
                            " back",
                            " in",
                            " the",
                            " van",
                            " and",
                            " took",
                            " off",
                            " after",
                            " Fres",
                            "cas",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            " Another",
                            " deputy",
                            " was",
                            " called",
                            " for",
                            " backup",
                            ",",
                            " and",
                            " the",
                            " hospital",
                            " was",
                            " placed",
                            " on",
                            " a",
                            " brief",
                            " lockdown",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " officer",
                            " caught",
                            " up",
                            " with",
                            " Fres",
                            "cas",
                            " about",
                            " 500",
                            " yards",
                            " away",
                            " from",
                            " the",
                            " hospital",
                            ",",
                            " exited",
                            " the",
                            " van",
                            " and",
                            " a",
                            " struggle",
                            " ensued",
                            " over",
                            " the",
                            " officer",
                            "'s",
                            " weapon",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Investigators",
                            " say",
                            " Fres",
                            "cas",
                            " held",
                            " the",
                            " gun",
                            " at",
                            " one",
                            " point",
                            ",",
                            " but",
                            " it",
                            " was",
                            " unclear",
                            " whether",
                            " Fres"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.617,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.701,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.935,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.219,
                            0,
                            0,
                            3.136,
                            0,
                            0,
                            15.275,
                            0,
                            0,
                            5.967,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.623,
                            0,
                            0,
                            0,
                            0.513,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.758,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.191,
                            0,
                            0.513,
                            39.617,
                            1.141,
                            0,
                            5.073,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjyi666ft8m5a48",
                        "tokens": [
                            "than",
                            "-",
                            "usual",
                            " target",
                            " number",
                            " may",
                            " be",
                            " partially",
                            " driven",
                            " by",
                            " an",
                            " effort",
                            " to",
                            " reach",
                            " a",
                            " deportation",
                            " goal",
                            " at",
                            " the",
                            " end",
                            " of",
                            " the",
                            " fiscal",
                            " year",
                            ",",
                            " which",
                            " ends",
                            " Sept",
                            ".",
                            " 30",
                            ",",
                            " one",
                            " of",
                            " the",
                            " officials",
                            " said",
                            ".",
                            " Operation",
                            " Mega",
                            " is",
                            " still",
                            " in",
                            " the",
                            " planning",
                            " stage",
                            " and",
                            " its",
                            " details",
                            " may",
                            " change",
                            " or",
                            " it",
                            " may",
                            " even",
                            " be",
                            " cancelled",
                            ",",
                            " the",
                            " officials",
                            " said",
                            ",",
                            " especially",
                            " as",
                            " the",
                            " agency",
                            " re",
                            "alloc",
                            "ates",
                            " resources",
                            " toward",
                            " rescue",
                            " operations",
                            " in",
                            " Florida",
                            " ahead",
                            " of",
                            " the",
                            " looming",
                            " Hurricane",
                            " Irma",
                            ".",
                            " If",
                            " carried",
                            " out",
                            ",",
                            " it",
                            " would",
                            " come",
                            " on",
                            " the",
                            " heels",
                            " of",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " controversial",
                            " decision",
                            " to",
                            " end",
                            " the",
                            " Def",
                            "erred",
                            " Action",
                            " for",
                            " Childhood",
                            " Arri",
                            "vals",
                            " program",
                            ",",
                            " known",
                            " as",
                            " DACA",
                            ",",
                            " that",
                            " allows",
                            " some",
                            " immigrants",
                            " who",
                            " were",
                            " brought",
                            " into",
                            " the",
                            " United",
                            " States",
                            " as",
                            " children"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.38,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.587,
                            0.206,
                            0,
                            0,
                            0,
                            0,
                            29.692,
                            9.692,
                            0.4,
                            3.468,
                            0.9,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.005,
                            1.471,
                            0,
                            2.862,
                            0,
                            0,
                            0,
                            0.226,
                            39.38,
                            4.746,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "63582",
            "description": "content related to education and its societal implications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4524303107005181,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "63582",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:51:50.812Z",
                "maxActApprox": 7.831,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    63582,
                    64497,
                    55874,
                    80895,
                    50122,
                    56534,
                    70865,
                    40785,
                    94816,
                    17831,
                    80956,
                    8770,
                    52920,
                    96957,
                    17952,
                    33912,
                    39152,
                    74607,
                    73316,
                    38966,
                    85524,
                    15985,
                    27583,
                    18728,
                    71258
                ],
                "topkCosSimValues": [
                    1,
                    0.5471,
                    0.5361,
                    0.5004,
                    0.4881,
                    0.4774,
                    0.4642,
                    0.4625,
                    0.4617,
                    0.4614,
                    0.4601,
                    0.4598,
                    0.4569,
                    0.4564,
                    0.4546,
                    0.4534,
                    0.4533,
                    0.4522,
                    0.4522,
                    0.451,
                    0.4486,
                    0.4478,
                    0.4455,
                    0.4439,
                    0.4408
                ],
                "neuron_alignment_indices": [
                    447,
                    480,
                    246
                ],
                "neuron_alignment_values": [
                    0.252,
                    0.128,
                    0.111
                ],
                "neuron_alignment_l1": [
                    0.012,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    6,
                    679,
                    640
                ],
                "correlated_neurons_pearson": [
                    0.074,
                    0.063,
                    0.062
                ],
                "correlated_neurons_l1": [
                    0.083,
                    0.074,
                    0.073
                ],
                "correlated_features_indices": [
                    63666,
                    63682,
                    63686
                ],
                "correlated_features_pearson": [
                    0.07,
                    0.005,
                    0.005
                ],
                "correlated_features_l1": [
                    0.071,
                    0.006,
                    0.006
                ],
                "neg_str": [
                    " asteroid",
                    " landfall",
                    " bolted",
                    " deton",
                    "ernaut",
                    " bullish",
                    " contingency",
                    " forecasting",
                    " powering",
                    "rium"
                ],
                "neg_values": [
                    -0.804,
                    -0.801,
                    -0.8,
                    -0.779,
                    -0.777,
                    -0.773,
                    -0.758,
                    -0.756,
                    -0.748,
                    -0.747
                ],
                "pos_str": [
                    " Parents",
                    " Similarly",
                    " Mothers",
                    " Femin",
                    " Teachers",
                    " Discrimination",
                    " Females",
                    "Parents",
                    " Often",
                    " Likewise"
                ],
                "pos_values": [
                    1.21,
                    1.116,
                    1.105,
                    1.104,
                    1.094,
                    1.09,
                    1.084,
                    1.067,
                    1.05,
                    1.043
                ],
                "frac_nonzero": 0.00299,
                "freq_hist_data_bar_heights": [
                    1185,
                    1042,
                    936,
                    802,
                    711,
                    559,
                    557,
                    451,
                    399,
                    376,
                    332,
                    250,
                    267,
                    190,
                    165,
                    141,
                    136,
                    123,
                    110,
                    98,
                    91,
                    66,
                    70,
                    60,
                    46,
                    21,
                    33,
                    21,
                    26,
                    20,
                    21,
                    17,
                    8,
                    9,
                    10,
                    5,
                    6,
                    5,
                    4,
                    6,
                    5,
                    3,
                    0,
                    4,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.078,
                    0.235,
                    0.392,
                    0.548,
                    0.705,
                    0.861,
                    1.018,
                    1.175,
                    1.331,
                    1.488,
                    1.644,
                    1.801,
                    1.958,
                    2.114,
                    2.271,
                    2.427,
                    2.584,
                    2.741,
                    2.897,
                    3.054,
                    3.211,
                    3.367,
                    3.524,
                    3.68,
                    3.837,
                    3.994,
                    4.15,
                    4.307,
                    4.463,
                    4.62,
                    4.777,
                    4.933,
                    5.09,
                    5.246,
                    5.403,
                    5.56,
                    5.716,
                    5.873,
                    6.03,
                    6.186,
                    6.343,
                    6.499,
                    6.656,
                    6.813,
                    6.969,
                    7.126,
                    7.282,
                    7.439,
                    7.596,
                    7.752
                ],
                "logits_hist_data_bar_heights": [
                    6,
                    9,
                    20,
                    22,
                    61,
                    117,
                    185,
                    305,
                    454,
                    668,
                    979,
                    1229,
                    1605,
                    2002,
                    2358,
                    2654,
                    3021,
                    3287,
                    3428,
                    3489,
                    3441,
                    3471,
                    3137,
                    2847,
                    2376,
                    1973,
                    1661,
                    1253,
                    964,
                    773,
                    616,
                    429,
                    325,
                    283,
                    196,
                    126,
                    123,
                    96,
                    78,
                    50,
                    41,
                    27,
                    22,
                    15,
                    14,
                    12,
                    3,
                    5,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.784,
                    -0.743,
                    -0.703,
                    -0.663,
                    -0.622,
                    -0.582,
                    -0.542,
                    -0.502,
                    -0.461,
                    -0.421,
                    -0.381,
                    -0.341,
                    -0.3,
                    -0.26,
                    -0.22,
                    -0.18,
                    -0.139,
                    -0.099,
                    -0.059,
                    -0.018,
                    0.022,
                    0.062,
                    0.102,
                    0.143,
                    0.183,
                    0.223,
                    0.263,
                    0.304,
                    0.344,
                    0.384,
                    0.425,
                    0.465,
                    0.505,
                    0.545,
                    0.586,
                    0.626,
                    0.666,
                    0.706,
                    0.747,
                    0.787,
                    0.827,
                    0.867,
                    0.908,
                    0.948,
                    0.988,
                    1.029,
                    1.069,
                    1.109,
                    1.149,
                    1.19
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "content related to education and its societal implications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " sentiments and discussions related to educational challenges and discrimination issues",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghv6cmnie910exfoyyhs1r",
                        "tokens": [
                            " blood",
                            " transf",
                            "usions",
                            ".",
                            " How",
                            " would",
                            " you",
                            " feel",
                            " if",
                            " your",
                            " loved",
                            " one",
                            " might",
                            " possibly",
                            " be",
                            " alive",
                            " had",
                            " a",
                            " blood",
                            " transf",
                            "usion",
                            " been",
                            " given",
                            "?",
                            "\n",
                            "\n",
                            "Which",
                            " brings",
                            " me",
                            " to",
                            " the",
                            " subject",
                            " of",
                            " religious",
                            " upbringing",
                            " and",
                            " education",
                            " of",
                            " young",
                            " children",
                            ".",
                            " Parents",
                            " do",
                            " have",
                            " the",
                            " right",
                            " to",
                            " raise",
                            " their",
                            " children",
                            " the",
                            " way",
                            " they",
                            " see",
                            " fit",
                            ".",
                            " That",
                            "'s",
                            " the",
                            " core",
                            " of",
                            " family",
                            " values",
                            ".",
                            " At",
                            " the",
                            " same",
                            " time",
                            ",",
                            " parents",
                            " don",
                            "'t",
                            " literally",
                            " own",
                            " their",
                            " children",
                            " (",
                            "like",
                            " slave",
                            " owners",
                            " once",
                            " owned",
                            " slaves",
                            "),",
                            " but",
                            " are",
                            " more",
                            " like",
                            " their",
                            " guardians",
                            " and",
                            " ought",
                            " to",
                            " be",
                            " held",
                            " accountable",
                            " by",
                            " outsiders",
                            ".",
                            " Outs",
                            "iders",
                            " have",
                            " a",
                            " right",
                            " to",
                            " interfere",
                            " if",
                            " the",
                            " parents",
                            " do",
                            " harm",
                            " to",
                            " their",
                            " children",
                            ".",
                            " Similarly",
                            ",",
                            " some",
                            " might",
                            " say",
                            " no",
                            " prospective",
                            " parent",
                            " has",
                            " the",
                            " right",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "63582",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.831,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0.704,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.319,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.831,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.283,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.771,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:51:52.279Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.831,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghv6cmniea10ex77p29owl",
                        "tokens": [
                            " cultural",
                            " backgrounds",
                            " that",
                            " are",
                            " Black",
                            " or",
                            " another",
                            " dark",
                            " group",
                            " that",
                            " white",
                            " people",
                            " tend",
                            " to",
                            " disbel",
                            "ieve",
                            " or",
                            " discount",
                            " their",
                            " tell",
                            "ings",
                            " of",
                            " their",
                            " histories",
                            ".",
                            " There",
                            " is",
                            " a",
                            " pressure",
                            " coming",
                            " from",
                            " white",
                            " people",
                            " to",
                            " make",
                            " light",
                            "-",
                            "skinned",
                            " people",
                            " be",
                            " white",
                            ".",
                            " Michelle",
                            " Cliff",
                            " speaks",
                            " of",
                            " this",
                            " in",
                            " her",
                            " book",
                            " Claim",
                            "ing",
                            " An",
                            " Identity",
                            " They",
                            " T",
                            "aught",
                            " Me",
                            " To",
                            " Des",
                            "p",
                            "ise",
                            ".",
                            "1",
                            " Cliff",
                            " is",
                            " a",
                            " light",
                            "-",
                            "skinned",
                            " woman",
                            " who",
                            " looks",
                            " white",
                            " to",
                            " most",
                            " white",
                            " people",
                            ".",
                            " She",
                            " encounters",
                            " among",
                            " white",
                            " people",
                            " resistance",
                            ",",
                            " even",
                            " hostility",
                            ",",
                            " to",
                            " her",
                            " assertion",
                            " that",
                            " she",
                            " is",
                            " Black",
                            ".",
                            " In",
                            " another",
                            " case",
                            ",",
                            " a",
                            " friend",
                            " of",
                            " mine",
                            " to",
                            " whom",
                            " I",
                            " have",
                            " been",
                            " quite",
                            " close",
                            " off",
                            " and",
                            " on",
                            " for",
                            " some",
                            " fifteen",
                            " or",
                            " twenty",
                            " years",
                            ",",
                            " noticed",
                            " I",
                            " was",
                            " assuming",
                            " she"
                        ],
                        "dataIndex": null,
                        "index": "63582",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.822,
                        "maxValueTokenIndex": 41,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.08,
                            3.248,
                            1.979,
                            1.435,
                            0.393,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.822,
                            0,
                            0,
                            0,
                            1.85,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.075,
                            0.542,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.355,
                            0.622,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:51:52.279Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.831,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghv6cnnieb10exbhqmwbn7",
                        "tokens": [
                            " that",
                            " black",
                            " children",
                            " were",
                            " inn",
                            "ately",
                            " unable",
                            " to",
                            " learn",
                            " as",
                            " well",
                            " as",
                            " white",
                            " children",
                            ".",
                            " Arthur",
                            " Jensen",
                            " stimulated",
                            " scholarly",
                            " discussion",
                            " of",
                            " the",
                            " issue",
                            " with",
                            " his",
                            " Harvard",
                            " Educational",
                            " Review",
                            " article",
                            ",",
                            " \"",
                            "How",
                            " Much",
                            " Can",
                            " We",
                            " Boost",
                            " IQ",
                            " and",
                            " Sch",
                            "ol",
                            "astic",
                            " Achievement",
                            "?\"",
                            "[",
                            "14",
                            "]",
                            " Jensen",
                            "'s",
                            " article",
                            " questioned",
                            " remed",
                            "ial",
                            " education",
                            " for",
                            " African",
                            "-",
                            "American",
                            " children",
                            ";",
                            " he",
                            " suggested",
                            " their",
                            " poor",
                            " educational",
                            " performance",
                            " reflected",
                            " an",
                            " underlying",
                            " genetic",
                            " cause",
                            " rather",
                            " than",
                            " lack",
                            " of",
                            " stimulation",
                            " at",
                            " home",
                            ".",
                            " Jensen",
                            " continued",
                            " to",
                            " publish",
                            " on",
                            " the",
                            " issue",
                            " until",
                            " his",
                            " death",
                            " in",
                            " 2012",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Bell",
                            " Curve",
                            " debate",
                            "\n",
                            "\n",
                            "Another",
                            " revival",
                            " of",
                            " public",
                            " debate",
                            " followed",
                            " the",
                            " appearance",
                            " of",
                            " The",
                            " Bell",
                            " Curve",
                            " (",
                            "1994",
                            "),",
                            " a",
                            " book",
                            " by",
                            " Richard",
                            " Her",
                            "rn",
                            "stein",
                            " and",
                            " Charles",
                            " Murray",
                            ",",
                            " who",
                            " strongly"
                        ],
                        "dataIndex": null,
                        "index": "63582",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.518,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.518,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.507,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.054,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:51:52.279Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.831,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "13984",
            "description": "motivated and instructional language related to personal development and community engagement",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.44765371084213257,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "13984",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:02:43.675Z",
                "maxActApprox": 12.673,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13984,
                    22569,
                    22039,
                    7861,
                    12138,
                    16669,
                    8386,
                    16837,
                    8790,
                    19965,
                    20239,
                    14889,
                    22554,
                    1662,
                    2730,
                    24311,
                    15787,
                    8240,
                    17379,
                    1099,
                    5321,
                    5231,
                    21727,
                    18260,
                    7740
                ],
                "topkCosSimValues": [
                    1,
                    0.5458,
                    0.5237,
                    0.5091,
                    0.4934,
                    0.4813,
                    0.4782,
                    0.4696,
                    0.4689,
                    0.4591,
                    0.4547,
                    0.453,
                    0.4458,
                    0.4439,
                    0.4342,
                    0.434,
                    0.433,
                    0.433,
                    0.4319,
                    0.4287,
                    0.4269,
                    0.4258,
                    0.4244,
                    0.422,
                    0.419
                ],
                "neuron_alignment_indices": [
                    480,
                    266,
                    763
                ],
                "neuron_alignment_values": [
                    0.477,
                    0.136,
                    0.079
                ],
                "neuron_alignment_l1": [
                    0.024,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    480,
                    266,
                    566
                ],
                "correlated_neurons_pearson": [
                    0.068,
                    0.062,
                    0.052
                ],
                "correlated_neurons_l1": [
                    0.015,
                    0.07,
                    0.054
                ],
                "correlated_features_indices": [
                    14065,
                    13983,
                    14058
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.007,
                    0.006
                ],
                "correlated_features_l1": [
                    0.014,
                    0.008,
                    0.007
                ],
                "neg_str": [
                    " Reconstruction",
                    " supplemented",
                    " Annex",
                    "gerald",
                    "Bridge",
                    " Alas",
                    "Eastern",
                    " purported",
                    "\u012c\u00b1",
                    "ighed"
                ],
                "neg_values": [
                    -0.58,
                    -0.562,
                    -0.561,
                    -0.561,
                    -0.549,
                    -0.538,
                    -0.522,
                    -0.52,
                    -0.51,
                    -0.507
                ],
                "pos_str": [
                    " yourself",
                    " yourselves",
                    " Yourself",
                    " your",
                    " YOUR",
                    "your",
                    "Your",
                    " Your",
                    " yours",
                    "?'"
                ],
                "pos_values": [
                    1.462,
                    1.282,
                    1.007,
                    0.99,
                    0.885,
                    0.817,
                    0.784,
                    0.744,
                    0.642,
                    0.6
                ],
                "frac_nonzero": 0.00573,
                "freq_hist_data_bar_heights": [
                    2059,
                    1771,
                    1478,
                    1353,
                    1174,
                    1087,
                    880,
                    833,
                    725,
                    655,
                    566,
                    549,
                    523,
                    489,
                    455,
                    386,
                    332,
                    297,
                    308,
                    282,
                    234,
                    229,
                    174,
                    184,
                    141,
                    149,
                    108,
                    105,
                    84,
                    71,
                    67,
                    67,
                    52,
                    45,
                    26,
                    12,
                    19,
                    14,
                    12,
                    8,
                    7,
                    11,
                    3,
                    3,
                    3,
                    1,
                    1,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.127,
                    0.38,
                    0.634,
                    0.887,
                    1.141,
                    1.394,
                    1.648,
                    1.901,
                    2.154,
                    2.408,
                    2.661,
                    2.915,
                    3.168,
                    3.422,
                    3.675,
                    3.929,
                    4.182,
                    4.436,
                    4.689,
                    4.942,
                    5.196,
                    5.449,
                    5.703,
                    5.956,
                    6.21,
                    6.463,
                    6.717,
                    6.97,
                    7.224,
                    7.477,
                    7.731,
                    7.984,
                    8.237,
                    8.491,
                    8.744,
                    8.998,
                    9.251,
                    9.505,
                    9.758,
                    10.012,
                    10.265,
                    10.519,
                    10.772,
                    11.025,
                    11.279,
                    11.532,
                    11.786,
                    12.039,
                    12.293,
                    12.546
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    16,
                    42,
                    100,
                    211,
                    457,
                    924,
                    1548,
                    2338,
                    3209,
                    4390,
                    5234,
                    5675,
                    5819,
                    5362,
                    4491,
                    3517,
                    2634,
                    1763,
                    1109,
                    659,
                    359,
                    211,
                    94,
                    36,
                    21,
                    12,
                    5,
                    1,
                    0,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.56,
                    -0.519,
                    -0.478,
                    -0.437,
                    -0.397,
                    -0.356,
                    -0.315,
                    -0.274,
                    -0.233,
                    -0.192,
                    -0.151,
                    -0.111,
                    -0.07,
                    -0.029,
                    0.012,
                    0.053,
                    0.094,
                    0.134,
                    0.175,
                    0.216,
                    0.257,
                    0.298,
                    0.339,
                    0.379,
                    0.42,
                    0.461,
                    0.502,
                    0.543,
                    0.584,
                    0.624,
                    0.665,
                    0.706,
                    0.747,
                    0.788,
                    0.829,
                    0.869,
                    0.91,
                    0.951,
                    0.992,
                    1.033,
                    1.074,
                    1.115,
                    1.155,
                    1.196,
                    1.237,
                    1.278,
                    1.319,
                    1.36,
                    1.4,
                    1.441
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "motivated and instructional language related to personal development and community engagement",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmndtjdafvi66634wirqxd",
                        "tokens": [
                            " to",
                            " get",
                            " better",
                            " at",
                            " it",
                            ".",
                            " By",
                            " participating",
                            " in",
                            " the",
                            " KC",
                            "IT",
                            "P",
                            " community",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " illustrated",
                            " an",
                            " enhanced",
                            " dedication",
                            " to",
                            " your",
                            " technology",
                            " career",
                            ".",
                            "\n",
                            "\n",
                            "Whether",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " sharing",
                            " content",
                            " or",
                            " answering",
                            " questions",
                            " on",
                            " our",
                            " Link",
                            "edin",
                            " forum",
                            ",",
                            " interacting",
                            " on",
                            " Twitter",
                            ",",
                            " or",
                            " attending",
                            " events",
                            "\u00e2\u0122\u00a6",
                            "you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " made",
                            " it",
                            " clear",
                            " that",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " motivated",
                            ".",
                            "\n",
                            "\n",
                            "Through",
                            " these",
                            " community",
                            " interactions",
                            ",",
                            " a",
                            " potential",
                            " employer",
                            " might",
                            " be",
                            " able",
                            " to",
                            " see",
                            " that",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " simply",
                            " not",
                            " interested",
                            " in",
                            " doing",
                            " the",
                            " bare",
                            " minimum",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " want",
                            " to",
                            " excel",
                            ".",
                            " That",
                            " matters",
                            ".",
                            "\n",
                            "\n",
                            "Reason",
                            " #",
                            "2",
                            ":",
                            " You",
                            " want",
                            " to",
                            " learn",
                            " more",
                            "\n",
                            "\n",
                            "Some",
                            " of",
                            " the",
                            " best",
                            " people",
                            " I",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "13984",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.673,
                        "maxValueTokenIndex": 19,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            1.499,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.504,
                            0,
                            10.536,
                            12.673,
                            1.615,
                            0,
                            1.563,
                            0,
                            0.602,
                            0,
                            3.947,
                            0.955,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.137,
                            4.916,
                            1.754,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.569,
                            1.938,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:45.893Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.673,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmndtjdafwi666usljkpj1",
                        "tokens": [
                            " proudly",
                            " wear",
                            " the",
                            " branded",
                            " apparel",
                            " you",
                            " provide",
                            ".",
                            " Knowing",
                            " that",
                            " every",
                            " dime",
                            " I",
                            " spend",
                            " at",
                            " the",
                            " NRA",
                            "store",
                            " goes",
                            " directly",
                            " to",
                            " forward",
                            " the",
                            " mission",
                            " of",
                            " the",
                            " National",
                            " Rifle",
                            " Association",
                            " makes",
                            " the",
                            " choice",
                            " even",
                            " easier",
                            ".",
                            " Thank",
                            " you",
                            " for",
                            " the",
                            " commitment",
                            " to",
                            " your",
                            " Members",
                            ",",
                            " David",
                            " S",
                            "oward",
                            " Life",
                            " Member",
                            "\n",
                            "\n",
                            "A",
                            " gift",
                            " from",
                            " the",
                            " NRA",
                            " store",
                            " is",
                            " a",
                            " great",
                            " way",
                            " to",
                            " support",
                            " our",
                            " 2",
                            "nd",
                            " amendment",
                            " rights",
                            " and",
                            " to",
                            " show",
                            " my",
                            " family",
                            " that",
                            " a",
                            " gift",
                            " can",
                            " serve",
                            " a",
                            " dual",
                            " purpose",
                            " for",
                            " those",
                            " that",
                            " give",
                            " and",
                            " receive",
                            ".",
                            " For",
                            " example",
                            ",",
                            " the",
                            " '",
                            "Don",
                            "'t",
                            " T",
                            "read",
                            " on",
                            " Me",
                            "'",
                            " shirts",
                            " that",
                            " my",
                            " wife",
                            " and",
                            " daughter",
                            " wear",
                            " and",
                            " the",
                            " NRA",
                            " water",
                            " bottle",
                            " my",
                            " son",
                            " carries",
                            " provides",
                            " the",
                            " NRA",
                            " ammunition",
                            " for",
                            " our",
                            " gun",
                            " rights",
                            " and",
                            " gives",
                            " our",
                            " family"
                        ],
                        "dataIndex": null,
                        "index": "13984",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.317,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.911,
                            2.23,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:45.893Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.673,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmndtjdafxi6668efuepnf",
                        "tokens": [
                            " from",
                            " management",
                            " after",
                            " 4",
                            " years",
                            " and",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " lost",
                            " something",
                            " else",
                            ":",
                            " first",
                            "-",
                            "hand",
                            " knowledge",
                            " of",
                            " the",
                            " new",
                            " technology",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " released",
                            " (",
                            "se",
                            "em",
                            "ingly",
                            ")",
                            " every",
                            " few",
                            " months",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " point",
                            " around",
                            " 12",
                            "-",
                            "18",
                            " months",
                            " where",
                            " returning",
                            " to",
                            " coding",
                            " becomes",
                            " exponentially",
                            " more",
                            " difficult",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " is",
                            " good",
                            " to",
                            " know",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " approaching",
                            " the",
                            " point",
                            " where",
                            " your",
                            " technical",
                            " skills",
                            " are",
                            " about",
                            " to",
                            " fall",
                            " a",
                            " full",
                            " version",
                            " behind",
                            ".",
                            " Real",
                            "ize",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " falling",
                            " off",
                            " a",
                            " technology",
                            " cliff",
                            " that",
                            " you",
                            " will",
                            " have",
                            " to",
                            " scale",
                            " if",
                            " you",
                            " ever",
                            " decide",
                            " to",
                            " code",
                            " again",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Real",
                            " Answer",
                            "\n",
                            "\n",
                            "Back",
                            " to",
                            " the",
                            " original",
                            " question",
                            ":",
                            " the",
                            " first",
                            " time",
                            " I",
                            " returned"
                        ],
                        "dataIndex": null,
                        "index": "13984",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.131,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.045,
                            12.131,
                            4.088,
                            4.713,
                            4.471,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.55,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:02:45.893Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.673,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "19860",
            "description": "references to students and their experiences in an academic context",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.440947247771837,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "19860",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:53:05.868Z",
                "maxActApprox": 38.862,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    19860,
                    9870,
                    25350,
                    43241,
                    7755,
                    74864,
                    54499,
                    87007,
                    64882,
                    25398,
                    76312,
                    88988,
                    94019,
                    22704,
                    19965,
                    65752,
                    68882,
                    74203,
                    69024,
                    23900,
                    10166,
                    9019,
                    34305,
                    41844,
                    12698
                ],
                "topkCosSimValues": [
                    1,
                    0.8275,
                    0.7712,
                    0.609,
                    0.5903,
                    0.5881,
                    0.5785,
                    0.5575,
                    0.5512,
                    0.5466,
                    0.5337,
                    0.53,
                    0.5219,
                    0.5201,
                    0.5066,
                    0.5029,
                    0.5003,
                    0.4908,
                    0.4849,
                    0.4828,
                    0.4811,
                    0.4681,
                    0.4672,
                    0.4632,
                    0.4611
                ],
                "neuron_alignment_indices": [
                    575,
                    157,
                    447
                ],
                "neuron_alignment_values": [
                    0.143,
                    0.109,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    575,
                    330,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.029,
                    0.029
                ],
                "correlated_features_indices": [
                    19850,
                    19782,
                    19853
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.016,
                    0.009
                ],
                "correlated_features_l1": [
                    0.02,
                    0.017,
                    0.01
                ],
                "neg_str": [
                    "\u00e3\u0125\u00a2",
                    "UTERS",
                    "rous",
                    "neum",
                    "SourceFile",
                    "oise",
                    "\u00e3\u0124\u00a4",
                    "SHIP",
                    " Shack",
                    "\u00e3\u0123\u00ae\u00e5"
                ],
                "neg_values": [
                    -0.711,
                    -0.71,
                    -0.682,
                    -0.663,
                    -0.631,
                    -0.626,
                    -0.625,
                    -0.623,
                    -0.62,
                    -0.614
                ],
                "pos_str": [
                    " enrolled",
                    "uates",
                    "hip",
                    " tuition",
                    "girls",
                    "hips",
                    " graduating",
                    " graduates",
                    " graduate",
                    "tu"
                ],
                "pos_values": [
                    0.977,
                    0.944,
                    0.898,
                    0.836,
                    0.826,
                    0.822,
                    0.808,
                    0.776,
                    0.766,
                    0.765
                ],
                "frac_nonzero": 0.00027,
                "freq_hist_data_bar_heights": [
                    65,
                    56,
                    38,
                    25,
                    21,
                    23,
                    16,
                    17,
                    12,
                    7,
                    9,
                    8,
                    8,
                    5,
                    11,
                    6,
                    6,
                    4,
                    6,
                    6,
                    6,
                    5,
                    13,
                    13,
                    9,
                    17,
                    11,
                    14,
                    9,
                    23,
                    9,
                    9,
                    20,
                    19,
                    27,
                    31,
                    31,
                    35,
                    25,
                    30,
                    20,
                    22,
                    24,
                    22,
                    17,
                    9,
                    13,
                    8,
                    6,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.393,
                    1.17,
                    1.947,
                    2.725,
                    3.502,
                    4.279,
                    5.056,
                    5.833,
                    6.61,
                    7.387,
                    8.165,
                    8.942,
                    9.719,
                    10.496,
                    11.273,
                    12.05,
                    12.828,
                    13.605,
                    14.382,
                    15.159,
                    15.936,
                    16.713,
                    17.49,
                    18.268,
                    19.045,
                    19.822,
                    20.599,
                    21.376,
                    22.153,
                    22.93,
                    23.708,
                    24.485,
                    25.262,
                    26.039,
                    26.816,
                    27.593,
                    28.37,
                    29.148,
                    29.925,
                    30.702,
                    31.479,
                    32.256,
                    33.033,
                    33.81,
                    34.588,
                    35.365,
                    36.142,
                    36.919,
                    37.696,
                    38.473
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    6,
                    6,
                    12,
                    18,
                    38,
                    48,
                    104,
                    181,
                    280,
                    510,
                    811,
                    1143,
                    1575,
                    2151,
                    2657,
                    3399,
                    3983,
                    4166,
                    4415,
                    4320,
                    4036,
                    3667,
                    3013,
                    2577,
                    1903,
                    1497,
                    1089,
                    797,
                    548,
                    399,
                    259,
                    196,
                    139,
                    101,
                    76,
                    49,
                    26,
                    19,
                    11,
                    5,
                    9,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.695,
                    -0.661,
                    -0.627,
                    -0.593,
                    -0.56,
                    -0.526,
                    -0.492,
                    -0.458,
                    -0.424,
                    -0.391,
                    -0.357,
                    -0.323,
                    -0.289,
                    -0.256,
                    -0.222,
                    -0.188,
                    -0.154,
                    -0.121,
                    -0.087,
                    -0.053,
                    -0.019,
                    0.014,
                    0.048,
                    0.082,
                    0.116,
                    0.15,
                    0.183,
                    0.217,
                    0.251,
                    0.285,
                    0.318,
                    0.352,
                    0.386,
                    0.42,
                    0.453,
                    0.487,
                    0.521,
                    0.555,
                    0.588,
                    0.622,
                    0.656,
                    0.69,
                    0.723,
                    0.757,
                    0.791,
                    0.825,
                    0.859,
                    0.892,
                    0.926,
                    0.96
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to students in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to students and their experiences in an academic context",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfruecqd6f10exjxs150ox",
                        "tokens": [
                            " films",
                            " and",
                            " recognizable",
                            " characters",
                            " (",
                            "yes",
                            ",",
                            " Iron",
                            " Man",
                            " was",
                            " a",
                            " gamble",
                            " at",
                            " that",
                            " point",
                            " but",
                            " even",
                            " he",
                            " had",
                            " already",
                            " been",
                            " the",
                            " subject",
                            " of",
                            " animated",
                            " TV",
                            " series",
                            " before",
                            ").",
                            "\n",
                            "\n",
                            "The",
                            " course",
                            " will",
                            " be",
                            " taught",
                            " by",
                            " Arnold",
                            " T",
                            ".",
                            " Bl",
                            "um",
                            "berg",
                            ",",
                            " an",
                            " adjunct",
                            " faculty",
                            " member",
                            " in",
                            " U",
                            "B",
                            "'s",
                            " Yale",
                            " Gordon",
                            " College",
                            " of",
                            " Arts",
                            " and",
                            " Sciences",
                            ".",
                            " Bl",
                            "um",
                            "berg",
                            " said",
                            " this",
                            " critical",
                            " look",
                            " will",
                            " encourage",
                            " students",
                            " to",
                            " better",
                            " understand",
                            " the",
                            " culture",
                            "'s",
                            " fixation",
                            " on",
                            " superheroes",
                            ",",
                            " fictional",
                            " global",
                            " threats",
                            ",",
                            " and",
                            " other",
                            " \"",
                            "w",
                            "ides",
                            "creen",
                            "\"",
                            " novel",
                            "istic",
                            " tales",
                            " that",
                            " have",
                            " pushed",
                            " the",
                            " comic",
                            " book",
                            "-",
                            "to",
                            "-",
                            "film",
                            " ethos",
                            " into",
                            " new",
                            " territory",
                            ".",
                            " \"",
                            "One",
                            " thing",
                            " we",
                            "'ll",
                            " do",
                            " is",
                            " dive",
                            " into",
                            " the",
                            " impact",
                            " of",
                            " the",
                            " Guardians",
                            " of",
                            " the",
                            " Galaxy",
                            " film"
                        ],
                        "dataIndex": null,
                        "index": "19860",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.862,
                        "maxValueTokenIndex": 69,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.862,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:53:17.582Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 38.862,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfruecqd6g10ex2el7gllu",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Math",
                            " Friend",
                            "zy",
                            " \u2013",
                            " Math",
                            " Friend",
                            "zy",
                            " is",
                            " the",
                            " most",
                            " revolutionary",
                            " math",
                            " educational",
                            " program",
                            " designed",
                            " to",
                            " help",
                            " students",
                            " excel",
                            " in",
                            " math",
                            ".",
                            " It",
                            " includes",
                            " several",
                            " patent",
                            " pending",
                            " features",
                            " and",
                            " all",
                            " the",
                            " fun",
                            ",",
                            " excitement",
                            " and",
                            " social",
                            " networking",
                            " components",
                            " of",
                            " popular",
                            " video",
                            " games",
                            " that",
                            " kids",
                            " love",
                            ".",
                            "\n",
                            "\n",
                            "Flash",
                            "cards",
                            " [",
                            "::",
                            "]",
                            " \u2013",
                            " Looking",
                            " for",
                            " a",
                            " powerful",
                            " and",
                            " easy",
                            "-",
                            "to",
                            "-",
                            "use",
                            " flash",
                            "cards",
                            " app",
                            " to",
                            " help",
                            " you",
                            " study",
                            "?",
                            " This",
                            " app",
                            " allows",
                            " you",
                            " to",
                            " create",
                            " or",
                            " download",
                            " millions",
                            " of",
                            " flash",
                            "cards",
                            " on",
                            " hundreds",
                            " of",
                            " subjects",
                            " created",
                            " by",
                            " both",
                            " experts",
                            " and",
                            " no",
                            "v",
                            "ices",
                            ".",
                            "\n",
                            "\n",
                            "Photo",
                            " Editor",
                            " \u2013",
                            " Photo",
                            " Editor",
                            " is",
                            " a",
                            " simple",
                            " and",
                            " easy",
                            " application",
                            " for",
                            " photo",
                            " manipulation",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " no",
                            " big",
                            " names",
                            " here"
                        ],
                        "dataIndex": null,
                        "index": "19860",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.83,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.83,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:53:17.582Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 38.862,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfruecqd6h10ex37ab8lx3",
                        "tokens": [
                            "ison",
                            " as",
                            " a",
                            " caring",
                            " and",
                            " religious",
                            " principal",
                            " who",
                            " often",
                            " purchased",
                            " \u2014",
                            " out",
                            " of",
                            " pocket",
                            " \u2014",
                            " shoes",
                            ",",
                            " clothes",
                            ",",
                            " back",
                            "packs",
                            " and",
                            " other",
                            " essentials",
                            " for",
                            " students",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " 2013",
                            " photos",
                            " shows",
                            " Wal",
                            "nut",
                            " Hill",
                            " Principal",
                            " Albert",
                            " Hard",
                            "ison",
                            " talking",
                            " to",
                            " a",
                            " fifth",
                            "-",
                            "grade",
                            " student",
                            " (",
                            "Photo",
                            ":",
                            " File",
                            " Photo",
                            ")",
                            "\n",
                            "\n",
                            "Row",
                            "e",
                            " said",
                            " Hard",
                            "ison",
                            "'s",
                            " messages",
                            " would",
                            " still",
                            " be",
                            " well",
                            "-",
                            "received",
                            " even",
                            " if",
                            " he",
                            " practiced",
                            " another",
                            " religion",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            "'s",
                            " the",
                            " basic",
                            " principles",
                            " of",
                            " doing",
                            " the",
                            " right",
                            " thing",
                            ",\"",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "R",
                            "oc",
                            "helle",
                            " Miller",
                            ",",
                            " a",
                            " parap",
                            "ro",
                            "f",
                            "essional",
                            " and",
                            " parent",
                            " of",
                            " Wal",
                            "nut",
                            " Hill",
                            " students",
                            ",",
                            " also",
                            " supports",
                            " Hard",
                            "ison",
                            "'s",
                            " messages",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " put",
                            " God",
                            " first",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "19860",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.824,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.824,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.306,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.488,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:53:17.582Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 38.862,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "1747",
            "description": "conversations about learning and personal experiences in the context of music and relationships",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4403156638145447,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "1747",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:00:49.388Z",
                "maxActApprox": 17.466,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1747,
                    33387,
                    46078,
                    33149,
                    36543,
                    16416,
                    35305,
                    15960,
                    1834,
                    607,
                    14621,
                    37942,
                    36526,
                    33230,
                    5182,
                    26637,
                    26264,
                    44963,
                    10317,
                    32851,
                    5632,
                    25952,
                    12310,
                    43534,
                    1991
                ],
                "topkCosSimValues": [
                    1,
                    0.5691,
                    0.5105,
                    0.5009,
                    0.4758,
                    0.4708,
                    0.4449,
                    0.4359,
                    0.4226,
                    0.4082,
                    0.4059,
                    0.3822,
                    0.3554,
                    0.3474,
                    0.3418,
                    0.3357,
                    0.3096,
                    0.2976,
                    0.2871,
                    0.2837,
                    0.2783,
                    0.2781,
                    0.275,
                    0.2748,
                    0.2634
                ],
                "neuron_alignment_indices": [
                    60,
                    243,
                    463
                ],
                "neuron_alignment_values": [
                    0.102,
                    0.097,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    638,
                    16
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.024,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.022,
                    0.019
                ],
                "correlated_features_indices": [
                    1724,
                    1749,
                    1736
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.001
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "'.\"",
                    ".'\"",
                    ".\")",
                    "cms",
                    " });",
                    " fixme",
                    " };",
                    "\"],\"",
                    "\u0143\u0136",
                    " @@"
                ],
                "neg_values": [
                    -0.808,
                    -0.699,
                    -0.659,
                    -0.617,
                    -0.603,
                    -0.6,
                    -0.597,
                    -0.592,
                    -0.585,
                    -0.583
                ],
                "pos_str": [
                    "?:",
                    "?",
                    "...?",
                    ")?",
                    "?\u00e3\u0122\u012f",
                    "?\",",
                    "?'",
                    "?]",
                    ".?",
                    "?????"
                ],
                "pos_values": [
                    1.231,
                    0.968,
                    0.895,
                    0.892,
                    0.842,
                    0.833,
                    0.818,
                    0.787,
                    0.768,
                    0.765
                ],
                "frac_nonzero": 0.00159,
                "freq_hist_data_bar_heights": [
                    951,
                    750,
                    592,
                    480,
                    364,
                    282,
                    214,
                    186,
                    138,
                    138,
                    118,
                    91,
                    86,
                    78,
                    75,
                    57,
                    49,
                    48,
                    33,
                    31,
                    37,
                    26,
                    18,
                    24,
                    18,
                    18,
                    14,
                    9,
                    14,
                    11,
                    4,
                    8,
                    8,
                    4,
                    8,
                    2,
                    3,
                    4,
                    4,
                    2,
                    1,
                    3,
                    1,
                    0,
                    1,
                    0,
                    1,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.175,
                    0.524,
                    0.873,
                    1.223,
                    1.572,
                    1.921,
                    2.271,
                    2.62,
                    2.969,
                    3.319,
                    3.668,
                    4.017,
                    4.366,
                    4.716,
                    5.065,
                    5.414,
                    5.764,
                    6.113,
                    6.462,
                    6.812,
                    7.161,
                    7.51,
                    7.86,
                    8.209,
                    8.558,
                    8.907,
                    9.257,
                    9.606,
                    9.955,
                    10.305,
                    10.654,
                    11.003,
                    11.353,
                    11.702,
                    12.051,
                    12.401,
                    12.75,
                    13.099,
                    13.448,
                    13.798,
                    14.147,
                    14.496,
                    14.846,
                    15.195,
                    15.544,
                    15.894,
                    16.243,
                    16.592,
                    16.942,
                    17.291
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    1,
                    10,
                    14,
                    23,
                    47,
                    124,
                    186,
                    389,
                    662,
                    1156,
                    1934,
                    2661,
                    3731,
                    4571,
                    5424,
                    5486,
                    5494,
                    5029,
                    4068,
                    3014,
                    2338,
                    1552,
                    975,
                    583,
                    334,
                    187,
                    116,
                    59,
                    31,
                    19,
                    11,
                    5,
                    7,
                    1,
                    4,
                    2,
                    2,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.787,
                    -0.747,
                    -0.706,
                    -0.665,
                    -0.624,
                    -0.584,
                    -0.543,
                    -0.502,
                    -0.461,
                    -0.42,
                    -0.38,
                    -0.339,
                    -0.298,
                    -0.257,
                    -0.217,
                    -0.176,
                    -0.135,
                    -0.094,
                    -0.053,
                    -0.013,
                    0.028,
                    0.069,
                    0.11,
                    0.15,
                    0.191,
                    0.232,
                    0.273,
                    0.314,
                    0.354,
                    0.395,
                    0.436,
                    0.477,
                    0.517,
                    0.558,
                    0.599,
                    0.64,
                    0.681,
                    0.721,
                    0.762,
                    0.803,
                    0.844,
                    0.884,
                    0.925,
                    0.966,
                    1.007,
                    1.048,
                    1.088,
                    1.129,
                    1.17,
                    1.211
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about learning and personal experiences in the context of music and relationships",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk47kxrd935i6666mgyz04p",
                        "tokens": [
                            " being",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " being",
                            " able",
                            " to",
                            " see",
                            " and",
                            " know",
                            " everything",
                            " that",
                            " goes",
                            " on",
                            " in",
                            " the",
                            " economy",
                            ".",
                            " And",
                            " that",
                            "'s",
                            " amazing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            "'ve",
                            " said",
                            " that",
                            " you",
                            " were",
                            " not",
                            " really",
                            " a",
                            " gamer",
                            " before",
                            " working",
                            " with",
                            " Valve",
                            ".",
                            " What",
                            " did",
                            " you",
                            " learn",
                            " about",
                            " video",
                            " game",
                            " worlds",
                            "?",
                            " What",
                            " surprised",
                            " you",
                            "?",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " The",
                            " most",
                            " poignant",
                            " observation",
                            " was",
                            " the",
                            " speed",
                            " with",
                            " which",
                            " these",
                            " economies",
                            " evolve",
                            ".",
                            " Within",
                            " a",
                            " year",
                            ",",
                            " you",
                            " have",
                            " an",
                            " evolutionary",
                            " process",
                            " that",
                            " can",
                            " replicate",
                            " what",
                            " happened",
                            " out",
                            " there",
                            " in",
                            " the",
                            " out",
                            "lying",
                            " economies",
                            ",",
                            " in",
                            " terms",
                            " of",
                            " creating",
                            " a",
                            " complex",
                            " web",
                            " of",
                            " exchanges",
                            " and",
                            " sound",
                            " economic",
                            " systems",
                            ".",
                            " And",
                            " the",
                            " out",
                            "lying",
                            " economy",
                            " took",
                            " centuries",
                            ".",
                            " I",
                            " didn",
                            "'t",
                            " expect",
                            " to",
                            " see",
                            " institutions",
                            " spontaneously"
                        ],
                        "dataIndex": null,
                        "index": "1747",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.466,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.095,
                            3.778,
                            4.979,
                            1.394,
                            6.704,
                            4.717,
                            4.009,
                            6.095,
                            1.51,
                            5.039,
                            9.862,
                            5.171,
                            0,
                            0,
                            0.128,
                            7.77,
                            2.339,
                            17.466,
                            13.74,
                            0,
                            1.368,
                            4.46,
                            1.046,
                            0.766,
                            13.579,
                            14.623,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:00:58.782Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 17.465,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk47kxsd93ci666wdmuq7hh",
                        "tokens": [
                            " being",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " being",
                            " able",
                            " to",
                            " see",
                            " and",
                            " know",
                            " everything",
                            " that",
                            " goes",
                            " on",
                            " in",
                            " the",
                            " economy",
                            ".",
                            " And",
                            " that",
                            "'s",
                            " amazing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            "'ve",
                            " said",
                            " that",
                            " you",
                            " were",
                            " not",
                            " really",
                            " a",
                            " gamer",
                            " before",
                            " working",
                            " with",
                            " Valve",
                            ".",
                            " What",
                            " did",
                            " you",
                            " learn",
                            " about",
                            " video",
                            " game",
                            " worlds",
                            "?",
                            " What",
                            " surprised",
                            " you",
                            "?",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " The",
                            " most",
                            " poignant",
                            " observation",
                            " was",
                            " the",
                            " speed",
                            " with",
                            " which",
                            " these",
                            " economies",
                            " evolve",
                            ".",
                            " Within",
                            " a",
                            " year",
                            ",",
                            " you",
                            " have",
                            " an",
                            " evolutionary",
                            " process",
                            " that",
                            " can",
                            " replicate",
                            " what",
                            " happened",
                            " out",
                            " there",
                            " in",
                            " the",
                            " out",
                            "lying",
                            " economies",
                            ",",
                            " in",
                            " terms",
                            " of",
                            " creating",
                            " a",
                            " complex",
                            " web",
                            " of",
                            " exchanges",
                            " and",
                            " sound",
                            " economic",
                            " systems",
                            ".",
                            " And",
                            " the",
                            " out",
                            "lying",
                            " economy",
                            " took",
                            " centuries",
                            ".",
                            " I",
                            " didn",
                            "'t",
                            " expect",
                            " to",
                            " see",
                            " institutions",
                            " spontaneously"
                        ],
                        "dataIndex": null,
                        "index": "1747",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.466,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.095,
                            3.778,
                            4.979,
                            1.394,
                            6.704,
                            4.717,
                            4.009,
                            6.095,
                            1.51,
                            5.039,
                            9.862,
                            5.171,
                            0,
                            0,
                            0.128,
                            7.77,
                            2.339,
                            17.466,
                            13.74,
                            0,
                            1.368,
                            4.46,
                            1.046,
                            0.766,
                            13.579,
                            14.623,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:00:58.782Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 17.465,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk47kxsd93gi6662l8s27me",
                        "tokens": [
                            " being",
                            " omn",
                            "is",
                            "cient",
                            ",",
                            " being",
                            " able",
                            " to",
                            " see",
                            " and",
                            " know",
                            " everything",
                            " that",
                            " goes",
                            " on",
                            " in",
                            " the",
                            " economy",
                            ".",
                            " And",
                            " that",
                            "'s",
                            " amazing",
                            ".",
                            "\n",
                            "\n",
                            "reason",
                            ":",
                            " You",
                            "'ve",
                            " said",
                            " that",
                            " you",
                            " were",
                            " not",
                            " really",
                            " a",
                            " gamer",
                            " before",
                            " working",
                            " with",
                            " Valve",
                            ".",
                            " What",
                            " did",
                            " you",
                            " learn",
                            " about",
                            " video",
                            " game",
                            " worlds",
                            "?",
                            " What",
                            " surprised",
                            " you",
                            "?",
                            "\n",
                            "\n",
                            "Var",
                            "ouf",
                            "akis",
                            ":",
                            " The",
                            " most",
                            " poignant",
                            " observation",
                            " was",
                            " the",
                            " speed",
                            " with",
                            " which",
                            " these",
                            " economies",
                            " evolve",
                            ".",
                            " Within",
                            " a",
                            " year",
                            ",",
                            " you",
                            " have",
                            " an",
                            " evolutionary",
                            " process",
                            " that",
                            " can",
                            " replicate",
                            " what",
                            " happened",
                            " out",
                            " there",
                            " in",
                            " the",
                            " out",
                            "lying",
                            " economies",
                            ",",
                            " in",
                            " terms",
                            " of",
                            " creating",
                            " a",
                            " complex",
                            " web",
                            " of",
                            " exchanges",
                            " and",
                            " sound",
                            " economic",
                            " systems",
                            ".",
                            " And",
                            " the",
                            " out",
                            "lying",
                            " economy",
                            " took",
                            " centuries",
                            ".",
                            " I",
                            " didn",
                            "'t",
                            " expect",
                            " to",
                            " see",
                            " institutions",
                            " spontaneously"
                        ],
                        "dataIndex": null,
                        "index": "1747",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.466,
                        "maxValueTokenIndex": 46,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.095,
                            3.778,
                            4.979,
                            1.394,
                            6.704,
                            4.717,
                            4.009,
                            6.095,
                            1.51,
                            5.039,
                            9.862,
                            5.171,
                            0,
                            0,
                            0.128,
                            7.77,
                            2.339,
                            17.466,
                            13.74,
                            0,
                            1.368,
                            4.46,
                            1.046,
                            0.766,
                            13.579,
                            14.623,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:00:58.782Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 17.465,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "39828",
            "description": "elements related to educational tools and applications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4364997446537018,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "39828",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:21:43.193Z",
                "maxActApprox": 17.852,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39828,
                    9600,
                    73803,
                    67178,
                    9065,
                    26941,
                    81397,
                    92569,
                    68077,
                    18680,
                    61382,
                    95003,
                    15931,
                    96291,
                    62950,
                    72457,
                    5459,
                    17041,
                    83593,
                    6160,
                    9782,
                    27729,
                    51531,
                    11595,
                    38049
                ],
                "topkCosSimValues": [
                    1,
                    0.6505,
                    0.5823,
                    0.5715,
                    0.5489,
                    0.5484,
                    0.5411,
                    0.5275,
                    0.5237,
                    0.5182,
                    0.511,
                    0.5076,
                    0.5061,
                    0.5037,
                    0.5007,
                    0.4995,
                    0.4967,
                    0.4949,
                    0.4942,
                    0.494,
                    0.4927,
                    0.4857,
                    0.4841,
                    0.4792,
                    0.4788
                ],
                "neuron_alignment_indices": [
                    640,
                    107,
                    6
                ],
                "neuron_alignment_values": [
                    0.288,
                    0.145,
                    0.127
                ],
                "neuron_alignment_l1": [
                    0.014,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    640,
                    160,
                    107
                ],
                "correlated_neurons_pearson": [
                    0.091,
                    0.071,
                    0.069
                ],
                "correlated_neurons_l1": [
                    0.086,
                    0.076,
                    0.067
                ],
                "correlated_features_indices": [
                    39701,
                    39716,
                    39714
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.009,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    " responding",
                    " pressing",
                    "anwhile",
                    " bloc",
                    " answ",
                    " briefed",
                    " answering",
                    " compr",
                    " rehears",
                    " encount"
                ],
                "neg_values": [
                    -0.877,
                    -0.86,
                    -0.854,
                    -0.85,
                    -0.828,
                    -0.812,
                    -0.812,
                    -0.798,
                    -0.798,
                    -0.795
                ],
                "pos_str": [
                    "Conclusion",
                    "\u00e2\u0135\u013a",
                    "Syn",
                    "Other",
                    "Operation",
                    "Bal",
                    "Magn",
                    "Vill",
                    "Example",
                    "Pont"
                ],
                "pos_values": [
                    1.309,
                    1.204,
                    1.176,
                    1.174,
                    1.163,
                    1.138,
                    1.135,
                    1.129,
                    1.119,
                    1.118
                ],
                "frac_nonzero": 0.0018,
                "freq_hist_data_bar_heights": [
                    905,
                    753,
                    625,
                    531,
                    434,
                    336,
                    314,
                    269,
                    198,
                    194,
                    148,
                    117,
                    108,
                    83,
                    68,
                    69,
                    47,
                    62,
                    31,
                    41,
                    29,
                    30,
                    29,
                    24,
                    24,
                    14,
                    22,
                    17,
                    13,
                    12,
                    16,
                    11,
                    17,
                    11,
                    9,
                    11,
                    6,
                    8,
                    8,
                    7,
                    2,
                    3,
                    4,
                    5,
                    5,
                    0,
                    4,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.179,
                    0.536,
                    0.893,
                    1.25,
                    1.607,
                    1.964,
                    2.321,
                    2.678,
                    3.035,
                    3.392,
                    3.749,
                    4.106,
                    4.463,
                    4.82,
                    5.177,
                    5.534,
                    5.891,
                    6.248,
                    6.605,
                    6.962,
                    7.319,
                    7.676,
                    8.033,
                    8.39,
                    8.747,
                    9.104,
                    9.462,
                    9.819,
                    10.176,
                    10.533,
                    10.89,
                    11.247,
                    11.604,
                    11.961,
                    12.318,
                    12.675,
                    13.032,
                    13.389,
                    13.746,
                    14.103,
                    14.46,
                    14.817,
                    15.174,
                    15.531,
                    15.888,
                    16.245,
                    16.602,
                    16.959,
                    17.316,
                    17.673
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    7,
                    28,
                    45,
                    96,
                    217,
                    373,
                    619,
                    954,
                    1333,
                    1622,
                    1951,
                    2288,
                    2324,
                    2344,
                    2313,
                    2382,
                    2326,
                    2455,
                    2518,
                    2639,
                    2562,
                    2627,
                    2581,
                    2133,
                    2022,
                    1553,
                    1333,
                    992,
                    742,
                    538,
                    418,
                    385,
                    401,
                    394,
                    419,
                    476,
                    491,
                    391,
                    351,
                    225,
                    172,
                    123,
                    48,
                    24,
                    11,
                    5,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.855,
                    -0.812,
                    -0.768,
                    -0.724,
                    -0.68,
                    -0.637,
                    -0.593,
                    -0.549,
                    -0.506,
                    -0.462,
                    -0.418,
                    -0.374,
                    -0.331,
                    -0.287,
                    -0.243,
                    -0.2,
                    -0.156,
                    -0.112,
                    -0.068,
                    -0.025,
                    0.019,
                    0.063,
                    0.106,
                    0.15,
                    0.194,
                    0.238,
                    0.281,
                    0.325,
                    0.369,
                    0.412,
                    0.456,
                    0.5,
                    0.544,
                    0.587,
                    0.631,
                    0.675,
                    0.719,
                    0.762,
                    0.806,
                    0.85,
                    0.893,
                    0.937,
                    0.981,
                    1.025,
                    1.068,
                    1.112,
                    1.156,
                    1.199,
                    1.243,
                    1.287
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases and terms related to educational tools and their functions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements related to educational tools and applications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggsnx75h6g10ex6nvwz73j",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Math",
                            " Friend",
                            "zy",
                            " \u2013",
                            " Math",
                            " Friend",
                            "zy",
                            " is",
                            " the",
                            " most",
                            " revolutionary",
                            " math",
                            " educational",
                            " program",
                            " designed",
                            " to",
                            " help",
                            " students",
                            " excel",
                            " in",
                            " math",
                            ".",
                            " It",
                            " includes",
                            " several",
                            " patent",
                            " pending",
                            " features",
                            " and",
                            " all",
                            " the",
                            " fun",
                            ",",
                            " excitement",
                            " and",
                            " social",
                            " networking",
                            " components",
                            " of",
                            " popular",
                            " video",
                            " games",
                            " that",
                            " kids",
                            " love",
                            ".",
                            "\n",
                            "\n",
                            "Flash",
                            "cards",
                            " [",
                            "::",
                            "]",
                            " \u2013",
                            " Looking",
                            " for",
                            " a",
                            " powerful",
                            " and",
                            " easy",
                            "-",
                            "to",
                            "-",
                            "use",
                            " flash",
                            "cards",
                            " app",
                            " to",
                            " help",
                            " you",
                            " study",
                            "?",
                            " This",
                            " app",
                            " allows",
                            " you",
                            " to",
                            " create",
                            " or",
                            " download",
                            " millions",
                            " of",
                            " flash",
                            "cards",
                            " on",
                            " hundreds",
                            " of",
                            " subjects",
                            " created",
                            " by",
                            " both",
                            " experts",
                            " and",
                            " no",
                            "v",
                            "ices",
                            ".",
                            "\n",
                            "\n",
                            "Photo",
                            " Editor",
                            " \u2013",
                            " Photo",
                            " Editor",
                            " is",
                            " a",
                            " simple",
                            " and",
                            " easy",
                            " application",
                            " for",
                            " photo",
                            " manipulation",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " no",
                            " big",
                            " names",
                            " here"
                        ],
                        "dataIndex": null,
                        "index": "39828",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.852,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.507,
                            15.151,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.374,
                            17.852,
                            1.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.041,
                            16.709,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:55.439Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.852,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggsnx75h6l10exmioqjesu",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Math",
                            " Friend",
                            "zy",
                            " \u2013",
                            " Math",
                            " Friend",
                            "zy",
                            " is",
                            " the",
                            " most",
                            " revolutionary",
                            " math",
                            " educational",
                            " program",
                            " designed",
                            " to",
                            " help",
                            " students",
                            " excel",
                            " in",
                            " math",
                            ".",
                            " It",
                            " includes",
                            " several",
                            " patent",
                            " pending",
                            " features",
                            " and",
                            " all",
                            " the",
                            " fun",
                            ",",
                            " excitement",
                            " and",
                            " social",
                            " networking",
                            " components",
                            " of",
                            " popular",
                            " video",
                            " games",
                            " that",
                            " kids",
                            " love",
                            ".",
                            "\n",
                            "\n",
                            "Flash",
                            "cards",
                            " [",
                            "::",
                            "]",
                            " \u2013",
                            " Looking",
                            " for",
                            " a",
                            " powerful",
                            " and",
                            " easy",
                            "-",
                            "to",
                            "-",
                            "use",
                            " flash",
                            "cards",
                            " app",
                            " to",
                            " help",
                            " you",
                            " study",
                            "?",
                            " This",
                            " app",
                            " allows",
                            " you",
                            " to",
                            " create",
                            " or",
                            " download",
                            " millions",
                            " of",
                            " flash",
                            "cards",
                            " on",
                            " hundreds",
                            " of",
                            " subjects",
                            " created",
                            " by",
                            " both",
                            " experts",
                            " and",
                            " no",
                            "v",
                            "ices",
                            ".",
                            "\n",
                            "\n",
                            "Photo",
                            " Editor",
                            " \u2013",
                            " Photo",
                            " Editor",
                            " is",
                            " a",
                            " simple",
                            " and",
                            " easy",
                            " application",
                            " for",
                            " photo",
                            " manipulation",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " no",
                            " big",
                            " names",
                            " here"
                        ],
                        "dataIndex": null,
                        "index": "39828",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.852,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.507,
                            15.151,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.374,
                            17.852,
                            1.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.041,
                            16.709,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:55.439Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.852,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggsnx95h6z10exxx3e83uz",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Math",
                            " Friend",
                            "zy",
                            " \u2013",
                            " Math",
                            " Friend",
                            "zy",
                            " is",
                            " the",
                            " most",
                            " revolutionary",
                            " math",
                            " educational",
                            " program",
                            " designed",
                            " to",
                            " help",
                            " students",
                            " excel",
                            " in",
                            " math",
                            ".",
                            " It",
                            " includes",
                            " several",
                            " patent",
                            " pending",
                            " features",
                            " and",
                            " all",
                            " the",
                            " fun",
                            ",",
                            " excitement",
                            " and",
                            " social",
                            " networking",
                            " components",
                            " of",
                            " popular",
                            " video",
                            " games",
                            " that",
                            " kids",
                            " love",
                            ".",
                            "\n",
                            "\n",
                            "Flash",
                            "cards",
                            " [",
                            "::",
                            "]",
                            " \u2013",
                            " Looking",
                            " for",
                            " a",
                            " powerful",
                            " and",
                            " easy",
                            "-",
                            "to",
                            "-",
                            "use",
                            " flash",
                            "cards",
                            " app",
                            " to",
                            " help",
                            " you",
                            " study",
                            "?",
                            " This",
                            " app",
                            " allows",
                            " you",
                            " to",
                            " create",
                            " or",
                            " download",
                            " millions",
                            " of",
                            " flash",
                            "cards",
                            " on",
                            " hundreds",
                            " of",
                            " subjects",
                            " created",
                            " by",
                            " both",
                            " experts",
                            " and",
                            " no",
                            "v",
                            "ices",
                            ".",
                            "\n",
                            "\n",
                            "Photo",
                            " Editor",
                            " \u2013",
                            " Photo",
                            " Editor",
                            " is",
                            " a",
                            " simple",
                            " and",
                            " easy",
                            " application",
                            " for",
                            " photo",
                            " manipulation",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " no",
                            " big",
                            " names",
                            " here"
                        ],
                        "dataIndex": null,
                        "index": "39828",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.852,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.507,
                            15.151,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.374,
                            17.852,
                            1.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.041,
                            16.709,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:55.439Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.852,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}